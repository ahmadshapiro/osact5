{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ec13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/mt/ashapiro/Hate_Speech\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch/mt/ashapiro/Hate_Speech/\n",
    "from utils import getData\n",
    "from datasets import load_dataset \n",
    "import pandas as pd \n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from datasets import load_metric\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1059020a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 332.26it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 14.91ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 29.27ba/s]\n"
     ]
    }
   ],
   "source": [
    "f1 = load_metric(\"f1\")\n",
    "recall = load_metric(\"recall\")\n",
    "precision =  load_metric(\"precision\")\n",
    "def preprocess_function(examples, tok):\n",
    "    return tok(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    metric = f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    metric.update(recall.compute(predictions=predictions, references=labels, average=\"macro\"))\n",
    "    metric.update(precision.compute(predictions=predictions, references=labels, average=\"macro\"))\n",
    "    return metric\n",
    "data = getData(sub_task = f\"A\", return_type = \"dataset\", pre_proccessed = True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "tokenized_data = data.map(preprocess_function,fn_kwargs = {'tok':tokenizer}, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bba67",
   "metadata": {},
   "source": [
    "BestRun(run_id='21', objective=2.572288460648268, hyperparameters={'learning_rate': 2.7589028213603294e-05, 'weight_decay': 1.496202107421057e-05, 'num_train_epochs': 1, 'seed': 20, 'per_device_train_batch_size': 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409bcf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file /scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/scratch/mt/ashapiro/Hate_Speech/Models/Marbertv2\", num_labels=2)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers\",\n",
    "    learning_rate=2.7589028213603294e-05,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=1.496202107421057e-05,\n",
    "    load_best_model_at_end=True,\n",
    "    group_by_length = True, \n",
    "    seed = 20,\n",
    "    report_to = None\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb810289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27800\n",
      "  1%|          | 277/27800 [00:27<37:18, 12.29it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 89.32it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 80.95it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 79.33it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 78.58it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 75.01it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 75.80it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 77.42it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 77.74it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:00<00:03, 77.81it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 77.25it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:02, 77.73it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 77.64it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 77.73it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 77.40it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 78.60it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 78.66it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 78.65it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:01<00:02, 77.79it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 78.13it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:01, 78.36it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 78.38it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 78.12it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 77.79it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 77.30it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 77.43it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 77.36it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 77.34it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:02<00:01, 72.70it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 71.27it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 72.93it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 74.63it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 69.50it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 70.77it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 72.32it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 73.57it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:03<00:00, 74.16it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:03<00:00, 74.70it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 75.77it/s]\u001b[A\n",
      "                                                   A\n",
      "  1%|          | 278/27800 [00:32<37:18, 12.29it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.56it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-278\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32315635681152344, 'eval_f1': 0.8505582936759521, 'eval_recall': 0.8512536299819359, 'eval_precision': 0.8498765804675422, 'eval_runtime': 4.2469, 'eval_samples_per_second': 299.041, 'eval_steps_per_second': 74.878, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-278/special_tokens_map.json\n",
      "  2%|▏         | 501/27800 [00:58<40:38, 11.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3382, 'learning_rate': 2.7092822670193162e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 555/27800 [01:03<39:43, 11.43it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 83.23it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 78.78it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 59.18it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:04, 61.48it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:04, 66.55it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:03, 69.67it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 71.65it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 73.24it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:01<00:03, 74.58it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 76.01it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:02, 76.58it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 77.10it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 77.04it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 77.19it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 77.72it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 78.32it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 78.49it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 78.63it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 79.49it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:01, 79.60it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 64.52it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 68.05it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 72.35it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 73.98it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 75.36it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 75.78it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:02<00:01, 76.54it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 77.03it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 77.17it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 78.40it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 76.69it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 72.50it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 73.33it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 69.77it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 68.76it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 70.74it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 72.53it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 73.74it/s]\u001b[A\n",
      "                                                   A\n",
      "  2%|▏         | 556/27800 [01:08<39:43, 11.43it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 74.21it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-556\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6867870688438416, 'eval_f1': 0.7526736096084476, 'eval_recall': 0.8074794777399218, 'eval_precision': 0.7672722213388457, 'eval_runtime': 4.4124, 'eval_samples_per_second': 287.826, 'eval_steps_per_second': 72.07, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-556/special_tokens_map.json\n",
      "  3%|▎         | 834/27800 [01:40<37:40, 11.93it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.34it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 79.84it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 79.10it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:04, 69.85it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 72.63it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 73.95it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 75.39it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 77.26it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 77.61it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:02, 79.48it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 79.87it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 80.53it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 80.61it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 73.83it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 75.75it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 76.50it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:01<00:02, 77.63it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 77.83it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:01, 77.80it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 78.08it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 78.43it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 78.57it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 78.83it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 77.64it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 77.57it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 73.58it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 68.93it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 67.37it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 68.80it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 70.08it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 71.93it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 73.73it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 72.84it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 74.09it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 74.73it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:03<00:00, 75.96it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 75.89it/s]\u001b[A\n",
      "                                                   A\n",
      "  3%|▎         | 834/27800 [01:44<37:40, 11.93it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.77it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-834\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.525390625, 'eval_f1': 0.8279881219036263, 'eval_recall': 0.846809045800654, 'eval_precision': 0.818199102593353, 'eval_runtime': 4.2832, 'eval_samples_per_second': 296.506, 'eval_steps_per_second': 74.243, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-834/special_tokens_map.json\n",
      "  4%|▎         | 1001/27800 [02:04<58:01,  7.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.143, 'learning_rate': 2.6596617126783033e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1111/27800 [02:15<41:39, 10.68it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 73.33it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 74.61it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 74.50it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 75.69it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 76.41it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 76.33it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 75.91it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 77.11it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 75.94it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 73.80it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 74.30it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 74.99it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 75.84it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 75.67it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 75.78it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 75.09it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 75.17it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 75.24it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 74.87it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 70.10it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 71.48it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 73.69it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 71.84it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 73.81it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 71.99it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 66.97it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 68.98it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 70.67it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 72.55it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 72.41it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 73.07it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 74.39it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 71.83it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 74.63it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 77.08it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 79.01it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 76.48it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 74.65it/s]\u001b[A\n",
      "                                                    \n",
      "  4%|▍         | 1112/27800 [02:20<41:39, 10.68it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.69it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1112\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.635993242263794, 'eval_f1': 0.8275373876060375, 'eval_recall': 0.8241087965609494, 'eval_precision': 0.8313521284802581, 'eval_runtime': 4.3954, 'eval_samples_per_second': 288.937, 'eval_steps_per_second': 72.348, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1112/special_tokens_map.json\n",
      "  5%|▍         | 1389/27800 [02:50<38:51, 11.33it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 92.31it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 85.57it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 82.48it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 81.39it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 81.98it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 77.69it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 77.21it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 77.40it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 76.84it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:02, 77.24it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 77.33it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 77.22it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 76.61it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 76.37it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 76.21it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 76.84it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 76.62it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:01<00:02, 76.16it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 75.81it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 76.46it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 75.91it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 75.97it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 75.59it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 75.38it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 75.55it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 76.43it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:02<00:01, 76.88it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:02<00:01, 77.34it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 77.25it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 78.00it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 76.48it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 76.32it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 77.05it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 78.40it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:03<00:00, 78.19it/s]\u001b[A\n",
      " 93%|█████████▎| 297/318 [00:03<00:00, 78.33it/s]\u001b[A\n",
      " 96%|█████████▌| 305/318 [00:03<00:00, 78.06it/s]\u001b[A\n",
      "                                                    \n",
      "  5%|▌         | 1390/27800 [02:55<38:51, 11.33it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 78.11it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1390\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1390/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.751518189907074, 'eval_f1': 0.8448994252873563, 'eval_recall': 0.8430847414995541, 'eval_precision': 0.8468119409194924, 'eval_runtime': 4.1788, 'eval_samples_per_second': 303.912, 'eval_steps_per_second': 76.098, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1390/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1390/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1390/special_tokens_map.json\n",
      "  5%|▌         | 1502/27800 [03:10<45:24,  9.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0712, 'learning_rate': 2.61004115833729e-05, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1668/27800 [03:26<44:28,  9.79it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.68it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 83.42it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 81.38it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 80.82it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 80.46it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 79.93it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 79.41it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:00<00:03, 75.39it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 71.75it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 72.88it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 74.48it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 76.74it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 73.10it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 73.97it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 74.80it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 76.65it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:01<00:02, 72.42it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 68.67it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 70.75it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 69.65it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 72.83it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 73.69it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 74.55it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 74.57it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 75.57it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:02<00:01, 72.73it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 73.39it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 74.20it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 75.27it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 76.35it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 72.53it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 75.25it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 76.44it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 78.27it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 79.71it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 80.49it/s]\u001b[A\n",
      "                                                    \n",
      "  6%|▌         | 1668/27800 [03:31<44:28,  9.79it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 81.20it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1668\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7190042734146118, 'eval_f1': 0.8280851939388525, 'eval_recall': 0.8495329613792788, 'eval_precision': 0.8180832136837506, 'eval_runtime': 4.2611, 'eval_samples_per_second': 298.042, 'eval_steps_per_second': 74.628, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1668/special_tokens_map.json\n",
      "  7%|▋         | 1945/27800 [04:01<35:12, 12.24it/s]   The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 78.48it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 77.16it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 77.59it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 76.35it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 77.62it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:04, 65.06it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 68.28it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 72.02it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:01<00:03, 71.96it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 73.34it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 75.06it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 76.00it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 76.69it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 76.86it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 77.30it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 77.67it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 72.52it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 70.30it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 71.09it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 72.76it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 73.75it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 74.34it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 75.26it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 70.37it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 71.89it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 73.35it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 74.70it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 75.60it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 75.63it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 76.07it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 77.14it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 72.65it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 72.19it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 73.51it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 74.93it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:03<00:00, 75.64it/s]\u001b[A\n",
      " 93%|█████████▎| 297/318 [00:04<00:00, 75.32it/s]\u001b[A\n",
      " 96%|█████████▌| 305/318 [00:04<00:00, 74.95it/s]\u001b[A\n",
      "                                                    \n",
      "  7%|▋         | 1946/27800 [04:06<35:12, 12.24it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.82it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1946\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1946/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9294851422309875, 'eval_f1': 0.8379392831032296, 'eval_recall': 0.8426760112500857, 'eval_precision': 0.8338391924817263, 'eval_runtime': 4.3986, 'eval_samples_per_second': 288.726, 'eval_steps_per_second': 72.295, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-1946/special_tokens_map.json\n",
      "  7%|▋         | 2002/27800 [04:14<42:59, 10.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0323, 'learning_rate': 2.5604206039962768e-05, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2223/27800 [04:37<33:47, 12.62it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 82.66it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.62it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 78.64it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 79.56it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 78.41it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 78.13it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 77.84it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 78.84it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:00<00:03, 79.06it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:02, 79.14it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:02, 80.89it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 80.75it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 80.01it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 79.61it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 80.61it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 80.33it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:01<00:02, 67.78it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 68.59it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 71.15it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 72.33it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 73.73it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 74.48it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 75.74it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 75.85it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 76.21it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:02<00:01, 77.27it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:02<00:01, 76.80it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 77.19it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 77.02it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 68.02it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 68.15it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 68.57it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 69.52it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 71.92it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 74.75it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 75.69it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 76.06it/s]\u001b[A\n",
      "                                                    \n",
      "  8%|▊         | 2224/27800 [04:41<33:47, 12.62it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 76.46it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2224\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9475439786911011, 'eval_f1': 0.8347364609500532, 'eval_recall': 0.8383028834061235, 'eval_precision': 0.8315406162464986, 'eval_runtime': 4.2853, 'eval_samples_per_second': 296.359, 'eval_steps_per_second': 74.206, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2224/special_tokens_map.json\n",
      "  9%|▉         | 2502/27800 [05:12<34:15, 12.30it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0187, 'learning_rate': 2.510800049655264e-05, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 85.42it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 78.32it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 77.27it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 76.70it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 77.57it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 76.95it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 76.54it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 76.48it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 76.52it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 76.28it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:02, 76.40it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 75.95it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 76.39it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 75.87it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 66.03it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 68.20it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 70.46it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 71.56it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 72.80it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 73.91it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 68.40it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 69.98it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 71.69it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 69.44it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 71.21it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 72.49it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 73.11it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 73.65it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 74.10it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 74.86it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 72.16it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 72.81it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 74.18it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 75.39it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 75.69it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 75.57it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 75.20it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 75.38it/s]\u001b[A\n",
      "                                                    \n",
      "  9%|▉         | 2502/27800 [05:17<34:15, 12.30it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 76.10it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2502\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2502/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0811339616775513, 'eval_f1': 0.8316096526120392, 'eval_recall': 0.8442480506711179, 'eval_precision': 0.8232420826623725, 'eval_runtime': 4.4039, 'eval_samples_per_second': 288.38, 'eval_steps_per_second': 72.209, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2502/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2502/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2502/special_tokens_map.json\n",
      " 10%|█         | 2780/27800 [05:48<37:23, 11.15it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 76.04it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 74.68it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 76.56it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 76.46it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 76.17it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 69.27it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 70.48it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 71.60it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 72.16it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 72.89it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 73.20it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 73.47it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 74.37it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 74.42it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 75.19it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 75.58it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 74.92it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 75.12it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 75.56it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 76.49it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 72.68it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 73.43it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 75.24it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 76.34it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 77.15it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 77.40it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 77.36it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:02<00:01, 77.15it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 78.54it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:00, 78.69it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 78.86it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 79.47it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 80.92it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 80.90it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 79.38it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:03<00:00, 79.04it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:03<00:00, 78.50it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 76.36it/s]\u001b[A\n",
      "                                                    \n",
      " 10%|█         | 2780/27800 [05:53<37:23, 11.15it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.78it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2780\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2780/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.283312439918518, 'eval_f1': 0.8188994204808488, 'eval_recall': 0.8405408958909748, 'eval_precision': 0.8092462668940403, 'eval_runtime': 4.2751, 'eval_samples_per_second': 297.069, 'eval_steps_per_second': 74.384, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2780/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2780/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-2780/special_tokens_map.json\n",
      " 11%|█         | 3001/27800 [06:19<44:33,  9.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0169, 'learning_rate': 2.4611794953142507e-05, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3058/27800 [06:25<49:34,  8.32it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 73.36it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 75.82it/s]\u001b[A\n",
      "  8%|▊         | 25/318 [00:00<00:03, 78.51it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 79.66it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 77.22it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 73.36it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 72.41it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 74.56it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:00<00:03, 75.78it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 76.62it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:02, 77.48it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:02, 78.06it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 78.00it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 78.41it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 78.37it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 78.07it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 78.33it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:01<00:02, 78.71it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 76.31it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:01, 77.99it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:01, 77.57it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 77.14it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 76.74it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 76.53it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 76.29it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 75.58it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 77.31it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:02<00:01, 77.79it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 78.73it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 78.70it/s]\u001b[A\n",
      " 80%|████████  | 255/318 [00:03<00:00, 79.36it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 79.66it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 79.71it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 77.20it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:03<00:00, 75.99it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:03<00:00, 76.76it/s]\u001b[A\n",
      " 96%|█████████▌| 305/318 [00:03<00:00, 78.16it/s]\u001b[A\n",
      "                                                    \n",
      " 11%|█         | 3058/27800 [06:29<49:34,  8.32it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 78.34it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-3058\n",
      "Configuration saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-3058/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0896872282028198, 'eval_f1': 0.8309000617462785, 'eval_recall': 0.8236114604532047, 'eval_precision': 0.8400000000000001, 'eval_runtime': 4.1986, 'eval_samples_per_second': 302.481, 'eval_steps_per_second': 75.739, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-3058/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-3058/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-3058/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /scratch/mt/ashapiro/Hate_Speech/Checkpoints/SentenceBert/Classifiers/checkpoint-278 (score: 0.8505582936759521).\n",
      " 11%|█         | 3058/27800 [06:33<53:01,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 393.2281, 'train_samples_per_second': 2260.011, 'train_steps_per_second': 70.697, 'train_loss': 0.10183306980787966, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3058, training_loss=0.10183306980787966, metrics={'train_runtime': 393.2281, 'train_samples_per_second': 2260.011, 'train_steps_per_second': 70.697, 'train_loss': 0.10183306980787966, 'epoch': 11.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbebee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT-Jupyter",
   "language": "python",
   "name": "mt-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
