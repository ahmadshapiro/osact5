{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54db0f3-3c4d-469a-9804-64c12f4b5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/mt/ashapiro/Hate_Speech\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch/mt/ashapiro/Hate_Speech/\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from contrastive_utils import *\n",
    "from utils import run_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d773362a-e531-4b8e-8eea-36e78eacfaa2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of utils failed: Traceback (most recent call last):\n",
      "  File \"/cm/shared/ebtree/software/IPython/7.18.1-GCCcore-10.2.0/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/cm/shared/ebtree/software/IPython/7.18.1-GCCcore-10.2.0/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 779, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 916, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/scratch/mt/ashapiro/Hate_Speech/utils.py\", line 71\n",
      "    learning_rate=2e-5,\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 308.20it/s]\n",
      "loading file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/vocab.txt from cache at /home/ashapiro/.cache/huggingface/transformers/70287eb828c90e9c283d8ec742aabdef27ef04c445676b31b397811b32f71548.9985cd6ca030442c4f68221160381b229fee63902f75a8f43e14e78007536585\n",
      "loading file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/special_tokens_map.json from cache at /home/ashapiro/.cache/huggingface/transformers/a113a59c0bf37b35124fc18bced37f691306bd1bd52300035a8fddfd80c991bc.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/tokenizer_config.json from cache at /home/ashapiro/.cache/huggingface/transformers/759baae7af852b4436c3d9b23edb87ae8a8e24aeeae639694250995a8a1b6ffa.bb0613cb5a3da0fa5fac2f60e56d9f918033289878c75841185c1436d2af0d48\n",
      "100%|██████████| 2/2 [00:00<00:00, 29.01ba/s]\n",
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "config = {'model_name' : \"MarBertV2_Task2\",\n",
    "          'model_link' : \"UBC-NLP/MARBERTv2\",\n",
    "          'pre_proccessed' : True,\n",
    "          'patience' : 20,\n",
    "          'seed' : 2903, \n",
    "          'task' : \"B\",\n",
    "          \"batch_size\" : 128,\n",
    "          'num_labels' : 6,\n",
    "          'epochs' : 100, \n",
    "          'dropout_ratio' : 0.1}\n",
    "trainer = run_baseline(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e636de-e73c-4adb-8d18-f9d711830505",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "  1%|          | 69/7000 [00:13<20:42,  5.58it/s] The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.69it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.59it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.85it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.44it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.30it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.52it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.94it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.53it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 26.22it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.71it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.57it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.24it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      "  1%|          | 70/7000 [00:15<20:41,  5.58it/s]A\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-70\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-70/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21275024116039276, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 1.5883, 'eval_samples_per_second': 799.612, 'eval_steps_per_second': 25.185, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-70/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-70/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-70/special_tokens_map.json\n",
      "  2%|▏         | 139/7000 [00:32<26:38,  4.29it/s] The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 33.38it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.30it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.23it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 27.54it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 27.80it/s]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:00<00:00, 27.83it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 26.68it/s]\u001b[A\n",
      " 70%|███████   | 28/40 [00:01<00:00, 26.52it/s]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:01<00:00, 26.20it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:01<00:00, 26.65it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 27.50it/s]\u001b[A\n",
      "                                                  \n",
      "  2%|▏         | 140/7000 [00:34<26:37,  4.29it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-140\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-140/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20964932441711426, 'eval_f1': 0.7721328430078289, 'eval_recall': 0.8763680471595983, 'eval_precision': 0.7243941278456204, 'eval_runtime': 1.5374, 'eval_samples_per_second': 826.052, 'eval_steps_per_second': 26.017, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-140/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-140/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-140/special_tokens_map.json\n",
      "  3%|▎         | 209/7000 [00:50<22:40,  4.99it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.61it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.48it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.39it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.73it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.21it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.29it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.20it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.89it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.59it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.27it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.42it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.80it/s]\u001b[A\n",
      "                                                  \n",
      "  3%|▎         | 210/7000 [00:52<22:40,  4.99it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-210\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-210/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30430150032043457, 'eval_f1': 0.7222431367487354, 'eval_recall': 0.8962496740393049, 'eval_precision': 0.6808982683982684, 'eval_runtime': 1.5965, 'eval_samples_per_second': 795.469, 'eval_steps_per_second': 25.054, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-210/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-210/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-210/special_tokens_map.json\n",
      "  4%|▍         | 279/7000 [01:09<22:06,  5.07it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.43it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 27.54it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.55it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 27.85it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 28.27it/s]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:00<00:00, 28.32it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 26.35it/s]\u001b[A\n",
      " 70%|███████   | 28/40 [00:01<00:00, 26.23it/s]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:01<00:00, 25.29it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:01<00:00, 25.03it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 26.21it/s]\u001b[A\n",
      "                                                  \n",
      "  4%|▍         | 280/7000 [01:11<22:06,  5.07it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-280\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-280/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19500282406806946, 'eval_f1': 0.8023653906006847, 'eval_recall': 0.8713699831685751, 'eval_precision': 0.7604535554558, 'eval_runtime': 1.6323, 'eval_samples_per_second': 778.047, 'eval_steps_per_second': 24.505, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-280/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-280/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-280/special_tokens_map.json\n",
      "  5%|▍         | 349/7000 [01:27<25:26,  4.36it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 29.98it/s]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:00<00:01, 27.87it/s]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:00<00:01, 25.64it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.45it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.98it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.41it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.48it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.29it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.05it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.72it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.08it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.09it/s]\u001b[A\n",
      "                                                  \n",
      "  5%|▌         | 350/7000 [01:29<25:25,  4.36it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-350\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-350/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3088558614253998, 'eval_f1': 0.7665129027944912, 'eval_recall': 0.8891180491351176, 'eval_precision': 0.7170946765127301, 'eval_runtime': 1.5956, 'eval_samples_per_second': 795.955, 'eval_steps_per_second': 25.069, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-350/special_tokens_map.json\n",
      "  6%|▌         | 419/7000 [01:46<20:20,  5.39it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.91it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 27.75it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.62it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.96it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.52it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.38it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 25.24it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.38it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.24it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.19it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 24.21it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 24.26it/s]\u001b[A\n",
      "                                                  \n",
      "  6%|▌         | 420/7000 [01:47<20:20,  5.39it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-420\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-420/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22678707540035248, 'eval_f1': 0.8092227074235807, 'eval_recall': 0.8507376589305329, 'eval_precision': 0.7788226573444145, 'eval_runtime': 1.6689, 'eval_samples_per_second': 760.975, 'eval_steps_per_second': 23.968, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-420/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-420/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-420/special_tokens_map.json\n",
      "  7%|▋         | 489/7000 [02:04<21:09,  5.13it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 33.14it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 30.17it/s]\u001b[A\n",
      " 30%|███       | 12/40 [00:00<00:01, 27.06it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 27.26it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 27.71it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 26.90it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 25.71it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.55it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 24.80it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.84it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.33it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.42it/s]\u001b[A\n",
      "                                                  \n",
      "  7%|▋         | 490/7000 [02:06<21:09,  5.13it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-490\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-490/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3139417767524719, 'eval_f1': 0.7831801109385972, 'eval_recall': 0.8504373799871987, 'eval_precision': 0.7432332373508843, 'eval_runtime': 1.6056, 'eval_samples_per_second': 790.998, 'eval_steps_per_second': 24.913, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-490/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-490/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-490/special_tokens_map.json\n",
      "  7%|▋         | 501/7000 [02:12<26:30,  4.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1478, 'learning_rate': 1.8571428571428575e-05, 'epoch': 7.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 559/7000 [02:23<20:20,  5.28it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.58it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.40it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.15it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.29it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.00it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.05it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.36it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 26.02it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.68it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.26it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.41it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.20it/s]\u001b[A\n",
      "                                                  \n",
      "  8%|▊         | 560/7000 [02:25<20:20,  5.28it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3136126399040222, 'eval_f1': 0.7872112272047932, 'eval_recall': 0.8405518810895385, 'eval_precision': 0.7521723102849018, 'eval_runtime': 1.5918, 'eval_samples_per_second': 797.824, 'eval_steps_per_second': 25.128, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-560/config.json\n",
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-560/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-560/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-560/special_tokens_map.json\n",
      "  9%|▉         | 629/7000 [02:41<23:48,  4.46it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 29.90it/s]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:00<00:01, 27.38it/s]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:00<00:01, 25.62it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.42it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.78it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.04it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.30it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 26.09it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.78it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.43it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.36it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.24it/s]\u001b[A\n",
      "                                                  \n",
      "  9%|▉         | 630/7000 [02:43<23:48,  4.46it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-630\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-630/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29990702867507935, 'eval_f1': 0.797296949414339, 'eval_recall': 0.8435665236390647, 'eval_precision': 0.7649417442597377, 'eval_runtime': 1.6074, 'eval_samples_per_second': 790.103, 'eval_steps_per_second': 24.885, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-630/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-630/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-630/special_tokens_map.json\n",
      " 10%|▉         | 699/7000 [03:00<17:22,  6.05it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.50it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.62it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.80it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.79it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 29.22it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.03it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.43it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.22it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.81it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.21it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.21it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.20it/s]\u001b[A\n",
      "                                                  \n",
      " 10%|█         | 700/7000 [03:01<17:21,  6.05it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-700\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4331706464290619, 'eval_f1': 0.7781149425287356, 'eval_recall': 0.8636180451840789, 'eval_precision': 0.7334520493736968, 'eval_runtime': 1.5752, 'eval_samples_per_second': 806.26, 'eval_steps_per_second': 25.394, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-700/special_tokens_map.json\n",
      " 11%|█         | 770/7000 [03:18<16:20,  6.36it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.59it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.39it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.24it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.45it/s]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:00<00:00, 27.93it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 27.97it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:00<00:00, 26.77it/s]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:00<00:00, 26.12it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:01<00:00, 25.28it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [00:01<00:00, 25.09it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:01<00:00, 26.04it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.70it/s]\u001b[A\n",
      "                                                  \n",
      " 11%|█         | 770/7000 [03:20<16:20,  6.36it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-770\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-770/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.412273645401001, 'eval_f1': 0.7940003434917848, 'eval_recall': 0.8687860038404096, 'eval_precision': 0.7508182448446544, 'eval_runtime': 1.6145, 'eval_samples_per_second': 786.606, 'eval_steps_per_second': 24.775, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-770/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-770/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-770/special_tokens_map.json\n",
      " 12%|█▏        | 839/7000 [03:37<23:23,  4.39it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.56it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.43it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.55it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.57it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.22it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.29it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.54it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.12it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.28it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.92it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.13it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.32it/s]\u001b[A\n",
      "                                                  \n",
      " 12%|█▏        | 840/7000 [03:38<23:23,  4.39it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-840\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-840/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38141050934791565, 'eval_f1': 0.788398179052656, 'eval_recall': 0.8186275671874136, 'eval_precision': 0.7648859575362623, 'eval_runtime': 1.5666, 'eval_samples_per_second': 810.673, 'eval_steps_per_second': 25.533, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-840/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-840/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-840/special_tokens_map.json\n",
      " 13%|█▎        | 909/7000 [03:55<25:36,  3.96it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.58it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.86it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.17it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.24it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.77it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 26.01it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 25.55it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.50it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.37it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.89it/s]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:01<00:00, 27.16it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.71it/s]\u001b[A\n",
      "                                                  \n",
      " 13%|█▎        | 910/7000 [03:57<25:36,  3.96it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-910\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-910/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3800164759159088, 'eval_f1': 0.789790783898305, 'eval_recall': 0.8116065713676126, 'eval_precision': 0.7716535433070866, 'eval_runtime': 1.6039, 'eval_samples_per_second': 791.843, 'eval_steps_per_second': 24.94, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-910/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-910/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-910/special_tokens_map.json\n",
      " 14%|█▍        | 979/7000 [04:13<20:32,  4.88it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.61it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.38it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.06it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.37it/s]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:00<00:00, 27.46it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 27.53it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:00<00:00, 26.66it/s]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:00<00:00, 25.97it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:01<00:00, 24.44it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [00:01<00:00, 23.84it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:01<00:00, 25.30it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 26.30it/s]\u001b[A\n",
      "                                                  \n",
      " 14%|█▍        | 980/7000 [04:15<20:32,  4.88it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-980\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-980/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.372679740190506, 'eval_f1': 0.7692587209302326, 'eval_recall': 0.7187413571027823, 'eval_precision': 0.8640338764613826, 'eval_runtime': 1.6453, 'eval_samples_per_second': 771.911, 'eval_steps_per_second': 24.312, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-980/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-980/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-980/special_tokens_map.json\n",
      " 14%|█▍        | 1000/7000 [04:23<30:30,  3.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0159, 'learning_rate': 1.7142857142857142e-05, 'epoch': 14.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1049/7000 [04:32<18:50,  5.26it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.99it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 26.95it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.32it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.56it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.28it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.04it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 24.91it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 24.31it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 24.04it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 23.77it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 24.49it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 25.00it/s]\u001b[A\n",
      "                                                   \n",
      " 15%|█▌        | 1050/7000 [04:34<18:50,  5.26it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1050\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1050/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3751230537891388, 'eval_f1': 0.8193585093521086, 'eval_recall': 0.8193585093521086, 'eval_precision': 0.8193585093521086, 'eval_runtime': 1.6795, 'eval_samples_per_second': 756.183, 'eval_steps_per_second': 23.817, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1050/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1050/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1050/special_tokens_map.json\n",
      " 16%|█▌        | 1119/7000 [04:52<26:49,  3.65it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.58it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.91it/s]\u001b[A\n",
      " 30%|███       | 12/40 [00:00<00:01, 27.88it/s]\u001b[A\n",
      " 40%|████      | 16/40 [00:00<00:00, 28.36it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 28.73it/s]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:00<00:00, 28.87it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 27.36it/s]\u001b[A\n",
      " 70%|███████   | 28/40 [00:01<00:00, 26.94it/s]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:01<00:00, 26.56it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:01<00:00, 26.89it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 27.79it/s]\u001b[A\n",
      "                                                   \n",
      " 16%|█▌        | 1120/7000 [04:54<26:49,  3.65it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1120\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1120/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34229034185409546, 'eval_f1': 0.8203841898153925, 'eval_recall': 0.8044551912697848, 'eval_precision': 0.8386198047125619, 'eval_runtime': 1.5428, 'eval_samples_per_second': 823.175, 'eval_steps_per_second': 25.927, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1120/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1120/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1120/special_tokens_map.json\n",
      " 17%|█▋        | 1189/7000 [05:12<23:36,  4.10it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.44it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 27.61it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.40it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.39it/s]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:00<00:00, 27.42it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 27.35it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:00<00:00, 26.24it/s]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:00<00:00, 25.49it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:01<00:00, 24.20it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [00:01<00:00, 24.15it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:01<00:00, 25.33it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 26.34it/s]\u001b[A\n",
      "                                                   \n",
      " 17%|█▋        | 1190/7000 [05:13<23:36,  4.10it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1190\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1190/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3952040672302246, 'eval_f1': 0.7860026227682659, 'eval_recall': 0.7333641514354123, 'eval_precision': 0.8826181592039801, 'eval_runtime': 1.6419, 'eval_samples_per_second': 773.503, 'eval_steps_per_second': 24.362, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1190/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1190/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1190/special_tokens_map.json\n",
      " 18%|█▊        | 1260/7000 [05:30<14:55,  6.41it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.06it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.86it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.18it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.85it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.40it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 26.69it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.29it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 26.19it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.86it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.18it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.60it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.75it/s]\u001b[A\n",
      "                                                   \n",
      " 18%|█▊        | 1260/7000 [05:32<14:55,  6.41it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1260\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1260/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3957746922969818, 'eval_f1': 0.81014838453889, 'eval_recall': 0.7832420643387147, 'eval_precision': 0.8446008306414399, 'eval_runtime': 1.5869, 'eval_samples_per_second': 800.29, 'eval_steps_per_second': 25.206, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1260/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1260/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1260/special_tokens_map.json\n",
      " 19%|█▉        | 1329/7000 [05:49<17:59,  5.25it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.15it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.25it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.24it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.21it/s]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:00<00:00, 28.00it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 27.90it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:00<00:00, 26.87it/s]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:00<00:00, 25.73it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:01<00:00, 24.80it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [00:01<00:00, 24.74it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:01<00:00, 25.89it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 26.28it/s]\u001b[A\n",
      "                                                   \n",
      " 19%|█▉        | 1330/7000 [05:51<17:59,  5.25it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1330\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1330/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5165820717811584, 'eval_f1': 0.7899426437241563, 'eval_recall': 0.8227840599293554, 'eval_precision': 0.7648615001556178, 'eval_runtime': 1.6217, 'eval_samples_per_second': 783.144, 'eval_steps_per_second': 24.666, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1330/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1330/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1330/special_tokens_map.json\n",
      " 20%|█▉        | 1399/7000 [06:08<17:28,  5.34it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.47it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.85it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.20it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.28it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.61it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.16it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.44it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.42it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.24it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.89it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.57it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.52it/s]\u001b[A\n",
      "                                                   \n",
      " 20%|██        | 1400/7000 [06:10<17:28,  5.34it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1400\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4986032545566559, 'eval_f1': 0.7959744673559148, 'eval_recall': 0.82823254233538, 'eval_precision': 0.7710882688856258, 'eval_runtime': 1.5887, 'eval_samples_per_second': 799.411, 'eval_steps_per_second': 25.178, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1400/special_tokens_map.json\n",
      " 21%|██        | 1469/7000 [06:27<19:35,  4.71it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.51it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.41it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.62it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.85it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.35it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.29it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.15it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.79it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.50it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.16it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.35it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.32it/s]\u001b[A\n",
      "                                                   \n",
      " 21%|██        | 1470/7000 [06:29<19:35,  4.71it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1470\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1470/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5143411755561829, 'eval_f1': 0.8019577405887397, 'eval_recall': 0.8374068542619855, 'eval_precision': 0.7750819798867421, 'eval_runtime': 1.6058, 'eval_samples_per_second': 790.869, 'eval_steps_per_second': 24.909, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1470/special_tokens_map.json\n",
      " 21%|██▏       | 1501/7000 [06:39<19:55,  4.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0027, 'learning_rate': 1.5714285714285715e-05, 'epoch': 21.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1540/7000 [06:46<18:01,  5.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.55it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.01it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.22it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.29it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.66it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.51it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.61it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.43it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 24.87it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.74it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.99it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.75it/s]\u001b[A\n",
      "                                                   \n",
      " 22%|██▏       | 1540/7000 [06:48<18:01,  5.05it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1540\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1540/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4894360601902008, 'eval_f1': 0.7959639498432602, 'eval_recall': 0.7984259061707323, 'eval_precision': 0.7935545554182311, 'eval_runtime': 1.5857, 'eval_samples_per_second': 800.913, 'eval_steps_per_second': 25.226, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1540/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1540/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1540/special_tokens_map.json\n",
      " 23%|██▎       | 1609/7000 [07:05<17:38,  5.09it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.14it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 27.24it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.40it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.42it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 27.93it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.08it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.10it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.72it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.48it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.21it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.44it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.37it/s]\u001b[A\n",
      "                                                   \n",
      " 23%|██▎       | 1610/7000 [07:06<17:38,  5.09it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1610\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1610/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5060531497001648, 'eval_f1': 0.7959297031686741, 'eval_recall': 0.7947000766501513, 'eval_precision': 0.7971728182571556, 'eval_runtime': 1.5869, 'eval_samples_per_second': 800.305, 'eval_steps_per_second': 25.206, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1610/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1610/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1610/special_tokens_map.json\n",
      " 24%|██▍       | 1679/7000 [07:23<16:18,  5.44it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.45it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.38it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.26it/s]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:00<00:00, 28.36it/s]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:00<00:00, 28.61it/s]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:00<00:00, 28.69it/s]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:00<00:00, 27.29it/s]\u001b[A\n",
      " 70%|███████   | 28/40 [00:01<00:00, 26.95it/s]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:01<00:00, 26.43it/s]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:01<00:00, 26.73it/s]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:01<00:00, 27.73it/s]\u001b[A\n",
      "                                                   \n",
      " 24%|██▍       | 1680/7000 [07:25<16:18,  5.44it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1680\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1680/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47334083914756775, 'eval_f1': 0.8078284922253762, 'eval_recall': 0.8014405487202585, 'eval_precision': 0.8145781105686766, 'eval_runtime': 1.5188, 'eval_samples_per_second': 836.172, 'eval_steps_per_second': 26.336, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1680/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1680/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1680/special_tokens_map.json\n",
      " 25%|██▍       | 1749/7000 [07:41<18:59,  4.61it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.13it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.43it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.46it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.83it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.51it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.00it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.10it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.47it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 24.95it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.82it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.99it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.16it/s]\u001b[A\n",
      "                                                   \n",
      " 25%|██▌       | 1750/7000 [07:43<18:59,  4.61it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1750\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1750/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4974256753921509, 'eval_f1': 0.7992385501598891, 'eval_recall': 0.810464721175197, 'eval_precision': 0.789025717984934, 'eval_runtime': 1.6205, 'eval_samples_per_second': 783.722, 'eval_steps_per_second': 24.684, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1750/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1750/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1750/special_tokens_map.json\n",
      " 26%|██▌       | 1819/7000 [08:00<16:57,  5.09it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.81it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.93it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.31it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.23it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.73it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.58it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.77it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.31it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.89it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.51it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.39it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.70it/s]\u001b[A\n",
      "                                                   \n",
      " 26%|██▌       | 1820/7000 [08:02<16:57,  5.09it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1820\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1820/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4883694052696228, 'eval_f1': 0.797603110856123, 'eval_recall': 0.7951307398715122, 'eval_precision': 0.8001301821746851, 'eval_runtime': 1.6084, 'eval_samples_per_second': 789.616, 'eval_steps_per_second': 24.87, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1820/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1820/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1820/special_tokens_map.json\n",
      " 27%|██▋       | 1889/7000 [08:19<16:47,  5.07it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 29.53it/s]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:00<00:01, 25.90it/s]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:00<00:01, 24.66it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.78it/s]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:00<00:00, 27.74it/s]\u001b[A\n",
      " 50%|█████     | 20/40 [00:00<00:00, 27.70it/s]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:00<00:00, 26.12it/s]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:00<00:00, 25.51it/s]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:01<00:00, 24.76it/s]\u001b[A\n",
      " 80%|████████  | 32/40 [00:01<00:00, 24.58it/s]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:01<00:00, 25.88it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.47it/s]\u001b[A\n",
      "                                                   \n",
      " 27%|██▋       | 1890/7000 [08:20<16:47,  5.07it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1890\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1890/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5652171969413757, 'eval_f1': 0.8020499094363556, 'eval_recall': 0.8336810247414046, 'eval_precision': 0.7774004099222198, 'eval_runtime': 1.6407, 'eval_samples_per_second': 774.072, 'eval_steps_per_second': 24.38, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1890/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1890/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1890/special_tokens_map.json\n",
      " 28%|██▊       | 1959/7000 [08:37<14:02,  5.98it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.32it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.41it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.46it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.29it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 27.89it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.02it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.33it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 26.22it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.55it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.17it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.39it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.45it/s]\u001b[A\n",
      "                                                   \n",
      " 28%|██▊       | 1960/7000 [08:39<14:02,  5.98it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1960\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1960/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5043092966079712, 'eval_f1': 0.8041574142610413, 'eval_recall': 0.8117567108392796, 'eval_precision': 0.7970261622435535, 'eval_runtime': 1.617, 'eval_samples_per_second': 785.414, 'eval_steps_per_second': 24.737, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1960/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1960/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1960/special_tokens_map.json\n",
      " 29%|██▊       | 2001/7000 [08:51<21:38,  3.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'learning_rate': 1.4285714285714287e-05, 'epoch': 28.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2029/7000 [08:55<14:17,  5.79it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 33.06it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 27.12it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 24.40it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:01, 25.52it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 27.53it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 26.79it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.12it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 25.73it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.34it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.80it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.10it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 27.07it/s]\u001b[A\n",
      "                                                   \n",
      " 29%|██▉       | 2030/7000 [08:57<14:17,  5.79it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2030\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2030/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5220500230789185, 'eval_f1': 0.7960089030984925, 'eval_recall': 0.8058775652118941, 'eval_precision': 0.786940052334675, 'eval_runtime': 1.5982, 'eval_samples_per_second': 794.635, 'eval_steps_per_second': 25.028, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2030/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2030/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2030/special_tokens_map.json\n",
      " 30%|██▉       | 2099/7000 [09:14<18:37,  4.39it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.06it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.09it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.38it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.17it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.40it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.32it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.69it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.29it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.31it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.62it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.91it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.62it/s]\u001b[A\n",
      "                                                   \n",
      " 30%|███       | 2100/7000 [09:16<18:37,  4.39it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2100\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5505305528640747, 'eval_f1': 0.7976233837188126, 'eval_recall': 0.8100340579538361, 'eval_precision': 0.7864480283859852, 'eval_runtime': 1.5905, 'eval_samples_per_second': 798.493, 'eval_steps_per_second': 25.149, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2100/special_tokens_map.json\n",
      " 31%|███       | 2169/7000 [09:33<19:44,  4.08it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 30.94it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.07it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.51it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.64it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 29.00it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.23it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.66it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.25it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 24.90it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.77it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 25.98it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.13it/s]\u001b[A\n",
      "                                                   \n",
      " 31%|███       | 2170/7000 [09:35<19:44,  4.08it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2170\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2170/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5515351295471191, 'eval_f1': 0.8022209152985191, 'eval_recall': 0.8262293657002426, 'eval_precision': 0.7824266637478108, 'eval_runtime': 1.5742, 'eval_samples_per_second': 806.772, 'eval_steps_per_second': 25.41, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2170/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2170/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2170/special_tokens_map.json\n",
      " 32%|███▏      | 2239/7000 [09:51<14:11,  5.59it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.43it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.89it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.57it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.81it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.48it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.39it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.65it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 26.27it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.61it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.24it/s]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:01<00:00, 27.28it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.98it/s]\u001b[A\n",
      "                                                   \n",
      " 32%|███▏      | 2240/7000 [09:53<14:10,  5.59it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2240\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2240/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6524773836135864, 'eval_f1': 0.7744439008370809, 'eval_recall': 0.8254984235355476, 'eval_precision': 0.7410255059946986, 'eval_runtime': 1.6196, 'eval_samples_per_second': 784.142, 'eval_steps_per_second': 24.697, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2240/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2240/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2240/special_tokens_map.json\n",
      " 33%|███▎      | 2309/7000 [10:10<16:09,  4.84it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.40it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.37it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.26it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.33it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.70it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.60it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.79it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.37it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.71it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.29it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.47it/s]\u001b[A\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.45it/s]\u001b[A\n",
      "                                                   \n",
      " 33%|███▎      | 2310/7000 [10:12<16:08,  4.84it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2310\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2310/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5303748846054077, 'eval_f1': 0.8026161766991475, 'eval_recall': 0.8038743885767569, 'eval_precision': 0.801371473354232, 'eval_runtime': 1.5961, 'eval_samples_per_second': 795.692, 'eval_steps_per_second': 25.061, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2310/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2310/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2310/special_tokens_map.json\n",
      " 34%|███▍      | 2379/7000 [10:29<14:04,  5.48it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.95it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 29.16it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.89it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 27.06it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 28.59it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.59it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.45it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:00<00:00, 26.22it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.86it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.47it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.32it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.91it/s]\u001b[A\n",
      "                                                   \n",
      " 34%|███▍      | 2380/7000 [10:30<14:03,  5.48it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2380\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2380/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5653599500656128, 'eval_f1': 0.8073818094552436, 'eval_recall': 0.8163438668025824, 'eval_precision': 0.7990572521364967, 'eval_runtime': 1.5728, 'eval_samples_per_second': 807.494, 'eval_steps_per_second': 25.433, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2380/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2380/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2380/special_tokens_map.json\n",
      " 35%|███▍      | 2449/7000 [10:47<16:38,  4.56it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 31.75it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 28.85it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 26.17it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:00, 26.35it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 27.95it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 27.09it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 26.42it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 26.10it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 25.65it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 25.20it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.29it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.98it/s]\u001b[A\n",
      "                                                   \n",
      " 35%|███▌      | 2450/7000 [10:48<16:38,  4.56it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2450\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2450/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6149811744689941, 'eval_f1': 0.7823727651796424, 'eval_recall': 0.8131790847813891, 'eval_precision': 0.758655571871431, 'eval_runtime': 1.5971, 'eval_samples_per_second': 795.189, 'eval_steps_per_second': 25.045, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2450/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2450/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2450/special_tokens_map.json\n",
      " 36%|███▌      | 2501/7000 [11:02<11:31,  6.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 1.2857142857142859e-05, 'epoch': 35.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2519/7000 [11:06<14:11,  5.26it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 4/40 [00:00<00:01, 32.19it/s]\u001b[A\n",
      " 20%|██        | 8/40 [00:00<00:01, 26.92it/s]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:00<00:01, 25.12it/s]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:00<00:01, 24.47it/s]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:00<00:00, 25.87it/s]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:00<00:00, 24.47it/s]\u001b[A\n",
      " 60%|██████    | 24/40 [00:00<00:00, 24.58it/s]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:01<00:00, 24.80it/s]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:01<00:00, 24.81it/s]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:01<00:00, 24.77it/s]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:01<00:00, 26.07it/s]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:01<00:00, 26.76it/s]\u001b[A\n",
      "                                                   \n",
      " 36%|███▌      | 2520/7000 [11:08<14:11,  5.26it/s]\n",
      "                                               \u001b[ASaving model checkpoint to ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2520\n",
      "Configuration saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2520/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5888202786445618, 'eval_f1': 0.7944673413460501, 'eval_recall': 0.824076049593438, 'eval_precision': 0.7712024123633623, 'eval_runtime': 1.6859, 'eval_samples_per_second': 753.301, 'eval_steps_per_second': 23.726, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2520/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2520/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-2520/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/Pre_processed/MarBertV2_Task2_d_0.1/checkpoint-1120 (score: 0.8203841898153925).\n",
      " 36%|███▌      | 2520/7000 [11:12<19:54,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 672.2342, 'train_samples_per_second': 1322.01, 'train_steps_per_second': 10.413, 'train_loss': 0.03344156945212966, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2520, training_loss=0.03344156945212966, metrics={'train_runtime': 672.2342, 'train_samples_per_second': 1322.01, 'train_steps_per_second': 10.413, 'train_loss': 0.03344156945212966, 'epoch': 36.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb31c98-ee44-42d1-b290-d1014bd78beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8887\n",
      "  Batch size = 32\n",
      "100%|██████████| 278/278 [00:10<00:00, 25.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13738210499286652,\n",
       " 'eval_f1': 0.8627207804130124,\n",
       " 'eval_recall': 0.8453155432258417,\n",
       " 'eval_precision': 0.8827037679175276,\n",
       " 'eval_runtime': 10.9481,\n",
       " 'eval_samples_per_second': 811.743,\n",
       " 'eval_steps_per_second': 25.393,\n",
       " 'epoch': 12.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainer.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92fb8032-b218-450e-b261-da31f1c7d208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 32\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.14619281888008118,\n",
       " 'eval_f1': 0.8190109733504346,\n",
       " 'eval_recall': 0.796572869007262,\n",
       " 'eval_precision': 0.8463036096552743,\n",
       " 'eval_runtime': 1.5913,\n",
       " 'eval_samples_per_second': 798.112,\n",
       " 'eval_steps_per_second': 25.137,\n",
       " 'epoch': 12.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainer.eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3504cc96-8928-4a3d-a522-aaaa6aaf4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getData\n",
    "from datasets import load_dataset \n",
    "import pandas as pd \n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from datasets import load_metric\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddb389d-b9a9-4639-82ad-fe30d00b9740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 312.65it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 23.27ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.98ba/s]\n"
     ]
    }
   ],
   "source": [
    "f1 = load_metric(\"f1\")\n",
    "recall = load_metric(\"recall\")\n",
    "precision =  load_metric(\"precision\")\n",
    "def preprocess_function(examples, tok):\n",
    "    return tok(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    metric = f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    metric.update(recall.compute(predictions=predictions, references=labels, average=\"macro\"))\n",
    "    metric.update(precision.compute(predictions=predictions, references=labels, average=\"macro\"))\n",
    "    return metric\n",
    "data = getData(sub_task = f\"B\", return_type = \"dataset\", pre_proccessed = True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERTv2\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "tokenized_data = data.map(preprocess_function,fn_kwargs = {'tok':tokenizer}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e99524-2d07-4b99-9ee6-b9da864d8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\"UBC-NLP/MARBERTv2\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e4abde-aa5d-4fe8-8d60-f1fe5de85a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./Checkpoints/MarBertv2_taskB_hyperparams\",\n",
    "    do_train = True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    group_by_length = True, \n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7715c338-4c95-463c-aac6-b346c8ec0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True),\n",
    "        \"weight_decay\" : trial.suggest_float(\"weight_decay\", 1e-10, 1e-4, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 25),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 50),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [32, 64, 128]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e875937-0776-4bc9-abb2-bb0991534476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-29 16:43:59,507]\u001b[0m A new study created in memory with name: no-name-320c3a79-b429-4c66-bfc5-305b2bc14bb1\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9999\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahmadshapiro\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stellar-feather-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2x4ohljl\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2x4ohljl</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_164404-2x4ohljl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 501/9999 [00:56<19:15,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4782, 'learning_rate': 0.001106742168944453, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1001/9999 [01:46<18:41,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4314, 'learning_rate': 0.0010484864489242165, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1110/9999 [01:56<12:33, 11.80it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 76.79it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 73.83it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 71.76it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:04, 70.28it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:04, 63.57it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:04, 63.71it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:04, 61.69it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:04, 58.04it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:01<00:04, 55.78it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 60.92it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 65.65it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 68.61it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 70.46it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:03, 69.23it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 71.94it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 70.62it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 71.52it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:02<00:02, 73.44it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 75.64it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 76.01it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:01, 77.95it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:01, 78.12it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 78.22it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 76.76it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 76.73it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 77.61it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 77.64it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 77.16it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 74.34it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 70.22it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 66.22it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 68.89it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 70.81it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 67.87it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 71.61it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:04<00:00, 69.07it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 69.08it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 68.14it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 70.40it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 72.63it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 11%|█         | 1111/9999 [02:01<12:33, 11.80it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 72.63it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-1111\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-1111/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4469417929649353, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6207, 'eval_samples_per_second': 274.847, 'eval_steps_per_second': 68.82, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-1111/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-1111/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-1111/special_tokens_map.json\n",
      " 15%|█▌        | 1501/9999 [02:40<17:09,  8.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4311, 'learning_rate': 0.00099023072890398, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2001/9999 [03:23<18:12,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4362, 'learning_rate': 0.0009319750088837435, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2221/9999 [03:42<11:35, 11.18it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 63.04it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 76.22it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 74.15it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:03, 78.23it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 81.39it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 78.81it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 76.54it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 73.88it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 72.13it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 75.62it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:02, 76.14it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:03, 70.56it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:03, 68.35it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 71.37it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 72.90it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 76.13it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 71.17it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 71.28it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 73.48it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:01, 77.38it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 79.99it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 78.35it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 73.62it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 77.10it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 79.67it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:02<00:01, 80.65it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 80.35it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:00, 81.34it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:00, 82.92it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 81.06it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 82.56it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 84.02it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 84.19it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 85.77it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:03<00:00, 84.75it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:03<00:00, 81.09it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 22%|██▏       | 2222/9999 [03:47<11:35, 11.18it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 81.09it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-2222\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-2222/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30832457542419434, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2105, 'eval_samples_per_second': 301.627, 'eval_steps_per_second': 75.525, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-2222/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-2222/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-2222/special_tokens_map.json\n",
      " 25%|██▌       | 2501/9999 [04:14<17:48,  7.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3881, 'learning_rate': 0.0008737192888635069, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3002/9999 [04:58<11:14, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3774, 'learning_rate': 0.0008154635688432706, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3332/9999 [05:27<09:47, 11.34it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.51it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 83.86it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:04, 66.21it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 64.64it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:04, 62.54it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:04, 62.04it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 66.17it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 64.89it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 70.31it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 73.37it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 67.44it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 64.68it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:03, 69.85it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:03, 62.68it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:03, 61.19it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 67.86it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:02<00:02, 70.42it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 75.03it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 73.94it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 74.32it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:01, 76.74it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 75.31it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 70.40it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 63.59it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 68.42it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 66.20it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 70.75it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 74.96it/s]\u001b[A\n",
      " 75%|███████▌  | 239/318 [00:03<00:01, 77.30it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:00, 77.48it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 79.95it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 76.06it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 78.69it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 74.77it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:04<00:00, 73.25it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 73.71it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 74.10it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 76.47it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 33%|███▎      | 3333/9999 [05:32<09:47, 11.34it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 76.47it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-3333\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-3333/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3248934745788574, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5872, 'eval_samples_per_second': 276.858, 'eval_steps_per_second': 69.324, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-3333/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-3333/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-3333/special_tokens_map.json\n",
      " 35%|███▌      | 3501/9999 [05:50<14:50,  7.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3946, 'learning_rate': 0.0007572078488230341, 'epoch': 3.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4001/9999 [06:36<13:01,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3611, 'learning_rate': 0.0006989521288027975, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4444/9999 [07:17<07:37, 12.14it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 89.59it/s]\u001b[A\n",
      "  6%|▌         | 19/318 [00:00<00:03, 82.77it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 72.18it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 73.98it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 76.08it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 73.81it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 75.65it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 76.08it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 75.82it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 76.69it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 72.30it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:03, 69.77it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:03, 68.39it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 68.10it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:03, 63.81it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 65.10it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 61.26it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 58.14it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 62.59it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 59.06it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 62.78it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:02, 66.94it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 70.40it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 70.74it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 69.66it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:03<00:01, 68.26it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:03<00:01, 69.65it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 72.38it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 74.03it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 67.91it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:01, 69.77it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 72.09it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 70.70it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 72.37it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 74.03it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:04<00:00, 70.52it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:04<00:00, 69.06it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 70.91it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 69.42it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 44%|████▍     | 4444/9999 [07:21<07:37, 12.14it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 69.42it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-4444\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-4444/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29520055651664734, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6773, 'eval_samples_per_second': 271.526, 'eval_steps_per_second': 67.988, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-4444/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-4444/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-4444/special_tokens_map.json\n",
      " 45%|████▌     | 4501/9999 [07:31<12:49,  7.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3506, 'learning_rate': 0.000640696408782561, 'epoch': 4.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5001/9999 [08:18<10:48,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.401, 'learning_rate': 0.0005824406887623245, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5501/9999 [09:05<08:40,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3494, 'learning_rate': 0.0005241849687420881, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5554/9999 [09:09<06:24, 11.56it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 67.16it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 69.99it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 66.79it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:04, 66.67it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 70.46it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 71.38it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 67.69it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 70.69it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:01<00:03, 70.69it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 72.35it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 66.91it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 66.53it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:03, 68.69it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 70.62it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 69.63it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 64.68it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 66.52it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:02<00:02, 68.43it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 70.06it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 68.06it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 70.26it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:02, 71.46it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 73.11it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 74.59it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 75.24it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 74.28it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 74.51it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 73.47it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 71.62it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 66.95it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 65.92it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 69.45it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 69.77it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 70.88it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 72.02it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:04<00:00, 73.81it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 75.93it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 71.81it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 71.34it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 72.37it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 56%|█████▌    | 5555/9999 [09:14<06:24, 11.56it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 72.37it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-5555\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-5555/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2990366518497467, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6306, 'eval_samples_per_second': 274.261, 'eval_steps_per_second': 68.673, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-5555/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-5555/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-5555/special_tokens_map.json\n",
      " 60%|██████    | 6001/9999 [09:57<08:06,  8.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3648, 'learning_rate': 0.0004659292487218515, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6501/9999 [10:39<07:13,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.344, 'learning_rate': 0.000407673528701615, 'epoch': 5.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6665/9999 [10:53<04:51, 11.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 89.59it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 78.38it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 74.58it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 76.48it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 72.90it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 75.97it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 76.24it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 71.71it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 70.69it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 74.12it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 73.77it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:02, 75.91it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 78.37it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 78.26it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 78.21it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:01<00:02, 79.14it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 79.61it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 75.76it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 74.92it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:01, 77.97it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 79.66it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 80.89it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 75.94it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 77.64it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 74.23it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:02<00:01, 76.35it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 77.95it/s]\u001b[A\n",
      " 75%|███████▌  | 239/318 [00:03<00:01, 78.11it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 80.00it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 81.05it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 80.11it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 78.52it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 78.23it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 78.32it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 78.21it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:03<00:00, 79.16it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 75.93it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 67%|██████▋   | 6666/9999 [10:57<04:51, 11.42it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.93it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-6666\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-6666/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2982141077518463, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2642, 'eval_samples_per_second': 297.826, 'eval_steps_per_second': 74.574, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-6666/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-6666/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-6666/special_tokens_map.json\n",
      " 70%|███████   | 7001/9999 [11:29<05:54,  8.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3519, 'learning_rate': 0.00034941780868137857, 'epoch': 6.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7501/9999 [12:10<04:37,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3581, 'learning_rate': 0.00029116208866114204, 'epoch': 6.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7777/9999 [12:33<03:07, 11.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 96.36it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 83.95it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 81.33it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 70.13it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:03, 70.70it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 72.00it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:04, 63.12it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 64.55it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:04, 59.56it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 63.93it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 66.95it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 69.18it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:03, 69.01it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 70.15it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 72.29it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 75.49it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 74.90it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 74.41it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 71.84it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 73.77it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:01, 76.35it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 76.44it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 76.68it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 76.39it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 75.37it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:02<00:01, 77.03it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:03<00:01, 77.63it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 71.25it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 74.28it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:01, 64.26it/s]\u001b[A\n",
      " 80%|████████  | 255/318 [00:03<00:00, 65.22it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 66.44it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 64.32it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 68.45it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:04<00:00, 73.05it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:04<00:00, 75.69it/s]\u001b[A\n",
      " 96%|█████████▌| 305/318 [00:04<00:00, 77.51it/s]\u001b[A\n",
      " 98%|█████████▊| 313/318 [00:04<00:00, 75.26it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 78%|███████▊  | 7777/9999 [12:38<03:07, 11.83it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.26it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-7777\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-7777/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.299702525138855, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5062, 'eval_samples_per_second': 281.836, 'eval_steps_per_second': 70.57, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-7777/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-7777/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-7777/special_tokens_map.json\n",
      " 80%|████████  | 8001/9999 [13:00<04:01,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3498, 'learning_rate': 0.00023290636864090552, 'epoch': 7.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8501/9999 [13:43<02:41,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.354, 'learning_rate': 0.00017465064862066902, 'epoch': 7.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8887/9999 [14:17<01:22, 13.55it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.33it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 78.21it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 78.05it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 77.97it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 73.50it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 74.18it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 75.29it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 76.70it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 77.65it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 72.99it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 67.84it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 70.62it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 72.46it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 73.08it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 72.28it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 73.16it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 74.68it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 75.52it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 72.82it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 70.39it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 68.92it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 69.97it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 72.13it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 70.98it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 72.28it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 73.93it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 75.35it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 75.30it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 74.15it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 76.30it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 67.49it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 71.20it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 67.66it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 65.61it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 65.55it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:04<00:00, 63.42it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:04<00:00, 64.36it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 67.88it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 70.88it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      " 89%|████████▉ | 8888/9999 [14:22<01:22, 13.55it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 70.88it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-8888\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-8888/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29335275292396545, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.502, 'eval_samples_per_second': 282.096, 'eval_steps_per_second': 70.635, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-8888/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-8888/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-8888/special_tokens_map.json\n",
      " 90%|█████████ | 9000/9999 [14:35<01:46,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3507, 'learning_rate': 0.00011639492860043252, 'epoch': 8.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9501/9999 [15:18<00:57,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3564, 'learning_rate': 5.813920858019602e-05, 'epoch': 8.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9998/9999 [16:01<00:00, 12.39it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 75.02it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 68.47it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 72.74it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 74.74it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:04, 67.89it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 69.96it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 67.61it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 69.29it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 69.22it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 69.18it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 65.67it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:03, 66.65it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:03, 69.71it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 71.86it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 72.57it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 72.41it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 70.12it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:02<00:02, 71.52it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 72.43it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 74.17it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 74.82it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 71.60it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 73.79it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 73.40it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 71.65it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 72.22it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:02<00:01, 74.89it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:03<00:01, 76.31it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 75.70it/s]\u001b[A\n",
      " 75%|███████▌  | 239/318 [00:03<00:01, 72.78it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:00, 73.84it/s]\u001b[A\n",
      " 80%|████████  | 255/318 [00:03<00:00, 75.55it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 76.43it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 75.80it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 76.08it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 75.54it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 72.03it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 63.23it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 67.03it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "                                                   \n",
      "100%|██████████| 9999/9999 [16:06<00:00, 12.39it/s]\n",
      "100%|██████████| 318/318 [00:04<00:00, 67.03it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-9999\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-9999/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.292985200881958, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5293, 'eval_samples_per_second': 280.394, 'eval_steps_per_second': 70.209, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-9999/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-9999/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-9999/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-0/checkpoint-1111 (score: 0.4775812422871246).\n",
      "100%|██████████| 9999/9999 [16:10<00:00, 10.30it/s]\n",
      "\u001b[32m[I 2022-03-29 17:00:18,229]\u001b[0m Trial 0 finished with value: 1.434667856460353 and parameters: {'learning_rate': 0.0011649978889646895, 'weight_decay': 3.137936315010828e-10, 'num_train_epochs': 9, 'seed': 10, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 1.434667856460353.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 974.3342, 'train_samples_per_second': 82.09, 'train_steps_per_second': 10.262, 'train_loss': 0.37787302442402443, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5270<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_164404-2x4ohljl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_164404-2x4ohljl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.3564</td></tr><tr><td>train/learning_rate</td><td>6e-05</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>9999</td></tr><tr><td>_runtime</td><td>973</td></tr><tr><td>_timestamp</td><td>1648566018</td></tr><tr><td>_step</td><td>28</td></tr><tr><td>eval/loss</td><td>0.29299</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.5293</td></tr><tr><td>eval/samples_per_second</td><td>280.394</td></tr><tr><td>eval/steps_per_second</td><td>70.209</td></tr><tr><td>train/train_runtime</td><td>974.3342</td></tr><tr><td>train/train_samples_per_second</td><td>82.09</td></tr><tr><td>train/train_steps_per_second</td><td>10.262</td></tr><tr><td>train/total_flos</td><td>779517376493220.0</td></tr><tr><td>train/train_loss</td><td>0.37787</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▆▆▆▃▃▄▂▁▄▁▂▁▁▂▁▂▁▂</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>eval/loss</td><td>█▂▂▁▁▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▇▁▇█▇▂▅▅▆</td></tr><tr><td>eval/samples_per_second</td><td>▂█▂▁▂▇▃▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▂█▂▁▂▇▃▃▃</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stellar-feather-10</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2x4ohljl\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2x4ohljl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">solar-sun-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/31ig8mk7\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/31ig8mk7</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170028-31ig8mk7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 138/695 [00:16<01:03,  8.79it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 64.52it/s]\u001b[A\n",
      "  5%|▍         | 15/318 [00:00<00:04, 68.79it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 74.59it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:03, 77.26it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:03, 75.68it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:03, 71.68it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 73.69it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 76.56it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 76.62it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 77.35it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:02, 77.53it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:02, 77.39it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 72.66it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 70.22it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 70.69it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 73.81it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 72.98it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 73.29it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 75.65it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 75.44it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 71.80it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 74.64it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 74.18it/s]\u001b[A\n",
      " 63%|██████▎   | 199/318 [00:02<00:01, 76.35it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 71.73it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:02<00:01, 66.57it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 70.06it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 64.78it/s]\u001b[A\n",
      " 75%|███████▌  | 239/318 [00:03<00:01, 64.32it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:01, 69.31it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 70.29it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 70.77it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 73.91it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 76.75it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 74.24it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 73.53it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 75.66it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 77.83it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 20%|██        | 139/695 [00:20<01:03,  8.79it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-139\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-139/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2969776690006256, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4202, 'eval_samples_per_second': 287.317, 'eval_steps_per_second': 71.942, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-139/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-139/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-139/special_tokens_map.json\n",
      " 40%|████      | 278/695 [00:40<00:53,  7.85it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 68.98it/s]\u001b[A\n",
      "  4%|▍         | 14/318 [00:00<00:04, 69.56it/s]\u001b[A\n",
      "  7%|▋         | 22/318 [00:00<00:04, 72.25it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:03, 75.82it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 77.23it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 78.88it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 81.26it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 77.34it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 76.40it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 74.40it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 66.77it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 69.98it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:03, 64.16it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:03, 63.11it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 67.12it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 71.69it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 74.85it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 76.85it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 77.32it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:01, 78.85it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 75.36it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 75.09it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 75.95it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 73.98it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 70.61it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 72.31it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 69.00it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 67.73it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 70.22it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 70.37it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 72.95it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 74.60it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 70.08it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 72.55it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 72.64it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 74.33it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 75.63it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 76.79it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 78.11it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 40%|████      | 278/695 [00:45<00:53,  7.85it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3859783411026001, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.463, 'eval_samples_per_second': 284.562, 'eval_steps_per_second': 71.252, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-278/special_tokens_map.json\n",
      " 60%|█████▉    | 416/695 [01:05<00:33,  8.43it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 77.93it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 77.62it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 76.41it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 76.89it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 77.92it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 77.73it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 77.00it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 76.79it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:00<00:03, 78.37it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 78.29it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:02, 77.26it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:03, 63.99it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:03, 61.00it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:03, 64.52it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 67.83it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 71.37it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 66.63it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 68.73it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 69.98it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 72.57it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 72.64it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:02, 69.48it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 71.68it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 71.62it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 74.89it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 75.46it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:03<00:01, 77.44it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 78.11it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 79.72it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 78.48it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 74.59it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 77.13it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 79.16it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 79.18it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 79.16it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 75.73it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 72.18it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 70.73it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 60%|██████    | 417/695 [01:09<00:32,  8.43it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-417\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-417/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3536161184310913, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.396, 'eval_samples_per_second': 288.899, 'eval_steps_per_second': 72.339, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-417/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-417/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-417/special_tokens_map.json\n",
      " 72%|███████▏  | 501/695 [01:23<00:34,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5034, 'learning_rate': 0.0006798795683166193, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 555/695 [01:30<00:16,  8.73it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 96.69it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 81.59it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 80.23it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 76.10it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:04, 59.36it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:04, 63.31it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 64.70it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:01<00:03, 66.46it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 63.88it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 64.72it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 69.59it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 72.40it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 74.06it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 74.25it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 75.52it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 70.97it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:02<00:02, 65.33it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:02<00:02, 63.12it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 64.78it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 68.38it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 70.83it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 73.23it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 69.58it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 66.27it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 70.39it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:03<00:01, 67.17it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:03<00:01, 70.07it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 72.59it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 74.30it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 75.68it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 77.05it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 73.52it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 73.25it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 74.31it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:04<00:00, 70.93it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 72.41it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 73.03it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 69.70it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 69.72it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 80%|████████  | 556/695 [01:35<00:15,  8.73it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4099193215370178, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6089, 'eval_samples_per_second': 275.552, 'eval_steps_per_second': 68.996, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-556/special_tokens_map.json\n",
      "100%|█████████▉| 694/695 [01:55<00:00,  9.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 82.10it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 81.73it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 81.87it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 81.30it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 79.55it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 79.04it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 79.21it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 79.30it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:00<00:02, 80.24it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 75.26it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:03, 72.77it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 75.50it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 77.20it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 77.75it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 79.20it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 81.56it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:01<00:02, 83.45it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:01<00:01, 81.08it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:01, 80.32it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 79.48it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 80.37it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 80.85it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 72.54it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 73.11it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 67.85it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:02<00:01, 68.34it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 70.50it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 72.06it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 69.36it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 70.66it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 72.95it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 75.84it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 77.89it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 79.14it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:03<00:00, 79.99it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 79.58it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      "100%|██████████| 695/695 [01:59<00:00,  9.11it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-695\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-695/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2952350974082947, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2336, 'eval_samples_per_second': 299.981, 'eval_steps_per_second': 75.113, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-695/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-695/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-695/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-1/checkpoint-139 (score: 0.4775812422871246).\n",
      "100%|██████████| 695/695 [02:02<00:00,  5.65it/s]\n",
      "\u001b[32m[I 2022-03-29 17:02:34,249]\u001b[0m Trial 1 finished with value: 1.434667856460353 and parameters: {'learning_rate': 0.0024231605127182075, 'weight_decay': 1.3817325135522506e-06, 'num_train_epochs': 5, 'seed': 39, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 1.434667856460353.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 131.5874, 'train_samples_per_second': 337.684, 'train_steps_per_second': 5.282, 'train_loss': 0.4707317654177439, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 973\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8656<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170028-31ig8mk7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170028-31ig8mk7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.29524</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.2336</td></tr><tr><td>eval/samples_per_second</td><td>299.981</td></tr><tr><td>eval/steps_per_second</td><td>75.113</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>695</td></tr><tr><td>_runtime</td><td>126</td></tr><tr><td>_timestamp</td><td>1648566154</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>train/loss</td><td>0.5034</td></tr><tr><td>train/learning_rate</td><td>0.00068</td></tr><tr><td>train/train_runtime</td><td>131.5874</td></tr><tr><td>train/train_samples_per_second</td><td>337.684</td></tr><tr><td>train/train_steps_per_second</td><td>5.282</td></tr><tr><td>train/total_flos</td><td>453545903897280.0</td></tr><tr><td>train/train_loss</td><td>0.47073</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▁▇▅█▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▅▄█▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▄▅▁█</td></tr><tr><td>eval/steps_per_second</td><td>▄▄▅▁█</td></tr><tr><td>train/epoch</td><td>▁▃▅▆▆██</td></tr><tr><td>train/global_step</td><td>▁▃▅▆▆██</td></tr><tr><td>_runtime</td><td>▁▃▄▅▆██</td></tr><tr><td>_timestamp</td><td>▁▃▄▅▆██</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">solar-sun-11</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/31ig8mk7\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/31ig8mk7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">jumping-breeze-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/19e9qjdr\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/19e9qjdr</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170245-19e9qjdr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 139/973 [00:17<01:46,  7.80it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 76.36it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 74.06it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 74.80it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:04, 69.35it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 72.70it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:03, 75.97it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 72.53it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 71.02it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 74.17it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 77.06it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:02, 79.77it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:02, 80.97it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 82.59it/s]\u001b[A\n",
      " 37%|███▋      | 119/318 [00:01<00:02, 83.72it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 83.14it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 82.59it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 80.11it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:01<00:01, 82.33it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:01, 82.57it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 76.43it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 76.93it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 78.00it/s]\u001b[A\n",
      " 63%|██████▎   | 199/318 [00:02<00:01, 78.83it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 79.00it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:02<00:01, 72.00it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:02<00:01, 73.10it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 73.36it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 75.90it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 77.21it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 71.67it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 70.71it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 74.51it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 64.74it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 67.13it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 70.94it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 71.06it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 72.47it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 14%|█▍        | 139/973 [00:21<01:46,  7.80it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-139\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-139/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33233383297920227, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3154, 'eval_samples_per_second': 294.297, 'eval_steps_per_second': 73.69, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-139/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-139/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-139/special_tokens_map.json\n",
      " 29%|██▊       | 278/973 [00:42<01:15,  9.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 85.16it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 65.01it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 69.91it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 74.63it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 77.60it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 78.66it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 79.88it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:00<00:03, 79.24it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 78.63it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:02, 78.96it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:02, 77.88it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 79.06it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 79.35it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 78.08it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 77.47it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 77.18it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 76.78it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:01<00:02, 76.87it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 75.88it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:01, 75.34it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 73.52it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 75.02it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 76.15it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 75.84it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 71.47it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 73.39it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:02<00:01, 69.62it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 72.19it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 68.59it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:01, 63.68it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 66.56it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 64.88it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 65.22it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 67.39it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 65.65it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:03<00:00, 69.20it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 72.96it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 73.12it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 74.97it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 29%|██▊       | 278/973 [00:46<01:15,  9.15it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34683507680892944, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3963, 'eval_samples_per_second': 288.879, 'eval_steps_per_second': 72.334, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-278/special_tokens_map.json\n",
      " 43%|████▎     | 416/973 [01:07<01:08,  8.09it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 90.82it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 84.26it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 83.29it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 74.63it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:03, 76.19it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 74.47it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 75.23it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 75.83it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 76.36it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 76.86it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:02, 76.92it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 76.82it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:03, 69.23it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 70.73it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 71.54it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 73.85it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 74.85it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 75.26it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 69.39it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 71.47it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:02, 68.10it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 69.62it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 71.94it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 71.11it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 74.14it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 76.05it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 77.49it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 67.87it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 68.27it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 72.06it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 73.13it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 75.45it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 76.35it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 76.28it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 71.25it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 71.83it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 71.46it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 73.56it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 43%|████▎     | 417/973 [01:11<01:08,  8.09it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-417\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-417/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36281710863113403, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4084, 'eval_samples_per_second': 288.084, 'eval_steps_per_second': 72.134, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-417/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-417/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-417/special_tokens_map.json\n",
      " 51%|█████▏    | 501/973 [01:26<01:35,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4066, 'learning_rate': 0.0004129435424970161, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 555/973 [01:32<00:57,  7.33it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 90.45it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 78.87it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:03, 73.30it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:04, 67.93it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:04, 64.52it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 68.84it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 73.17it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 70.46it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 71.16it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 71.44it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:03, 71.37it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:03, 63.84it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:03, 67.51it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:03, 60.86it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 65.31it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 70.08it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:02<00:02, 69.25it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 70.70it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 68.64it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 71.17it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 70.93it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 73.71it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 71.79it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 72.30it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 73.61it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 74.47it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 69.68it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 62.80it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 63.70it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 67.79it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 70.74it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 72.80it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 75.39it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 72.34it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 74.15it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 75.20it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 74.62it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 71.88it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 69.56it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 57%|█████▋    | 556/973 [01:37<00:56,  7.33it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32012939453125, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6253, 'eval_samples_per_second': 274.58, 'eval_steps_per_second': 68.753, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-556/special_tokens_map.json\n",
      " 71%|███████▏  | 694/973 [01:57<00:33,  8.31it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 66.09it/s]\u001b[A\n",
      "  4%|▍         | 14/318 [00:00<00:05, 51.50it/s]\u001b[A\n",
      "  7%|▋         | 22/318 [00:00<00:04, 60.71it/s]\u001b[A\n",
      "  9%|▉         | 30/318 [00:00<00:04, 66.57it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 70.92it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 71.86it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 72.70it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 74.20it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:01<00:03, 75.24it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 70.53it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 70.75it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:03, 73.21it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:03, 70.60it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 72.83it/s]\u001b[A\n",
      " 37%|███▋      | 119/318 [00:01<00:02, 73.91it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 76.53it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 77.99it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 77.99it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 75.41it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 73.11it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 73.98it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 75.46it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 76.30it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 75.37it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 74.46it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 73.04it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 74.59it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 75.17it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 75.92it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:00, 77.46it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 75.66it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 74.14it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 75.40it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 76.21it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 76.84it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 77.33it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 73.64it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 74.81it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 75.31it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 71%|███████▏  | 695/973 [02:01<00:33,  8.31it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-695\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-695/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2966465651988983, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4088, 'eval_samples_per_second': 288.059, 'eval_steps_per_second': 72.128, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-695/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-695/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-695/special_tokens_map.json\n",
      " 86%|████████▌ | 834/973 [02:22<00:16,  8.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 86.65it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 85.55it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 85.31it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 79.31it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 74.73it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 72.56it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 74.27it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 73.10it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 72.32it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 66.89it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 68.81it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:02, 72.65it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 75.06it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 75.28it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 75.01it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 74.44it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:01<00:02, 76.22it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 74.00it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 75.44it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:01, 76.70it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 77.23it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 78.73it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 74.53it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 69.88it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 63.81it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 68.64it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 63.46it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 65.35it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 68.87it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 72.41it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 74.39it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 76.63it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 76.47it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 77.25it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 71.64it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 70.24it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 69.18it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 70.00it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      " 86%|████████▌ | 834/973 [02:27<00:16,  8.47it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29293376207351685, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4586, 'eval_samples_per_second': 284.841, 'eval_steps_per_second': 71.322, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-834/special_tokens_map.json\n",
      "100%|██████████| 973/973 [02:48<00:00,  7.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.91it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 76.13it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 65.56it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:04, 63.49it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:04, 61.58it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:04, 62.72it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:04, 65.33it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 65.41it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:01<00:04, 61.46it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 65.86it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 66.74it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 67.13it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 70.59it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 73.80it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 75.11it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 76.03it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 76.42it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:02<00:02, 69.51it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 69.44it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 70.72it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 71.15it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:02, 72.89it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 74.46it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 76.36it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 71.17it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 73.21it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:03<00:01, 74.07it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 69.63it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 67.48it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 66.62it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:01, 65.21it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 68.42it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 71.00it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 73.32it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 74.98it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:04<00:00, 74.11it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 74.09it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 74.91it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 71.42it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 72.30it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                 \n",
      "100%|██████████| 973/973 [02:53<00:00,  7.13it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-973\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-973/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2927788197994232, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6001, 'eval_samples_per_second': 276.078, 'eval_steps_per_second': 69.128, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-973/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-973/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-973/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-2/checkpoint-139 (score: 0.4775812422871246).\n",
      "100%|██████████| 973/973 [02:57<00:00,  5.49it/s]\n",
      "\u001b[32m[I 2022-03-29 17:05:45,836]\u001b[0m Trial 2 finished with value: 1.434667856460353 and parameters: {'learning_rate': 0.0008494589151154263, 'weight_decay': 2.835858876096589e-09, 'num_train_epochs': 7, 'seed': 27, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 1.434667856460353.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 187.3572, 'train_samples_per_second': 332.034, 'train_steps_per_second': 5.193, 'train_loss': 0.3802850141064604, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9148<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170245-19e9qjdr/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170245-19e9qjdr/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.29278</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.6001</td></tr><tr><td>eval/samples_per_second</td><td>276.078</td></tr><tr><td>eval/steps_per_second</td><td>69.128</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>973</td></tr><tr><td>_runtime</td><td>179</td></tr><tr><td>_timestamp</td><td>1648566345</td></tr><tr><td>_step</td><td>8</td></tr><tr><td>train/loss</td><td>0.4066</td></tr><tr><td>train/learning_rate</td><td>0.00041</td></tr><tr><td>train/train_runtime</td><td>187.3572</td></tr><tr><td>train/train_samples_per_second</td><td>332.034</td></tr><tr><td>train/train_steps_per_second</td><td>5.193</td></tr><tr><td>train/total_flos</td><td>635469726460200.0</td></tr><tr><td>train/train_loss</td><td>0.38029</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▅▆█▄▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▃▃█▃▄▇</td></tr><tr><td>eval/samples_per_second</td><td>█▆▆▁▆▅▂</td></tr><tr><td>eval/steps_per_second</td><td>█▆▆▁▆▅▂</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇██</td></tr><tr><td>_runtime</td><td>▁▂▃▄▄▆▇██</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▄▆▇██</td></tr><tr><td>_step</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">jumping-breeze-12</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/19e9qjdr\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/19e9qjdr</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vibrant-glade-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2ppoaz56\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2ppoaz56</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170556-2ppoaz56</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 139/2224 [00:18<03:57,  8.78it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 87.27it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 75.05it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 62.34it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 67.01it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:04, 60.51it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:04, 64.89it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 68.11it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 69.62it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:01<00:03, 71.67it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 73.37it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 74.83it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 76.73it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 77.07it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 71.94it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:03, 60.45it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:03, 60.28it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:02<00:02, 61.95it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 67.41it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 68.44it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 69.82it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 69.76it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:02, 61.21it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:02, 64.89it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 68.48it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 71.23it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:03<00:01, 73.51it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:03<00:01, 74.34it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 74.78it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 73.46it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 67.18it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:01, 68.87it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 71.52it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 70.89it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 69.03it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:04<00:00, 71.85it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:04<00:00, 74.65it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 77.08it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 75.71it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 76.78it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "  6%|▋         | 139/2224 [00:22<03:57,  8.78it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-139\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-139/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.320453017950058, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6437, 'eval_samples_per_second': 273.491, 'eval_steps_per_second': 68.48, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-139/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-139/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-139/special_tokens_map.json\n",
      " 12%|█▏        | 277/2224 [00:43<04:28,  7.26it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.48it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 84.38it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:04, 70.40it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:03, 71.87it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:04, 67.87it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 67.42it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:04, 63.14it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 67.75it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 72.28it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 71.71it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 72.52it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 74.21it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 74.13it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 76.76it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 77.35it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 79.47it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 68.95it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 63.69it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 68.33it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 70.89it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 74.24it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 78.17it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 80.73it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 81.87it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 83.04it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 75.19it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 69.43it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 60.39it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 62.18it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 67.41it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 66.86it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 70.08it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 75.03it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 79.01it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:04<00:00, 81.78it/s]\u001b[A\n",
      " 96%|█████████▌| 305/318 [00:04<00:00, 82.70it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 84.52it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 12%|█▎        | 278/2224 [00:48<04:27,  7.26it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3068886995315552, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3833, 'eval_samples_per_second': 289.736, 'eval_steps_per_second': 72.548, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-278/special_tokens_map.json\n",
      " 19%|█▊        | 416/2224 [01:08<03:28,  8.67it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 80.80it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 80.93it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 82.29it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 80.26it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 81.47it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 81.57it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 81.03it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 81.68it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:00<00:02, 81.93it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 74.92it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 74.85it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 74.80it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 77.51it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 79.50it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 80.06it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 79.21it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 78.94it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:01<00:01, 81.86it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 76.62it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 73.19it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 75.61it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 73.46it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 70.86it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 74.01it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 74.17it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:02<00:01, 76.30it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 77.77it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 79.21it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 80.18it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 75.59it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 74.88it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 77.47it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:03<00:00, 77.13it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:03<00:00, 70.57it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:03<00:00, 71.47it/s]\u001b[A\n",
      " 98%|█████████▊| 313/318 [00:04<00:00, 74.44it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 19%|█▉        | 417/2224 [01:12<03:28,  8.67it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-417\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-417/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4481296241283417, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2174, 'eval_samples_per_second': 301.13, 'eval_steps_per_second': 75.401, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-417/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-417/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-417/special_tokens_map.json\n",
      " 23%|██▎       | 501/2224 [01:26<05:03,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4802, 'learning_rate': 0.0019306953643728722, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 555/2224 [01:32<03:13,  8.62it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 78.51it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 67.31it/s]\u001b[A\n",
      "  8%|▊         | 25/318 [00:00<00:03, 73.33it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:03, 75.45it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 78.00it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 75.83it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 74.32it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 73.67it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:00<00:03, 76.31it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 77.14it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:02, 76.07it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 78.01it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 79.67it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 78.89it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 74.28it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 76.42it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:01<00:02, 78.16it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 71.14it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 74.80it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 72.88it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 71.46it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 71.44it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 72.19it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 71.84it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 74.76it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 75.42it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 77.51it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 79.19it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 78.71it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 74.86it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 75.56it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 71.72it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 73.67it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 76.09it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:03<00:00, 70.54it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 71.19it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 72.54it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 71.35it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 25%|██▌       | 556/2224 [01:37<03:13,  8.62it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41163647174835205, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3854, 'eval_samples_per_second': 289.594, 'eval_steps_per_second': 72.513, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-556/special_tokens_map.json\n",
      " 31%|███       | 694/2224 [01:56<03:26,  7.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 64.60it/s]\u001b[A\n",
      "  5%|▍         | 15/318 [00:00<00:04, 73.29it/s]\u001b[A\n",
      "  7%|▋         | 23/318 [00:00<00:04, 72.00it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:03, 73.50it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:04, 68.86it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 72.16it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 67.30it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 71.23it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:01<00:03, 72.98it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 75.71it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:02, 76.91it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 77.78it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 71.72it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:03, 66.73it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 71.05it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 69.10it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 68.50it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 67.56it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 64.76it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 64.53it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 69.23it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 73.28it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 76.62it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 76.46it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 72.10it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 74.71it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 76.08it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 75.07it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 74.18it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 75.38it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 70.61it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 66.42it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 71.12it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 72.52it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 74.05it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 73.33it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 70.39it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 71.67it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.03it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 31%|███▏      | 695/2224 [02:01<03:26,  7.42it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-695\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-695/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3783847689628601, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5411, 'eval_samples_per_second': 279.666, 'eval_steps_per_second': 70.027, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-695/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-695/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-695/special_tokens_map.json\n",
      " 37%|███▋      | 833/2224 [02:20<02:52,  8.07it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.65it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.82it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 76.94it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 73.45it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 76.07it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 78.31it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 78.60it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 78.42it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 75.78it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:03, 72.67it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:03, 73.26it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 75.64it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 78.16it/s]\u001b[A\n",
      " 37%|███▋      | 119/318 [00:01<00:02, 77.53it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 78.07it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 80.24it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 80.35it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:01<00:02, 80.59it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 70.29it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 69.25it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:02, 66.29it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:02, 63.94it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 68.71it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 67.91it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 68.03it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 72.23it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 74.21it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 74.94it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 76.98it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 77.32it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 78.87it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 75.60it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 76.11it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 78.92it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:03<00:00, 80.14it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 77.67it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 78.98it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 38%|███▊      | 834/2224 [02:25<02:52,  8.07it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.332744300365448, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3112, 'eval_samples_per_second': 294.579, 'eval_steps_per_second': 73.761, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-834/special_tokens_map.json\n",
      " 44%|████▎     | 972/2224 [02:44<02:15,  9.25it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 76.65it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 67.83it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 72.07it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 74.51it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 74.05it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 74.00it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 75.44it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 78.09it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:00<00:03, 77.68it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 77.68it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 70.81it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:03, 72.77it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 72.04it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 74.64it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 76.06it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 76.95it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 76.69it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:01<00:02, 76.65it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 65.89it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 66.45it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 68.56it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 58.99it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:02, 57.99it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:02, 60.52it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 64.02it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 67.80it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:03<00:01, 70.26it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 68.59it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 67.73it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 67.95it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 70.23it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 70.89it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 74.07it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 76.77it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 74.98it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 77.69it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 78.16it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 79.12it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 80.29it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 44%|████▍     | 973/2224 [02:48<02:15,  9.25it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-973\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-973/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35396766662597656, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5397, 'eval_samples_per_second': 279.752, 'eval_steps_per_second': 70.048, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-973/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-973/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-973/special_tokens_map.json\n",
      " 45%|████▌     | 1001/2224 [02:55<02:41,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4317, 'learning_rate': 0.0013707489129886287, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1112/2224 [03:09<01:53,  9.77it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 6/318 [00:00<00:05, 58.10it/s]\u001b[A\n",
      "  4%|▍         | 13/318 [00:00<00:04, 64.11it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:04, 61.13it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 67.54it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:04, 69.23it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 72.01it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 74.42it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 77.14it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 77.74it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 77.85it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:02, 77.91it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:02, 79.45it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 78.18it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 77.07it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 76.19it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 73.47it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 75.11it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:01<00:02, 76.49it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 72.96it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 69.66it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 71.22it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 74.54it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 72.37it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 75.45it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 71.81it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 73.13it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 74.68it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 74.61it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 72.90it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 74.24it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 75.12it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 76.09it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 77.95it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 77.73it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 77.12it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 63.26it/s]\u001b[A\n",
      " 93%|█████████▎| 297/318 [00:04<00:00, 63.17it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 62.62it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 64.55it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 50%|█████     | 1112/2224 [03:13<01:53,  9.77it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3591021001338959, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4617, 'eval_samples_per_second': 284.645, 'eval_steps_per_second': 71.273, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1112/config.json\n",
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1112/special_tokens_map.json\n",
      " 56%|█████▋    | 1251/2224 [03:33<01:42,  9.52it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.00it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 80.17it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:04, 70.99it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 72.25it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 72.96it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 68.98it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 71.62it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 74.53it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 69.70it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:03, 70.65it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:03, 70.36it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:02, 72.71it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 72.24it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 72.05it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 72.74it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 74.76it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 77.82it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 76.47it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 76.51it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 71.51it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:02, 71.92it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 73.93it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 73.77it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 68.44it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 70.13it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:02<00:01, 71.13it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 72.92it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 71.71it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 73.11it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 74.24it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 75.61it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 75.95it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 75.94it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 76.75it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 76.77it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 71.34it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 72.29it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 66.32it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 65.40it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 56%|█████▋    | 1251/2224 [03:38<01:42,  9.52it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1251\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1251/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3570883274078369, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4964, 'eval_samples_per_second': 282.448, 'eval_steps_per_second': 70.723, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1251/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1251/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1251/special_tokens_map.json\n",
      " 62%|██████▎   | 1390/2224 [03:58<01:33,  8.96it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.69it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:04, 70.86it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:03, 74.05it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 73.59it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 74.59it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:04, 64.89it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:04, 63.50it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 64.52it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 68.05it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 71.82it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 72.50it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 72.39it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 74.06it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 75.00it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 76.69it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 77.08it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 71.54it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 68.32it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 68.37it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 65.83it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 68.81it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 71.34it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 74.38it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 74.88it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 73.20it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 73.15it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 75.55it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 75.17it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 75.83it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 76.92it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 76.60it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 77.96it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 78.20it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 78.94it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 79.16it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 76.22it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 73.93it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 75.73it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 62%|██████▎   | 1390/2224 [04:03<01:33,  8.96it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1390\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1390/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3031848073005676, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4279, 'eval_samples_per_second': 286.817, 'eval_steps_per_second': 71.817, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1390/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1390/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1390/special_tokens_map.json\n",
      " 67%|██████▋   | 1501/2224 [04:20<02:02,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3962, 'learning_rate': 0.0008108024616043848, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 1528/2224 [04:23<01:37,  7.16it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 85.30it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.74it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 71.45it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 73.77it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 73.15it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 73.22it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 74.30it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 69.97it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 72.38it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 73.46it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 72.36it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 71.88it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:03, 70.58it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 70.86it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 72.09it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 69.42it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 69.63it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 68.15it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 64.06it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 62.15it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 61.02it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:02, 65.40it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:02, 61.19it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 65.77it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 66.76it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 68.96it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 71.89it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 62.15it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 62.38it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 66.64it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 66.20it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:01, 61.60it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 65.62it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 69.31it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 72.27it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:04<00:00, 74.12it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:04<00:00, 74.80it/s]\u001b[A\n",
      " 93%|█████████▎| 297/318 [00:04<00:00, 76.12it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 75.73it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 77.37it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 69%|██████▉   | 1529/2224 [04:28<01:37,  7.16it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1529\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1529/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2963477075099945, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6389, 'eval_samples_per_second': 273.769, 'eval_steps_per_second': 68.55, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1529/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1529/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1529/special_tokens_map.json\n",
      " 75%|███████▌  | 1668/2224 [04:48<01:03,  8.72it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 90.12it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:04, 67.49it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 66.58it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 70.88it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 71.63it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 73.45it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 72.24it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 74.22it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 75.81it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 73.17it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 72.91it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 74.16it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 75.50it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 77.57it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 75.07it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 75.06it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 74.24it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 72.62it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 69.67it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 71.49it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 73.22it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 74.97it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 75.91it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 72.31it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 73.60it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 74.02it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 71.14it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 73.28it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 74.10it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 74.00it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 75.44it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 77.28it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 68.10it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 66.80it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 68.27it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 66.75it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 66.53it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 65.21it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 69.06it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 75%|███████▌  | 1668/2224 [04:52<01:03,  8.72it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1668\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29509976506233215, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.515, 'eval_samples_per_second': 281.286, 'eval_steps_per_second': 70.432, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1668/special_tokens_map.json\n",
      " 81%|████████  | 1806/2224 [05:13<00:50,  8.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 89.43it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 81.60it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 78.78it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 71.71it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 73.50it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 74.69it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 71.49it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 72.18it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 71.81it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 72.09it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 69.59it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 66.92it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:03, 68.87it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 70.98it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 71.49it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 68.86it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 69.45it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 69.41it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 71.88it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 74.73it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:01, 76.49it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 71.86it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 73.15it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 74.18it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 75.71it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 75.89it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:03<00:01, 73.60it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 75.79it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 76.92it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 78.01it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 78.03it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 77.90it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 74.41it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 72.98it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 74.42it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 69.24it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 71.84it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 74.71it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.26it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 81%|████████▏ | 1807/2224 [05:18<00:50,  8.23it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1807\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1807/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2935766875743866, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.446, 'eval_samples_per_second': 285.647, 'eval_steps_per_second': 71.524, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1807/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1807/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1807/special_tokens_map.json\n",
      " 88%|████████▊ | 1946/2224 [05:39<00:32,  8.54it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 63.48it/s]\u001b[A\n",
      "  5%|▍         | 15/318 [00:00<00:05, 53.01it/s]\u001b[A\n",
      "  7%|▋         | 21/318 [00:00<00:05, 50.34it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:05, 55.63it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:05, 55.61it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:04, 59.27it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:04, 63.40it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:04, 61.14it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:01<00:04, 61.61it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:01<00:03, 63.78it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 64.87it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 69.06it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 71.48it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:02, 74.11it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 74.09it/s]\u001b[A\n",
      " 37%|███▋      | 119/318 [00:01<00:02, 70.23it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 71.43it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:02<00:02, 70.17it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:02<00:02, 70.67it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 72.20it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 70.59it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 72.18it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 73.16it/s]\u001b[A\n",
      " 58%|█████▊    | 183/318 [00:02<00:01, 74.22it/s]\u001b[A\n",
      " 60%|██████    | 191/318 [00:02<00:01, 75.28it/s]\u001b[A\n",
      " 63%|██████▎   | 199/318 [00:02<00:01, 75.28it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:03<00:01, 74.38it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:03<00:01, 66.73it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:03<00:01, 70.06it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 68.68it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 60.52it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:01, 65.84it/s]\u001b[A\n",
      " 80%|████████  | 255/318 [00:03<00:00, 68.33it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 70.82it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:04<00:00, 65.31it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:04<00:00, 66.64it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:04<00:00, 68.94it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 68.16it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 65.09it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 63.07it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 68.05it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 88%|████████▊ | 1946/2224 [05:44<00:32,  8.54it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1946\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1946/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29277467727661133, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.8441, 'eval_samples_per_second': 262.173, 'eval_steps_per_second': 65.646, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-1946/special_tokens_map.json\n",
      " 90%|████████▉ | 2001/2224 [05:54<00:36,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3536, 'learning_rate': 0.0002508560102201412, 'epoch': 14.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 2084/2224 [06:04<00:20,  6.78it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 89.88it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.30it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 78.23it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 77.14it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 74.26it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 67.27it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 69.58it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 71.62it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 72.36it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 73.19it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 70.73it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 69.09it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:03, 70.27it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 71.52it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 72.78it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 72.05it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 65.74it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 66.78it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 64.49it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 61.55it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 64.54it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:02, 64.84it/s]\u001b[A\n",
      " 58%|█████▊    | 183/318 [00:02<00:01, 68.23it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 68.31it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 71.23it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 71.05it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 72.09it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 62.77it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 61.03it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 61.11it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 64.45it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:01, 56.49it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:01, 52.72it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 56.68it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:04<00:00, 62.15it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:04<00:00, 66.25it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:04<00:00, 69.48it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:04<00:00, 68.62it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 68.31it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 69.50it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 94%|█████████▍| 2085/2224 [06:09<00:20,  6.78it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2085\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2085/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2928142249584198, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.7716, 'eval_samples_per_second': 266.157, 'eval_steps_per_second': 66.644, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2085/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2085/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2085/special_tokens_map.json\n",
      "100%|██████████| 2224/2224 [06:30<00:00,  8.50it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 78.44it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 69.29it/s]\u001b[A\n",
      "  7%|▋         | 23/318 [00:00<00:04, 67.62it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:04, 70.37it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 71.79it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 73.89it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 71.10it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 71.29it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:00<00:03, 72.18it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 73.89it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 68.66it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 61.17it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:03, 63.84it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:03, 66.76it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 67.45it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:03, 64.37it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 64.62it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:02<00:02, 65.71it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 69.56it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 70.50it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 71.87it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 67.57it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 69.77it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 67.20it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 65.11it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 68.37it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:03<00:01, 63.77it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:03<00:01, 62.38it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 63.62it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 65.07it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 68.46it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 69.84it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 70.64it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 71.15it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 73.39it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:04<00:00, 74.90it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:04<00:00, 75.72it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 76.58it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 75.77it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 74.63it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 75.02it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "100%|██████████| 2224/2224 [06:35<00:00,  8.50it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2224\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2929558753967285, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6899, 'eval_samples_per_second': 270.793, 'eval_steps_per_second': 67.805, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-2224/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-3/checkpoint-139 (score: 0.4775812422871246).\n",
      "100%|██████████| 2224/2224 [06:39<00:00,  5.57it/s]\n",
      "\u001b[32m[I 2022-03-29 17:12:38,615]\u001b[0m Trial 3 finished with value: 1.434667856460353 and parameters: {'learning_rate': 0.002490641815757116, 'weight_decay': 1.7100001240638694e-05, 'num_train_epochs': 16, 'seed': 26, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 1.434667856460353.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 408.6615, 'train_samples_per_second': 347.946, 'train_steps_per_second': 5.442, 'train_loss': 0.4068588181365308, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9852<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170556-2ppoaz56/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_170556-2ppoaz56/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.29296</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.6899</td></tr><tr><td>eval/samples_per_second</td><td>270.793</td></tr><tr><td>eval/steps_per_second</td><td>67.805</td></tr><tr><td>train/epoch</td><td>16.0</td></tr><tr><td>train/global_step</td><td>2224</td></tr><tr><td>_runtime</td><td>402</td></tr><tr><td>_timestamp</td><td>1648566758</td></tr><tr><td>_step</td><td>20</td></tr><tr><td>train/loss</td><td>0.3536</td></tr><tr><td>train/learning_rate</td><td>0.00025</td></tr><tr><td>train/train_runtime</td><td>408.6615</td></tr><tr><td>train/train_samples_per_second</td><td>347.946</td></tr><tr><td>train/train_steps_per_second</td><td>5.442</td></tr><tr><td>train/total_flos</td><td>1452957317130060.0</td></tr><tr><td>train/train_loss</td><td>0.40686</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▂▂█▆▅▃▄▄▄▁▁▁▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▃▁▃▅▂▅▄▄▃▆▄▄█▇▆</td></tr><tr><td>eval/samples_per_second</td><td>▃▆█▆▄▇▄▅▅▅▃▄▅▁▂▃</td></tr><tr><td>eval/steps_per_second</td><td>▃▆█▆▄▇▄▅▅▅▃▄▅▁▂▃</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">vibrant-glade-13</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2ppoaz56\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2ppoaz56</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dry-blaze-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2z7gxtwl\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2z7gxtwl</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_171248-2z7gxtwl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 501/19998 [00:50<41:22,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7598, 'learning_rate': 0.0022551185040614453, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1001/19998 [01:33<39:36,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6408, 'learning_rate': 0.002197289021446268, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1501/19998 [02:17<40:30,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.702, 'learning_rate': 0.002139459538831091, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2003/19998 [03:00<26:55, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8806, 'learning_rate': 0.002081630056215914, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2221/19998 [03:19<26:19, 11.25it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 88.69it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 63.92it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 69.47it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 73.75it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 75.69it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 67.53it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 65.84it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 70.90it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 71.10it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 73.11it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 74.66it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:02, 74.74it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 77.04it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 77.75it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 76.82it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 77.70it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 78.80it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 79.54it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 79.45it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:01, 79.99it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 77.06it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 78.94it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 79.06it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 69.04it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 56.16it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:03<00:01, 56.92it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 58.96it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 62.60it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 65.82it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:01, 70.09it/s]\u001b[A\n",
      " 80%|████████  | 255/318 [00:03<00:00, 66.99it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 63.53it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 68.46it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 61.87it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 66.30it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 68.15it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 71.95it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 74.47it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                    \n",
      " 11%|█         | 2222/19998 [03:24<26:19, 11.25it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-2222\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-2222/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.818261444568634, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5757, 'eval_samples_per_second': 277.553, 'eval_steps_per_second': 69.498, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-2222/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-2222/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-2222/special_tokens_map.json\n",
      " 13%|█▎        | 2501/19998 [03:53<49:58,  5.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7975, 'learning_rate': 0.0020238005736007373, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3001/19998 [04:38<31:58,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7875, 'learning_rate': 0.00196597109098556, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3502/19998 [05:22<29:03,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7189, 'learning_rate': 0.0019081416083703829, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4002/19998 [06:06<31:12,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6096, 'learning_rate': 0.001850312125755206, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4443/19998 [06:45<27:11,  9.53it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 87.70it/s]\u001b[A\n",
      "  6%|▌         | 19/318 [00:00<00:03, 91.14it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 89.30it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 91.43it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:02, 91.69it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:02, 91.80it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:02, 93.06it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:00<00:02, 82.76it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:02, 81.53it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 81.36it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:03, 70.44it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:03, 67.16it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 67.26it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 67.55it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 72.21it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:01<00:02, 74.81it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:01<00:02, 78.51it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:01, 81.70it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:01, 81.63it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 84.35it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 82.31it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 79.23it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 80.85it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:02<00:01, 82.09it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:02<00:01, 76.78it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:02<00:01, 79.76it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:00, 75.58it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 77.99it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 80.89it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 81.15it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 82.67it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 81.56it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:03<00:00, 83.41it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:03<00:00, 83.49it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                    \n",
      " 22%|██▏       | 4444/19998 [06:49<27:11,  9.53it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-4444\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-4444/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5727452039718628, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.0402, 'eval_samples_per_second': 314.342, 'eval_steps_per_second': 78.709, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-4444/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-4444/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-4444/special_tokens_map.json\n",
      " 23%|██▎       | 4502/19998 [06:58<26:18,  9.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5515, 'learning_rate': 0.0017924826431400288, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5001/19998 [07:40<26:07,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5819, 'learning_rate': 0.0017346531605248515, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5503/19998 [08:20<18:48, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4587, 'learning_rate': 0.0016768236779096746, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6001/19998 [09:03<27:40,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5216, 'learning_rate': 0.0016189941952944975, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6501/19998 [09:44<27:49,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3951, 'learning_rate': 0.0015611647126793204, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6665/19998 [09:59<19:49, 11.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 89.61it/s]\u001b[A\n",
      "  6%|▌         | 19/318 [00:00<00:03, 83.72it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:03, 83.50it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:03, 75.08it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 76.63it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 78.13it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 79.58it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 80.57it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 74.05it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 64.24it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:03, 67.47it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 71.68it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 73.59it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 76.33it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 78.81it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 80.01it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 79.69it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:01, 79.89it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 78.64it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 78.72it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 73.71it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 69.22it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 66.98it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 69.76it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 72.22it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:02<00:01, 73.20it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 74.23it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 74.82it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 75.86it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 76.51it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 76.65it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 78.94it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 80.33it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 79.07it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:03<00:00, 78.77it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 79.61it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 78.44it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                    \n",
      " 33%|███▎      | 6666/19998 [10:03<19:49, 11.21it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-6666\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-6666/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3134390413761139, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3278, 'eval_samples_per_second': 293.455, 'eval_steps_per_second': 73.479, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-6666/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-6666/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-6666/special_tokens_map.json\n",
      " 35%|███▌      | 7001/19998 [10:38<25:20,  8.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.439, 'learning_rate': 0.0015033352300641435, 'epoch': 3.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 7503/19998 [11:23<20:10, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4346, 'learning_rate': 0.0014455057474489664, 'epoch': 3.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8001/19998 [12:07<24:15,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.409, 'learning_rate': 0.001387676264833789, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 8501/19998 [12:51<24:35,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4246, 'learning_rate': 0.0013298467822186121, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8887/19998 [13:25<15:04, 12.28it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 66.75it/s]\u001b[A\n",
      "  5%|▍         | 15/318 [00:00<00:04, 66.82it/s]\u001b[A\n",
      "  7%|▋         | 22/318 [00:00<00:04, 62.57it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:04, 64.23it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:04, 67.75it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 70.66it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 70.65it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 72.70it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 75.04it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 76.09it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 76.72it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 67.11it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:03, 66.31it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 69.92it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 69.00it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 71.86it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 65.40it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:02<00:02, 69.85it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 70.81it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 71.51it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 70.45it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:01, 72.39it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 73.65it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 74.71it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 75.68it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 72.41it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 73.26it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 74.40it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 75.71it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 74.23it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 71.56it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 73.73it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 68.89it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 70.26it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 71.09it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 67.54it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 69.60it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 68.24it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 71.63it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                    \n",
      " 44%|████▍     | 8888/19998 [13:30<15:04, 12.28it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-8888\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-8888/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2958014905452728, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5695, 'eval_samples_per_second': 277.928, 'eval_steps_per_second': 69.591, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-8888/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-8888/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-8888/special_tokens_map.json\n",
      " 45%|████▌     | 9001/19998 [13:43<20:09,  9.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4036, 'learning_rate': 0.001272017299603435, 'epoch': 4.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 9501/19998 [14:25<19:55,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3876, 'learning_rate': 0.001214187816988258, 'epoch': 4.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10001/19998 [15:06<17:53,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3687, 'learning_rate': 0.0011563583343730808, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 10502/19998 [15:47<15:13, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3952, 'learning_rate': 0.0010985288517579039, 'epoch': 4.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11001/19998 [16:30<19:38,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4121, 'learning_rate': 0.0010406993691427268, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 11110/19998 [16:40<13:08, 11.28it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 88.42it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 77.91it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 77.03it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 75.35it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 75.95it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 76.48it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 75.75it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 76.33it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 74.84it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 75.94it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:02, 77.07it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 75.60it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 74.27it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 72.44it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 69.23it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 68.77it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 70.69it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 72.22it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 65.77it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 66.67it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 57.88it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:02, 59.70it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:02, 64.73it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 68.06it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 69.91it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 69.04it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:03<00:01, 71.31it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 72.42it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 70.13it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 64.45it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:01, 67.70it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 69.97it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 68.20it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 70.57it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 71.33it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:04<00:00, 73.10it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:04<00:00, 74.43it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 74.90it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 74.28it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                     \n",
      " 56%|█████▌    | 11110/19998 [16:45<13:08, 11.28it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-11110\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-11110/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45962077379226685, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5529, 'eval_samples_per_second': 278.941, 'eval_steps_per_second': 69.845, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-11110/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-11110/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-11110/special_tokens_map.json\n",
      " 58%|█████▊    | 11501/19998 [17:23<20:08,  7.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3701, 'learning_rate': 0.0009828698865275497, 'epoch': 5.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12001/19998 [18:07<14:37,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.369, 'learning_rate': 0.0009250404039123725, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 12501/19998 [18:50<17:21,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.395, 'learning_rate': 0.0008672109212971955, 'epoch': 5.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13002/19998 [19:33<12:50,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3635, 'learning_rate': 0.0008093814386820184, 'epoch': 5.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 13331/19998 [20:02<08:46, 12.67it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 93.76it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 85.17it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 83.99it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 83.36it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 78.04it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 76.16it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 75.83it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 78.69it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 74.25it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 75.27it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 77.74it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 79.68it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 80.06it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 80.27it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 79.89it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 80.19it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:01<00:02, 80.01it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 77.08it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 76.33it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 76.10it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 77.02it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 77.86it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 67.31it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 65.85it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:02<00:01, 65.58it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:02<00:01, 68.98it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 73.40it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 77.06it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 77.83it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 77.63it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 74.91it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 76.95it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 78.03it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 78.36it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:03<00:00, 72.36it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 73.10it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 74.85it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                     \n",
      " 67%|██████▋   | 13332/19998 [20:07<08:45, 12.67it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-13332\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-13332/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29666534066200256, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2738, 'eval_samples_per_second': 297.161, 'eval_steps_per_second': 74.407, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-13332/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-13332/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-13332/special_tokens_map.json\n",
      " 68%|██████▊   | 13501/19998 [20:24<13:20,  8.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3542, 'learning_rate': 0.0007515519560668413, 'epoch': 6.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14002/19998 [21:05<09:06, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3611, 'learning_rate': 0.0006937224734516643, 'epoch': 6.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 14502/19998 [21:46<08:47, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3501, 'learning_rate': 0.0006358929908364872, 'epoch': 6.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15002/19998 [22:27<08:13, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3548, 'learning_rate': 0.0005780635082213101, 'epoch': 6.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 15502/19998 [23:13<07:47,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3655, 'learning_rate': 0.0005202340256061329, 'epoch': 6.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 15554/19998 [23:17<07:13, 10.25it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 6/318 [00:00<00:05, 56.10it/s]\u001b[A\n",
      "  4%|▍         | 13/318 [00:00<00:05, 60.02it/s]\u001b[A\n",
      "  7%|▋         | 21/318 [00:00<00:04, 65.62it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 65.06it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:04, 65.89it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:04, 68.74it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 71.63it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 73.92it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 72.58it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 73.16it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 73.45it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 73.21it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 65.23it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:03, 68.94it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 70.19it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 73.40it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 73.89it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:02<00:02, 70.11it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 66.54it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 68.98it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 70.30it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 71.16it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 70.73it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 71.83it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 70.32it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 67.28it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 66.59it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 69.34it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 65.30it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 64.86it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 68.06it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 69.71it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 70.67it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 72.83it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 69.75it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:04<00:00, 70.09it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:04<00:00, 71.18it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 71.58it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 73.19it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 73.28it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                     \n",
      " 78%|███████▊  | 15554/19998 [23:22<07:13, 10.25it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-15554\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-15554/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29574865102767944, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6878, 'eval_samples_per_second': 270.916, 'eval_steps_per_second': 67.836, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-15554/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-15554/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-15554/special_tokens_map.json\n",
      " 80%|████████  | 16001/19998 [24:06<07:46,  8.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3286, 'learning_rate': 0.0004624045429909559, 'epoch': 7.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 16502/19998 [24:51<06:40,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3711, 'learning_rate': 0.0004045750603757789, 'epoch': 7.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17001/19998 [25:35<06:03,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3387, 'learning_rate': 0.00034674557776060176, 'epoch': 7.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 17501/19998 [26:20<05:57,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3345, 'learning_rate': 0.0002889160951454247, 'epoch': 7.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 17776/19998 [26:43<02:47, 13.30it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 90.37it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 80.39it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 80.09it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:04, 69.66it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:04, 64.48it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:04, 62.72it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 65.37it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 66.08it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 63.97it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 65.27it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 70.16it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 73.48it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 74.02it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 75.25it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 76.15it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 77.09it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 77.72it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 70.33it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 63.85it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 64.04it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 66.65it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 70.85it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 72.57it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 74.61it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 76.05it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 65.40it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 66.31it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 66.59it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 69.52it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:01, 69.06it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 71.37it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 64.35it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 68.12it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 70.84it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:04<00:00, 69.65it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 70.58it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 72.99it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 75.26it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 75.33it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                     \n",
      " 89%|████████▉ | 17776/19998 [26:48<02:47, 13.30it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-17776\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-17776/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2928398549556732, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6374, 'eval_samples_per_second': 273.86, 'eval_steps_per_second': 68.573, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-17776/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-17776/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-17776/special_tokens_map.json\n",
      " 90%|█████████ | 18002/19998 [27:09<03:39,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3765, 'learning_rate': 0.00023108661253024758, 'epoch': 8.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 18502/19998 [27:52<02:22, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3406, 'learning_rate': 0.00017325712991507052, 'epoch': 8.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19000/19998 [28:34<02:08,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3526, 'learning_rate': 0.00011542764729989345, 'epoch': 8.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 19501/19998 [29:17<00:56,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3703, 'learning_rate': 5.759816468471638e-05, 'epoch': 8.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 19997/19998 [30:01<00:00, 15.57it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 77.10it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 73.26it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 74.31it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 72.75it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 74.37it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 76.16it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 74.37it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 64.15it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 67.40it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 70.76it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 71.00it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 73.97it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 74.14it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 75.05it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 76.97it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 76.68it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 76.88it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 68.02it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 62.67it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 65.50it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 70.38it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 71.44it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 70.04it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 71.46it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 73.98it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 75.50it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 76.97it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 78.29it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 77.55it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 74.76it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 71.32it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 71.27it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 62.53it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 63.86it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:04<00:00, 62.99it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 61.05it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 65.50it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 69.96it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 72.28it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                     \n",
      "100%|██████████| 19998/19998 [30:06<00:00, 15.57it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-19998\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-19998/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2928270101547241, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5487, 'eval_samples_per_second': 279.198, 'eval_steps_per_second': 69.91, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-19998/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-19998/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-19998/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-4/checkpoint-2222 (score: 0.4775812422871246).\n",
      "100%|██████████| 19998/19998 [30:12<00:00, 11.04it/s]\n",
      "\u001b[32m[I 2022-03-29 17:43:04,199]\u001b[0m Trial 4 finished with value: 1.434667856460353 and parameters: {'learning_rate': 0.0023129479866766224, 'weight_decay': 2.1959951671889066e-09, 'num_train_epochs': 9, 'seed': 32, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 1.434667856460353.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1821.1542, 'train_samples_per_second': 43.919, 'train_steps_per_second': 10.981, 'train_loss': 0.4625328141029435, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11372<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_171248-2z7gxtwl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_171248-2z7gxtwl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.3703</td></tr><tr><td>train/learning_rate</td><td>6e-05</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>19998</td></tr><tr><td>_runtime</td><td>1816</td></tr><tr><td>_timestamp</td><td>1648568584</td></tr><tr><td>_step</td><td>48</td></tr><tr><td>eval/loss</td><td>0.29283</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.5487</td></tr><tr><td>eval/samples_per_second</td><td>279.198</td></tr><tr><td>eval/steps_per_second</td><td>69.91</td></tr><tr><td>train/train_runtime</td><td>1821.1542</td></tr><tr><td>train/train_samples_per_second</td><td>43.919</td></tr><tr><td>train/train_steps_per_second</td><td>10.981</td></tr><tr><td>train/total_flos</td><td>773422141673640.0</td></tr><tr><td>train/train_loss</td><td>0.46253</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>▆▅▆█▇▇▆▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▂▁▁▂</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>█▅▁▁▃▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▇▁▄▇▇▄█▇▆</td></tr><tr><td>eval/samples_per_second</td><td>▂█▅▂▂▅▁▁▂</td></tr><tr><td>eval/steps_per_second</td><td>▂█▅▂▂▅▁▁▂</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dry-blaze-14</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2z7gxtwl\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2z7gxtwl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dainty-bird-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/13w7z0wt\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/13w7z0wt</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_174315-13w7z0wt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 278/556 [00:33<00:28,  9.82it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 79.76it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 77.23it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:05, 57.73it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:05, 52.30it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:04, 56.23it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:04, 58.69it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:04, 61.43it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 66.06it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:01<00:03, 68.39it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 71.63it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 72.54it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 74.63it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:02, 77.08it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 77.72it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 74.82it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:03, 63.77it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 67.76it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:02<00:02, 70.91it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 71.10it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 63.18it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 66.94it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 69.82it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 72.18it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 72.81it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 65.69it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:03<00:01, 64.17it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 67.33it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 70.12it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 71.59it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 72.92it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 74.42it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 75.88it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 75.28it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 75.19it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 75.93it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:04<00:00, 76.99it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 67.32it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 66.03it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 70.44it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 64.49it/s]\u001b[A\n",
      "                                                 \n",
      " 50%|█████     | 278/556 [00:38<00:28,  9.82it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16076955199241638, 'eval_f1': 0.8083018867924527, 'eval_recall': 0.8693668065334377, 'eval_precision': 0.768971827095705, 'eval_runtime': 4.7207, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 67.363, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-278/special_tokens_map.json\n",
      " 90%|█████████ | 501/556 [01:05<00:06,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1993, 'learning_rate': 7.978482304859454e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [01:10<00:00,  8.94it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.11it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.63it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 75.81it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 73.44it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:04, 68.42it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 70.22it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 72.49it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 73.66it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 70.45it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 72.05it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 73.68it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 61.96it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:03, 59.73it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:03, 62.09it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:03, 65.04it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 67.19it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 69.24it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:02<00:02, 66.54it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 68.20it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 71.06it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 71.88it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:02, 68.13it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 69.57it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 68.80it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 70.13it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:03<00:01, 68.16it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:03<00:01, 61.83it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 62.87it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 65.86it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 68.81it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 70.93it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 71.99it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 63.24it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 66.88it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:04<00:00, 69.69it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 62.09it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 63.35it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 66.67it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 66.87it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 69.72it/s]\u001b[A\n",
      "                                                 \n",
      "100%|██████████| 556/556 [01:15<00:00,  8.94it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17594236135482788, 'eval_f1': 0.8094005519350391, 'eval_recall': 0.8470118294099518, 'eval_precision': 0.7811107697034876, 'eval_runtime': 4.7809, 'eval_samples_per_second': 265.641, 'eval_steps_per_second': 66.515, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-556/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-5/checkpoint-556 (score: 0.8094005519350391).\n",
      "100%|██████████| 556/556 [01:19<00:00,  7.03it/s]\n",
      "\u001b[32m[I 2022-03-29 17:44:37,741]\u001b[0m Trial 5 finished with value: 2.4375231510484783 and parameters: {'learning_rate': 7.92149314553903e-05, 'weight_decay': 3.930577930103368e-10, 'num_train_epochs': 2, 'seed': 50, 'per_device_train_batch_size': 32}. Best is trial 5 with value: 2.4375231510484783.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 89.3527, 'train_samples_per_second': 198.92, 'train_steps_per_second': 6.223, 'train_loss': 0.18696516023265372, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 19\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17490<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_174315-13w7z0wt/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_174315-13w7z0wt/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.17594</td></tr><tr><td>eval/f1</td><td>0.8094</td></tr><tr><td>eval/recall</td><td>0.84701</td></tr><tr><td>eval/precision</td><td>0.78111</td></tr><tr><td>eval/runtime</td><td>4.7809</td></tr><tr><td>eval/samples_per_second</td><td>265.641</td></tr><tr><td>eval/steps_per_second</td><td>66.515</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>556</td></tr><tr><td>_runtime</td><td>82</td></tr><tr><td>_timestamp</td><td>1648568677</td></tr><tr><td>_step</td><td>3</td></tr><tr><td>train/loss</td><td>0.1993</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/train_runtime</td><td>89.3527</td></tr><tr><td>train/train_samples_per_second</td><td>198.92</td></tr><tr><td>train/train_steps_per_second</td><td>6.223</td></tr><tr><td>train/total_flos</td><td>175366601730120.0</td></tr><tr><td>train/train_loss</td><td>0.18697</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▁█</td></tr><tr><td>eval/f1</td><td>▁█</td></tr><tr><td>eval/recall</td><td>█▁</td></tr><tr><td>eval/precision</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▇██</td></tr><tr><td>train/global_step</td><td>▁▇██</td></tr><tr><td>_runtime</td><td>▁▆▇█</td></tr><tr><td>_timestamp</td><td>▁▆▇█</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dainty-bird-15</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/13w7z0wt\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/13w7z0wt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">clear-silence-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/3ve2luxi\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/3ve2luxi</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_174447-3ve2luxi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 501/10564 [00:48<23:44,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2473, 'learning_rate': 3.0617415970854626e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 555/10564 [00:52<13:05, 12.73it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 95.58it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 86.94it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 83.99it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 84.53it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 85.31it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 85.40it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:02, 86.30it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:02, 86.77it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 77.52it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 72.94it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 75.23it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 78.30it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 78.57it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 76.16it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 77.10it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 77.56it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 79.68it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:01<00:01, 80.50it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 81.00it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 78.88it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 75.78it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 70.56it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 74.12it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 76.41it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:02<00:01, 78.81it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:02<00:01, 70.79it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 72.30it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 73.41it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 75.10it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 77.74it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 80.08it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 76.78it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 77.04it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 73.51it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:03<00:00, 68.45it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 70.30it/s]\u001b[A\n",
      "                                                   \n",
      "  5%|▌         | 556/10564 [00:57<13:05, 12.73it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17823027074337006, 'eval_f1': 0.7744816420326944, 'eval_recall': 0.7597254818291729, 'eval_precision': 0.7916311754684838, 'eval_runtime': 4.2068, 'eval_samples_per_second': 301.891, 'eval_steps_per_second': 75.592, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-556/special_tokens_map.json\n",
      "  9%|▉         | 1001/10564 [01:36<17:41,  9.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1704, 'learning_rate': 2.9096280439711218e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1112/10564 [01:46<15:47,  9.97it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 90.51it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 91.47it/s]\u001b[A\n",
      "  9%|▉         | 30/318 [00:00<00:03, 92.69it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 81.87it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 84.89it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 84.45it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 78.89it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:00<00:03, 66.93it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 65.64it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 66.48it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 70.76it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 70.97it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 73.17it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 76.08it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 77.87it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 79.32it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 79.47it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:01, 80.38it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 80.70it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 80.83it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 80.59it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 81.02it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 78.36it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 78.17it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:02<00:01, 72.71it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:02<00:01, 73.09it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 76.00it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 76.81it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 73.23it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 73.29it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 72.19it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 74.10it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 76.48it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 77.22it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:03<00:00, 78.52it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 78.76it/s]\u001b[A\n",
      "                                                    \n",
      " 11%|█         | 1112/10564 [01:51<15:47,  9.97it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1112\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33639824390411377, 'eval_f1': 0.7457562045797339, 'eval_recall': 0.8664627930682977, 'eval_precision': 0.7000418411846663, 'eval_runtime': 4.2086, 'eval_samples_per_second': 301.762, 'eval_steps_per_second': 75.559, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1112/special_tokens_map.json\n",
      " 14%|█▍        | 1503/10564 [02:28<14:15, 10.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.108, 'learning_rate': 2.75751449085678e-05, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1667/10564 [02:41<11:16, 13.16it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 77.19it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 76.32it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 73.32it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:04, 68.50it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 70.67it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 71.71it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 73.91it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 73.43it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 70.00it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 70.73it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 70.23it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 68.03it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 72.33it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 75.24it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:03, 65.18it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 67.66it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 63.33it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:02<00:02, 60.02it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 64.31it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 68.94it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 67.92it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 71.60it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 67.48it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 70.92it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 71.45it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:03<00:01, 72.71it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:03<00:01, 74.53it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 75.63it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 77.40it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 78.00it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 77.79it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 77.57it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 77.66it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 73.28it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 73.10it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 74.95it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 75.03it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 75.13it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 75.11it/s]\u001b[A\n",
      "                                                    \n",
      " 16%|█▌        | 1668/10564 [02:46<11:16, 13.16it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1668\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2546732425689697, 'eval_f1': 0.7957761578044598, 'eval_recall': 0.7835225880884085, 'eval_precision': 0.80949546705311, 'eval_runtime': 4.5304, 'eval_samples_per_second': 280.326, 'eval_steps_per_second': 70.192, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-1668/special_tokens_map.json\n",
      " 19%|█▉        | 2001/10564 [03:17<17:18,  8.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0549, 'learning_rate': 2.605400937742439e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2223/10564 [03:36<11:24, 12.18it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 81.65it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 73.06it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 77.40it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 74.68it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 74.13it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 73.72it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 76.34it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 78.94it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 77.21it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:02, 78.30it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:02, 77.61it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:02, 76.69it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 77.58it/s]\u001b[A\n",
      " 37%|███▋      | 119/318 [00:01<00:02, 72.64it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 66.40it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:01<00:02, 68.09it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:01<00:02, 70.75it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 72.36it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 73.32it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 74.02it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 72.04it/s]\u001b[A\n",
      " 58%|█████▊    | 183/318 [00:02<00:01, 73.48it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 75.73it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 68.17it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 63.52it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:02<00:01, 67.42it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 70.16it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 70.80it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 73.29it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 71.58it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 69.20it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 67.59it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 62.96it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 67.30it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 70.31it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 70.77it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 72.08it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 73.24it/s]\u001b[A\n",
      "                                                    \n",
      " 21%|██        | 2224/10564 [03:41<11:24, 12.18it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2224\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35617783665657043, 'eval_f1': 0.795990253362261, 'eval_recall': 0.8021517356913133, 'eval_precision': 0.7901490317489225, 'eval_runtime': 4.4718, 'eval_samples_per_second': 284.001, 'eval_steps_per_second': 71.112, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2224/special_tokens_map.json\n",
      " 24%|██▎       | 2502/10564 [04:09<14:21,  9.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0269, 'learning_rate': 2.4532873846280975e-05, 'epoch': 4.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 2780/10564 [04:35<12:28, 10.40it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 73.58it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 69.36it/s]\u001b[A\n",
      "  7%|▋         | 23/318 [00:00<00:04, 64.19it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:04, 67.11it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:04, 67.66it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 69.16it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 71.93it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 73.29it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:00<00:03, 75.15it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 76.51it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 72.53it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:03, 70.08it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:02, 71.72it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 74.65it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 70.31it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 69.47it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 70.55it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:02<00:02, 70.42it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 71.08it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 73.43it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 63.44it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:02, 67.03it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 70.04it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 73.67it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 75.15it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 75.07it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:03<00:01, 74.86it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 76.48it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 68.54it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 68.19it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 70.48it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 71.86it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 73.71it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 73.18it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 73.90it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:04<00:00, 74.75it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 76.51it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 75.38it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 77.12it/s]\u001b[A\n",
      "                                                    \n",
      " 26%|██▋       | 2780/10564 [04:39<12:28, 10.40it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2780\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2780/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4454020857810974, 'eval_f1': 0.8089138007545933, 'eval_recall': 0.8205003595445243, 'eval_precision': 0.798368349811676, 'eval_runtime': 4.4935, 'eval_samples_per_second': 282.632, 'eval_steps_per_second': 70.769, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2780/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2780/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2780/special_tokens_map.json\n",
      " 28%|██▊       | 3001/10564 [05:03<15:05,  8.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0148, 'learning_rate': 2.3011738315137564e-05, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3335/10564 [05:33<10:20, 11.65it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.53it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:04, 73.37it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 70.67it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 73.34it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 73.77it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 74.23it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 74.01it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 74.67it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 75.64it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 68.99it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 59.90it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 58.02it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:03, 60.63it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:03, 64.54it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:03, 64.17it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 64.02it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:02<00:02, 62.46it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:02<00:02, 67.01it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 61.59it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 63.68it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 66.37it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 69.24it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 72.83it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 70.46it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 64.91it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:03<00:01, 65.18it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:03<00:01, 68.86it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 71.29it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 72.89it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 73.58it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 75.45it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 75.32it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 76.58it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 76.40it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 76.53it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 76.83it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 75.44it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 68.64it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 66.68it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 69.14it/s]\u001b[A\n",
      "                                                    \n",
      " 32%|███▏      | 3336/10564 [05:38<10:20, 11.65it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3336\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3336/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5335162878036499, 'eval_f1': 0.7872658761845441, 'eval_recall': 0.8517293696512813, 'eval_precision': 0.7479776708116058, 'eval_runtime': 4.6757, 'eval_samples_per_second': 271.619, 'eval_steps_per_second': 68.012, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3336/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3336/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3336/special_tokens_map.json\n",
      " 33%|███▎      | 3502/10564 [05:55<12:13,  9.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0084, 'learning_rate': 2.149060278399415e-05, 'epoch': 6.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3891/10564 [06:29<08:21, 13.31it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 86.98it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 82.02it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 81.22it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 73.49it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 73.63it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 75.38it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 75.89it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 74.63it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:00<00:03, 75.50it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 72.44it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 68.20it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 70.09it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 71.90it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 72.94it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 74.37it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 73.48it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 74.14it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 72.77it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 71.71it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 68.42it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 61.33it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 57.81it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:02, 63.86it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 67.06it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 70.20it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 73.40it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 74.08it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 75.55it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 71.53it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 71.98it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 74.45it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 74.29it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 74.86it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 76.48it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 77.42it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 76.97it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 77.56it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 77.54it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 78.18it/s]\u001b[A\n",
      "                                                    \n",
      " 37%|███▋      | 3892/10564 [06:33<08:21, 13.31it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3892\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3892/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4382701516151428, 'eval_f1': 0.8043050517981177, 'eval_recall': 0.8043050517981177, 'eval_precision': 0.8043050517981177, 'eval_runtime': 4.4455, 'eval_samples_per_second': 285.684, 'eval_steps_per_second': 71.534, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3892/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3892/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-3892/special_tokens_map.json\n",
      " 38%|███▊      | 4001/10564 [06:47<12:30,  8.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0134, 'learning_rate': 1.9969467252850735e-05, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4447/10564 [07:28<08:12, 12.43it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 89.20it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 83.12it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 80.49it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 80.42it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 77.25it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 74.63it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 75.64it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 76.38it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:00<00:03, 76.45it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:02, 77.81it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:02, 78.14it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 77.47it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 78.15it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 71.49it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 73.59it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 74.08it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 75.39it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 76.31it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 77.03it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 73.87it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:01, 74.59it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 75.57it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 76.48it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 77.26it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 77.74it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:02<00:01, 76.14it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:02<00:01, 75.69it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 75.51it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 75.92it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 76.82it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 77.29it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 78.30it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 72.15it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 69.79it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 70.55it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 72.51it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 71.69it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 67.38it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 61.84it/s]\u001b[A\n",
      "                                                    \n",
      " 42%|████▏     | 4448/10564 [07:33<08:12, 12.43it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-4448\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-4448/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6000714302062988, 'eval_f1': 0.7845611204998209, 'eval_recall': 0.8545938727291404, 'eval_precision': 0.7436115981997926, 'eval_runtime': 4.3842, 'eval_samples_per_second': 289.679, 'eval_steps_per_second': 72.534, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-4448/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-4448/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-4448/special_tokens_map.json\n",
      " 43%|████▎     | 4501/10564 [07:40<12:04,  8.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0083, 'learning_rate': 1.844833172170732e-05, 'epoch': 8.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 5001/10564 [08:23<12:13,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0058, 'learning_rate': 1.692719619056391e-05, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 5004/10564 [08:23<11:50,  7.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 81.00it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 82.63it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 82.38it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 80.15it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 71.70it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:04, 65.23it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 70.85it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 69.13it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 73.07it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 75.55it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 76.10it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 76.65it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 71.78it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 74.91it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 77.15it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 68.61it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 68.33it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 72.45it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 76.26it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 78.88it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 79.87it/s]\u001b[A\n",
      " 60%|██████    | 191/318 [00:02<00:01, 80.72it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 81.78it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 83.05it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 79.76it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:02<00:01, 79.65it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 80.35it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 81.48it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 80.34it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 80.89it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 80.48it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 81.15it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 81.47it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 80.98it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:03<00:00, 80.49it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 81.72it/s]\u001b[A\n",
      "                                                    \n",
      " 47%|████▋     | 5004/10564 [08:28<11:50,  7.83it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5004\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5004/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.547671914100647, 'eval_f1': 0.7777555561110971, 'eval_recall': 0.7423883238903508, 'eval_precision': 0.8299130958526932, 'eval_runtime': 4.1904, 'eval_samples_per_second': 303.076, 'eval_steps_per_second': 75.888, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5004/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5004/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5004/special_tokens_map.json\n",
      " 52%|█████▏    | 5501/10564 [09:12<10:44,  7.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.004, 'learning_rate': 1.5406060659420495e-05, 'epoch': 9.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5559/10564 [09:17<06:55, 12.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 72.72it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 67.48it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 70.82it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 71.68it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:04, 68.15it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 70.89it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 73.23it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 74.89it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 76.40it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 73.55it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 71.53it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 72.31it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 73.34it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 75.70it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 77.18it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 77.72it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 69.98it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 65.01it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 68.67it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 69.78it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 72.17it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 74.96it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 76.62it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 77.43it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 72.83it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 75.42it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 77.34it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 77.43it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 69.53it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 65.94it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:01, 64.78it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 69.56it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 72.04it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 74.83it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 74.47it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 63.58it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 62.54it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 65.81it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 69.20it/s]\u001b[A\n",
      "                                                    \n",
      " 53%|█████▎    | 5560/10564 [09:22<06:55, 12.05it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5560\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5560/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5440048575401306, 'eval_f1': 0.7992385501598891, 'eval_recall': 0.810464721175197, 'eval_precision': 0.789025717984934, 'eval_runtime': 4.5597, 'eval_samples_per_second': 278.529, 'eval_steps_per_second': 69.742, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5560/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5560/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-5560/special_tokens_map.json\n",
      " 57%|█████▋    | 6001/10564 [10:03<09:44,  7.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0064, 'learning_rate': 1.388492512827708e-05, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 6115/10564 [10:14<06:17, 11.78it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 89.48it/s]\u001b[A\n",
      "  6%|▌         | 19/318 [00:00<00:03, 79.77it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 69.84it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 70.77it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 73.05it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 74.88it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 74.73it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 66.70it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 69.60it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 71.41it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 70.11it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 70.06it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 71.41it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 73.33it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 70.81it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 72.95it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 74.84it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 72.02it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 66.27it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 68.56it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:02, 70.16it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 72.13it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 74.78it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 75.52it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 75.84it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 76.33it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 77.18it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 76.64it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 77.43it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 68.58it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 68.79it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 71.70it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 72.46it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 74.04it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 77.51it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 79.24it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 79.81it/s]\u001b[A\n",
      " 98%|█████████▊| 313/318 [00:04<00:00, 79.72it/s]\u001b[A\n",
      "                                                    \n",
      " 58%|█████▊    | 6116/10564 [10:18<06:17, 11.78it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6116\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6116/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5466281771659851, 'eval_f1': 0.7881366030361525, 'eval_recall': 0.7631707876000601, 'eval_precision': 0.8201815105368404, 'eval_runtime': 4.428, 'eval_samples_per_second': 286.809, 'eval_steps_per_second': 71.815, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6116/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6116/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6116/special_tokens_map.json\n",
      " 62%|██████▏   | 6501/10564 [10:56<08:07,  8.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0018, 'learning_rate': 1.2363789597133667e-05, 'epoch': 11.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6672/10564 [11:11<05:58, 10.84it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 79.30it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 65.09it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 68.05it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 72.07it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 72.88it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 71.18it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 72.89it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 73.52it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 74.68it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 75.32it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 75.72it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 75.91it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 75.68it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 74.09it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 76.39it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 76.81it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 71.57it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 73.61it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 74.55it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 73.15it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:01, 74.69it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 75.91it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 72.73it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 68.20it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 69.26it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 62.57it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 66.91it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:03<00:01, 66.89it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 69.95it/s]\u001b[A\n",
      " 75%|███████▌  | 239/318 [00:03<00:01, 68.87it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:00, 71.17it/s]\u001b[A\n",
      " 80%|████████  | 255/318 [00:03<00:00, 71.36it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 71.85it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 73.62it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 75.30it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 75.37it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 76.16it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 75.64it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 76.02it/s]\u001b[A\n",
      "                                                    \n",
      " 63%|██████▎   | 6672/10564 [11:16<05:58, 10.84it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6672\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6672/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6284126043319702, 'eval_f1': 0.7596463205069003, 'eval_recall': 0.7058412156555959, 'eval_precision': 0.87056162512803, 'eval_runtime': 4.4641, 'eval_samples_per_second': 284.489, 'eval_steps_per_second': 71.234, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6672/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6672/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-6672/special_tokens_map.json\n",
      " 66%|██████▋   | 7001/10564 [11:51<07:41,  7.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0055, 'learning_rate': 1.0842654065990253e-05, 'epoch': 12.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 7228/10564 [12:11<05:55,  9.38it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:04, 76.83it/s]\u001b[A\n",
      "  5%|▌         | 17/318 [00:00<00:03, 76.71it/s]\u001b[A\n",
      "  8%|▊         | 25/318 [00:00<00:03, 74.21it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:04, 68.13it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:04, 67.49it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:04, 65.74it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:04, 65.07it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 69.01it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 72.92it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 74.21it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:02, 76.41it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 76.80it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 77.25it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 76.41it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 76.70it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 75.85it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 74.70it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 76.05it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 75.18it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 74.56it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:01, 76.63it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 77.45it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 74.19it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 70.47it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 69.22it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 65.97it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 68.64it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 71.06it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 72.25it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 73.72it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 75.04it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 75.59it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 76.66it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 75.62it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 76.55it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:03<00:00, 76.49it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 77.73it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 76.19it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 76.45it/s]\u001b[A\n",
      "                                                    \n",
      " 68%|██████▊   | 7228/10564 [12:16<05:55,  9.38it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7228\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7228/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6309823393821716, 'eval_f1': 0.7899777627652986, 'eval_recall': 0.8265098894499363, 'eval_precision': 0.7628316444987246, 'eval_runtime': 4.3812, 'eval_samples_per_second': 289.874, 'eval_steps_per_second': 72.583, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7228/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7228/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7228/special_tokens_map.json\n",
      " 71%|███████   | 7501/10564 [12:44<06:21,  8.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0001, 'learning_rate': 9.32151853484684e-06, 'epoch': 13.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 7784/10564 [13:10<04:49,  9.61it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 88.06it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 72.88it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 73.84it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 75.17it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 73.45it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 74.89it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 72.27it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 64.80it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:01<00:03, 66.13it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 68.01it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 68.90it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:03, 70.95it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 72.90it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 73.92it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 72.14it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:03, 60.85it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 65.18it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 68.10it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 71.28it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 72.19it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 72.15it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 73.18it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 67.55it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 69.18it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 71.03it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:03<00:01, 66.97it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:03<00:01, 69.50it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 71.12it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 72.75it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 72.93it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 73.26it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 76.79it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 74.08it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 76.71it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 75.29it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 74.98it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 76.36it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 69.36it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 73.82it/s]\u001b[A\n",
      "                                                    \n",
      " 74%|███████▎  | 7784/10564 [13:15<04:49,  9.61it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7784\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7784/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5896457433700562, 'eval_f1': 0.795990253362261, 'eval_recall': 0.8021517356913133, 'eval_precision': 0.7901490317489225, 'eval_runtime': 4.5219, 'eval_samples_per_second': 280.856, 'eval_steps_per_second': 70.325, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7784/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7784/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-7784/special_tokens_map.json\n",
      " 76%|███████▌  | 8001/10564 [13:37<04:41,  9.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0033, 'learning_rate': 7.800383003703425e-06, 'epoch': 14.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 8339/10564 [14:05<03:07, 11.87it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 90.17it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 75.29it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 71.35it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:03, 74.99it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 76.32it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 77.57it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 73.10it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 72.57it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 69.80it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 70.22it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 72.00it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:02, 75.24it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 76.99it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 77.76it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 78.22it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 77.98it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 78.25it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 79.03it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 76.29it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 73.73it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 76.54it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 70.59it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 72.53it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 69.76it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 71.81it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 73.00it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 72.07it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 75.46it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 76.55it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 75.67it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 75.87it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 76.61it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 78.08it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 78.12it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 71.94it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 75.07it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 74.46it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 68.88it/s]\u001b[A\n",
      "                                                    \n",
      " 79%|███████▉  | 8340/10564 [14:09<03:07, 11.87it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8340\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8340/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6524924039840698, 'eval_f1': 0.7860109717868338, 'eval_recall': 0.788390267801405, 'eval_precision': 0.7836827336395931, 'eval_runtime': 4.3613, 'eval_samples_per_second': 291.198, 'eval_steps_per_second': 72.914, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8340/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8340/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8340/special_tokens_map.json\n",
      " 80%|████████  | 8501/10564 [14:26<04:19,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 6.279247472560012e-06, 'epoch': 15.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8895/10564 [15:00<02:06, 13.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.28it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:04, 72.70it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 70.27it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:04, 68.29it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 71.14it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 73.28it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 74.53it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 76.13it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 77.21it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 77.66it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:02, 78.12it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 77.90it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 78.87it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 78.86it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 79.86it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:01<00:02, 80.21it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 75.85it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:01<00:02, 75.74it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 76.59it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:01, 78.05it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 77.69it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 78.78it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 79.89it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 80.36it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 76.08it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 76.02it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:02<00:01, 77.57it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 76.50it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 76.44it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 76.69it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 77.83it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 74.86it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 75.88it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 67.31it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 69.49it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 73.15it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 66.49it/s]\u001b[A\n",
      "                                                    \n",
      " 84%|████████▍ | 8896/10564 [15:04<02:06, 13.23it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8896\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8896/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6563089489936829, 'eval_f1': 0.7638836288517817, 'eval_recall': 0.7281961927790817, 'eval_precision': 0.8182359164242263, 'eval_runtime': 4.3164, 'eval_samples_per_second': 294.227, 'eval_steps_per_second': 73.673, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8896/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8896/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-8896/special_tokens_map.json\n",
      " 85%|████████▌ | 9001/10564 [15:16<03:30,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 4.758111941416598e-06, 'epoch': 16.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 9451/10564 [15:53<01:46, 10.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 93.39it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 87.23it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 84.80it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 82.54it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 81.57it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 78.67it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 76.54it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 76.76it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 76.28it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:02, 77.14it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 78.15it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 75.56it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 75.83it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 75.85it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 75.91it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 72.55it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 65.63it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 66.47it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 65.94it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 68.47it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:02, 71.11it/s]\u001b[A\n",
      " 58%|█████▊    | 183/318 [00:02<00:01, 70.74it/s]\u001b[A\n",
      " 60%|██████    | 191/318 [00:02<00:01, 71.90it/s]\u001b[A\n",
      " 63%|██████▎   | 199/318 [00:02<00:01, 73.66it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 67.43it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:02<00:01, 68.04it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 69.66it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 72.44it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 74.57it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 74.71it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 74.15it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 74.24it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 75.65it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 76.53it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 77.14it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:03<00:00, 77.58it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 78.00it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 71.54it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 71.80it/s]\u001b[A\n",
      "                                                    \n",
      " 89%|████████▉ | 9452/10564 [15:58<01:46, 10.44it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-9452\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-9452/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6811586618423462, 'eval_f1': 0.7577282084043158, 'eval_recall': 0.730199369414219, 'eval_precision': 0.7956882289055125, 'eval_runtime': 4.3704, 'eval_samples_per_second': 290.594, 'eval_steps_per_second': 72.763, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-9452/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-9452/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-9452/special_tokens_map.json\n",
      " 90%|████████▉ | 9500/10564 [16:05<01:54,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 3.236976410273184e-06, 'epoch': 17.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 10001/10564 [16:52<01:13,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.7158408791297706e-06, 'epoch': 17.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 10008/10564 [16:53<01:09,  8.01it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 71.56it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 75.09it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 76.02it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 76.55it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 73.69it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 74.92it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 75.09it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 75.85it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:00<00:03, 76.98it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 78.08it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:02, 79.06it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:02, 75.05it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 73.89it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 74.33it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 75.58it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 76.64it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 77.91it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:01<00:02, 77.00it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 67.58it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 70.00it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 72.25it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 73.80it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 73.42it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 73.16it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 74.32it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 75.45it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 76.16it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 74.22it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 74.78it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 76.56it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 76.36it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 75.52it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 70.60it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 65.27it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 68.41it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 71.55it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 70.08it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 68.15it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 66.40it/s]\u001b[A\n",
      "                                                     \n",
      " 95%|█████████▍| 10008/10564 [16:57<01:09,  8.01it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10008\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10008/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6911682486534119, 'eval_f1': 0.7639276146738834, 'eval_recall': 0.7389430181194636, 'eval_precision': 0.7969633878064111, 'eval_runtime': 4.4887, 'eval_samples_per_second': 282.93, 'eval_steps_per_second': 70.844, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10008/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10008/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10008/special_tokens_map.json\n",
      " 99%|█████████▉| 10501/10564 [17:46<00:08,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 1.9470534798635693e-07, 'epoch': 18.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10564/10564 [17:52<00:00, 11.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 83.43it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.66it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 64.50it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:04, 65.94it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:04, 60.60it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:04, 64.53it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 67.73it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 70.85it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 66.49it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 66.93it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 70.28it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:03, 68.88it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:03, 71.62it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 73.41it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 75.83it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 75.54it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 72.28it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:02<00:02, 70.87it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 71.83it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 68.25it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 68.35it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:02, 69.46it/s]\u001b[A\n",
      " 58%|█████▊    | 183/318 [00:02<00:01, 70.61it/s]\u001b[A\n",
      " 60%|██████    | 191/318 [00:02<00:01, 70.20it/s]\u001b[A\n",
      " 63%|██████▎   | 199/318 [00:02<00:01, 66.75it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 69.60it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:03<00:01, 68.31it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 68.54it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 69.25it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 71.13it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:00, 72.70it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 74.43it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 74.97it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 75.22it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 71.72it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 71.88it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 73.58it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 74.97it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 75.31it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 68.80it/s]\u001b[A\n",
      "                                                     \n",
      "100%|██████████| 10564/10564 [17:57<00:00, 11.02it/s]\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10564\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10564/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7008821964263916, 'eval_f1': 0.7666239316239316, 'eval_recall': 0.7468253403819864, 'eval_precision': 0.7911342262487301, 'eval_runtime': 4.6131, 'eval_samples_per_second': 275.302, 'eval_steps_per_second': 68.934, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10564/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10564/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-10564/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-6/checkpoint-2780 (score: 0.8089138007545933).\n",
      "100%|██████████| 10564/10564 [18:01<00:00,  9.77it/s]\n",
      "\u001b[32m[I 2022-03-29 18:02:51,786]\u001b[0m Trial 6 finished with value: 2.3045834982546483 and parameters: {'learning_rate': 3.2138551501998044e-05, 'weight_decay': 5.085301006631757e-07, 'num_train_epochs': 19, 'seed': 36, 'per_device_train_batch_size': 16}. Best is trial 5 with value: 2.4375231510484783.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1089.9198, 'train_samples_per_second': 154.922, 'train_steps_per_second': 9.692, 'train_loss': 0.03215660897298867, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 17\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17910<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_174447-3ve2luxi/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_174447-3ve2luxi/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.0</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/epoch</td><td>19.0</td></tr><tr><td>train/global_step</td><td>10564</td></tr><tr><td>_runtime</td><td>1084</td></tr><tr><td>_timestamp</td><td>1648569771</td></tr><tr><td>_step</td><td>40</td></tr><tr><td>eval/loss</td><td>0.70088</td></tr><tr><td>eval/f1</td><td>0.76662</td></tr><tr><td>eval/recall</td><td>0.74683</td></tr><tr><td>eval/precision</td><td>0.79113</td></tr><tr><td>eval/runtime</td><td>4.6131</td></tr><tr><td>eval/samples_per_second</td><td>275.302</td></tr><tr><td>eval/steps_per_second</td><td>68.934</td></tr><tr><td>train/train_runtime</td><td>1089.9198</td></tr><tr><td>train/train_samples_per_second</td><td>154.922</td></tr><tr><td>train/train_steps_per_second</td><td>9.692</td></tr><tr><td>train/total_flos</td><td>1657025121111960.0</td></tr><tr><td>train/train_loss</td><td>0.03216</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>eval/loss</td><td>▁▃▂▃▅▆▄▇▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval/f1</td><td>▄▁▇▇█▆▇▅▅▇▆▃▆▇▅▃▂▃▃</td></tr><tr><td>eval/recall</td><td>▃█▄▅▆▇▅▇▃▆▃▁▆▅▅▂▂▂▃</td></tr><tr><td>eval/precision</td><td>▅▁▅▅▅▃▅▃▆▅▆█▄▅▄▆▅▅▅</td></tr><tr><td>eval/runtime</td><td>▁▁▆▅▅█▅▄▁▆▄▅▄▆▃▃▄▅▇</td></tr><tr><td>eval/samples_per_second</td><td>██▃▄▃▁▄▅█▃▄▄▅▃▅▆▅▄▂</td></tr><tr><td>eval/steps_per_second</td><td>██▃▄▃▁▄▅█▃▄▄▅▃▅▆▅▄▂</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">clear-silence-16</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/3ve2luxi\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/3ve2luxi</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fancy-blaze-17</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2me0cxss\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2me0cxss</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_180302-2me0cxss</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 139/2363 [00:18<04:51,  7.62it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 86.33it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 80.95it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 76.50it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 76.73it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 76.97it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 77.13it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 72.11it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 64.86it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 67.65it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 60.07it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 61.46it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 63.52it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:03, 66.49it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:03, 68.55it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 70.46it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 73.13it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 74.45it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:02<00:02, 75.34it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 76.29it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 75.53it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 75.44it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 71.49it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 73.66it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 73.76it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 68.95it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 68.82it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 66.18it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 69.24it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 71.45it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 69.90it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 67.34it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 66.50it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 69.56it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 71.39it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 68.36it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:04<00:00, 66.50it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 69.03it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 67.64it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 66.55it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 69.89it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "  6%|▌         | 139/2363 [00:23<04:51,  7.62it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-139\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-139/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29790136218070984, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6383, 'eval_samples_per_second': 273.807, 'eval_steps_per_second': 68.56, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-139/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-139/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-139/special_tokens_map.json\n",
      " 12%|█▏        | 278/2363 [00:44<04:36,  7.54it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 79.56it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 74.33it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 74.18it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 75.18it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 76.44it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 75.85it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 75.82it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 75.27it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 71.14it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 72.04it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 73.37it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 74.09it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 73.67it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 74.65it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 75.45it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 75.69it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 70.33it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 65.82it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 68.09it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 69.41it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 68.40it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:02, 69.68it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 69.00it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 70.40it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 71.91it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:02<00:01, 73.46it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:02<00:01, 71.45it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 73.28it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 73.43it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 73.23it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 73.68it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 75.33it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 69.60it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 70.56it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 71.90it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:03<00:00, 73.33it/s]\u001b[A\n",
      " 93%|█████████▎| 297/318 [00:04<00:00, 75.43it/s]\u001b[A\n",
      " 96%|█████████▌| 305/318 [00:04<00:00, 73.35it/s]\u001b[A\n",
      " 98%|█████████▊| 313/318 [00:04<00:00, 71.16it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 12%|█▏        | 278/2363 [00:49<04:36,  7.54it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30280277132987976, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5164, 'eval_samples_per_second': 281.195, 'eval_steps_per_second': 70.409, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-278/special_tokens_map.json\n",
      " 18%|█▊        | 416/2363 [01:11<04:26,  7.32it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 93.73it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 80.90it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 76.82it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 78.23it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:03, 78.02it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 78.91it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 79.56it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 75.46it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 74.41it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 75.06it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 77.07it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 74.14it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:02, 75.16it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 76.28it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 77.95it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 76.36it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 66.03it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 68.85it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 70.71it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 72.20it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 72.64it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 74.52it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 72.96it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 62.20it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 62.63it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:02<00:01, 66.98it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 71.13it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 73.09it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 74.38it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 75.38it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 76.52it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 77.72it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 74.63it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 76.75it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 67.31it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 63.46it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 67.39it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 71.67it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 18%|█▊        | 417/2363 [01:15<04:25,  7.32it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-417\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-417/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5089823603630066, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4637, 'eval_samples_per_second': 284.52, 'eval_steps_per_second': 71.242, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-417/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-417/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-417/special_tokens_map.json\n",
      " 21%|██        | 501/2363 [01:30<05:21,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5356, 'learning_rate': 0.002207610883455425, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 556/2363 [01:36<03:39,  8.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 82.14it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 80.01it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 80.29it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 78.03it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 78.37it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 78.76it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 75.82it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 73.00it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 64.08it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:03, 67.92it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 71.68it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 73.82it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 72.35it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 69.17it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:03, 63.85it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:03, 58.29it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:02<00:03, 56.83it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:02<00:02, 61.94it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 66.39it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 68.28it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 71.41it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 73.50it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 76.36it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 78.80it/s]\u001b[A\n",
      " 65%|██████▍   | 206/318 [00:02<00:01, 79.54it/s]\u001b[A\n",
      " 67%|██████▋   | 214/318 [00:03<00:01, 67.16it/s]\u001b[A\n",
      " 70%|██████▉   | 222/318 [00:03<00:01, 67.66it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 71.95it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 75.44it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 76.09it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 77.89it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 79.31it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 79.99it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 79.01it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 73.93it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 74.99it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 76.83it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 77.50it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 24%|██▎       | 556/2363 [01:41<03:39,  8.23it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31795039772987366, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.455, 'eval_samples_per_second': 285.071, 'eval_steps_per_second': 71.38, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-556/special_tokens_map.json\n",
      " 29%|██▉       | 694/2363 [02:01<03:25,  8.14it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 82.06it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.02it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 76.30it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 74.98it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 77.76it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 78.43it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 78.43it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 71.58it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:00<00:03, 73.64it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 66.41it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 68.19it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 69.20it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 72.67it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 72.88it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 74.18it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 74.80it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 74.64it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 74.34it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 74.86it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 75.00it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:01, 75.76it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 75.90it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 70.81it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 72.31it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 73.41it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 74.72it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:02<00:01, 74.16it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 73.99it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 75.94it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 74.96it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 75.26it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 77.17it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 77.02it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 76.68it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 77.31it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:03<00:00, 77.88it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 73.61it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 71.95it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 73.39it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 29%|██▉       | 695/2363 [02:05<03:24,  8.14it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-695\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-695/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3015657663345337, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3632, 'eval_samples_per_second': 291.07, 'eval_steps_per_second': 72.882, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-695/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-695/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-695/special_tokens_map.json\n",
      " 35%|███▌      | 833/2363 [02:25<02:57,  8.62it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 80.83it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 77.48it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 79.26it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 80.24it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 81.30it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 79.35it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 76.55it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 75.15it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 76.97it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 76.87it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:02, 76.47it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:02, 76.08it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 77.12it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 78.12it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 78.58it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 72.99it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 74.24it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:01<00:02, 72.68it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 72.32it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 71.83it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 74.80it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 76.45it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 77.43it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 77.57it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 76.82it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 74.94it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:02<00:01, 75.70it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 77.45it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 78.00it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 79.68it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 73.42it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 74.75it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 75.94it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 77.03it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 73.50it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:03<00:00, 69.49it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 68.10it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 67.65it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 35%|███▌      | 834/2363 [02:30<02:57,  8.62it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4314303994178772, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3326, 'eval_samples_per_second': 293.124, 'eval_steps_per_second': 73.396, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-834/special_tokens_map.json\n",
      " 41%|████      | 972/2363 [02:50<02:59,  7.77it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 74.80it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 75.05it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 75.46it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 75.76it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 73.21it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:03, 76.13it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 78.94it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 81.98it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:00<00:02, 84.15it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:02, 85.57it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 73.24it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:03, 68.43it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:02, 71.94it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 74.65it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 76.37it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 77.62it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 76.83it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 76.52it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:01, 78.74it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:01, 81.64it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 81.38it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 81.38it/s]\u001b[A\n",
      " 63%|██████▎   | 199/318 [00:02<00:01, 75.45it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 71.12it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:02<00:01, 73.02it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:02<00:01, 74.77it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 76.01it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 77.77it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 78.70it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 79.66it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 79.35it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 78.66it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 79.77it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 75.67it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:03<00:00, 77.01it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 71.01it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 68.91it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 41%|████      | 973/2363 [02:55<02:58,  7.77it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-973\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-973/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3823038637638092, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2669, 'eval_samples_per_second': 297.639, 'eval_steps_per_second': 74.527, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-973/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-973/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-973/special_tokens_map.json\n",
      " 42%|████▏     | 1001/2363 [03:02<03:09,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4835, 'learning_rate': 0.001615122723644522, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1112/2363 [03:15<02:43,  7.65it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.53it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 83.10it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 82.57it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 74.55it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:03, 75.66it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 68.56it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:03, 72.25it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 75.59it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 77.00it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:02, 78.69it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 70.28it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 71.24it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 72.92it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 75.23it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 75.37it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 71.69it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:01<00:02, 73.88it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 74.23it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 64.17it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 65.08it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 59.36it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:02, 64.14it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 64.16it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 68.03it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 71.02it/s]\u001b[A\n",
      " 68%|██████▊   | 217/318 [00:03<00:01, 70.56it/s]\u001b[A\n",
      " 71%|███████   | 225/318 [00:03<00:01, 72.58it/s]\u001b[A\n",
      " 73%|███████▎  | 233/318 [00:03<00:01, 73.53it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 74.45it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 75.71it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 73.18it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 75.87it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 77.42it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 78.80it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:03<00:00, 78.74it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 75.22it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 73.84it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 73.69it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 47%|████▋     | 1112/2363 [03:20<02:43,  7.65it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1112\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47361090779304504, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4794, 'eval_samples_per_second': 283.517, 'eval_steps_per_second': 70.991, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1112/special_tokens_map.json\n",
      " 53%|█████▎    | 1250/2363 [03:40<02:15,  8.22it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 75.51it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:05, 60.11it/s]\u001b[A\n",
      "  8%|▊         | 25/318 [00:00<00:04, 69.32it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 72.95it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 74.54it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 71.91it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 73.81it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 71.23it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 74.26it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 74.81it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:02, 75.99it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 78.64it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 79.26it/s]\u001b[A\n",
      " 37%|███▋      | 117/318 [00:01<00:02, 74.39it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 76.04it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 72.84it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 68.98it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 72.56it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 76.13it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 72.77it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 74.28it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 77.19it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 79.04it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 80.11it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 81.98it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 81.83it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 81.75it/s]\u001b[A\n",
      " 75%|███████▌  | 239/318 [00:03<00:01, 74.39it/s]\u001b[A\n",
      " 78%|███████▊  | 247/318 [00:03<00:01, 67.75it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 71.69it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 73.58it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 75.20it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 74.62it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:03<00:00, 76.92it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:03<00:00, 78.53it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 74.31it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 64.50it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 53%|█████▎    | 1251/2363 [03:45<02:15,  8.22it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1251\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1251/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3965841829776764, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3915, 'eval_samples_per_second': 289.196, 'eval_steps_per_second': 72.413, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1251/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1251/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-7/checkpoint-1251/special_tokens_map.json\n",
      " 59%|█████▉    | 1389/2363 [04:06<02:00,  8.10it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 86.86it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 64.76it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 69.62it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 74.04it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:04, 68.55it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 70.23it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 71.95it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 71.57it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 73.53it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 75.14it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:02, 76.47it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:02, 77.07it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 77.54it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 76.67it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 77.26it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 75.11it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 73.00it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:02<00:02, 72.39it/s]\u001b[A\n",
      " 49%|████▊     | 155/318 [00:02<00:02, 69.91it/s]\u001b[A\n",
      " 51%|█████▏    | 163/318 [00:02<00:02, 72.55it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:01, 73.98it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 75.63it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 76.13it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 70.89it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:02<00:01, 72.93it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 66.41it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:03<00:01, 67.05it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 69.77it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 72.51it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 70.37it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:01, 59.73it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 64.38it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 68.05it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 67.34it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 67.53it/s]\u001b[A\n",
      " 91%|█████████ | 289/318 [00:04<00:00, 69.59it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 72.82it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 74.30it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 75.18it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 59%|█████▉    | 1390/2363 [04:11<02:00,  8.10it/s]A\n",
      "                                                 \u001b[A\u001b[32m[I 2022-03-29 18:07:16,661]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3673970103263855, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5452, 'eval_samples_per_second': 279.413, 'eval_steps_per_second': 69.963, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 11\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21784<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_180302-2me0cxss/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_180302-2me0cxss/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.3674</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.5452</td></tr><tr><td>eval/samples_per_second</td><td>279.413</td></tr><tr><td>eval/steps_per_second</td><td>69.963</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>1390</td></tr><tr><td>_runtime</td><td>254</td></tr><tr><td>_timestamp</td><td>1648570036</td></tr><tr><td>_step</td><td>11</td></tr><tr><td>train/loss</td><td>0.4835</td></tr><tr><td>train/learning_rate</td><td>0.00162</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▁▁█▂▁▅▄▇▄▃</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▆▅▅▃▂▁▅▃▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▄▄▆▇█▄▆▃</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▄▄▆▇█▄▆▃</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▃▄▅▆▆▆▇█</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▃▄▅▆▆▆▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▃▃▄▅▆▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▃▄▅▆▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fancy-blaze-17</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2me0cxss\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2me0cxss</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lilac-firefly-19</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/1z3vt49b\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/1z3vt49b</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_180726-1z3vt49b</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 1390/2363 [04:23<03:04,  5.27it/s]\n",
      "\n",
      "  0%|          | 1/3058 [00:00<13:21,  3.81it/s]\u001b[A\n",
      "  0%|          | 2/3058 [00:00<10:18,  4.94it/s]\u001b[A\n",
      "  0%|          | 3/3058 [00:00<09:24,  5.41it/s]\u001b[A\n",
      "  0%|          | 4/3058 [00:00<08:49,  5.77it/s]\u001b[A\n",
      "  0%|          | 5/3058 [00:00<08:23,  6.07it/s]\u001b[A\n",
      "  0%|          | 6/3058 [00:01<08:04,  6.30it/s]\u001b[A\n",
      "  0%|          | 7/3058 [00:01<07:56,  6.40it/s]\u001b[A\n",
      "  0%|          | 8/3058 [00:01<07:50,  6.48it/s]\u001b[A\n",
      "  0%|          | 9/3058 [00:01<07:43,  6.58it/s]\u001b[A\n",
      "  0%|          | 10/3058 [00:01<07:30,  6.76it/s]\u001b[A\n",
      "  0%|          | 11/3058 [00:01<07:22,  6.89it/s]\u001b[A\n",
      "  0%|          | 12/3058 [00:01<07:22,  6.88it/s]\u001b[A\n",
      "  0%|          | 13/3058 [00:02<07:17,  6.97it/s]\u001b[A\n",
      "  0%|          | 14/3058 [00:02<07:07,  7.12it/s]\u001b[A\n",
      "  0%|          | 15/3058 [00:02<07:09,  7.08it/s]\u001b[A\n",
      "  1%|          | 16/3058 [00:02<06:55,  7.33it/s]\u001b[A\n",
      "  1%|          | 17/3058 [00:02<06:59,  7.25it/s]\u001b[A\n",
      "  1%|          | 18/3058 [00:02<07:13,  7.01it/s]\u001b[A\n",
      "  1%|          | 20/3058 [00:02<05:56,  8.52it/s]\u001b[A\n",
      "  1%|          | 21/3058 [00:03<06:30,  7.78it/s]\u001b[A\n",
      "  1%|          | 22/3058 [00:03<06:42,  7.55it/s]\u001b[A\n",
      "  1%|          | 23/3058 [00:03<06:49,  7.42it/s]\u001b[A\n",
      "  1%|          | 24/3058 [00:03<06:58,  7.26it/s]\u001b[A\n",
      "  1%|          | 25/3058 [00:03<06:39,  7.59it/s]\u001b[A\n",
      "  1%|          | 26/3058 [00:03<06:13,  8.12it/s]\u001b[A\n",
      "  1%|          | 27/3058 [00:03<06:19,  7.99it/s]\u001b[A\n",
      "  1%|          | 28/3058 [00:04<06:47,  7.44it/s]\u001b[A\n",
      "  1%|          | 29/3058 [00:04<06:54,  7.30it/s]\u001b[A\n",
      "  1%|          | 30/3058 [00:04<06:31,  7.73it/s]\u001b[A\n",
      "  1%|          | 31/3058 [00:04<06:31,  7.72it/s]\u001b[A\n",
      "  1%|          | 32/3058 [00:04<06:42,  7.52it/s]\u001b[A\n",
      "  1%|          | 33/3058 [00:04<06:48,  7.41it/s]\u001b[A\n",
      "  1%|          | 34/3058 [00:04<06:51,  7.35it/s]\u001b[A\n",
      "  1%|          | 35/3058 [00:04<06:46,  7.44it/s]\u001b[A\n",
      "  1%|          | 36/3058 [00:05<06:50,  7.37it/s]\u001b[A\n",
      "  1%|          | 37/3058 [00:05<06:51,  7.35it/s]\u001b[A\n",
      "  1%|          | 38/3058 [00:05<06:58,  7.22it/s]\u001b[A\n",
      "  1%|▏         | 39/3058 [00:05<06:58,  7.21it/s]\u001b[A\n",
      "  1%|▏         | 40/3058 [00:05<06:51,  7.34it/s]\u001b[A\n",
      "  1%|▏         | 41/3058 [00:05<06:54,  7.27it/s]\u001b[A\n",
      "  1%|▏         | 42/3058 [00:05<06:52,  7.31it/s]\u001b[A\n",
      "  1%|▏         | 43/3058 [00:06<06:54,  7.27it/s]\u001b[A\n",
      "  1%|▏         | 44/3058 [00:06<06:48,  7.38it/s]\u001b[A\n",
      "  1%|▏         | 45/3058 [00:06<06:52,  7.30it/s]\u001b[A\n",
      "  2%|▏         | 46/3058 [00:06<06:50,  7.34it/s]\u001b[A\n",
      "  2%|▏         | 47/3058 [00:06<06:39,  7.53it/s]\u001b[A\n",
      "  2%|▏         | 49/3058 [00:06<05:32,  9.05it/s]\u001b[A\n",
      "  2%|▏         | 50/3058 [00:06<05:28,  9.15it/s]\u001b[A\n",
      "  2%|▏         | 51/3058 [00:07<06:46,  7.40it/s]\u001b[A\n",
      "  2%|▏         | 52/3058 [00:07<07:23,  6.78it/s]\u001b[A\n",
      "  2%|▏         | 53/3058 [00:07<07:31,  6.66it/s]\u001b[A\n",
      "  2%|▏         | 54/3058 [00:07<07:40,  6.53it/s]\u001b[A\n",
      "  2%|▏         | 55/3058 [00:07<07:33,  6.63it/s]\u001b[A\n",
      "  2%|▏         | 56/3058 [00:07<07:32,  6.64it/s]\u001b[A\n",
      "  2%|▏         | 57/3058 [00:08<07:17,  6.86it/s]\u001b[A\n",
      "  2%|▏         | 58/3058 [00:08<07:21,  6.80it/s]\u001b[A\n",
      "  2%|▏         | 59/3058 [00:08<07:18,  6.83it/s]\u001b[A\n",
      "  2%|▏         | 60/3058 [00:08<07:25,  6.72it/s]\u001b[A\n",
      "  2%|▏         | 61/3058 [00:08<07:28,  6.68it/s]\u001b[A\n",
      "  2%|▏         | 62/3058 [00:08<06:58,  7.17it/s]\u001b[A\n",
      "  2%|▏         | 63/3058 [00:08<06:40,  7.49it/s]\u001b[A\n",
      "  2%|▏         | 64/3058 [00:08<06:18,  7.92it/s]\u001b[A\n",
      "  2%|▏         | 65/3058 [00:09<06:18,  7.91it/s]\u001b[A\n",
      "  2%|▏         | 66/3058 [00:09<06:30,  7.66it/s]\u001b[A\n",
      "  2%|▏         | 67/3058 [00:09<06:37,  7.53it/s]\u001b[A\n",
      "  2%|▏         | 68/3058 [00:09<06:46,  7.35it/s]\u001b[A\n",
      "  2%|▏         | 69/3058 [00:09<06:55,  7.19it/s]\u001b[A\n",
      "  2%|▏         | 70/3058 [00:09<07:03,  7.05it/s]\u001b[A\n",
      "  2%|▏         | 71/3058 [00:09<06:59,  7.12it/s]\u001b[A\n",
      "  2%|▏         | 72/3058 [00:10<07:06,  7.00it/s]\u001b[A\n",
      "  2%|▏         | 73/3058 [00:10<07:05,  7.02it/s]\u001b[A\n",
      "  2%|▏         | 74/3058 [00:10<07:07,  6.98it/s]\u001b[A\n",
      "  2%|▏         | 75/3058 [00:10<07:02,  7.05it/s]\u001b[A\n",
      "  2%|▏         | 76/3058 [00:10<07:04,  7.02it/s]\u001b[A\n",
      "  3%|▎         | 77/3058 [00:10<07:02,  7.05it/s]\u001b[A\n",
      "  3%|▎         | 78/3058 [00:10<07:02,  7.06it/s]\u001b[A\n",
      "  3%|▎         | 79/3058 [00:11<06:54,  7.18it/s]\u001b[A\n",
      "  3%|▎         | 80/3058 [00:11<06:57,  7.13it/s]\u001b[A\n",
      "  3%|▎         | 81/3058 [00:11<06:59,  7.10it/s]\u001b[A\n",
      "  3%|▎         | 82/3058 [00:11<06:58,  7.11it/s]\u001b[A\n",
      "  3%|▎         | 83/3058 [00:11<07:01,  7.06it/s]\u001b[A\n",
      "  3%|▎         | 84/3058 [00:11<07:01,  7.06it/s]\u001b[A\n",
      "  3%|▎         | 86/3058 [00:11<05:35,  8.86it/s]\u001b[A\n",
      "  3%|▎         | 87/3058 [00:12<05:26,  9.11it/s]\u001b[A\n",
      "  3%|▎         | 88/3058 [00:12<05:51,  8.44it/s]\u001b[A\n",
      "  3%|▎         | 89/3058 [00:12<05:45,  8.59it/s]\u001b[A\n",
      "  3%|▎         | 91/3058 [00:12<05:12,  9.50it/s]\u001b[A\n",
      "  3%|▎         | 92/3058 [00:12<05:09,  9.57it/s]\u001b[A\n",
      "  3%|▎         | 93/3058 [00:12<05:07,  9.65it/s]\u001b[A\n",
      "  3%|▎         | 94/3058 [00:12<05:27,  9.05it/s]\u001b[A\n",
      "  3%|▎         | 95/3058 [00:12<05:48,  8.50it/s]\u001b[A\n",
      "  3%|▎         | 96/3058 [00:13<05:41,  8.67it/s]\u001b[A\n",
      "  3%|▎         | 98/3058 [00:13<05:17,  9.31it/s]\u001b[A\n",
      "  3%|▎         | 99/3058 [00:13<05:32,  8.91it/s]\u001b[A\n",
      "  3%|▎         | 100/3058 [00:13<05:51,  8.42it/s]\u001b[A\n",
      "  3%|▎         | 101/3058 [00:13<07:01,  7.02it/s]\u001b[A\n",
      "  3%|▎         | 102/3058 [00:13<07:09,  6.88it/s]\u001b[A\n",
      "  3%|▎         | 103/3058 [00:13<06:55,  7.12it/s]\u001b[A\n",
      "  3%|▎         | 104/3058 [00:14<06:32,  7.52it/s]\u001b[A\n",
      "  3%|▎         | 105/3058 [00:14<06:18,  7.81it/s]\u001b[A\n",
      "  3%|▎         | 106/3058 [00:14<06:23,  7.70it/s]\u001b[A\n",
      "  3%|▎         | 107/3058 [00:14<06:30,  7.55it/s]\u001b[A\n",
      "  4%|▎         | 108/3058 [00:14<06:48,  7.21it/s]\u001b[A\n",
      "  4%|▎         | 109/3058 [00:14<06:54,  7.12it/s]\u001b[A\n",
      "  4%|▎         | 110/3058 [00:14<06:55,  7.10it/s]\u001b[A\n",
      "  4%|▎         | 111/3058 [00:15<06:53,  7.12it/s]\u001b[A\n",
      "  4%|▎         | 112/3058 [00:15<07:19,  6.71it/s]\u001b[A\n",
      "  4%|▎         | 113/3058 [00:15<06:50,  7.17it/s]\u001b[A\n",
      "  4%|▎         | 114/3058 [00:15<06:37,  7.41it/s]\u001b[A\n",
      "  4%|▍         | 115/3058 [00:15<06:45,  7.25it/s]\u001b[A\n",
      "  4%|▍         | 116/3058 [00:15<06:50,  7.17it/s]\u001b[A\n",
      "  4%|▍         | 117/3058 [00:15<06:48,  7.19it/s]\u001b[A\n",
      "  4%|▍         | 118/3058 [00:16<06:51,  7.14it/s]\u001b[A\n",
      "  4%|▍         | 119/3058 [00:16<06:55,  7.08it/s]\u001b[A\n",
      "  4%|▍         | 120/3058 [00:16<06:56,  7.05it/s]\u001b[A\n",
      "  4%|▍         | 121/3058 [00:16<06:52,  7.13it/s]\u001b[A\n",
      "  4%|▍         | 122/3058 [00:16<06:57,  7.04it/s]\u001b[A\n",
      "  4%|▍         | 123/3058 [00:16<06:32,  7.47it/s]\u001b[A\n",
      "  4%|▍         | 125/3058 [00:16<05:35,  8.74it/s]\u001b[A\n",
      "  4%|▍         | 126/3058 [00:17<05:50,  8.36it/s]\u001b[A\n",
      "  4%|▍         | 127/3058 [00:17<06:08,  7.95it/s]\u001b[A\n",
      "  4%|▍         | 128/3058 [00:17<06:22,  7.65it/s]\u001b[A\n",
      "  4%|▍         | 129/3058 [00:17<06:26,  7.58it/s]\u001b[A\n",
      "  4%|▍         | 130/3058 [00:17<06:38,  7.34it/s]\u001b[A\n",
      "  4%|▍         | 131/3058 [00:17<06:41,  7.29it/s]\u001b[A\n",
      "  4%|▍         | 132/3058 [00:17<06:40,  7.30it/s]\u001b[A\n",
      "  4%|▍         | 133/3058 [00:18<06:45,  7.21it/s]\u001b[A\n",
      "  4%|▍         | 134/3058 [00:18<06:17,  7.74it/s]\u001b[A\n",
      "  4%|▍         | 135/3058 [00:18<06:15,  7.79it/s]\u001b[A\n",
      "  4%|▍         | 136/3058 [00:18<06:22,  7.63it/s]\u001b[A\n",
      "  4%|▍         | 137/3058 [00:18<06:27,  7.55it/s]\u001b[A\n",
      "  5%|▍         | 138/3058 [00:18<06:31,  7.47it/s]\u001b[A\n",
      "  5%|▍         | 139/3058 [00:18<06:35,  7.38it/s]\u001b[A\n",
      "  5%|▍         | 140/3058 [00:18<06:46,  7.18it/s]\u001b[A\n",
      "  5%|▍         | 141/3058 [00:19<06:22,  7.63it/s]\u001b[A\n",
      "  5%|▍         | 142/3058 [00:19<06:25,  7.56it/s]\u001b[A\n",
      "  5%|▍         | 143/3058 [00:19<06:13,  7.80it/s]\u001b[A\n",
      "  5%|▍         | 144/3058 [00:19<06:15,  7.76it/s]\u001b[A\n",
      "  5%|▍         | 145/3058 [00:19<06:22,  7.62it/s]\u001b[A\n",
      "  5%|▍         | 146/3058 [00:19<06:27,  7.51it/s]\u001b[A\n",
      "  5%|▍         | 147/3058 [00:19<06:28,  7.49it/s]\u001b[A\n",
      "  5%|▍         | 148/3058 [00:20<06:30,  7.45it/s]\u001b[A\n",
      "  5%|▍         | 149/3058 [00:20<06:27,  7.51it/s]\u001b[A\n",
      "  5%|▍         | 150/3058 [00:20<06:29,  7.47it/s]\u001b[A\n",
      "  5%|▍         | 151/3058 [00:20<07:40,  6.32it/s]\u001b[A\n",
      "  5%|▍         | 152/3058 [00:20<08:01,  6.03it/s]\u001b[A\n",
      "  5%|▌         | 153/3058 [00:20<08:04,  5.99it/s]\u001b[A\n",
      "  5%|▌         | 154/3058 [00:21<07:57,  6.08it/s]\u001b[A\n",
      "  5%|▌         | 155/3058 [00:21<07:51,  6.16it/s]\u001b[A\n",
      "  5%|▌         | 156/3058 [00:21<07:39,  6.32it/s]\u001b[A\n",
      "  5%|▌         | 157/3058 [00:21<07:25,  6.51it/s]\u001b[A\n",
      "  5%|▌         | 158/3058 [00:21<07:20,  6.58it/s]\u001b[A\n",
      "  5%|▌         | 159/3058 [00:21<07:17,  6.63it/s]\u001b[A\n",
      "  5%|▌         | 160/3058 [00:21<07:08,  6.77it/s]\u001b[A\n",
      "  5%|▌         | 161/3058 [00:22<07:04,  6.82it/s]\u001b[A\n",
      "  5%|▌         | 162/3058 [00:22<07:06,  6.80it/s]\u001b[A\n",
      "  5%|▌         | 163/3058 [00:22<06:35,  7.32it/s]\u001b[A\n",
      "  5%|▌         | 164/3058 [00:22<06:20,  7.60it/s]\u001b[A\n",
      "  5%|▌         | 165/3058 [00:22<06:24,  7.52it/s]\u001b[A\n",
      "  5%|▌         | 166/3058 [00:22<06:37,  7.27it/s]\u001b[A\n",
      "  5%|▌         | 167/3058 [00:22<06:35,  7.31it/s]\u001b[A\n",
      "  5%|▌         | 168/3058 [00:22<06:05,  7.92it/s]\u001b[A\n",
      "  6%|▌         | 170/3058 [00:23<05:36,  8.58it/s]\u001b[A\n",
      "  6%|▌         | 171/3058 [00:23<05:49,  8.26it/s]\u001b[A\n",
      "  6%|▌         | 172/3058 [00:23<06:06,  7.87it/s]\u001b[A\n",
      "  6%|▌         | 173/3058 [00:23<06:15,  7.68it/s]\u001b[A\n",
      "  6%|▌         | 174/3058 [00:23<06:12,  7.73it/s]\u001b[A\n",
      "  6%|▌         | 175/3058 [00:23<06:15,  7.67it/s]\u001b[A\n",
      "  6%|▌         | 176/3058 [00:23<06:23,  7.52it/s]\u001b[A\n",
      "  6%|▌         | 177/3058 [00:24<06:28,  7.41it/s]\u001b[A\n",
      "  6%|▌         | 179/3058 [00:24<05:20,  8.98it/s]\u001b[A\n",
      "  6%|▌         | 181/3058 [00:24<04:58,  9.64it/s]\u001b[A\n",
      "  6%|▌         | 182/3058 [00:24<05:20,  8.99it/s]\u001b[A\n",
      "  6%|▌         | 183/3058 [00:24<05:37,  8.53it/s]\u001b[A\n",
      "  6%|▌         | 184/3058 [00:24<05:51,  8.18it/s]\u001b[A\n",
      "  6%|▌         | 185/3058 [00:25<06:01,  7.96it/s]\u001b[A\n",
      "  6%|▌         | 186/3058 [00:25<06:09,  7.78it/s]\u001b[A\n",
      "  6%|▌         | 187/3058 [00:25<06:13,  7.68it/s]\u001b[A\n",
      "  6%|▌         | 188/3058 [00:25<06:17,  7.59it/s]\u001b[A\n",
      "  6%|▌         | 189/3058 [00:25<06:20,  7.55it/s]\u001b[A\n",
      "  6%|▌         | 190/3058 [00:25<06:24,  7.46it/s]\u001b[A\n",
      "  6%|▌         | 191/3058 [00:25<06:28,  7.38it/s]\u001b[A\n",
      "  6%|▋         | 192/3058 [00:25<06:32,  7.30it/s]\u001b[A\n",
      "  6%|▋         | 193/3058 [00:26<06:32,  7.31it/s]\u001b[A\n",
      "  6%|▋         | 194/3058 [00:26<06:33,  7.28it/s]\u001b[A\n",
      "  6%|▋         | 195/3058 [00:26<06:33,  7.28it/s]\u001b[A\n",
      "  6%|▋         | 196/3058 [00:26<06:26,  7.41it/s]\u001b[A\n",
      "  6%|▋         | 197/3058 [00:26<06:23,  7.46it/s]\u001b[A\n",
      "  6%|▋         | 198/3058 [00:26<06:24,  7.44it/s]\u001b[A\n",
      "  7%|▋         | 199/3058 [00:26<06:00,  7.92it/s]\u001b[A\n",
      "  7%|▋         | 200/3058 [00:27<06:05,  7.81it/s]\u001b[A\n",
      "  7%|▋         | 201/3058 [00:27<07:28,  6.37it/s]\u001b[A\n",
      "  7%|▋         | 202/3058 [00:27<08:00,  5.94it/s]\u001b[A\n",
      "  7%|▋         | 203/3058 [00:27<08:06,  5.87it/s]\u001b[A\n",
      "  7%|▋         | 204/3058 [00:27<08:01,  5.92it/s]\u001b[A\n",
      "  7%|▋         | 205/3058 [00:27<07:57,  5.98it/s]\u001b[A\n",
      "  7%|▋         | 206/3058 [00:28<07:46,  6.12it/s]\u001b[A\n",
      "  7%|▋         | 207/3058 [00:28<07:34,  6.27it/s]\u001b[A\n",
      "  7%|▋         | 208/3058 [00:28<06:54,  6.87it/s]\u001b[A\n",
      "  7%|▋         | 210/3058 [00:28<06:10,  7.69it/s]\u001b[A\n",
      "  7%|▋         | 211/3058 [00:28<06:29,  7.31it/s]\u001b[A\n",
      "  7%|▋         | 212/3058 [00:28<06:12,  7.63it/s]\u001b[A\n",
      "  7%|▋         | 214/3058 [00:29<05:21,  8.85it/s]\u001b[A\n",
      "  7%|▋         | 216/3058 [00:29<04:54,  9.66it/s]\u001b[A\n",
      "  7%|▋         | 218/3058 [00:29<04:37, 10.22it/s]\u001b[A\n",
      "  7%|▋         | 220/3058 [00:29<04:51,  9.72it/s]\u001b[A\n",
      "  7%|▋         | 222/3058 [00:29<04:38, 10.19it/s]\u001b[A\n",
      "  7%|▋         | 224/3058 [00:29<04:44,  9.95it/s]\u001b[A\n",
      "  7%|▋         | 226/3058 [00:30<04:22, 10.77it/s]\u001b[A\n",
      "  7%|▋         | 228/3058 [00:30<04:16, 11.03it/s]\u001b[A\n",
      "  8%|▊         | 230/3058 [00:30<04:49,  9.78it/s]\u001b[A\n",
      "  8%|▊         | 232/3058 [00:30<04:34, 10.30it/s]\u001b[A\n",
      "  8%|▊         | 234/3058 [00:30<04:27, 10.57it/s]\u001b[A\n",
      "  8%|▊         | 236/3058 [00:31<04:18, 10.92it/s]\u001b[A\n",
      "  8%|▊         | 238/3058 [00:31<04:42,  9.99it/s]\u001b[A\n",
      "  8%|▊         | 240/3058 [00:31<05:06,  9.20it/s]\u001b[A\n",
      "  8%|▊         | 242/3058 [00:31<04:45,  9.87it/s]\u001b[A\n",
      "  8%|▊         | 244/3058 [00:31<04:29, 10.45it/s]\u001b[A\n",
      "  8%|▊         | 246/3058 [00:32<04:25, 10.57it/s]\u001b[A\n",
      "  8%|▊         | 248/3058 [00:32<04:22, 10.72it/s]\u001b[A\n",
      "  8%|▊         | 250/3058 [00:32<04:27, 10.52it/s]\u001b[A\n",
      "  8%|▊         | 252/3058 [00:32<05:45,  8.11it/s]\u001b[A\n",
      "  8%|▊         | 253/3058 [00:32<05:43,  8.16it/s]\u001b[A\n",
      "  8%|▊         | 254/3058 [00:33<05:40,  8.24it/s]\u001b[A\n",
      "  8%|▊         | 255/3058 [00:33<05:39,  8.26it/s]\u001b[A\n",
      "  8%|▊         | 256/3058 [00:33<05:28,  8.52it/s]\u001b[A\n",
      "  8%|▊         | 257/3058 [00:33<05:29,  8.51it/s]\u001b[A\n",
      "  8%|▊         | 258/3058 [00:33<05:52,  7.94it/s]\u001b[A\n",
      "  8%|▊         | 259/3058 [00:33<05:45,  8.09it/s]\u001b[A\n",
      "  9%|▊         | 261/3058 [00:33<05:09,  9.04it/s]\u001b[A\n",
      "  9%|▊         | 263/3058 [00:34<04:49,  9.66it/s]\u001b[A\n",
      "  9%|▊         | 264/3058 [00:34<05:05,  9.15it/s]\u001b[A\n",
      "  9%|▊         | 265/3058 [00:34<05:02,  9.23it/s]\u001b[A\n",
      "  9%|▊         | 267/3058 [00:34<04:36, 10.09it/s]\u001b[A\n",
      "  9%|▉         | 269/3058 [00:34<04:18, 10.78it/s]\u001b[A\n",
      "  9%|▉         | 271/3058 [00:34<04:10, 11.15it/s]\u001b[A\n",
      "  9%|▉         | 273/3058 [00:35<04:47,  9.70it/s]\u001b[A\n",
      "  9%|▉         | 274/3058 [00:35<05:08,  9.03it/s]\u001b[A\n",
      "  9%|▉         | 275/3058 [00:35<05:23,  8.61it/s]\u001b[A\n",
      "  9%|▉         | 276/3058 [00:35<05:35,  8.28it/s]\u001b[A\n",
      "  9%|▉         | 277/3058 [00:35<05:31,  8.38it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 68.55it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3667420446872711, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4978, 'eval_samples_per_second': 282.361, 'eval_steps_per_second': 70.701, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-278/special_tokens_map.json\n",
      "\n",
      "  9%|▉         | 279/3058 [00:43<1:19:23,  1.71s/it]\u001b[A\n",
      "  9%|▉         | 280/3058 [00:43<1:02:47,  1.36s/it]\u001b[A\n",
      "  9%|▉         | 281/3058 [00:43<48:40,  1.05s/it]  \u001b[A\n",
      "  9%|▉         | 282/3058 [00:43<37:53,  1.22it/s]\u001b[A\n",
      "  9%|▉         | 283/3058 [00:44<29:16,  1.58it/s]\u001b[A\n",
      "  9%|▉         | 284/3058 [00:44<22:30,  2.05it/s]\u001b[A\n",
      "  9%|▉         | 285/3058 [00:44<17:41,  2.61it/s]\u001b[A\n",
      "  9%|▉         | 286/3058 [00:44<14:12,  3.25it/s]\u001b[A\n",
      "  9%|▉         | 287/3058 [00:44<11:36,  3.98it/s]\u001b[A\n",
      "  9%|▉         | 289/3058 [00:44<08:11,  5.64it/s]\u001b[A\n",
      "  9%|▉         | 290/3058 [00:44<07:40,  6.02it/s]\u001b[A\n",
      " 10%|▉         | 291/3058 [00:44<07:26,  6.20it/s]\u001b[A\n",
      " 10%|▉         | 292/3058 [00:45<07:09,  6.44it/s]\u001b[A\n",
      " 10%|▉         | 293/3058 [00:45<06:37,  6.95it/s]\u001b[A\n",
      " 10%|▉         | 295/3058 [00:45<05:32,  8.31it/s]\u001b[A\n",
      " 10%|▉         | 296/3058 [00:45<05:39,  8.14it/s]\u001b[A\n",
      " 10%|▉         | 298/3058 [00:45<04:56,  9.32it/s]\u001b[A\n",
      " 10%|▉         | 300/3058 [00:45<04:19, 10.61it/s]\u001b[A\n",
      " 10%|▉         | 302/3058 [00:46<04:11, 10.97it/s]\u001b[A\n",
      " 10%|▉         | 304/3058 [00:46<04:08, 11.08it/s]\u001b[A\n",
      " 10%|█         | 306/3058 [00:46<04:18, 10.66it/s]\u001b[A\n",
      " 10%|█         | 308/3058 [00:46<04:04, 11.25it/s]\u001b[A\n",
      " 10%|█         | 310/3058 [00:46<04:03, 11.27it/s]\u001b[A\n",
      " 10%|█         | 312/3058 [00:46<03:47, 12.05it/s]\u001b[A\n",
      " 10%|█         | 314/3058 [00:47<03:39, 12.48it/s]\u001b[A\n",
      " 10%|█         | 316/3058 [00:47<03:54, 11.71it/s]\u001b[A\n",
      " 10%|█         | 318/3058 [00:47<03:59, 11.42it/s]\u001b[A\n",
      " 10%|█         | 320/3058 [00:47<03:54, 11.66it/s]\u001b[A\n",
      " 11%|█         | 322/3058 [00:47<03:37, 12.57it/s]\u001b[A\n",
      " 11%|█         | 324/3058 [00:47<03:28, 13.10it/s]\u001b[A\n",
      " 11%|█         | 326/3058 [00:48<04:07, 11.02it/s]\u001b[A\n",
      " 11%|█         | 328/3058 [00:48<04:47,  9.50it/s]\u001b[A\n",
      " 11%|█         | 330/3058 [00:48<05:44,  7.92it/s]\u001b[A\n",
      " 11%|█         | 331/3058 [00:48<05:44,  7.92it/s]\u001b[A\n",
      " 11%|█         | 332/3058 [00:49<06:01,  7.54it/s]\u001b[A\n",
      " 11%|█         | 333/3058 [00:49<06:12,  7.32it/s]\u001b[A\n",
      " 11%|█         | 334/3058 [00:49<06:08,  7.38it/s]\u001b[A\n",
      " 11%|█         | 335/3058 [00:49<06:03,  7.49it/s]\u001b[A\n",
      " 11%|█         | 336/3058 [00:49<06:19,  7.17it/s]\u001b[A\n",
      " 11%|█         | 337/3058 [00:49<05:52,  7.73it/s]\u001b[A\n",
      " 11%|█         | 339/3058 [00:49<05:02,  9.00it/s]\u001b[A\n",
      " 11%|█         | 341/3058 [00:50<04:56,  9.16it/s]\u001b[A\n",
      " 11%|█         | 342/3058 [00:50<05:16,  8.59it/s]\u001b[A\n",
      " 11%|█         | 343/3058 [00:50<05:46,  7.83it/s]\u001b[A\n",
      " 11%|█         | 344/3058 [00:50<05:54,  7.66it/s]\u001b[A\n",
      " 11%|█▏        | 345/3058 [00:50<05:35,  8.09it/s]\u001b[A\n",
      " 11%|█▏        | 347/3058 [00:50<05:20,  8.47it/s]\u001b[A\n",
      " 11%|█▏        | 348/3058 [00:50<05:12,  8.67it/s]\u001b[A\n",
      " 11%|█▏        | 349/3058 [00:51<05:03,  8.94it/s]\u001b[A\n",
      " 11%|█▏        | 351/3058 [00:51<05:03,  8.91it/s]\u001b[A\n",
      " 12%|█▏        | 352/3058 [00:51<04:56,  9.13it/s]\u001b[A\n",
      " 12%|█▏        | 354/3058 [00:51<04:30, 10.01it/s]\u001b[A\n",
      " 12%|█▏        | 356/3058 [00:51<04:47,  9.39it/s]\u001b[A\n",
      " 12%|█▏        | 357/3058 [00:51<04:56,  9.12it/s]\u001b[A\n",
      " 12%|█▏        | 358/3058 [00:52<05:06,  8.80it/s]\u001b[A\n",
      " 12%|█▏        | 360/3058 [00:52<04:33,  9.85it/s]\u001b[A\n",
      " 12%|█▏        | 362/3058 [00:52<04:10, 10.74it/s]\u001b[A\n",
      " 12%|█▏        | 364/3058 [00:52<04:03, 11.08it/s]\u001b[A\n",
      " 12%|█▏        | 366/3058 [00:52<03:59, 11.24it/s]\u001b[A\n",
      " 12%|█▏        | 368/3058 [00:52<04:08, 10.82it/s]\u001b[A\n",
      " 12%|█▏        | 370/3058 [00:53<04:30,  9.95it/s]\u001b[A\n",
      " 12%|█▏        | 372/3058 [00:53<04:37,  9.68it/s]\u001b[A\n",
      " 12%|█▏        | 374/3058 [00:53<04:31,  9.89it/s]\u001b[A\n",
      " 12%|█▏        | 376/3058 [00:53<04:41,  9.53it/s]\u001b[A\n",
      " 12%|█▏        | 377/3058 [00:53<04:46,  9.36it/s]\u001b[A\n",
      " 12%|█▏        | 379/3058 [00:54<05:03,  8.83it/s]\u001b[A\n",
      " 12%|█▏        | 380/3058 [00:54<05:19,  8.38it/s]\u001b[A\n",
      " 12%|█▏        | 381/3058 [00:54<05:45,  7.75it/s]\u001b[A\n",
      " 12%|█▏        | 382/3058 [00:54<06:03,  7.37it/s]\u001b[A\n",
      " 13%|█▎        | 383/3058 [00:54<06:12,  7.18it/s]\u001b[A\n",
      " 13%|█▎        | 384/3058 [00:54<06:22,  7.00it/s]\u001b[A\n",
      " 13%|█▎        | 385/3058 [00:55<06:28,  6.88it/s]\u001b[A\n",
      " 13%|█▎        | 386/3058 [00:55<06:30,  6.84it/s]\u001b[A\n",
      " 13%|█▎        | 387/3058 [00:55<06:37,  6.72it/s]\u001b[A\n",
      " 13%|█▎        | 388/3058 [00:55<06:21,  7.00it/s]\u001b[A\n",
      " 13%|█▎        | 389/3058 [00:55<05:58,  7.45it/s]\u001b[A\n",
      " 13%|█▎        | 390/3058 [00:55<05:44,  7.75it/s]\u001b[A\n",
      " 13%|█▎        | 391/3058 [00:55<05:41,  7.81it/s]\u001b[A\n",
      " 13%|█▎        | 392/3058 [00:55<05:21,  8.31it/s]\u001b[A\n",
      " 13%|█▎        | 393/3058 [00:56<05:07,  8.65it/s]\u001b[A\n",
      " 13%|█▎        | 394/3058 [00:56<05:03,  8.78it/s]\u001b[A\n",
      " 13%|█▎        | 396/3058 [00:56<04:32,  9.78it/s]\u001b[A\n",
      " 13%|█▎        | 397/3058 [00:56<04:55,  9.00it/s]\u001b[A\n",
      " 13%|█▎        | 398/3058 [00:56<05:20,  8.30it/s]\u001b[A\n",
      " 13%|█▎        | 399/3058 [00:56<05:40,  7.82it/s]\u001b[A\n",
      " 13%|█▎        | 400/3058 [00:56<05:23,  8.21it/s]\u001b[A\n",
      " 13%|█▎        | 401/3058 [00:57<05:24,  8.20it/s]\u001b[A\n",
      " 13%|█▎        | 402/3058 [00:57<05:40,  7.81it/s]\u001b[A\n",
      " 13%|█▎        | 403/3058 [00:57<05:43,  7.73it/s]\u001b[A\n",
      " 13%|█▎        | 405/3058 [00:57<04:53,  9.04it/s]\u001b[A\n",
      " 13%|█▎        | 407/3058 [00:57<04:30,  9.80it/s]\u001b[A\n",
      " 13%|█▎        | 409/3058 [00:57<04:12, 10.50it/s]\u001b[A\n",
      " 13%|█▎        | 411/3058 [00:57<04:14, 10.39it/s]\u001b[A\n",
      " 14%|█▎        | 413/3058 [00:58<04:52,  9.04it/s]\u001b[A\n",
      " 14%|█▎        | 414/3058 [00:58<05:07,  8.59it/s]\u001b[A\n",
      " 14%|█▎        | 415/3058 [00:58<05:22,  8.20it/s]\u001b[A\n",
      " 14%|█▎        | 416/3058 [00:58<05:16,  8.34it/s]\u001b[A\n",
      " 14%|█▎        | 417/3058 [00:58<05:23,  8.17it/s]\u001b[A\n",
      " 14%|█▎        | 418/3058 [00:58<05:35,  7.87it/s]\u001b[A\n",
      " 14%|█▎        | 419/3058 [00:59<05:53,  7.47it/s]\u001b[A\n",
      " 14%|█▎        | 420/3058 [00:59<05:46,  7.62it/s]\u001b[A\n",
      " 14%|█▍        | 421/3058 [00:59<05:38,  7.80it/s]\u001b[A\n",
      " 14%|█▍        | 422/3058 [00:59<05:16,  8.32it/s]\u001b[A\n",
      " 14%|█▍        | 424/3058 [00:59<04:30,  9.73it/s]\u001b[A\n",
      " 14%|█▍        | 426/3058 [00:59<04:06, 10.67it/s]\u001b[A\n",
      " 14%|█▍        | 428/3058 [00:59<03:54, 11.21it/s]\u001b[A\n",
      " 14%|█▍        | 430/3058 [01:00<05:01,  8.70it/s]\u001b[A\n",
      " 14%|█▍        | 431/3058 [01:00<05:36,  7.80it/s]\u001b[A\n",
      " 14%|█▍        | 432/3058 [01:00<05:30,  7.93it/s]\u001b[A\n",
      " 14%|█▍        | 433/3058 [01:00<05:17,  8.27it/s]\u001b[A\n",
      " 14%|█▍        | 435/3058 [01:00<04:50,  9.04it/s]\u001b[A\n",
      " 14%|█▍        | 436/3058 [01:00<04:46,  9.15it/s]\u001b[A\n",
      " 14%|█▍        | 437/3058 [01:01<05:03,  8.63it/s]\u001b[A\n",
      " 14%|█▍        | 438/3058 [01:01<04:55,  8.87it/s]\u001b[A\n",
      " 14%|█▍        | 440/3058 [01:01<04:35,  9.51it/s]\u001b[A\n",
      " 14%|█▍        | 441/3058 [01:01<04:43,  9.24it/s]\u001b[A\n",
      " 14%|█▍        | 442/3058 [01:01<04:41,  9.30it/s]\u001b[A\n",
      " 14%|█▍        | 443/3058 [01:01<04:55,  8.85it/s]\u001b[A\n",
      " 15%|█▍        | 444/3058 [01:01<04:52,  8.93it/s]\u001b[A\n",
      " 15%|█▍        | 445/3058 [01:01<05:00,  8.70it/s]\u001b[A\n",
      " 15%|█▍        | 446/3058 [01:02<04:52,  8.92it/s]\u001b[A\n",
      " 15%|█▍        | 448/3058 [01:02<04:26,  9.78it/s]\u001b[A\n",
      " 15%|█▍        | 449/3058 [01:02<04:46,  9.11it/s]\u001b[A\n",
      " 15%|█▍        | 450/3058 [01:02<05:06,  8.50it/s]\u001b[A\n",
      " 15%|█▍        | 451/3058 [01:02<04:59,  8.71it/s]\u001b[A\n",
      " 15%|█▍        | 453/3058 [01:02<04:43,  9.19it/s]\u001b[A\n",
      " 15%|█▍        | 455/3058 [01:03<04:16, 10.15it/s]\u001b[A\n",
      " 15%|█▍        | 457/3058 [01:03<03:55, 11.06it/s]\u001b[A\n",
      " 15%|█▌        | 459/3058 [01:03<04:03, 10.68it/s]\u001b[A\n",
      " 15%|█▌        | 461/3058 [01:03<04:00, 10.79it/s]\u001b[A\n",
      " 15%|█▌        | 463/3058 [01:03<03:52, 11.17it/s]\u001b[A\n",
      " 15%|█▌        | 465/3058 [01:03<03:52, 11.13it/s]\u001b[A\n",
      " 15%|█▌        | 467/3058 [01:04<03:50, 11.23it/s]\u001b[A\n",
      " 15%|█▌        | 469/3058 [01:04<04:24,  9.78it/s]\u001b[A\n",
      " 15%|█▌        | 471/3058 [01:04<04:25,  9.74it/s]\u001b[A\n",
      " 15%|█▌        | 473/3058 [01:04<04:05, 10.52it/s]\u001b[A\n",
      " 16%|█▌        | 475/3058 [01:04<03:42, 11.62it/s]\u001b[A\n",
      " 16%|█▌        | 477/3058 [01:04<03:44, 11.48it/s]\u001b[A\n",
      " 16%|█▌        | 479/3058 [01:05<04:10, 10.31it/s]\u001b[A\n",
      " 16%|█▌        | 481/3058 [01:05<04:48,  8.92it/s]\u001b[A\n",
      " 16%|█▌        | 482/3058 [01:05<04:48,  8.92it/s]\u001b[A\n",
      " 16%|█▌        | 483/3058 [01:05<05:16,  8.13it/s]\u001b[A\n",
      " 16%|█▌        | 484/3058 [01:05<05:29,  7.80it/s]\u001b[A\n",
      " 16%|█▌        | 485/3058 [01:06<05:17,  8.10it/s]\u001b[A\n",
      " 16%|█▌        | 487/3058 [01:06<04:42,  9.09it/s]\u001b[A\n",
      " 16%|█▌        | 489/3058 [01:06<04:33,  9.40it/s]\u001b[A\n",
      " 16%|█▌        | 490/3058 [01:06<04:49,  8.88it/s]\u001b[A\n",
      " 16%|█▌        | 491/3058 [01:06<05:15,  8.14it/s]\u001b[A\n",
      " 16%|█▌        | 492/3058 [01:06<05:04,  8.42it/s]\u001b[A\n",
      " 16%|█▌        | 493/3058 [01:06<05:00,  8.52it/s]\u001b[A\n",
      " 16%|█▌        | 494/3058 [01:07<04:54,  8.69it/s]\u001b[A\n",
      " 16%|█▌        | 496/3058 [01:07<04:23,  9.72it/s]\u001b[A\n",
      " 16%|█▋        | 498/3058 [01:07<04:02, 10.57it/s]\u001b[A\n",
      " 16%|█▋        | 500/3058 [01:07<05:27,  7.80it/s]\u001b[A\n",
      "\u001b[A                                               \n",
      " 16%|█▋        | 500/3058 [01:07<05:27,  7.80it/s]\u001b[A\n",
      " 16%|█▋        | 501/3058 [01:07<06:05,  6.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4024, 'learning_rate': 0.0009216030650600681, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▋        | 502/3058 [01:08<05:49,  7.31it/s]\u001b[A\n",
      " 16%|█▋        | 503/3058 [01:08<05:48,  7.34it/s]\u001b[A\n",
      " 17%|█▋        | 505/3058 [01:08<05:12,  8.17it/s]\u001b[A\n",
      " 17%|█▋        | 506/3058 [01:08<05:07,  8.30it/s]\u001b[A\n",
      " 17%|█▋        | 508/3058 [01:08<04:13, 10.04it/s]\u001b[A\n",
      " 17%|█▋        | 510/3058 [01:08<04:04, 10.43it/s]\u001b[A\n",
      " 17%|█▋        | 512/3058 [01:09<03:49, 11.11it/s]\u001b[A\n",
      " 17%|█▋        | 514/3058 [01:09<03:52, 10.93it/s]\u001b[A\n",
      " 17%|█▋        | 516/3058 [01:09<03:41, 11.47it/s]\u001b[A\n",
      " 17%|█▋        | 518/3058 [01:09<04:00, 10.54it/s]\u001b[A\n",
      " 17%|█▋        | 520/3058 [01:09<03:52, 10.93it/s]\u001b[A\n",
      " 17%|█▋        | 522/3058 [01:09<03:51, 10.97it/s]\u001b[A\n",
      " 17%|█▋        | 524/3058 [01:10<03:47, 11.14it/s]\u001b[A\n",
      " 17%|█▋        | 526/3058 [01:10<03:32, 11.90it/s]\u001b[A\n",
      " 17%|█▋        | 528/3058 [01:10<03:37, 11.62it/s]\u001b[A\n",
      " 17%|█▋        | 530/3058 [01:10<04:18,  9.77it/s]\u001b[A\n",
      " 17%|█▋        | 532/3058 [01:10<04:31,  9.32it/s]\u001b[A\n",
      " 17%|█▋        | 533/3058 [01:11<04:42,  8.92it/s]\u001b[A\n",
      " 17%|█▋        | 534/3058 [01:11<05:00,  8.41it/s]\u001b[A\n",
      " 17%|█▋        | 535/3058 [01:11<04:59,  8.43it/s]\u001b[A\n",
      " 18%|█▊        | 536/3058 [01:11<05:13,  8.04it/s]\u001b[A\n",
      " 18%|█▊        | 537/3058 [01:11<05:22,  7.81it/s]\u001b[A\n",
      " 18%|█▊        | 538/3058 [01:11<05:29,  7.66it/s]\u001b[A\n",
      " 18%|█▊        | 539/3058 [01:11<05:34,  7.52it/s]\u001b[A\n",
      " 18%|█▊        | 540/3058 [01:12<05:23,  7.77it/s]\u001b[A\n",
      " 18%|█▊        | 542/3058 [01:12<04:42,  8.89it/s]\u001b[A\n",
      " 18%|█▊        | 543/3058 [01:12<04:47,  8.73it/s]\u001b[A\n",
      " 18%|█▊        | 545/3058 [01:12<04:31,  9.26it/s]\u001b[A\n",
      " 18%|█▊        | 547/3058 [01:12<04:11,  9.97it/s]\u001b[A\n",
      " 18%|█▊        | 549/3058 [01:12<03:59, 10.46it/s]\u001b[A\n",
      " 18%|█▊        | 551/3058 [01:13<03:51, 10.83it/s]\u001b[A\n",
      " 18%|█▊        | 553/3058 [01:13<04:03, 10.27it/s]\u001b[A\n",
      " 18%|█▊        | 555/3058 [01:13<04:17,  9.70it/s]\u001b[A\n",
      " 18%|█▊        | 556/3058 [01:13<04:46,  8.74it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 60.14it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42946699261665344, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4973, 'eval_samples_per_second': 282.389, 'eval_steps_per_second': 70.708, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-556/special_tokens_map.json\n",
      "\n",
      " 18%|█▊        | 557/3058 [01:21<1:13:54,  1.77s/it]\u001b[A\n",
      " 18%|█▊        | 558/3058 [01:21<58:33,  1.41s/it]  \u001b[A\n",
      " 18%|█▊        | 559/3058 [01:22<45:46,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 560/3058 [01:22<35:43,  1.17it/s]\u001b[A\n",
      " 18%|█▊        | 561/3058 [01:22<27:47,  1.50it/s]\u001b[A\n",
      " 18%|█▊        | 562/3058 [01:22<21:23,  1.94it/s]\u001b[A\n",
      " 18%|█▊        | 564/3058 [01:22<13:37,  3.05it/s]\u001b[A\n",
      " 18%|█▊        | 565/3058 [01:22<11:50,  3.51it/s]\u001b[A\n",
      " 19%|█▊        | 566/3058 [01:22<10:00,  4.15it/s]\u001b[A\n",
      " 19%|█▊        | 567/3058 [01:23<09:03,  4.59it/s]\u001b[A\n",
      " 19%|█▊        | 568/3058 [01:23<07:43,  5.37it/s]\u001b[A\n",
      " 19%|█▊        | 570/3058 [01:23<05:59,  6.91it/s]\u001b[A\n",
      " 19%|█▊        | 571/3058 [01:23<05:56,  6.99it/s]\u001b[A\n",
      " 19%|█▊        | 573/3058 [01:23<04:53,  8.46it/s]\u001b[A\n",
      " 19%|█▉        | 575/3058 [01:23<04:14,  9.77it/s]\u001b[A\n",
      " 19%|█▉        | 577/3058 [01:24<03:47, 10.92it/s]\u001b[A\n",
      " 19%|█▉        | 579/3058 [01:24<04:12,  9.83it/s]\u001b[A\n",
      " 19%|█▉        | 581/3058 [01:24<03:57, 10.41it/s]\u001b[A\n",
      " 19%|█▉        | 583/3058 [01:24<03:58, 10.38it/s]\u001b[A\n",
      " 19%|█▉        | 585/3058 [01:24<03:40, 11.19it/s]\u001b[A\n",
      " 19%|█▉        | 587/3058 [01:24<03:39, 11.27it/s]\u001b[A\n",
      " 19%|█▉        | 589/3058 [01:25<03:29, 11.79it/s]\u001b[A\n",
      " 19%|█▉        | 591/3058 [01:25<03:39, 11.26it/s]\u001b[A\n",
      " 19%|█▉        | 593/3058 [01:25<03:39, 11.24it/s]\u001b[A\n",
      " 19%|█▉        | 595/3058 [01:25<03:38, 11.28it/s]\u001b[A\n",
      " 20%|█▉        | 597/3058 [01:25<03:40, 11.16it/s]\u001b[A\n",
      " 20%|█▉        | 599/3058 [01:26<03:41, 11.11it/s]\u001b[A\n",
      " 20%|█▉        | 601/3058 [01:26<03:44, 10.94it/s]\u001b[A\n",
      " 20%|█▉        | 603/3058 [01:26<03:41, 11.11it/s]\u001b[A\n",
      " 20%|█▉        | 605/3058 [01:26<03:55, 10.43it/s]\u001b[A\n",
      " 20%|█▉        | 607/3058 [01:26<04:22,  9.35it/s]\u001b[A\n",
      " 20%|█▉        | 608/3058 [01:27<04:55,  8.29it/s]\u001b[A\n",
      " 20%|█▉        | 609/3058 [01:27<05:07,  7.97it/s]\u001b[A\n",
      " 20%|█▉        | 610/3058 [01:27<05:24,  7.54it/s]\u001b[A\n",
      " 20%|█▉        | 611/3058 [01:27<05:12,  7.83it/s]\u001b[A\n",
      " 20%|██        | 612/3058 [01:27<05:12,  7.82it/s]\u001b[A\n",
      " 20%|██        | 613/3058 [01:27<05:19,  7.64it/s]\u001b[A\n",
      " 20%|██        | 614/3058 [01:27<05:34,  7.32it/s]\u001b[A\n",
      " 20%|██        | 615/3058 [01:28<05:41,  7.15it/s]\u001b[A\n",
      " 20%|██        | 616/3058 [01:28<05:53,  6.91it/s]\u001b[A\n",
      " 20%|██        | 617/3058 [01:28<05:22,  7.57it/s]\u001b[A\n",
      " 20%|██        | 619/3058 [01:28<05:18,  7.66it/s]\u001b[A\n",
      " 20%|██        | 620/3058 [01:28<05:10,  7.86it/s]\u001b[A\n",
      " 20%|██        | 621/3058 [01:28<05:23,  7.53it/s]\u001b[A\n",
      " 20%|██        | 622/3058 [01:28<05:30,  7.38it/s]\u001b[A\n",
      " 20%|██        | 624/3058 [01:29<04:38,  8.73it/s]\u001b[A\n",
      " 20%|██        | 625/3058 [01:29<04:45,  8.54it/s]\u001b[A\n",
      " 20%|██        | 626/3058 [01:29<04:58,  8.15it/s]\u001b[A\n",
      " 21%|██        | 627/3058 [01:29<04:55,  8.23it/s]\u001b[A\n",
      " 21%|██        | 628/3058 [01:29<04:46,  8.48it/s]\u001b[A\n",
      " 21%|██        | 630/3058 [01:29<04:27,  9.07it/s]\u001b[A\n",
      " 21%|██        | 631/3058 [01:29<04:40,  8.64it/s]\u001b[A\n",
      " 21%|██        | 633/3058 [01:30<04:12,  9.62it/s]\u001b[A\n",
      " 21%|██        | 635/3058 [01:30<03:36, 11.18it/s]\u001b[A\n",
      " 21%|██        | 637/3058 [01:30<03:43, 10.86it/s]\u001b[A\n",
      " 21%|██        | 639/3058 [01:30<03:38, 11.10it/s]\u001b[A\n",
      " 21%|██        | 641/3058 [01:30<03:42, 10.88it/s]\u001b[A\n",
      " 21%|██        | 643/3058 [01:31<03:41, 10.91it/s]\u001b[A\n",
      " 21%|██        | 645/3058 [01:31<03:50, 10.49it/s]\u001b[A\n",
      " 21%|██        | 647/3058 [01:31<03:49, 10.52it/s]\u001b[A\n",
      " 21%|██        | 649/3058 [01:31<03:33, 11.30it/s]\u001b[A\n",
      " 21%|██▏       | 651/3058 [01:31<03:39, 10.97it/s]\u001b[A\n",
      " 21%|██▏       | 653/3058 [01:31<03:33, 11.27it/s]\u001b[A\n",
      " 21%|██▏       | 655/3058 [01:32<03:45, 10.64it/s]\u001b[A\n",
      " 21%|██▏       | 657/3058 [01:32<04:23,  9.13it/s]\u001b[A\n",
      " 22%|██▏       | 658/3058 [01:32<04:51,  8.24it/s]\u001b[A\n",
      " 22%|██▏       | 659/3058 [01:32<05:12,  7.67it/s]\u001b[A\n",
      " 22%|██▏       | 660/3058 [01:32<05:09,  7.74it/s]\u001b[A\n",
      " 22%|██▏       | 661/3058 [01:32<05:03,  7.89it/s]\u001b[A\n",
      " 22%|██▏       | 663/3058 [01:33<04:32,  8.80it/s]\u001b[A\n",
      " 22%|██▏       | 665/3058 [01:33<04:11,  9.52it/s]\u001b[A\n",
      " 22%|██▏       | 666/3058 [01:33<04:27,  8.94it/s]\u001b[A\n",
      " 22%|██▏       | 667/3058 [01:33<04:42,  8.45it/s]\u001b[A\n",
      " 22%|██▏       | 668/3058 [01:33<04:57,  8.03it/s]\u001b[A\n",
      " 22%|██▏       | 669/3058 [01:33<05:08,  7.74it/s]\u001b[A\n",
      " 22%|██▏       | 670/3058 [01:34<04:57,  8.02it/s]\u001b[A\n",
      " 22%|██▏       | 671/3058 [01:34<04:56,  8.06it/s]\u001b[A\n",
      " 22%|██▏       | 672/3058 [01:34<04:41,  8.47it/s]\u001b[A\n",
      " 22%|██▏       | 674/3058 [01:34<04:02,  9.82it/s]\u001b[A\n",
      " 22%|██▏       | 676/3058 [01:34<03:47, 10.48it/s]\u001b[A\n",
      " 22%|██▏       | 678/3058 [01:34<03:39, 10.83it/s]\u001b[A\n",
      " 22%|██▏       | 680/3058 [01:35<04:23,  9.04it/s]\u001b[A\n",
      " 22%|██▏       | 682/3058 [01:35<04:06,  9.64it/s]\u001b[A\n",
      " 22%|██▏       | 684/3058 [01:35<03:50, 10.29it/s]\u001b[A\n",
      " 22%|██▏       | 686/3058 [01:35<03:39, 10.81it/s]\u001b[A\n",
      " 22%|██▏       | 688/3058 [01:35<03:33, 11.12it/s]\u001b[A\n",
      " 23%|██▎       | 690/3058 [01:35<03:40, 10.73it/s]\u001b[A\n",
      " 23%|██▎       | 692/3058 [01:36<04:00,  9.82it/s]\u001b[A\n",
      " 23%|██▎       | 694/3058 [01:36<04:02,  9.76it/s]\u001b[A\n",
      " 23%|██▎       | 695/3058 [01:36<04:04,  9.67it/s]\u001b[A\n",
      " 23%|██▎       | 697/3058 [01:36<04:04,  9.67it/s]\u001b[A\n",
      " 23%|██▎       | 698/3058 [01:36<04:21,  9.02it/s]\u001b[A\n",
      " 23%|██▎       | 699/3058 [01:37<04:39,  8.45it/s]\u001b[A\n",
      " 23%|██▎       | 700/3058 [01:37<04:34,  8.60it/s]\u001b[A\n",
      " 23%|██▎       | 701/3058 [01:37<04:27,  8.83it/s]\u001b[A\n",
      " 23%|██▎       | 702/3058 [01:37<04:49,  8.14it/s]\u001b[A\n",
      " 23%|██▎       | 703/3058 [01:37<05:02,  7.78it/s]\u001b[A\n",
      " 23%|██▎       | 704/3058 [01:37<05:10,  7.59it/s]\u001b[A\n",
      " 23%|██▎       | 705/3058 [01:37<05:17,  7.42it/s]\u001b[A\n",
      " 23%|██▎       | 706/3058 [01:37<05:02,  7.76it/s]\u001b[A\n",
      " 23%|██▎       | 707/3058 [01:38<05:57,  6.58it/s]\u001b[A\n",
      " 23%|██▎       | 708/3058 [01:38<06:08,  6.38it/s]\u001b[A\n",
      " 23%|██▎       | 709/3058 [01:38<05:46,  6.77it/s]\u001b[A\n",
      " 23%|██▎       | 710/3058 [01:38<05:24,  7.24it/s]\u001b[A\n",
      " 23%|██▎       | 711/3058 [01:38<05:07,  7.64it/s]\u001b[A\n",
      " 23%|██▎       | 712/3058 [01:38<04:50,  8.09it/s]\u001b[A\n",
      " 23%|██▎       | 714/3058 [01:38<04:37,  8.43it/s]\u001b[A\n",
      " 23%|██▎       | 715/3058 [01:39<05:07,  7.63it/s]\u001b[A\n",
      " 23%|██▎       | 716/3058 [01:39<04:50,  8.07it/s]\u001b[A\n",
      " 23%|██▎       | 718/3058 [01:39<04:13,  9.22it/s]\u001b[A\n",
      " 24%|██▎       | 720/3058 [01:39<04:11,  9.29it/s]\u001b[A\n",
      " 24%|██▎       | 721/3058 [01:39<04:25,  8.80it/s]\u001b[A\n",
      " 24%|██▎       | 722/3058 [01:39<04:28,  8.70it/s]\u001b[A\n",
      " 24%|██▎       | 723/3058 [01:40<04:53,  7.96it/s]\u001b[A\n",
      " 24%|██▎       | 724/3058 [01:40<05:07,  7.60it/s]\u001b[A\n",
      " 24%|██▎       | 725/3058 [01:40<05:15,  7.39it/s]\u001b[A\n",
      " 24%|██▎       | 726/3058 [01:40<05:00,  7.77it/s]\u001b[A\n",
      " 24%|██▍       | 727/3058 [01:40<04:44,  8.20it/s]\u001b[A\n",
      " 24%|██▍       | 728/3058 [01:40<04:39,  8.32it/s]\u001b[A\n",
      " 24%|██▍       | 729/3058 [01:40<04:30,  8.60it/s]\u001b[A\n",
      " 24%|██▍       | 730/3058 [01:40<04:23,  8.84it/s]\u001b[A\n",
      " 24%|██▍       | 731/3058 [01:40<04:27,  8.71it/s]\u001b[A\n",
      " 24%|██▍       | 733/3058 [01:41<04:16,  9.05it/s]\u001b[A\n",
      " 24%|██▍       | 734/3058 [01:41<04:13,  9.17it/s]\u001b[A\n",
      " 24%|██▍       | 735/3058 [01:41<04:11,  9.22it/s]\u001b[A\n",
      " 24%|██▍       | 737/3058 [01:41<03:47, 10.19it/s]\u001b[A\n",
      " 24%|██▍       | 739/3058 [01:41<04:27,  8.68it/s]\u001b[A\n",
      " 24%|██▍       | 740/3058 [01:41<04:20,  8.91it/s]\u001b[A\n",
      " 24%|██▍       | 742/3058 [01:42<03:58,  9.70it/s]\u001b[A\n",
      " 24%|██▍       | 743/3058 [01:42<03:59,  9.69it/s]\u001b[A\n",
      " 24%|██▍       | 745/3058 [01:42<03:41, 10.46it/s]\u001b[A\n",
      " 24%|██▍       | 747/3058 [01:42<03:33, 10.84it/s]\u001b[A\n",
      " 24%|██▍       | 749/3058 [01:42<03:52,  9.93it/s]\u001b[A\n",
      " 25%|██▍       | 751/3058 [01:43<04:19,  8.88it/s]\u001b[A\n",
      " 25%|██▍       | 752/3058 [01:43<04:30,  8.52it/s]\u001b[A\n",
      " 25%|██▍       | 754/3058 [01:43<04:05,  9.37it/s]\u001b[A\n",
      " 25%|██▍       | 756/3058 [01:43<03:36, 10.63it/s]\u001b[A\n",
      " 25%|██▍       | 758/3058 [01:43<04:55,  7.79it/s]\u001b[A\n",
      " 25%|██▍       | 759/3058 [01:44<05:01,  7.62it/s]\u001b[A\n",
      " 25%|██▍       | 760/3058 [01:44<04:51,  7.88it/s]\u001b[A\n",
      " 25%|██▍       | 761/3058 [01:44<04:38,  8.25it/s]\u001b[A\n",
      " 25%|██▍       | 762/3058 [01:44<04:48,  7.95it/s]\u001b[A\n",
      " 25%|██▍       | 763/3058 [01:44<05:04,  7.53it/s]\u001b[A\n",
      " 25%|██▍       | 764/3058 [01:44<04:48,  7.96it/s]\u001b[A\n",
      " 25%|██▌       | 766/3058 [01:44<04:26,  8.60it/s]\u001b[A\n",
      " 25%|██▌       | 767/3058 [01:45<04:21,  8.75it/s]\u001b[A\n",
      " 25%|██▌       | 769/3058 [01:45<03:55,  9.72it/s]\u001b[A\n",
      " 25%|██▌       | 771/3058 [01:45<03:47, 10.04it/s]\u001b[A\n",
      " 25%|██▌       | 772/3058 [01:45<04:04,  9.34it/s]\u001b[A\n",
      " 25%|██▌       | 773/3058 [01:45<04:14,  8.99it/s]\u001b[A\n",
      " 25%|██▌       | 775/3058 [01:45<03:50,  9.92it/s]\u001b[A\n",
      " 25%|██▌       | 777/3058 [01:45<03:36, 10.53it/s]\u001b[A\n",
      " 25%|██▌       | 779/3058 [01:46<03:34, 10.60it/s]\u001b[A\n",
      " 26%|██▌       | 781/3058 [01:46<03:51,  9.83it/s]\u001b[A\n",
      " 26%|██▌       | 782/3058 [01:46<04:08,  9.18it/s]\u001b[A\n",
      " 26%|██▌       | 784/3058 [01:46<03:52,  9.79it/s]\u001b[A\n",
      " 26%|██▌       | 785/3058 [01:46<03:53,  9.72it/s]\u001b[A\n",
      " 26%|██▌       | 787/3058 [01:47<03:41, 10.26it/s]\u001b[A\n",
      " 26%|██▌       | 789/3058 [01:47<03:27, 10.96it/s]\u001b[A\n",
      " 26%|██▌       | 791/3058 [01:47<03:14, 11.67it/s]\u001b[A\n",
      " 26%|██▌       | 793/3058 [01:47<03:19, 11.33it/s]\u001b[A\n",
      " 26%|██▌       | 795/3058 [01:47<03:37, 10.42it/s]\u001b[A\n",
      " 26%|██▌       | 797/3058 [01:47<04:01,  9.34it/s]\u001b[A\n",
      " 26%|██▌       | 798/3058 [01:48<04:19,  8.72it/s]\u001b[A\n",
      " 26%|██▌       | 799/3058 [01:48<04:31,  8.34it/s]\u001b[A\n",
      " 26%|██▌       | 800/3058 [01:48<04:21,  8.65it/s]\u001b[A\n",
      " 26%|██▌       | 802/3058 [01:48<03:45, 10.01it/s]\u001b[A\n",
      " 26%|██▋       | 804/3058 [01:48<03:54,  9.62it/s]\u001b[A\n",
      " 26%|██▋       | 805/3058 [01:48<04:05,  9.17it/s]\u001b[A\n",
      " 26%|██▋       | 806/3058 [01:48<04:01,  9.33it/s]\u001b[A\n",
      " 26%|██▋       | 807/3058 [01:49<04:28,  8.38it/s]\u001b[A\n",
      " 26%|██▋       | 808/3058 [01:49<04:40,  8.03it/s]\u001b[A\n",
      " 26%|██▋       | 809/3058 [01:49<04:52,  7.68it/s]\u001b[A\n",
      " 27%|██▋       | 811/3058 [01:49<04:26,  8.43it/s]\u001b[A\n",
      " 27%|██▋       | 812/3058 [01:49<04:17,  8.74it/s]\u001b[A\n",
      " 27%|██▋       | 813/3058 [01:49<04:11,  8.91it/s]\u001b[A\n",
      " 27%|██▋       | 814/3058 [01:49<04:38,  8.07it/s]\u001b[A\n",
      " 27%|██▋       | 815/3058 [01:50<04:28,  8.34it/s]\u001b[A\n",
      " 27%|██▋       | 816/3058 [01:50<04:31,  8.27it/s]\u001b[A\n",
      " 27%|██▋       | 817/3058 [01:50<04:19,  8.62it/s]\u001b[A\n",
      " 27%|██▋       | 819/3058 [01:50<03:46,  9.87it/s]\u001b[A\n",
      " 27%|██▋       | 820/3058 [01:50<03:50,  9.73it/s]\u001b[A\n",
      " 27%|██▋       | 821/3058 [01:50<04:02,  9.23it/s]\u001b[A\n",
      " 27%|██▋       | 822/3058 [01:50<04:03,  9.17it/s]\u001b[A\n",
      " 27%|██▋       | 824/3058 [01:51<03:38, 10.21it/s]\u001b[A\n",
      " 27%|██▋       | 826/3058 [01:51<03:20, 11.12it/s]\u001b[A\n",
      " 27%|██▋       | 828/3058 [01:51<03:15, 11.40it/s]\u001b[A\n",
      " 27%|██▋       | 830/3058 [01:51<03:08, 11.84it/s]\u001b[A\n",
      " 27%|██▋       | 832/3058 [01:51<03:08, 11.82it/s]\u001b[A\n",
      " 27%|██▋       | 834/3058 [01:51<03:10, 11.66it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 65.12it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3946535885334015, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5395, 'eval_samples_per_second': 279.767, 'eval_steps_per_second': 70.052, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-834/special_tokens_map.json\n",
      "\n",
      " 27%|██▋       | 836/3058 [01:59<47:05,  1.27s/it]\u001b[A\n",
      " 27%|██▋       | 837/3058 [01:59<39:19,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 838/3058 [01:59<32:02,  1.15it/s]\u001b[A\n",
      " 27%|██▋       | 839/3058 [01:59<25:49,  1.43it/s]\u001b[A\n",
      " 27%|██▋       | 840/3058 [02:00<20:38,  1.79it/s]\u001b[A\n",
      " 28%|██▊       | 842/3058 [02:00<13:34,  2.72it/s]\u001b[A\n",
      " 28%|██▊       | 844/3058 [02:00<09:48,  3.76it/s]\u001b[A\n",
      " 28%|██▊       | 845/3058 [02:00<08:32,  4.32it/s]\u001b[A\n",
      " 28%|██▊       | 846/3058 [02:00<07:41,  4.79it/s]\u001b[A\n",
      " 28%|██▊       | 847/3058 [02:00<06:59,  5.27it/s]\u001b[A\n",
      " 28%|██▊       | 849/3058 [02:01<05:37,  6.54it/s]\u001b[A\n",
      " 28%|██▊       | 851/3058 [02:01<04:40,  7.86it/s]\u001b[A\n",
      " 28%|██▊       | 853/3058 [02:01<04:11,  8.76it/s]\u001b[A\n",
      " 28%|██▊       | 855/3058 [02:01<03:49,  9.59it/s]\u001b[A\n",
      " 28%|██▊       | 857/3058 [02:01<03:33, 10.32it/s]\u001b[A\n",
      " 28%|██▊       | 859/3058 [02:01<03:24, 10.77it/s]\u001b[A\n",
      " 28%|██▊       | 861/3058 [02:02<03:19, 10.99it/s]\u001b[A\n",
      " 28%|██▊       | 863/3058 [02:02<03:13, 11.33it/s]\u001b[A\n",
      " 28%|██▊       | 865/3058 [02:02<03:15, 11.23it/s]\u001b[A\n",
      " 28%|██▊       | 867/3058 [02:02<03:16, 11.13it/s]\u001b[A\n",
      " 28%|██▊       | 869/3058 [02:02<03:12, 11.39it/s]\u001b[A\n",
      " 28%|██▊       | 871/3058 [02:02<03:08, 11.60it/s]\u001b[A\n",
      " 29%|██▊       | 873/3058 [02:03<03:06, 11.71it/s]\u001b[A\n",
      " 29%|██▊       | 875/3058 [02:03<03:21, 10.86it/s]\u001b[A\n",
      " 29%|██▊       | 877/3058 [02:03<03:18, 10.99it/s]\u001b[A\n",
      " 29%|██▊       | 879/3058 [02:03<03:12, 11.35it/s]\u001b[A\n",
      " 29%|██▉       | 881/3058 [02:03<03:06, 11.65it/s]\u001b[A\n",
      " 29%|██▉       | 883/3058 [02:04<03:30, 10.32it/s]\u001b[A\n",
      " 29%|██▉       | 885/3058 [02:04<03:48,  9.51it/s]\u001b[A\n",
      " 29%|██▉       | 886/3058 [02:04<04:14,  8.55it/s]\u001b[A\n",
      " 29%|██▉       | 887/3058 [02:04<04:38,  7.81it/s]\u001b[A\n",
      " 29%|██▉       | 888/3058 [02:04<04:53,  7.39it/s]\u001b[A\n",
      " 29%|██▉       | 889/3058 [02:04<04:49,  7.49it/s]\u001b[A\n",
      " 29%|██▉       | 890/3058 [02:05<04:39,  7.74it/s]\u001b[A\n",
      " 29%|██▉       | 891/3058 [02:05<04:45,  7.60it/s]\u001b[A\n",
      " 29%|██▉       | 892/3058 [02:05<04:29,  8.02it/s]\u001b[A\n",
      " 29%|██▉       | 893/3058 [02:05<04:25,  8.15it/s]\u001b[A\n",
      " 29%|██▉       | 894/3058 [02:05<04:19,  8.34it/s]\u001b[A\n",
      " 29%|██▉       | 896/3058 [02:05<03:43,  9.66it/s]\u001b[A\n",
      " 29%|██▉       | 898/3058 [02:05<03:43,  9.65it/s]\u001b[A\n",
      " 29%|██▉       | 899/3058 [02:06<04:02,  8.89it/s]\u001b[A\n",
      " 29%|██▉       | 900/3058 [02:06<04:14,  8.47it/s]\u001b[A\n",
      " 29%|██▉       | 901/3058 [02:06<04:05,  8.79it/s]\u001b[A\n",
      " 30%|██▉       | 903/3058 [02:06<03:39,  9.81it/s]\u001b[A\n",
      " 30%|██▉       | 905/3058 [02:06<03:31, 10.18it/s]\u001b[A\n",
      " 30%|██▉       | 907/3058 [02:06<03:26, 10.41it/s]\u001b[A\n",
      " 30%|██▉       | 909/3058 [02:07<03:20, 10.70it/s]\u001b[A\n",
      " 30%|██▉       | 911/3058 [02:07<03:22, 10.63it/s]\u001b[A\n",
      " 30%|██▉       | 913/3058 [02:07<03:31, 10.14it/s]\u001b[A\n",
      " 30%|██▉       | 915/3058 [02:07<03:42,  9.64it/s]\u001b[A\n",
      " 30%|██▉       | 917/3058 [02:07<03:27, 10.31it/s]\u001b[A\n",
      " 30%|███       | 919/3058 [02:07<03:21, 10.60it/s]\u001b[A\n",
      " 30%|███       | 921/3058 [02:08<03:44,  9.54it/s]\u001b[A\n",
      " 30%|███       | 923/3058 [02:08<03:35,  9.90it/s]\u001b[A\n",
      " 30%|███       | 925/3058 [02:08<03:24, 10.42it/s]\u001b[A\n",
      " 30%|███       | 927/3058 [02:08<03:19, 10.69it/s]\u001b[A\n",
      " 30%|███       | 929/3058 [02:09<03:34,  9.92it/s]\u001b[A\n",
      " 30%|███       | 931/3058 [02:09<03:21, 10.53it/s]\u001b[A\n",
      " 31%|███       | 933/3058 [02:09<03:12, 11.02it/s]\u001b[A\n",
      " 31%|███       | 935/3058 [02:09<03:50,  9.20it/s]\u001b[A\n",
      " 31%|███       | 936/3058 [02:09<04:18,  8.20it/s]\u001b[A\n",
      " 31%|███       | 937/3058 [02:09<04:28,  7.90it/s]\u001b[A\n",
      " 31%|███       | 938/3058 [02:10<04:20,  8.13it/s]\u001b[A\n",
      " 31%|███       | 939/3058 [02:10<04:10,  8.45it/s]\u001b[A\n",
      " 31%|███       | 940/3058 [02:10<04:01,  8.77it/s]\u001b[A\n",
      " 31%|███       | 941/3058 [02:10<03:59,  8.82it/s]\u001b[A\n",
      " 31%|███       | 942/3058 [02:10<03:52,  9.12it/s]\u001b[A\n",
      " 31%|███       | 943/3058 [02:10<03:49,  9.21it/s]\u001b[A\n",
      " 31%|███       | 944/3058 [02:10<04:14,  8.31it/s]\u001b[A\n",
      " 31%|███       | 945/3058 [02:10<04:08,  8.51it/s]\u001b[A\n",
      " 31%|███       | 947/3058 [02:11<03:41,  9.51it/s]\u001b[A\n",
      " 31%|███       | 949/3058 [02:11<03:36,  9.72it/s]\u001b[A\n",
      " 31%|███       | 951/3058 [02:11<03:22, 10.40it/s]\u001b[A\n",
      " 31%|███       | 953/3058 [02:11<03:22, 10.42it/s]\u001b[A\n",
      " 31%|███       | 955/3058 [02:11<03:12, 10.90it/s]\u001b[A\n",
      " 31%|███▏      | 957/3058 [02:11<03:06, 11.26it/s]\u001b[A\n",
      " 31%|███▏      | 959/3058 [02:12<03:07, 11.19it/s]\u001b[A\n",
      " 31%|███▏      | 961/3058 [02:12<03:06, 11.25it/s]\u001b[A\n",
      " 31%|███▏      | 963/3058 [02:12<03:42,  9.43it/s]\u001b[A\n",
      " 32%|███▏      | 964/3058 [02:12<03:59,  8.75it/s]\u001b[A\n",
      " 32%|███▏      | 965/3058 [02:12<04:05,  8.51it/s]\u001b[A\n",
      " 32%|███▏      | 966/3058 [02:12<04:08,  8.41it/s]\u001b[A\n",
      " 32%|███▏      | 967/3058 [02:13<04:09,  8.40it/s]\u001b[A\n",
      " 32%|███▏      | 969/3058 [02:13<03:39,  9.52it/s]\u001b[A\n",
      " 32%|███▏      | 971/3058 [02:13<03:24, 10.19it/s]\u001b[A\n",
      " 32%|███▏      | 973/3058 [02:13<03:20, 10.40it/s]\u001b[A\n",
      " 32%|███▏      | 975/3058 [02:13<03:16, 10.59it/s]\u001b[A\n",
      " 32%|███▏      | 977/3058 [02:13<03:08, 11.03it/s]\u001b[A\n",
      " 32%|███▏      | 979/3058 [02:14<03:02, 11.41it/s]\u001b[A\n",
      " 32%|███▏      | 981/3058 [02:14<03:22, 10.28it/s]\u001b[A\n",
      " 32%|███▏      | 983/3058 [02:14<03:37,  9.53it/s]\u001b[A\n",
      " 32%|███▏      | 984/3058 [02:14<03:49,  9.03it/s]\u001b[A\n",
      " 32%|███▏      | 985/3058 [02:14<04:15,  8.12it/s]\u001b[A\n",
      " 32%|███▏      | 986/3058 [02:15<04:20,  7.95it/s]\u001b[A\n",
      " 32%|███▏      | 987/3058 [02:15<04:16,  8.06it/s]\u001b[A\n",
      " 32%|███▏      | 988/3058 [02:15<04:24,  7.84it/s]\u001b[A\n",
      " 32%|███▏      | 989/3058 [02:15<04:09,  8.28it/s]\u001b[A\n",
      " 32%|███▏      | 991/3058 [02:15<03:44,  9.19it/s]\u001b[A\n",
      " 32%|███▏      | 993/3058 [02:15<03:29,  9.84it/s]\u001b[A\n",
      " 33%|███▎      | 994/3058 [02:15<03:30,  9.82it/s]\u001b[A\n",
      " 33%|███▎      | 996/3058 [02:16<03:19, 10.33it/s]\u001b[A\n",
      " 33%|███▎      | 998/3058 [02:16<03:13, 10.67it/s]\u001b[A\n",
      " 33%|███▎      | 1000/3058 [02:16<04:05,  8.38it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 33%|███▎      | 1000/3058 [02:16<04:05,  8.38it/s]\u001b[A\n",
      " 33%|███▎      | 1001/3058 [02:16<04:25,  7.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4049, 'learning_rate': 0.0007414617309982877, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1003/3058 [02:16<03:53,  8.81it/s]\u001b[A\n",
      " 33%|███▎      | 1005/3058 [02:17<03:32,  9.66it/s]\u001b[A\n",
      " 33%|███▎      | 1007/3058 [02:17<03:25,  9.98it/s]\u001b[A\n",
      " 33%|███▎      | 1009/3058 [02:17<03:40,  9.30it/s]\u001b[A\n",
      " 33%|███▎      | 1010/3058 [02:17<03:46,  9.03it/s]\u001b[A\n",
      " 33%|███▎      | 1011/3058 [02:17<03:45,  9.08it/s]\u001b[A\n",
      " 33%|███▎      | 1013/3058 [02:17<03:23, 10.07it/s]\u001b[A\n",
      " 33%|███▎      | 1015/3058 [02:18<03:38,  9.36it/s]\u001b[A\n",
      " 33%|███▎      | 1016/3058 [02:18<03:40,  9.27it/s]\u001b[A\n",
      " 33%|███▎      | 1017/3058 [02:18<03:44,  9.10it/s]\u001b[A\n",
      " 33%|███▎      | 1018/3058 [02:18<03:54,  8.71it/s]\u001b[A\n",
      " 33%|███▎      | 1019/3058 [02:18<04:00,  8.47it/s]\u001b[A\n",
      " 33%|███▎      | 1020/3058 [02:18<04:25,  7.66it/s]\u001b[A\n",
      " 33%|███▎      | 1021/3058 [02:18<04:35,  7.39it/s]\u001b[A\n",
      " 33%|███▎      | 1022/3058 [02:19<04:21,  7.78it/s]\u001b[A\n",
      " 33%|███▎      | 1024/3058 [02:19<03:53,  8.73it/s]\u001b[A\n",
      " 34%|███▎      | 1025/3058 [02:19<03:55,  8.62it/s]\u001b[A\n",
      " 34%|███▎      | 1026/3058 [02:19<04:08,  8.18it/s]\u001b[A\n",
      " 34%|███▎      | 1027/3058 [02:19<04:04,  8.31it/s]\u001b[A\n",
      " 34%|███▎      | 1029/3058 [02:19<03:41,  9.16it/s]\u001b[A\n",
      " 34%|███▎      | 1031/3058 [02:20<03:35,  9.42it/s]\u001b[A\n",
      " 34%|███▎      | 1032/3058 [02:20<03:55,  8.60it/s]\u001b[A\n",
      " 34%|███▍      | 1033/3058 [02:20<04:09,  8.11it/s]\u001b[A\n",
      " 34%|███▍      | 1034/3058 [02:20<04:21,  7.73it/s]\u001b[A\n",
      " 34%|███▍      | 1035/3058 [02:20<05:03,  6.67it/s]\u001b[A\n",
      " 34%|███▍      | 1036/3058 [02:20<05:15,  6.42it/s]\u001b[A\n",
      " 34%|███▍      | 1037/3058 [02:21<05:22,  6.26it/s]\u001b[A\n",
      " 34%|███▍      | 1038/3058 [02:21<05:25,  6.20it/s]\u001b[A\n",
      " 34%|███▍      | 1039/3058 [02:21<05:19,  6.31it/s]\u001b[A\n",
      " 34%|███▍      | 1040/3058 [02:21<05:16,  6.37it/s]\u001b[A\n",
      " 34%|███▍      | 1041/3058 [02:21<04:50,  6.94it/s]\u001b[A\n",
      " 34%|███▍      | 1042/3058 [02:21<04:47,  7.00it/s]\u001b[A\n",
      " 34%|███▍      | 1043/3058 [02:21<04:50,  6.94it/s]\u001b[A\n",
      " 34%|███▍      | 1044/3058 [02:22<04:34,  7.34it/s]\u001b[A\n",
      " 34%|███▍      | 1045/3058 [02:22<04:26,  7.56it/s]\u001b[A\n",
      " 34%|███▍      | 1047/3058 [02:22<04:01,  8.32it/s]\u001b[A\n",
      " 34%|███▍      | 1049/3058 [02:22<03:33,  9.40it/s]\u001b[A\n",
      " 34%|███▍      | 1050/3058 [02:22<03:45,  8.91it/s]\u001b[A\n",
      " 34%|███▍      | 1051/3058 [02:22<03:41,  9.04it/s]\u001b[A\n",
      " 34%|███▍      | 1053/3058 [02:22<03:25,  9.76it/s]\u001b[A\n",
      " 34%|███▍      | 1054/3058 [02:23<03:39,  9.15it/s]\u001b[A\n",
      " 34%|███▍      | 1055/3058 [02:23<03:37,  9.20it/s]\u001b[A\n",
      " 35%|███▍      | 1056/3058 [02:23<03:39,  9.13it/s]\u001b[A\n",
      " 35%|███▍      | 1057/3058 [02:23<03:49,  8.71it/s]\u001b[A\n",
      " 35%|███▍      | 1058/3058 [02:23<03:50,  8.68it/s]\u001b[A\n",
      " 35%|███▍      | 1060/3058 [02:23<03:11, 10.45it/s]\u001b[A\n",
      " 35%|███▍      | 1062/3058 [02:23<03:18, 10.05it/s]\u001b[A\n",
      " 35%|███▍      | 1064/3058 [02:24<03:21,  9.92it/s]\u001b[A\n",
      " 35%|███▍      | 1065/3058 [02:24<03:41,  8.99it/s]\u001b[A\n",
      " 35%|███▍      | 1066/3058 [02:24<03:45,  8.83it/s]\u001b[A\n",
      " 35%|███▍      | 1067/3058 [02:24<03:54,  8.50it/s]\u001b[A\n",
      " 35%|███▍      | 1069/3058 [02:24<03:28,  9.56it/s]\u001b[A\n",
      " 35%|███▍      | 1070/3058 [02:24<03:38,  9.12it/s]\u001b[A\n",
      " 35%|███▌      | 1071/3058 [02:24<03:53,  8.50it/s]\u001b[A\n",
      " 35%|███▌      | 1072/3058 [02:25<04:07,  8.01it/s]\u001b[A\n",
      " 35%|███▌      | 1073/3058 [02:25<04:17,  7.70it/s]\u001b[A\n",
      " 35%|███▌      | 1074/3058 [02:25<04:06,  8.05it/s]\u001b[A\n",
      " 35%|███▌      | 1076/3058 [02:25<03:33,  9.29it/s]\u001b[A\n",
      " 35%|███▌      | 1077/3058 [02:25<03:29,  9.43it/s]\u001b[A\n",
      " 35%|███▌      | 1079/3058 [02:25<03:09, 10.45it/s]\u001b[A\n",
      " 35%|███▌      | 1081/3058 [02:25<03:13, 10.24it/s]\u001b[A\n",
      " 35%|███▌      | 1083/3058 [02:26<02:54, 11.35it/s]\u001b[A\n",
      " 35%|███▌      | 1085/3058 [02:26<03:15, 10.08it/s]\u001b[A\n",
      " 36%|███▌      | 1087/3058 [02:26<03:33,  9.23it/s]\u001b[A\n",
      " 36%|███▌      | 1088/3058 [02:26<03:54,  8.40it/s]\u001b[A\n",
      " 36%|███▌      | 1089/3058 [02:26<03:55,  8.35it/s]\u001b[A\n",
      " 36%|███▌      | 1090/3058 [02:27<04:09,  7.87it/s]\u001b[A\n",
      " 36%|███▌      | 1091/3058 [02:27<04:16,  7.68it/s]\u001b[A\n",
      " 36%|███▌      | 1092/3058 [02:27<04:16,  7.67it/s]\u001b[A\n",
      " 36%|███▌      | 1094/3058 [02:27<03:42,  8.82it/s]\u001b[A\n",
      " 36%|███▌      | 1096/3058 [02:27<03:19,  9.82it/s]\u001b[A\n",
      " 36%|███▌      | 1098/3058 [02:27<03:10, 10.29it/s]\u001b[A\n",
      " 36%|███▌      | 1100/3058 [02:28<03:03, 10.67it/s]\u001b[A\n",
      " 36%|███▌      | 1102/3058 [02:28<03:06, 10.51it/s]\u001b[A\n",
      " 36%|███▌      | 1104/3058 [02:28<03:00, 10.82it/s]\u001b[A\n",
      " 36%|███▌      | 1106/3058 [02:28<03:21,  9.70it/s]\u001b[A\n",
      " 36%|███▌      | 1107/3058 [02:28<03:23,  9.60it/s]\u001b[A\n",
      " 36%|███▋      | 1109/3058 [02:28<03:12, 10.13it/s]\u001b[A\n",
      " 36%|███▋      | 1111/3058 [02:29<03:28,  9.33it/s]\u001b[A\n",
      " 36%|███▋      | 1112/3058 [02:29<03:26,  9.41it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 78.42it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1112\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33850374817848206, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2796, 'eval_samples_per_second': 296.755, 'eval_steps_per_second': 74.306, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1112/special_tokens_map.json\n",
      "\n",
      " 36%|███▋      | 1113/3058 [02:37<57:01,  1.76s/it]\u001b[A\n",
      " 36%|███▋      | 1114/3058 [02:37<44:52,  1.38s/it]\u001b[A\n",
      " 36%|███▋      | 1115/3058 [02:37<34:53,  1.08s/it]\u001b[A\n",
      " 36%|███▋      | 1116/3058 [02:37<27:05,  1.19it/s]\u001b[A\n",
      " 37%|███▋      | 1117/3058 [02:37<20:46,  1.56it/s]\u001b[A\n",
      " 37%|███▋      | 1118/3058 [02:37<16:10,  2.00it/s]\u001b[A\n",
      " 37%|███▋      | 1119/3058 [02:38<12:49,  2.52it/s]\u001b[A\n",
      " 37%|███▋      | 1120/3058 [02:38<10:27,  3.09it/s]\u001b[A\n",
      " 37%|███▋      | 1121/3058 [02:38<08:23,  3.85it/s]\u001b[A\n",
      " 37%|███▋      | 1122/3058 [02:38<06:58,  4.63it/s]\u001b[A\n",
      " 37%|███▋      | 1123/3058 [02:38<06:05,  5.29it/s]\u001b[A\n",
      " 37%|███▋      | 1124/3058 [02:38<05:37,  5.73it/s]\u001b[A\n",
      " 37%|███▋      | 1125/3058 [02:38<05:15,  6.12it/s]\u001b[A\n",
      " 37%|███▋      | 1126/3058 [02:38<05:01,  6.40it/s]\u001b[A\n",
      " 37%|███▋      | 1127/3058 [02:39<04:35,  7.02it/s]\u001b[A\n",
      " 37%|███▋      | 1128/3058 [02:39<04:17,  7.51it/s]\u001b[A\n",
      " 37%|███▋      | 1130/3058 [02:39<03:40,  8.76it/s]\u001b[A\n",
      " 37%|███▋      | 1131/3058 [02:39<03:39,  8.78it/s]\u001b[A\n",
      " 37%|███▋      | 1132/3058 [02:39<03:47,  8.47it/s]\u001b[A\n",
      " 37%|███▋      | 1133/3058 [02:39<03:38,  8.82it/s]\u001b[A\n",
      " 37%|███▋      | 1134/3058 [02:39<03:43,  8.62it/s]\u001b[A\n",
      " 37%|███▋      | 1135/3058 [02:39<03:55,  8.16it/s]\u001b[A\n",
      " 37%|███▋      | 1136/3058 [02:40<04:04,  7.85it/s]\u001b[A\n",
      " 37%|███▋      | 1137/3058 [02:40<04:11,  7.64it/s]\u001b[A\n",
      " 37%|███▋      | 1138/3058 [02:40<04:14,  7.55it/s]\u001b[A\n",
      " 37%|███▋      | 1139/3058 [02:40<04:15,  7.50it/s]\u001b[A\n",
      " 37%|███▋      | 1140/3058 [02:40<04:18,  7.42it/s]\u001b[A\n",
      " 37%|███▋      | 1141/3058 [02:40<04:18,  7.43it/s]\u001b[A\n",
      " 37%|███▋      | 1142/3058 [02:40<04:18,  7.40it/s]\u001b[A\n",
      " 37%|███▋      | 1143/3058 [02:41<04:21,  7.33it/s]\u001b[A\n",
      " 37%|███▋      | 1144/3058 [02:41<04:03,  7.85it/s]\u001b[A\n",
      " 37%|███▋      | 1145/3058 [02:41<03:59,  8.00it/s]\u001b[A\n",
      " 37%|███▋      | 1146/3058 [02:41<03:47,  8.41it/s]\u001b[A\n",
      " 38%|███▊      | 1147/3058 [02:41<03:41,  8.61it/s]\u001b[A\n",
      " 38%|███▊      | 1148/3058 [02:41<03:35,  8.88it/s]\u001b[A\n",
      " 38%|███▊      | 1150/3058 [02:41<03:01, 10.50it/s]\u001b[A\n",
      " 38%|███▊      | 1152/3058 [02:41<02:49, 11.21it/s]\u001b[A\n",
      " 38%|███▊      | 1154/3058 [02:42<02:52, 11.02it/s]\u001b[A\n",
      " 38%|███▊      | 1156/3058 [02:42<02:46, 11.45it/s]\u001b[A\n",
      " 38%|███▊      | 1158/3058 [02:42<02:35, 12.24it/s]\u001b[A\n",
      " 38%|███▊      | 1160/3058 [02:42<02:33, 12.38it/s]\u001b[A\n",
      " 38%|███▊      | 1162/3058 [02:42<02:37, 12.03it/s]\u001b[A\n",
      " 38%|███▊      | 1164/3058 [02:43<03:14,  9.74it/s]\u001b[A\n",
      " 38%|███▊      | 1166/3058 [02:43<03:19,  9.48it/s]\u001b[A\n",
      " 38%|███▊      | 1168/3058 [02:43<03:35,  8.79it/s]\u001b[A\n",
      " 38%|███▊      | 1169/3058 [02:43<03:37,  8.70it/s]\u001b[A\n",
      " 38%|███▊      | 1171/3058 [02:43<03:22,  9.34it/s]\u001b[A\n",
      " 38%|███▊      | 1172/3058 [02:43<03:20,  9.43it/s]\u001b[A\n",
      " 38%|███▊      | 1174/3058 [02:44<03:05, 10.18it/s]\u001b[A\n",
      " 38%|███▊      | 1176/3058 [02:44<02:51, 10.96it/s]\u001b[A\n",
      " 39%|███▊      | 1178/3058 [02:44<02:41, 11.67it/s]\u001b[A\n",
      " 39%|███▊      | 1180/3058 [02:44<02:30, 12.46it/s]\u001b[A\n",
      " 39%|███▊      | 1182/3058 [02:44<02:35, 12.07it/s]\u001b[A\n",
      " 39%|███▊      | 1184/3058 [02:44<02:50, 11.01it/s]\u001b[A\n",
      " 39%|███▉      | 1186/3058 [02:45<02:44, 11.36it/s]\u001b[A\n",
      " 39%|███▉      | 1188/3058 [02:45<02:45, 11.31it/s]\u001b[A\n",
      " 39%|███▉      | 1190/3058 [02:45<02:40, 11.61it/s]\u001b[A\n",
      " 39%|███▉      | 1192/3058 [02:45<02:37, 11.84it/s]\u001b[A\n",
      " 39%|███▉      | 1194/3058 [02:45<02:47, 11.10it/s]\u001b[A\n",
      " 39%|███▉      | 1196/3058 [02:45<02:54, 10.70it/s]\u001b[A\n",
      " 39%|███▉      | 1198/3058 [02:46<02:55, 10.58it/s]\u001b[A\n",
      " 39%|███▉      | 1200/3058 [02:46<02:52, 10.80it/s]\u001b[A\n",
      " 39%|███▉      | 1202/3058 [02:46<02:41, 11.53it/s]\u001b[A\n",
      " 39%|███▉      | 1204/3058 [02:46<02:57, 10.43it/s]\u001b[A\n",
      " 39%|███▉      | 1206/3058 [02:46<03:17,  9.36it/s]\u001b[A\n",
      " 40%|███▉      | 1208/3058 [02:47<03:06,  9.90it/s]\u001b[A\n",
      " 40%|███▉      | 1210/3058 [02:47<03:05,  9.98it/s]\u001b[A\n",
      " 40%|███▉      | 1212/3058 [02:47<03:15,  9.44it/s]\u001b[A\n",
      " 40%|███▉      | 1213/3058 [02:47<03:38,  8.44it/s]\u001b[A\n",
      " 40%|███▉      | 1214/3058 [02:47<03:44,  8.22it/s]\u001b[A\n",
      " 40%|███▉      | 1215/3058 [02:48<03:42,  8.28it/s]\u001b[A\n",
      " 40%|███▉      | 1216/3058 [02:48<03:39,  8.39it/s]\u001b[A\n",
      " 40%|███▉      | 1217/3058 [02:48<03:31,  8.70it/s]\u001b[A\n",
      " 40%|███▉      | 1219/3058 [02:48<03:15,  9.41it/s]\u001b[A\n",
      " 40%|███▉      | 1221/3058 [02:48<03:06,  9.84it/s]\u001b[A\n",
      " 40%|███▉      | 1223/3058 [02:48<02:56, 10.41it/s]\u001b[A\n",
      " 40%|████      | 1225/3058 [02:48<02:53, 10.59it/s]\u001b[A\n",
      " 40%|████      | 1227/3058 [02:49<02:54, 10.52it/s]\u001b[A\n",
      " 40%|████      | 1229/3058 [02:49<02:48, 10.84it/s]\u001b[A\n",
      " 40%|████      | 1231/3058 [02:49<02:39, 11.44it/s]\u001b[A\n",
      " 40%|████      | 1233/3058 [02:49<02:38, 11.54it/s]\u001b[A\n",
      " 40%|████      | 1235/3058 [02:49<02:56, 10.32it/s]\u001b[A\n",
      " 40%|████      | 1237/3058 [02:50<03:16,  9.27it/s]\u001b[A\n",
      " 41%|████      | 1239/3058 [02:50<03:02,  9.96it/s]\u001b[A\n",
      " 41%|████      | 1241/3058 [02:50<02:53, 10.48it/s]\u001b[A\n",
      " 41%|████      | 1243/3058 [02:50<03:03,  9.88it/s]\u001b[A\n",
      " 41%|████      | 1245/3058 [02:50<02:50, 10.66it/s]\u001b[A\n",
      " 41%|████      | 1247/3058 [02:51<02:42, 11.16it/s]\u001b[A\n",
      " 41%|████      | 1249/3058 [02:51<02:55, 10.29it/s]\u001b[A\n",
      " 41%|████      | 1251/3058 [02:51<03:11,  9.46it/s]\u001b[A\n",
      " 41%|████      | 1253/3058 [02:51<02:59, 10.06it/s]\u001b[A\n",
      " 41%|████      | 1255/3058 [02:51<02:49, 10.66it/s]\u001b[A\n",
      " 41%|████      | 1257/3058 [02:52<03:05,  9.69it/s]\u001b[A\n",
      " 41%|████      | 1259/3058 [02:52<02:53, 10.34it/s]\u001b[A\n",
      " 41%|████      | 1261/3058 [02:52<02:46, 10.79it/s]\u001b[A\n",
      " 41%|████▏     | 1263/3058 [02:52<03:01,  9.91it/s]\u001b[A\n",
      " 41%|████▏     | 1265/3058 [02:52<03:19,  9.00it/s]\u001b[A\n",
      " 41%|████▏     | 1266/3058 [02:53<03:20,  8.94it/s]\u001b[A\n",
      " 41%|████▏     | 1267/3058 [02:53<03:18,  9.03it/s]\u001b[A\n",
      " 41%|████▏     | 1268/3058 [02:53<03:29,  8.55it/s]\u001b[A\n",
      " 41%|████▏     | 1269/3058 [02:53<03:43,  7.99it/s]\u001b[A\n",
      " 42%|████▏     | 1270/3058 [02:53<03:35,  8.28it/s]\u001b[A\n",
      " 42%|████▏     | 1272/3058 [02:53<03:13,  9.24it/s]\u001b[A\n",
      " 42%|████▏     | 1273/3058 [02:53<03:23,  8.79it/s]\u001b[A\n",
      " 42%|████▏     | 1274/3058 [02:53<03:17,  9.02it/s]\u001b[A\n",
      " 42%|████▏     | 1275/3058 [02:54<03:34,  8.32it/s]\u001b[A\n",
      " 42%|████▏     | 1276/3058 [02:54<03:26,  8.62it/s]\u001b[A\n",
      " 42%|████▏     | 1277/3058 [02:54<03:36,  8.24it/s]\u001b[A\n",
      " 42%|████▏     | 1278/3058 [02:54<03:27,  8.57it/s]\u001b[A\n",
      " 42%|████▏     | 1280/3058 [02:54<03:00,  9.85it/s]\u001b[A\n",
      " 42%|████▏     | 1282/3058 [02:54<02:48, 10.56it/s]\u001b[A\n",
      " 42%|████▏     | 1284/3058 [02:54<02:40, 11.03it/s]\u001b[A\n",
      " 42%|████▏     | 1286/3058 [02:55<02:36, 11.35it/s]\u001b[A\n",
      " 42%|████▏     | 1288/3058 [02:55<02:36, 11.32it/s]\u001b[A\n",
      " 42%|████▏     | 1290/3058 [02:55<02:35, 11.40it/s]\u001b[A\n",
      " 42%|████▏     | 1292/3058 [02:55<02:46, 10.61it/s]\u001b[A\n",
      " 42%|████▏     | 1294/3058 [02:55<02:50, 10.37it/s]\u001b[A\n",
      " 42%|████▏     | 1296/3058 [02:56<02:57,  9.90it/s]\u001b[A\n",
      " 42%|████▏     | 1298/3058 [02:56<03:00,  9.73it/s]\u001b[A\n",
      " 42%|████▏     | 1299/3058 [02:56<03:00,  9.76it/s]\u001b[A\n",
      " 43%|████▎     | 1301/3058 [02:56<02:56,  9.95it/s]\u001b[A\n",
      " 43%|████▎     | 1303/3058 [02:56<02:47, 10.47it/s]\u001b[A\n",
      " 43%|████▎     | 1305/3058 [02:57<02:45, 10.59it/s]\u001b[A\n",
      " 43%|████▎     | 1307/3058 [02:57<02:56,  9.92it/s]\u001b[A\n",
      " 43%|████▎     | 1309/3058 [02:57<02:52, 10.15it/s]\u001b[A\n",
      " 43%|████▎     | 1311/3058 [02:57<02:59,  9.71it/s]\u001b[A\n",
      " 43%|████▎     | 1312/3058 [02:57<03:06,  9.37it/s]\u001b[A\n",
      " 43%|████▎     | 1313/3058 [02:57<03:31,  8.26it/s]\u001b[A\n",
      " 43%|████▎     | 1314/3058 [02:58<03:37,  8.02it/s]\u001b[A\n",
      " 43%|████▎     | 1315/3058 [02:58<03:40,  7.92it/s]\u001b[A\n",
      " 43%|████▎     | 1316/3058 [02:58<03:34,  8.12it/s]\u001b[A\n",
      " 43%|████▎     | 1317/3058 [02:58<03:27,  8.39it/s]\u001b[A\n",
      " 43%|████▎     | 1318/3058 [02:58<03:19,  8.72it/s]\u001b[A\n",
      " 43%|████▎     | 1320/3058 [02:58<03:03,  9.46it/s]\u001b[A\n",
      " 43%|████▎     | 1321/3058 [02:58<03:09,  9.17it/s]\u001b[A\n",
      " 43%|████▎     | 1322/3058 [02:58<03:08,  9.23it/s]\u001b[A\n",
      " 43%|████▎     | 1324/3058 [02:59<02:50, 10.15it/s]\u001b[A\n",
      " 43%|████▎     | 1326/3058 [02:59<02:42, 10.69it/s]\u001b[A\n",
      " 43%|████▎     | 1328/3058 [02:59<02:57,  9.75it/s]\u001b[A\n",
      " 43%|████▎     | 1329/3058 [02:59<03:01,  9.55it/s]\u001b[A\n",
      " 44%|████▎     | 1331/3058 [02:59<02:50, 10.15it/s]\u001b[A\n",
      " 44%|████▎     | 1333/3058 [02:59<02:42, 10.59it/s]\u001b[A\n",
      " 44%|████▎     | 1335/3058 [03:00<02:38, 10.89it/s]\u001b[A\n",
      " 44%|████▎     | 1337/3058 [03:00<02:33, 11.23it/s]\u001b[A\n",
      " 44%|████▍     | 1339/3058 [03:00<02:40, 10.69it/s]\u001b[A\n",
      " 44%|████▍     | 1341/3058 [03:00<02:49, 10.13it/s]\u001b[A\n",
      " 44%|████▍     | 1343/3058 [03:00<02:38, 10.80it/s]\u001b[A\n",
      " 44%|████▍     | 1345/3058 [03:01<02:41, 10.62it/s]\u001b[A\n",
      " 44%|████▍     | 1347/3058 [03:01<02:46, 10.30it/s]\u001b[A\n",
      " 44%|████▍     | 1349/3058 [03:01<02:40, 10.63it/s]\u001b[A\n",
      " 44%|████▍     | 1351/3058 [03:01<02:36, 10.90it/s]\u001b[A\n",
      " 44%|████▍     | 1353/3058 [03:01<02:26, 11.61it/s]\u001b[A\n",
      " 44%|████▍     | 1355/3058 [03:02<02:29, 11.39it/s]\u001b[A\n",
      " 44%|████▍     | 1357/3058 [03:02<02:24, 11.74it/s]\u001b[A\n",
      " 44%|████▍     | 1359/3058 [03:02<02:23, 11.86it/s]\u001b[A\n",
      " 45%|████▍     | 1361/3058 [03:02<02:22, 11.94it/s]\u001b[A\n",
      " 45%|████▍     | 1363/3058 [03:02<02:56,  9.59it/s]\u001b[A\n",
      " 45%|████▍     | 1365/3058 [03:03<03:06,  9.07it/s]\u001b[A\n",
      " 45%|████▍     | 1366/3058 [03:03<03:09,  8.93it/s]\u001b[A\n",
      " 45%|████▍     | 1368/3058 [03:03<02:56,  9.57it/s]\u001b[A\n",
      " 45%|████▍     | 1369/3058 [03:03<03:05,  9.08it/s]\u001b[A\n",
      " 45%|████▍     | 1371/3058 [03:03<02:44, 10.24it/s]\u001b[A\n",
      " 45%|████▍     | 1373/3058 [03:03<02:30, 11.22it/s]\u001b[A\n",
      " 45%|████▍     | 1375/3058 [03:03<02:18, 12.20it/s]\u001b[A\n",
      " 45%|████▌     | 1377/3058 [03:04<02:16, 12.28it/s]\u001b[A\n",
      " 45%|████▌     | 1379/3058 [03:04<02:08, 13.05it/s]\u001b[A\n",
      " 45%|████▌     | 1381/3058 [03:04<02:14, 12.43it/s]\u001b[A\n",
      " 45%|████▌     | 1383/3058 [03:04<02:06, 13.23it/s]\u001b[A\n",
      " 45%|████▌     | 1385/3058 [03:04<02:01, 13.76it/s]\u001b[A\n",
      " 45%|████▌     | 1387/3058 [03:04<02:01, 13.79it/s]\u001b[A\n",
      " 45%|████▌     | 1389/3058 [03:04<01:57, 14.18it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 98%|█████████▊| 313/318 [00:04<00:00, 80.72it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1390\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1390/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29705747961997986, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.1588, 'eval_samples_per_second': 305.379, 'eval_steps_per_second': 76.465, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1390/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1390/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1390/special_tokens_map.json\n",
      "\n",
      " 45%|████▌     | 1391/3058 [03:12<33:46,  1.22s/it]\u001b[A\n",
      " 46%|████▌     | 1393/3058 [03:12<24:49,  1.12it/s]\u001b[A\n",
      " 46%|████▌     | 1394/3058 [03:13<21:13,  1.31it/s]\u001b[A\n",
      " 46%|████▌     | 1395/3058 [03:13<17:40,  1.57it/s]\u001b[A\n",
      " 46%|████▌     | 1396/3058 [03:13<14:20,  1.93it/s]\u001b[A\n",
      " 46%|████▌     | 1397/3058 [03:13<11:48,  2.35it/s]\u001b[A\n",
      " 46%|████▌     | 1398/3058 [03:13<09:36,  2.88it/s]\u001b[A\n",
      " 46%|████▌     | 1399/3058 [03:13<07:57,  3.47it/s]\u001b[A\n",
      " 46%|████▌     | 1400/3058 [03:13<06:33,  4.22it/s]\u001b[A\n",
      " 46%|████▌     | 1402/3058 [03:14<04:53,  5.65it/s]\u001b[A\n",
      " 46%|████▌     | 1403/3058 [03:14<04:22,  6.30it/s]\u001b[A\n",
      " 46%|████▌     | 1405/3058 [03:14<03:40,  7.50it/s]\u001b[A\n",
      " 46%|████▌     | 1407/3058 [03:14<03:17,  8.38it/s]\u001b[A\n",
      " 46%|████▌     | 1409/3058 [03:14<03:03,  8.99it/s]\u001b[A\n",
      " 46%|████▌     | 1411/3058 [03:14<02:57,  9.29it/s]\u001b[A\n",
      " 46%|████▌     | 1413/3058 [03:15<02:53,  9.46it/s]\u001b[A\n",
      " 46%|████▌     | 1414/3058 [03:15<03:02,  9.00it/s]\u001b[A\n",
      " 46%|████▋     | 1415/3058 [03:15<03:13,  8.51it/s]\u001b[A\n",
      " 46%|████▋     | 1416/3058 [03:15<03:11,  8.58it/s]\u001b[A\n",
      " 46%|████▋     | 1417/3058 [03:15<03:17,  8.32it/s]\u001b[A\n",
      " 46%|████▋     | 1418/3058 [03:15<03:30,  7.79it/s]\u001b[A\n",
      " 46%|████▋     | 1419/3058 [03:15<03:39,  7.46it/s]\u001b[A\n",
      " 46%|████▋     | 1420/3058 [03:16<03:43,  7.34it/s]\u001b[A\n",
      " 46%|████▋     | 1421/3058 [03:16<03:43,  7.31it/s]\u001b[A\n",
      " 47%|████▋     | 1422/3058 [03:16<03:34,  7.64it/s]\u001b[A\n",
      " 47%|████▋     | 1424/3058 [03:16<02:57,  9.21it/s]\u001b[A\n",
      " 47%|████▋     | 1426/3058 [03:16<02:43,  9.96it/s]\u001b[A\n",
      " 47%|████▋     | 1428/3058 [03:16<02:42, 10.01it/s]\u001b[A\n",
      " 47%|████▋     | 1430/3058 [03:17<02:37, 10.34it/s]\u001b[A\n",
      " 47%|████▋     | 1432/3058 [03:17<02:50,  9.54it/s]\u001b[A\n",
      " 47%|████▋     | 1434/3058 [03:17<02:40, 10.09it/s]\u001b[A\n",
      " 47%|████▋     | 1436/3058 [03:17<02:34, 10.51it/s]\u001b[A\n",
      " 47%|████▋     | 1438/3058 [03:17<02:31, 10.66it/s]\u001b[A\n",
      " 47%|████▋     | 1440/3058 [03:17<02:25, 11.11it/s]\u001b[A\n",
      " 47%|████▋     | 1442/3058 [03:18<03:24,  7.90it/s]\u001b[A\n",
      " 47%|████▋     | 1443/3058 [03:18<03:22,  7.98it/s]\u001b[A\n",
      " 47%|████▋     | 1444/3058 [03:18<03:18,  8.13it/s]\u001b[A\n",
      " 47%|████▋     | 1445/3058 [03:18<03:21,  8.02it/s]\u001b[A\n",
      " 47%|████▋     | 1446/3058 [03:18<03:12,  8.39it/s]\u001b[A\n",
      " 47%|████▋     | 1448/3058 [03:19<02:54,  9.20it/s]\u001b[A\n",
      " 47%|████▋     | 1450/3058 [03:19<02:42,  9.91it/s]\u001b[A\n",
      " 47%|████▋     | 1452/3058 [03:19<02:35, 10.31it/s]\u001b[A\n",
      " 48%|████▊     | 1454/3058 [03:19<02:27, 10.88it/s]\u001b[A\n",
      " 48%|████▊     | 1456/3058 [03:19<02:26, 10.92it/s]\u001b[A\n",
      " 48%|████▊     | 1458/3058 [03:19<02:24, 11.06it/s]\u001b[A\n",
      " 48%|████▊     | 1460/3058 [03:20<02:21, 11.28it/s]\u001b[A\n",
      " 48%|████▊     | 1462/3058 [03:20<02:27, 10.80it/s]\u001b[A\n",
      " 48%|████▊     | 1464/3058 [03:20<02:28, 10.71it/s]\u001b[A\n",
      " 48%|████▊     | 1466/3058 [03:20<02:32, 10.41it/s]\u001b[A\n",
      " 48%|████▊     | 1468/3058 [03:20<02:25, 10.92it/s]\u001b[A\n",
      " 48%|████▊     | 1470/3058 [03:21<02:18, 11.47it/s]\u001b[A\n",
      " 48%|████▊     | 1472/3058 [03:21<02:21, 11.18it/s]\u001b[A\n",
      " 48%|████▊     | 1474/3058 [03:21<02:33, 10.33it/s]\u001b[A\n",
      " 48%|████▊     | 1476/3058 [03:21<02:24, 10.98it/s]\u001b[A\n",
      " 48%|████▊     | 1478/3058 [03:21<02:24, 10.96it/s]\u001b[A\n",
      " 48%|████▊     | 1480/3058 [03:21<02:18, 11.37it/s]\u001b[A\n",
      " 48%|████▊     | 1482/3058 [03:22<02:13, 11.77it/s]\u001b[A\n",
      " 49%|████▊     | 1484/3058 [03:22<02:16, 11.53it/s]\u001b[A\n",
      " 49%|████▊     | 1486/3058 [03:22<02:12, 11.89it/s]\u001b[A\n",
      " 49%|████▊     | 1488/3058 [03:22<02:12, 11.86it/s]\u001b[A\n",
      " 49%|████▊     | 1490/3058 [03:22<02:13, 11.78it/s]\u001b[A\n",
      " 49%|████▉     | 1492/3058 [03:23<02:41,  9.67it/s]\u001b[A\n",
      " 49%|████▉     | 1494/3058 [03:23<02:46,  9.37it/s]\u001b[A\n",
      " 49%|████▉     | 1495/3058 [03:23<02:45,  9.45it/s]\u001b[A\n",
      " 49%|████▉     | 1496/3058 [03:23<02:49,  9.20it/s]\u001b[A\n",
      " 49%|████▉     | 1497/3058 [03:23<03:00,  8.65it/s]\u001b[A\n",
      " 49%|████▉     | 1498/3058 [03:23<03:02,  8.55it/s]\u001b[A\n",
      " 49%|████▉     | 1500/3058 [03:24<03:41,  7.03it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 49%|████▉     | 1500/3058 [03:24<03:41,  7.03it/s]\u001b[A\n",
      " 49%|████▉     | 1501/3058 [03:24<03:53,  6.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3923, 'learning_rate': 0.0005613203969365075, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 1503/3058 [03:24<03:21,  7.71it/s]\u001b[A\n",
      " 49%|████▉     | 1505/3058 [03:24<03:00,  8.60it/s]\u001b[A\n",
      " 49%|████▉     | 1507/3058 [03:24<02:42,  9.52it/s]\u001b[A\n",
      " 49%|████▉     | 1509/3058 [03:25<02:33, 10.06it/s]\u001b[A\n",
      " 49%|████▉     | 1511/3058 [03:25<02:30, 10.30it/s]\u001b[A\n",
      " 49%|████▉     | 1513/3058 [03:25<02:18, 11.14it/s]\u001b[A\n",
      " 50%|████▉     | 1515/3058 [03:25<02:36,  9.89it/s]\u001b[A\n",
      " 50%|████▉     | 1517/3058 [03:25<02:25, 10.60it/s]\u001b[A\n",
      " 50%|████▉     | 1519/3058 [03:25<02:18, 11.10it/s]\u001b[A\n",
      " 50%|████▉     | 1521/3058 [03:26<02:11, 11.73it/s]\u001b[A\n",
      " 50%|████▉     | 1523/3058 [03:26<02:09, 11.82it/s]\u001b[A\n",
      " 50%|████▉     | 1525/3058 [03:26<02:10, 11.75it/s]\u001b[A\n",
      " 50%|████▉     | 1527/3058 [03:26<02:15, 11.33it/s]\u001b[A\n",
      " 50%|█████     | 1529/3058 [03:26<02:22, 10.74it/s]\u001b[A\n",
      " 50%|█████     | 1531/3058 [03:27<02:25, 10.53it/s]\u001b[A\n",
      " 50%|█████     | 1533/3058 [03:27<02:21, 10.79it/s]\u001b[A\n",
      " 50%|█████     | 1535/3058 [03:27<02:13, 11.39it/s]\u001b[A\n",
      " 50%|█████     | 1537/3058 [03:27<02:14, 11.34it/s]\u001b[A\n",
      " 50%|█████     | 1539/3058 [03:27<02:18, 10.97it/s]\u001b[A\n",
      " 50%|█████     | 1541/3058 [03:27<02:27, 10.25it/s]\u001b[A\n",
      " 50%|█████     | 1543/3058 [03:28<02:39,  9.48it/s]\u001b[A\n",
      " 50%|█████     | 1544/3058 [03:28<02:41,  9.37it/s]\u001b[A\n",
      " 51%|█████     | 1545/3058 [03:28<02:39,  9.48it/s]\u001b[A\n",
      " 51%|█████     | 1546/3058 [03:28<02:52,  8.76it/s]\u001b[A\n",
      " 51%|█████     | 1547/3058 [03:28<03:06,  8.09it/s]\u001b[A\n",
      " 51%|█████     | 1548/3058 [03:28<02:59,  8.44it/s]\u001b[A\n",
      " 51%|█████     | 1549/3058 [03:28<03:07,  8.06it/s]\u001b[A\n",
      " 51%|█████     | 1551/3058 [03:29<02:42,  9.30it/s]\u001b[A\n",
      " 51%|█████     | 1552/3058 [03:29<02:48,  8.93it/s]\u001b[A\n",
      " 51%|█████     | 1554/3058 [03:29<02:32,  9.85it/s]\u001b[A\n",
      " 51%|█████     | 1555/3058 [03:29<02:40,  9.39it/s]\u001b[A\n",
      " 51%|█████     | 1556/3058 [03:29<02:44,  9.12it/s]\u001b[A\n",
      " 51%|█████     | 1558/3058 [03:29<02:23, 10.43it/s]\u001b[A\n",
      " 51%|█████     | 1560/3058 [03:30<02:51,  8.76it/s]\u001b[A\n",
      " 51%|█████     | 1562/3058 [03:30<02:36,  9.59it/s]\u001b[A\n",
      " 51%|█████     | 1564/3058 [03:30<02:18, 10.78it/s]\u001b[A\n",
      " 51%|█████     | 1566/3058 [03:30<02:13, 11.16it/s]\u001b[A\n",
      " 51%|█████▏    | 1568/3058 [03:30<02:07, 11.66it/s]\u001b[A\n",
      " 51%|█████▏    | 1570/3058 [03:30<01:58, 12.51it/s]\u001b[A\n",
      " 51%|█████▏    | 1572/3058 [03:31<02:18, 10.76it/s]\u001b[A\n",
      " 51%|█████▏    | 1574/3058 [03:31<02:17, 10.77it/s]\u001b[A\n",
      " 52%|█████▏    | 1576/3058 [03:31<02:12, 11.16it/s]\u001b[A\n",
      " 52%|█████▏    | 1578/3058 [03:31<02:09, 11.41it/s]\u001b[A\n",
      " 52%|█████▏    | 1580/3058 [03:31<02:27, 10.03it/s]\u001b[A\n",
      " 52%|█████▏    | 1582/3058 [03:32<02:23, 10.31it/s]\u001b[A\n",
      " 52%|█████▏    | 1584/3058 [03:32<02:16, 10.81it/s]\u001b[A\n",
      " 52%|█████▏    | 1586/3058 [03:32<02:10, 11.29it/s]\u001b[A\n",
      " 52%|█████▏    | 1588/3058 [03:32<02:06, 11.64it/s]\u001b[A\n",
      " 52%|█████▏    | 1590/3058 [03:32<02:07, 11.48it/s]\u001b[A\n",
      " 52%|█████▏    | 1592/3058 [03:33<02:40,  9.12it/s]\u001b[A\n",
      " 52%|█████▏    | 1594/3058 [03:33<02:43,  8.97it/s]\u001b[A\n",
      " 52%|█████▏    | 1595/3058 [03:33<02:46,  8.79it/s]\u001b[A\n",
      " 52%|█████▏    | 1596/3058 [03:33<02:55,  8.35it/s]\u001b[A\n",
      " 52%|█████▏    | 1597/3058 [03:33<03:06,  7.85it/s]\u001b[A\n",
      " 52%|█████▏    | 1598/3058 [03:33<03:13,  7.54it/s]\u001b[A\n",
      " 52%|█████▏    | 1599/3058 [03:34<03:17,  7.37it/s]\u001b[A\n",
      " 52%|█████▏    | 1600/3058 [03:34<03:23,  7.17it/s]\u001b[A\n",
      " 52%|█████▏    | 1601/3058 [03:34<03:15,  7.46it/s]\u001b[A\n",
      " 52%|█████▏    | 1602/3058 [03:34<03:08,  7.74it/s]\u001b[A\n",
      " 52%|█████▏    | 1603/3058 [03:34<03:07,  7.76it/s]\u001b[A\n",
      " 52%|█████▏    | 1605/3058 [03:34<02:46,  8.71it/s]\u001b[A\n",
      " 53%|█████▎    | 1606/3058 [03:34<02:56,  8.23it/s]\u001b[A\n",
      " 53%|█████▎    | 1607/3058 [03:34<03:03,  7.89it/s]\u001b[A\n",
      " 53%|█████▎    | 1608/3058 [03:35<02:59,  8.06it/s]\u001b[A\n",
      " 53%|█████▎    | 1610/3058 [03:35<02:40,  9.05it/s]\u001b[A\n",
      " 53%|█████▎    | 1612/3058 [03:35<02:20, 10.27it/s]\u001b[A\n",
      " 53%|█████▎    | 1614/3058 [03:35<02:19, 10.38it/s]\u001b[A\n",
      " 53%|█████▎    | 1616/3058 [03:35<02:25,  9.94it/s]\u001b[A\n",
      " 53%|█████▎    | 1618/3058 [03:36<02:14, 10.70it/s]\u001b[A\n",
      " 53%|█████▎    | 1620/3058 [03:36<02:06, 11.37it/s]\u001b[A\n",
      " 53%|█████▎    | 1622/3058 [03:36<01:55, 12.45it/s]\u001b[A\n",
      " 53%|█████▎    | 1624/3058 [03:36<01:53, 12.59it/s]\u001b[A\n",
      " 53%|█████▎    | 1626/3058 [03:36<01:50, 12.94it/s]\u001b[A\n",
      " 53%|█████▎    | 1628/3058 [03:36<01:48, 13.18it/s]\u001b[A\n",
      " 53%|█████▎    | 1630/3058 [03:36<01:50, 12.89it/s]\u001b[A\n",
      " 53%|█████▎    | 1632/3058 [03:37<01:52, 12.64it/s]\u001b[A\n",
      " 53%|█████▎    | 1634/3058 [03:37<01:49, 13.06it/s]\u001b[A\n",
      " 53%|█████▎    | 1636/3058 [03:37<02:02, 11.58it/s]\u001b[A\n",
      " 54%|█████▎    | 1638/3058 [03:37<02:03, 11.54it/s]\u001b[A\n",
      " 54%|█████▎    | 1640/3058 [03:37<01:51, 12.70it/s]\u001b[A\n",
      " 54%|█████▎    | 1642/3058 [03:37<02:15, 10.44it/s]\u001b[A\n",
      " 54%|█████▍    | 1644/3058 [03:38<02:34,  9.17it/s]\u001b[A\n",
      " 54%|█████▍    | 1646/3058 [03:38<02:26,  9.65it/s]\u001b[A\n",
      " 54%|█████▍    | 1648/3058 [03:38<02:18, 10.20it/s]\u001b[A\n",
      " 54%|█████▍    | 1650/3058 [03:38<02:11, 10.70it/s]\u001b[A\n",
      " 54%|█████▍    | 1652/3058 [03:38<02:11, 10.72it/s]\u001b[A\n",
      " 54%|█████▍    | 1654/3058 [03:39<02:13, 10.49it/s]\u001b[A\n",
      " 54%|█████▍    | 1656/3058 [03:39<02:07, 11.02it/s]\u001b[A\n",
      " 54%|█████▍    | 1658/3058 [03:39<02:09, 10.84it/s]\u001b[A\n",
      " 54%|█████▍    | 1660/3058 [03:39<02:05, 11.16it/s]\u001b[A\n",
      " 54%|█████▍    | 1662/3058 [03:39<02:10, 10.68it/s]\u001b[A\n",
      " 54%|█████▍    | 1664/3058 [03:40<02:04, 11.22it/s]\u001b[A\n",
      " 54%|█████▍    | 1666/3058 [03:40<02:10, 10.69it/s]\u001b[A\n",
      " 55%|█████▍    | 1668/3058 [03:40<02:03, 11.26it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 82.70it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1668\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29336977005004883, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.1048, 'eval_samples_per_second': 309.391, 'eval_steps_per_second': 77.47, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1668/special_tokens_map.json\n",
      "\n",
      " 55%|█████▍    | 1670/3058 [03:47<27:26,  1.19s/it]\u001b[A\n",
      " 55%|█████▍    | 1671/3058 [03:48<23:06,  1.00it/s]\u001b[A\n",
      " 55%|█████▍    | 1672/3058 [03:48<19:03,  1.21it/s]\u001b[A\n",
      " 55%|█████▍    | 1673/3058 [03:48<15:19,  1.51it/s]\u001b[A\n",
      " 55%|█████▍    | 1675/3058 [03:48<10:10,  2.27it/s]\u001b[A\n",
      " 55%|█████▍    | 1677/3058 [03:48<07:15,  3.17it/s]\u001b[A\n",
      " 55%|█████▍    | 1678/3058 [03:48<06:22,  3.61it/s]\u001b[A\n",
      " 55%|█████▍    | 1679/3058 [03:48<05:30,  4.17it/s]\u001b[A\n",
      " 55%|█████▍    | 1681/3058 [03:49<04:07,  5.57it/s]\u001b[A\n",
      " 55%|█████▌    | 1683/3058 [03:49<03:22,  6.79it/s]\u001b[A\n",
      " 55%|█████▌    | 1685/3058 [03:49<03:07,  7.32it/s]\u001b[A\n",
      " 55%|█████▌    | 1686/3058 [03:49<03:01,  7.57it/s]\u001b[A\n",
      " 55%|█████▌    | 1687/3058 [03:49<02:56,  7.75it/s]\u001b[A\n",
      " 55%|█████▌    | 1688/3058 [03:49<02:57,  7.73it/s]\u001b[A\n",
      " 55%|█████▌    | 1689/3058 [03:49<02:52,  7.93it/s]\u001b[A\n",
      " 55%|█████▌    | 1690/3058 [03:50<03:03,  7.45it/s]\u001b[A\n",
      " 55%|█████▌    | 1691/3058 [03:50<03:05,  7.37it/s]\u001b[A\n",
      " 55%|█████▌    | 1692/3058 [03:50<02:53,  7.85it/s]\u001b[A\n",
      " 55%|█████▌    | 1694/3058 [03:50<02:31,  9.03it/s]\u001b[A\n",
      " 55%|█████▌    | 1696/3058 [03:50<02:05, 10.82it/s]\u001b[A\n",
      " 56%|█████▌    | 1698/3058 [03:50<02:07, 10.66it/s]\u001b[A\n",
      " 56%|█████▌    | 1700/3058 [03:51<02:04, 10.95it/s]\u001b[A\n",
      " 56%|█████▌    | 1702/3058 [03:51<01:58, 11.40it/s]\u001b[A\n",
      " 56%|█████▌    | 1704/3058 [03:51<01:56, 11.63it/s]\u001b[A\n",
      " 56%|█████▌    | 1706/3058 [03:51<01:55, 11.73it/s]\u001b[A\n",
      " 56%|█████▌    | 1708/3058 [03:51<01:54, 11.75it/s]\u001b[A\n",
      " 56%|█████▌    | 1710/3058 [03:51<02:04, 10.86it/s]\u001b[A\n",
      " 56%|█████▌    | 1712/3058 [03:52<02:08, 10.45it/s]\u001b[A\n",
      " 56%|█████▌    | 1714/3058 [03:52<02:25,  9.22it/s]\u001b[A\n",
      " 56%|█████▌    | 1716/3058 [03:52<02:16,  9.83it/s]\u001b[A\n",
      " 56%|█████▌    | 1718/3058 [03:52<02:17,  9.77it/s]\u001b[A\n",
      " 56%|█████▌    | 1720/3058 [03:53<02:42,  8.21it/s]\u001b[A\n",
      " 56%|█████▋    | 1721/3058 [03:53<02:41,  8.27it/s]\u001b[A\n",
      " 56%|█████▋    | 1722/3058 [03:53<02:38,  8.43it/s]\u001b[A\n",
      " 56%|█████▋    | 1724/3058 [03:53<02:27,  9.02it/s]\u001b[A\n",
      " 56%|█████▋    | 1725/3058 [03:53<02:30,  8.84it/s]\u001b[A\n",
      " 56%|█████▋    | 1727/3058 [03:53<02:20,  9.44it/s]\u001b[A\n",
      " 57%|█████▋    | 1729/3058 [03:54<02:12, 10.00it/s]\u001b[A\n",
      " 57%|█████▋    | 1731/3058 [03:54<02:04, 10.63it/s]\u001b[A\n",
      " 57%|█████▋    | 1733/3058 [03:54<02:01, 10.89it/s]\u001b[A\n",
      " 57%|█████▋    | 1735/3058 [03:54<02:17,  9.61it/s]\u001b[A\n",
      " 57%|█████▋    | 1736/3058 [03:54<02:19,  9.46it/s]\u001b[A\n",
      " 57%|█████▋    | 1738/3058 [03:54<02:11, 10.06it/s]\u001b[A\n",
      " 57%|█████▋    | 1740/3058 [03:55<02:13,  9.86it/s]\u001b[A\n",
      " 57%|█████▋    | 1741/3058 [03:55<02:14,  9.79it/s]\u001b[A\n",
      " 57%|█████▋    | 1742/3058 [03:55<02:14,  9.78it/s]\u001b[A\n",
      " 57%|█████▋    | 1744/3058 [03:55<02:11,  9.98it/s]\u001b[A\n",
      " 57%|█████▋    | 1746/3058 [03:55<02:03, 10.64it/s]\u001b[A\n",
      " 57%|█████▋    | 1748/3058 [03:55<01:58, 11.08it/s]\u001b[A\n",
      " 57%|█████▋    | 1750/3058 [03:56<02:06, 10.34it/s]\u001b[A\n",
      " 57%|█████▋    | 1752/3058 [03:56<02:04, 10.48it/s]\u001b[A\n",
      " 57%|█████▋    | 1754/3058 [03:56<02:05, 10.40it/s]\u001b[A\n",
      " 57%|█████▋    | 1756/3058 [03:56<01:58, 11.00it/s]\u001b[A\n",
      " 57%|█████▋    | 1758/3058 [03:56<02:09, 10.01it/s]\u001b[A\n",
      " 58%|█████▊    | 1760/3058 [03:56<02:01, 10.67it/s]\u001b[A\n",
      " 58%|█████▊    | 1762/3058 [03:57<01:57, 11.06it/s]\u001b[A\n",
      " 58%|█████▊    | 1764/3058 [03:57<02:12,  9.80it/s]\u001b[A\n",
      " 58%|█████▊    | 1766/3058 [03:57<02:03, 10.44it/s]\u001b[A\n",
      " 58%|█████▊    | 1768/3058 [03:57<01:53, 11.35it/s]\u001b[A\n",
      " 58%|█████▊    | 1770/3058 [03:58<02:16,  9.47it/s]\u001b[A\n",
      " 58%|█████▊    | 1772/3058 [03:58<02:18,  9.32it/s]\u001b[A\n",
      " 58%|█████▊    | 1773/3058 [03:58<02:17,  9.33it/s]\u001b[A\n",
      " 58%|█████▊    | 1774/3058 [03:58<02:22,  9.04it/s]\u001b[A\n",
      " 58%|█████▊    | 1775/3058 [03:58<02:30,  8.50it/s]\u001b[A\n",
      " 58%|█████▊    | 1776/3058 [03:58<02:30,  8.55it/s]\u001b[A\n",
      " 58%|█████▊    | 1778/3058 [03:58<02:19,  9.19it/s]\u001b[A\n",
      " 58%|█████▊    | 1779/3058 [03:59<02:23,  8.89it/s]\u001b[A\n",
      " 58%|█████▊    | 1780/3058 [03:59<02:20,  9.12it/s]\u001b[A\n",
      " 58%|█████▊    | 1781/3058 [03:59<02:21,  9.02it/s]\u001b[A\n",
      " 58%|█████▊    | 1782/3058 [03:59<02:28,  8.57it/s]\u001b[A\n",
      " 58%|█████▊    | 1783/3058 [03:59<02:22,  8.92it/s]\u001b[A\n",
      " 58%|█████▊    | 1784/3058 [03:59<02:24,  8.83it/s]\u001b[A\n",
      " 58%|█████▊    | 1785/3058 [03:59<02:19,  9.12it/s]\u001b[A\n",
      " 58%|█████▊    | 1787/3058 [03:59<01:58, 10.71it/s]\u001b[A\n",
      " 59%|█████▊    | 1789/3058 [04:00<02:07,  9.94it/s]\u001b[A\n",
      " 59%|█████▊    | 1791/3058 [04:00<02:22,  8.91it/s]\u001b[A\n",
      " 59%|█████▊    | 1793/3058 [04:00<02:11,  9.63it/s]\u001b[A\n",
      " 59%|█████▊    | 1795/3058 [04:00<02:11,  9.58it/s]\u001b[A\n",
      " 59%|█████▊    | 1796/3058 [04:00<02:10,  9.65it/s]\u001b[A\n",
      " 59%|█████▉    | 1798/3058 [04:00<02:00, 10.47it/s]\u001b[A\n",
      " 59%|█████▉    | 1800/3058 [04:01<01:57, 10.70it/s]\u001b[A\n",
      " 59%|█████▉    | 1802/3058 [04:01<01:52, 11.15it/s]\u001b[A\n",
      " 59%|█████▉    | 1804/3058 [04:01<01:50, 11.34it/s]\u001b[A\n",
      " 59%|█████▉    | 1806/3058 [04:01<01:46, 11.71it/s]\u001b[A\n",
      " 59%|█████▉    | 1808/3058 [04:01<02:01, 10.25it/s]\u001b[A\n",
      " 59%|█████▉    | 1810/3058 [04:02<02:01, 10.27it/s]\u001b[A\n",
      " 59%|█████▉    | 1812/3058 [04:02<02:07,  9.80it/s]\u001b[A\n",
      " 59%|█████▉    | 1814/3058 [04:02<01:58, 10.47it/s]\u001b[A\n",
      " 59%|█████▉    | 1816/3058 [04:02<01:55, 10.73it/s]\u001b[A\n",
      " 59%|█████▉    | 1818/3058 [04:02<01:49, 11.31it/s]\u001b[A\n",
      " 60%|█████▉    | 1820/3058 [04:03<02:30,  8.25it/s]\u001b[A\n",
      " 60%|█████▉    | 1821/3058 [04:03<02:30,  8.20it/s]\u001b[A\n",
      " 60%|█████▉    | 1822/3058 [04:03<02:29,  8.26it/s]\u001b[A\n",
      " 60%|█████▉    | 1823/3058 [04:03<02:26,  8.41it/s]\u001b[A\n",
      " 60%|█████▉    | 1824/3058 [04:03<02:24,  8.54it/s]\u001b[A\n",
      " 60%|█████▉    | 1826/3058 [04:03<02:12,  9.31it/s]\u001b[A\n",
      " 60%|█████▉    | 1828/3058 [04:04<02:04,  9.84it/s]\u001b[A\n",
      " 60%|█████▉    | 1830/3058 [04:04<02:02, 10.05it/s]\u001b[A\n",
      " 60%|█████▉    | 1832/3058 [04:04<01:56, 10.55it/s]\u001b[A\n",
      " 60%|█████▉    | 1834/3058 [04:04<01:49, 11.16it/s]\u001b[A\n",
      " 60%|██████    | 1836/3058 [04:04<01:47, 11.42it/s]\u001b[A\n",
      " 60%|██████    | 1838/3058 [04:04<01:47, 11.30it/s]\u001b[A\n",
      " 60%|██████    | 1840/3058 [04:05<01:44, 11.68it/s]\u001b[A\n",
      " 60%|██████    | 1842/3058 [04:05<01:42, 11.91it/s]\u001b[A\n",
      " 60%|██████    | 1844/3058 [04:05<01:41, 11.99it/s]\u001b[A\n",
      " 60%|██████    | 1846/3058 [04:05<01:39, 12.22it/s]\u001b[A\n",
      " 60%|██████    | 1848/3058 [04:05<01:46, 11.38it/s]\u001b[A\n",
      " 60%|██████    | 1850/3058 [04:05<01:45, 11.46it/s]\u001b[A\n",
      " 61%|██████    | 1852/3058 [04:06<01:43, 11.66it/s]\u001b[A\n",
      " 61%|██████    | 1854/3058 [04:06<01:39, 12.12it/s]\u001b[A\n",
      " 61%|██████    | 1856/3058 [04:06<01:51, 10.75it/s]\u001b[A\n",
      " 61%|██████    | 1858/3058 [04:06<01:46, 11.22it/s]\u001b[A\n",
      " 61%|██████    | 1860/3058 [04:06<01:42, 11.68it/s]\u001b[A\n",
      " 61%|██████    | 1862/3058 [04:06<01:38, 12.18it/s]\u001b[A\n",
      " 61%|██████    | 1864/3058 [04:07<01:36, 12.41it/s]\u001b[A\n",
      " 61%|██████    | 1866/3058 [04:07<01:34, 12.64it/s]\u001b[A\n",
      " 61%|██████    | 1868/3058 [04:07<01:39, 11.96it/s]\u001b[A\n",
      " 61%|██████    | 1870/3058 [04:07<02:04,  9.55it/s]\u001b[A\n",
      " 61%|██████    | 1872/3058 [04:07<02:06,  9.38it/s]\u001b[A\n",
      " 61%|██████▏   | 1874/3058 [04:08<02:06,  9.39it/s]\u001b[A\n",
      " 61%|██████▏   | 1875/3058 [04:08<02:16,  8.70it/s]\u001b[A\n",
      " 61%|██████▏   | 1876/3058 [04:08<02:14,  8.77it/s]\u001b[A\n",
      " 61%|██████▏   | 1878/3058 [04:08<02:02,  9.60it/s]\u001b[A\n",
      " 61%|██████▏   | 1880/3058 [04:08<01:53, 10.38it/s]\u001b[A\n",
      " 62%|██████▏   | 1882/3058 [04:08<01:53, 10.40it/s]\u001b[A\n",
      " 62%|██████▏   | 1884/3058 [04:09<02:07,  9.22it/s]\u001b[A\n",
      " 62%|██████▏   | 1885/3058 [04:09<02:07,  9.19it/s]\u001b[A\n",
      " 62%|██████▏   | 1887/3058 [04:09<01:59,  9.83it/s]\u001b[A\n",
      " 62%|██████▏   | 1888/3058 [04:09<02:02,  9.56it/s]\u001b[A\n",
      " 62%|██████▏   | 1889/3058 [04:09<02:08,  9.06it/s]\u001b[A\n",
      " 62%|██████▏   | 1890/3058 [04:09<02:08,  9.09it/s]\u001b[A\n",
      " 62%|██████▏   | 1892/3058 [04:10<01:54, 10.18it/s]\u001b[A\n",
      " 62%|██████▏   | 1894/3058 [04:10<01:57,  9.94it/s]\u001b[A\n",
      " 62%|██████▏   | 1896/3058 [04:10<01:47, 10.77it/s]\u001b[A\n",
      " 62%|██████▏   | 1898/3058 [04:10<01:43, 11.22it/s]\u001b[A\n",
      " 62%|██████▏   | 1900/3058 [04:10<01:43, 11.22it/s]\u001b[A\n",
      " 62%|██████▏   | 1902/3058 [04:11<01:57,  9.80it/s]\u001b[A\n",
      " 62%|██████▏   | 1904/3058 [04:11<01:58,  9.71it/s]\u001b[A\n",
      " 62%|██████▏   | 1905/3058 [04:11<02:05,  9.22it/s]\u001b[A\n",
      " 62%|██████▏   | 1906/3058 [04:11<02:04,  9.29it/s]\u001b[A\n",
      " 62%|██████▏   | 1908/3058 [04:11<01:53, 10.12it/s]\u001b[A\n",
      " 62%|██████▏   | 1910/3058 [04:11<01:57,  9.73it/s]\u001b[A\n",
      " 63%|██████▎   | 1912/3058 [04:12<01:51, 10.25it/s]\u001b[A\n",
      " 63%|██████▎   | 1914/3058 [04:12<01:47, 10.69it/s]\u001b[A\n",
      " 63%|██████▎   | 1916/3058 [04:12<01:39, 11.44it/s]\u001b[A\n",
      " 63%|██████▎   | 1918/3058 [04:12<01:42, 11.14it/s]\u001b[A\n",
      " 63%|██████▎   | 1920/3058 [04:12<01:58,  9.64it/s]\u001b[A\n",
      " 63%|██████▎   | 1922/3058 [04:13<01:57,  9.64it/s]\u001b[A\n",
      " 63%|██████▎   | 1924/3058 [04:13<01:51, 10.13it/s]\u001b[A\n",
      " 63%|██████▎   | 1926/3058 [04:13<01:47, 10.55it/s]\u001b[A\n",
      " 63%|██████▎   | 1928/3058 [04:13<01:44, 10.85it/s]\u001b[A\n",
      " 63%|██████▎   | 1930/3058 [04:13<01:41, 11.14it/s]\u001b[A\n",
      " 63%|██████▎   | 1932/3058 [04:13<01:37, 11.56it/s]\u001b[A\n",
      " 63%|██████▎   | 1934/3058 [04:14<01:33, 11.98it/s]\u001b[A\n",
      " 63%|██████▎   | 1936/3058 [04:14<01:35, 11.79it/s]\u001b[A\n",
      " 63%|██████▎   | 1938/3058 [04:14<01:30, 12.36it/s]\u001b[A\n",
      " 63%|██████▎   | 1940/3058 [04:14<01:36, 11.65it/s]\u001b[A\n",
      " 64%|██████▎   | 1942/3058 [04:14<01:34, 11.78it/s]\u001b[A\n",
      " 64%|██████▎   | 1944/3058 [04:14<01:30, 12.36it/s]\u001b[A\n",
      " 64%|██████▎   | 1946/3058 [04:14<01:28, 12.55it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 98%|█████████▊| 312/318 [00:03<00:00, 82.86it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1946\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1946/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2929741442203522, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.0363, 'eval_samples_per_second': 314.643, 'eval_steps_per_second': 78.785, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-1946/special_tokens_map.json\n",
      "\n",
      " 64%|██████▎   | 1948/3058 [04:22<21:06,  1.14s/it]\u001b[A\n",
      " 64%|██████▎   | 1949/3058 [04:22<17:45,  1.04it/s]\u001b[A\n",
      " 64%|██████▍   | 1950/3058 [04:22<14:34,  1.27it/s]\u001b[A\n",
      " 64%|██████▍   | 1952/3058 [04:22<09:52,  1.87it/s]\u001b[A\n",
      " 64%|██████▍   | 1954/3058 [04:22<07:04,  2.60it/s]\u001b[A\n",
      " 64%|██████▍   | 1956/3058 [04:23<05:15,  3.49it/s]\u001b[A\n",
      " 64%|██████▍   | 1958/3058 [04:23<04:03,  4.52it/s]\u001b[A\n",
      " 64%|██████▍   | 1960/3058 [04:23<03:13,  5.69it/s]\u001b[A\n",
      " 64%|██████▍   | 1962/3058 [04:23<02:53,  6.30it/s]\u001b[A\n",
      " 64%|██████▍   | 1964/3058 [04:23<02:40,  6.81it/s]\u001b[A\n",
      " 64%|██████▍   | 1966/3058 [04:23<02:20,  7.75it/s]\u001b[A\n",
      " 64%|██████▍   | 1968/3058 [04:24<02:05,  8.69it/s]\u001b[A\n",
      " 64%|██████▍   | 1970/3058 [04:24<01:55,  9.40it/s]\u001b[A\n",
      " 64%|██████▍   | 1972/3058 [04:24<01:56,  9.32it/s]\u001b[A\n",
      " 65%|██████▍   | 1974/3058 [04:24<02:08,  8.46it/s]\u001b[A\n",
      " 65%|██████▍   | 1975/3058 [04:24<02:05,  8.60it/s]\u001b[A\n",
      " 65%|██████▍   | 1977/3058 [04:25<01:50,  9.80it/s]\u001b[A\n",
      " 65%|██████▍   | 1979/3058 [04:25<01:43, 10.46it/s]\u001b[A\n",
      " 65%|██████▍   | 1981/3058 [04:25<01:42, 10.51it/s]\u001b[A\n",
      " 65%|██████▍   | 1983/3058 [04:25<01:39, 10.84it/s]\u001b[A\n",
      " 65%|██████▍   | 1985/3058 [04:25<01:43, 10.38it/s]\u001b[A\n",
      " 65%|██████▍   | 1987/3058 [04:26<01:54,  9.32it/s]\u001b[A\n",
      " 65%|██████▌   | 1988/3058 [04:26<01:56,  9.16it/s]\u001b[A\n",
      " 65%|██████▌   | 1990/3058 [04:26<01:40, 10.59it/s]\u001b[A\n",
      " 65%|██████▌   | 1992/3058 [04:26<01:28, 12.03it/s]\u001b[A\n",
      " 65%|██████▌   | 1994/3058 [04:26<01:25, 12.47it/s]\u001b[A\n",
      " 65%|██████▌   | 1996/3058 [04:26<01:30, 11.78it/s]\u001b[A\n",
      " 65%|██████▌   | 1998/3058 [04:27<02:04,  8.55it/s]\u001b[A\n",
      " 65%|██████▌   | 2000/3058 [04:27<02:23,  7.35it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 65%|██████▌   | 2000/3058 [04:27<02:23,  7.35it/s]\u001b[A\n",
      " 65%|██████▌   | 2001/3058 [04:27<02:24,  7.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3656, 'learning_rate': 0.00038117906287472717, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 2002/3058 [04:27<02:17,  7.69it/s]\u001b[A\n",
      " 66%|██████▌   | 2003/3058 [04:27<02:10,  8.10it/s]\u001b[A\n",
      " 66%|██████▌   | 2004/3058 [04:28<02:19,  7.55it/s]\u001b[A\n",
      " 66%|██████▌   | 2005/3058 [04:28<02:12,  7.97it/s]\u001b[A\n",
      " 66%|██████▌   | 2007/3058 [04:28<01:54,  9.15it/s]\u001b[A\n",
      " 66%|██████▌   | 2009/3058 [04:28<01:44, 10.05it/s]\u001b[A\n",
      " 66%|██████▌   | 2011/3058 [04:28<01:39, 10.54it/s]\u001b[A\n",
      " 66%|██████▌   | 2013/3058 [04:28<01:34, 11.06it/s]\u001b[A\n",
      " 66%|██████▌   | 2015/3058 [04:28<01:30, 11.48it/s]\u001b[A\n",
      " 66%|██████▌   | 2017/3058 [04:29<01:30, 11.46it/s]\u001b[A\n",
      " 66%|██████▌   | 2019/3058 [04:29<01:26, 11.98it/s]\u001b[A\n",
      " 66%|██████▌   | 2021/3058 [04:29<01:28, 11.74it/s]\u001b[A\n",
      " 66%|██████▌   | 2023/3058 [04:29<01:32, 11.25it/s]\u001b[A\n",
      " 66%|██████▌   | 2025/3058 [04:29<01:32, 11.14it/s]\u001b[A\n",
      " 66%|██████▋   | 2027/3058 [04:30<01:36, 10.64it/s]\u001b[A\n",
      " 66%|██████▋   | 2029/3058 [04:30<01:41, 10.16it/s]\u001b[A\n",
      " 66%|██████▋   | 2031/3058 [04:30<01:39, 10.31it/s]\u001b[A\n",
      " 66%|██████▋   | 2033/3058 [04:30<01:36, 10.65it/s]\u001b[A\n",
      " 67%|██████▋   | 2035/3058 [04:30<01:41, 10.11it/s]\u001b[A\n",
      " 67%|██████▋   | 2037/3058 [04:31<01:34, 10.77it/s]\u001b[A\n",
      " 67%|██████▋   | 2039/3058 [04:31<01:32, 11.07it/s]\u001b[A\n",
      " 67%|██████▋   | 2041/3058 [04:31<01:28, 11.44it/s]\u001b[A\n",
      " 67%|██████▋   | 2043/3058 [04:31<01:27, 11.61it/s]\u001b[A\n",
      " 67%|██████▋   | 2045/3058 [04:31<01:25, 11.86it/s]\u001b[A\n",
      " 67%|██████▋   | 2047/3058 [04:31<01:36, 10.52it/s]\u001b[A\n",
      " 67%|██████▋   | 2049/3058 [04:32<01:51,  9.02it/s]\u001b[A\n",
      " 67%|██████▋   | 2050/3058 [04:32<01:53,  8.92it/s]\u001b[A\n",
      " 67%|██████▋   | 2051/3058 [04:32<01:50,  9.09it/s]\u001b[A\n",
      " 67%|██████▋   | 2052/3058 [04:32<01:55,  8.75it/s]\u001b[A\n",
      " 67%|██████▋   | 2053/3058 [04:32<01:55,  8.69it/s]\u001b[A\n",
      " 67%|██████▋   | 2055/3058 [04:32<01:45,  9.47it/s]\u001b[A\n",
      " 67%|██████▋   | 2057/3058 [04:33<01:37, 10.27it/s]\u001b[A\n",
      " 67%|██████▋   | 2059/3058 [04:33<01:33, 10.66it/s]\u001b[A\n",
      " 67%|██████▋   | 2061/3058 [04:33<01:43,  9.66it/s]\u001b[A\n",
      " 67%|██████▋   | 2063/3058 [04:33<01:37, 10.21it/s]\u001b[A\n",
      " 68%|██████▊   | 2065/3058 [04:33<01:35, 10.41it/s]\u001b[A\n",
      " 68%|██████▊   | 2067/3058 [04:33<01:32, 10.75it/s]\u001b[A\n",
      " 68%|██████▊   | 2069/3058 [04:34<01:32, 10.66it/s]\u001b[A\n",
      " 68%|██████▊   | 2071/3058 [04:34<01:28, 11.12it/s]\u001b[A\n",
      " 68%|██████▊   | 2073/3058 [04:34<01:27, 11.26it/s]\u001b[A\n",
      " 68%|██████▊   | 2075/3058 [04:34<01:24, 11.69it/s]\u001b[A\n",
      " 68%|██████▊   | 2077/3058 [04:34<01:26, 11.30it/s]\u001b[A\n",
      " 68%|██████▊   | 2079/3058 [04:35<01:24, 11.53it/s]\u001b[A\n",
      " 68%|██████▊   | 2081/3058 [04:35<01:29, 10.97it/s]\u001b[A\n",
      " 68%|██████▊   | 2083/3058 [04:35<01:29, 10.87it/s]\u001b[A\n",
      " 68%|██████▊   | 2085/3058 [04:35<01:33, 10.39it/s]\u001b[A\n",
      " 68%|██████▊   | 2087/3058 [04:35<01:32, 10.44it/s]\u001b[A\n",
      " 68%|██████▊   | 2089/3058 [04:36<01:39,  9.77it/s]\u001b[A\n",
      " 68%|██████▊   | 2091/3058 [04:36<01:36, 10.02it/s]\u001b[A\n",
      " 68%|██████▊   | 2093/3058 [04:36<01:32, 10.38it/s]\u001b[A\n",
      " 69%|██████▊   | 2095/3058 [04:36<01:28, 10.92it/s]\u001b[A\n",
      " 69%|██████▊   | 2097/3058 [04:36<01:44,  9.20it/s]\u001b[A\n",
      " 69%|██████▊   | 2098/3058 [04:36<01:48,  8.82it/s]\u001b[A\n",
      " 69%|██████▊   | 2099/3058 [04:37<01:50,  8.67it/s]\u001b[A\n",
      " 69%|██████▊   | 2100/3058 [04:37<01:59,  8.01it/s]\u001b[A\n",
      " 69%|██████▊   | 2101/3058 [04:37<02:04,  7.66it/s]\u001b[A\n",
      " 69%|██████▊   | 2102/3058 [04:37<01:58,  8.05it/s]\u001b[A\n",
      " 69%|██████▉   | 2104/3058 [04:37<01:45,  9.05it/s]\u001b[A\n",
      " 69%|██████▉   | 2106/3058 [04:37<01:39,  9.62it/s]\u001b[A\n",
      " 69%|██████▉   | 2108/3058 [04:38<01:32, 10.26it/s]\u001b[A\n",
      " 69%|██████▉   | 2110/3058 [04:38<01:29, 10.56it/s]\u001b[A\n",
      " 69%|██████▉   | 2112/3058 [04:38<01:29, 10.58it/s]\u001b[A\n",
      " 69%|██████▉   | 2114/3058 [04:38<01:29, 10.53it/s]\u001b[A\n",
      " 69%|██████▉   | 2116/3058 [04:38<01:36,  9.78it/s]\u001b[A\n",
      " 69%|██████▉   | 2117/3058 [04:38<01:39,  9.44it/s]\u001b[A\n",
      " 69%|██████▉   | 2118/3058 [04:39<01:47,  8.76it/s]\u001b[A\n",
      " 69%|██████▉   | 2119/3058 [04:39<01:46,  8.79it/s]\u001b[A\n",
      " 69%|██████▉   | 2121/3058 [04:39<01:35,  9.78it/s]\u001b[A\n",
      " 69%|██████▉   | 2123/3058 [04:39<01:26, 10.78it/s]\u001b[A\n",
      " 69%|██████▉   | 2125/3058 [04:39<01:23, 11.19it/s]\u001b[A\n",
      " 70%|██████▉   | 2127/3058 [04:39<01:34,  9.84it/s]\u001b[A\n",
      " 70%|██████▉   | 2129/3058 [04:40<01:35,  9.69it/s]\u001b[A\n",
      " 70%|██████▉   | 2131/3058 [04:40<01:30, 10.19it/s]\u001b[A\n",
      " 70%|██████▉   | 2133/3058 [04:40<01:26, 10.73it/s]\u001b[A\n",
      " 70%|██████▉   | 2135/3058 [04:40<01:22, 11.16it/s]\u001b[A\n",
      " 70%|██████▉   | 2137/3058 [04:40<01:19, 11.63it/s]\u001b[A\n",
      " 70%|██████▉   | 2139/3058 [04:41<01:18, 11.77it/s]\u001b[A\n",
      " 70%|███████   | 2141/3058 [04:41<01:26, 10.54it/s]\u001b[A\n",
      " 70%|███████   | 2143/3058 [04:41<01:18, 11.64it/s]\u001b[A\n",
      " 70%|███████   | 2145/3058 [04:41<01:18, 11.56it/s]\u001b[A\n",
      " 70%|███████   | 2147/3058 [04:41<01:31,  9.99it/s]\u001b[A\n",
      " 70%|███████   | 2149/3058 [04:42<01:40,  9.04it/s]\u001b[A\n",
      " 70%|███████   | 2150/3058 [04:42<01:40,  9.04it/s]\u001b[A\n",
      " 70%|███████   | 2152/3058 [04:42<01:35,  9.49it/s]\u001b[A\n",
      " 70%|███████   | 2153/3058 [04:42<01:36,  9.36it/s]\u001b[A\n",
      " 70%|███████   | 2155/3058 [04:42<01:31,  9.82it/s]\u001b[A\n",
      " 71%|███████   | 2157/3058 [04:42<01:33,  9.66it/s]\u001b[A\n",
      " 71%|███████   | 2159/3058 [04:43<01:28, 10.19it/s]\u001b[A\n",
      " 71%|███████   | 2161/3058 [04:43<01:26, 10.41it/s]\u001b[A\n",
      " 71%|███████   | 2163/3058 [04:43<01:20, 11.10it/s]\u001b[A\n",
      " 71%|███████   | 2165/3058 [04:43<01:19, 11.21it/s]\u001b[A\n",
      " 71%|███████   | 2167/3058 [04:43<01:22, 10.80it/s]\u001b[A\n",
      " 71%|███████   | 2169/3058 [04:43<01:19, 11.19it/s]\u001b[A\n",
      " 71%|███████   | 2171/3058 [04:44<01:13, 12.03it/s]\u001b[A\n",
      " 71%|███████   | 2173/3058 [04:44<01:20, 10.96it/s]\u001b[A\n",
      " 71%|███████   | 2175/3058 [04:44<01:19, 11.06it/s]\u001b[A\n",
      " 71%|███████   | 2177/3058 [04:44<01:18, 11.15it/s]\u001b[A\n",
      " 71%|███████▏  | 2179/3058 [04:44<01:18, 11.22it/s]\u001b[A\n",
      " 71%|███████▏  | 2181/3058 [04:45<01:17, 11.35it/s]\u001b[A\n",
      " 71%|███████▏  | 2183/3058 [04:45<01:15, 11.65it/s]\u001b[A\n",
      " 71%|███████▏  | 2185/3058 [04:45<01:15, 11.51it/s]\u001b[A\n",
      " 72%|███████▏  | 2187/3058 [04:45<01:22, 10.62it/s]\u001b[A\n",
      " 72%|███████▏  | 2189/3058 [04:45<01:30,  9.64it/s]\u001b[A\n",
      " 72%|███████▏  | 2190/3058 [04:45<01:36,  8.99it/s]\u001b[A\n",
      " 72%|███████▏  | 2191/3058 [04:46<01:41,  8.56it/s]\u001b[A\n",
      " 72%|███████▏  | 2193/3058 [04:46<01:35,  9.05it/s]\u001b[A\n",
      " 72%|███████▏  | 2195/3058 [04:46<01:25, 10.10it/s]\u001b[A\n",
      " 72%|███████▏  | 2197/3058 [04:46<01:37,  8.84it/s]\u001b[A\n",
      " 72%|███████▏  | 2198/3058 [04:46<01:38,  8.72it/s]\u001b[A\n",
      " 72%|███████▏  | 2199/3058 [04:47<01:47,  7.96it/s]\u001b[A\n",
      " 72%|███████▏  | 2200/3058 [04:47<01:51,  7.70it/s]\u001b[A\n",
      " 72%|███████▏  | 2201/3058 [04:47<01:46,  8.07it/s]\u001b[A\n",
      " 72%|███████▏  | 2202/3058 [04:47<01:43,  8.24it/s]\u001b[A\n",
      " 72%|███████▏  | 2204/3058 [04:47<01:28,  9.62it/s]\u001b[A\n",
      " 72%|███████▏  | 2206/3058 [04:47<01:19, 10.67it/s]\u001b[A\n",
      " 72%|███████▏  | 2208/3058 [04:47<01:18, 10.82it/s]\u001b[A\n",
      " 72%|███████▏  | 2210/3058 [04:48<01:15, 11.23it/s]\u001b[A\n",
      " 72%|███████▏  | 2212/3058 [04:48<01:14, 11.35it/s]\u001b[A\n",
      " 72%|███████▏  | 2214/3058 [04:48<01:12, 11.68it/s]\u001b[A\n",
      " 72%|███████▏  | 2216/3058 [04:48<01:09, 12.04it/s]\u001b[A\n",
      " 73%|███████▎  | 2218/3058 [04:48<01:09, 12.10it/s]\u001b[A\n",
      " 73%|███████▎  | 2220/3058 [04:48<01:13, 11.43it/s]\u001b[A\n",
      " 73%|███████▎  | 2222/3058 [04:49<01:16, 10.91it/s]\u001b[A\n",
      " 73%|███████▎  | 2224/3058 [04:49<01:16, 10.96it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:03<00:00, 80.05it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2224\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2931189239025116, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.0763, 'eval_samples_per_second': 311.555, 'eval_steps_per_second': 78.011, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2224/special_tokens_map.json\n",
      "\n",
      " 73%|███████▎  | 2226/3058 [04:56<16:39,  1.20s/it]\u001b[A\n",
      " 73%|███████▎  | 2227/3058 [04:56<13:58,  1.01s/it]\u001b[A\n",
      " 73%|███████▎  | 2228/3058 [04:57<11:31,  1.20it/s]\u001b[A\n",
      " 73%|███████▎  | 2229/3058 [04:57<09:14,  1.49it/s]\u001b[A\n",
      " 73%|███████▎  | 2230/3058 [04:57<07:23,  1.87it/s]\u001b[A\n",
      " 73%|███████▎  | 2231/3058 [04:57<05:52,  2.35it/s]\u001b[A\n",
      " 73%|███████▎  | 2233/3058 [04:57<03:54,  3.52it/s]\u001b[A\n",
      " 73%|███████▎  | 2234/3058 [04:57<03:21,  4.10it/s]\u001b[A\n",
      " 73%|███████▎  | 2236/3058 [04:57<02:29,  5.48it/s]\u001b[A\n",
      " 73%|███████▎  | 2238/3058 [04:58<02:08,  6.38it/s]\u001b[A\n",
      " 73%|███████▎  | 2239/3058 [04:58<01:59,  6.87it/s]\u001b[A\n",
      " 73%|███████▎  | 2240/3058 [04:58<01:54,  7.11it/s]\u001b[A\n",
      " 73%|███████▎  | 2242/3058 [04:58<01:36,  8.46it/s]\u001b[A\n",
      " 73%|███████▎  | 2244/3058 [04:58<01:28,  9.23it/s]\u001b[A\n",
      " 73%|███████▎  | 2246/3058 [04:58<01:28,  9.20it/s]\u001b[A\n",
      " 73%|███████▎  | 2247/3058 [04:59<01:32,  8.77it/s]\u001b[A\n",
      " 74%|███████▎  | 2248/3058 [04:59<01:33,  8.71it/s]\u001b[A\n",
      " 74%|███████▎  | 2250/3058 [04:59<01:23,  9.68it/s]\u001b[A\n",
      " 74%|███████▎  | 2252/3058 [04:59<01:17, 10.36it/s]\u001b[A\n",
      " 74%|███████▎  | 2254/3058 [04:59<01:12, 11.09it/s]\u001b[A\n",
      " 74%|███████▍  | 2256/3058 [04:59<01:09, 11.48it/s]\u001b[A\n",
      " 74%|███████▍  | 2258/3058 [04:59<01:09, 11.47it/s]\u001b[A\n",
      " 74%|███████▍  | 2260/3058 [05:00<01:08, 11.73it/s]\u001b[A\n",
      " 74%|███████▍  | 2262/3058 [05:00<01:08, 11.57it/s]\u001b[A\n",
      " 74%|███████▍  | 2264/3058 [05:00<01:07, 11.79it/s]\u001b[A\n",
      " 74%|███████▍  | 2266/3058 [05:00<01:09, 11.41it/s]\u001b[A\n",
      " 74%|███████▍  | 2268/3058 [05:00<01:12, 10.87it/s]\u001b[A\n",
      " 74%|███████▍  | 2270/3058 [05:01<01:09, 11.36it/s]\u001b[A\n",
      " 74%|███████▍  | 2272/3058 [05:01<01:06, 11.84it/s]\u001b[A\n",
      " 74%|███████▍  | 2274/3058 [05:01<00:59, 13.07it/s]\u001b[A\n",
      " 74%|███████▍  | 2276/3058 [05:01<01:18, 10.01it/s]\u001b[A\n",
      " 74%|███████▍  | 2278/3058 [05:01<01:21,  9.62it/s]\u001b[A\n",
      " 75%|███████▍  | 2280/3058 [05:02<01:19,  9.81it/s]\u001b[A\n",
      " 75%|███████▍  | 2282/3058 [05:02<01:20,  9.58it/s]\u001b[A\n",
      " 75%|███████▍  | 2284/3058 [05:02<01:24,  9.17it/s]\u001b[A\n",
      " 75%|███████▍  | 2286/3058 [05:02<01:17,  9.90it/s]\u001b[A\n",
      " 75%|███████▍  | 2288/3058 [05:02<01:14, 10.38it/s]\u001b[A\n",
      " 75%|███████▍  | 2290/3058 [05:03<01:12, 10.57it/s]\u001b[A\n",
      " 75%|███████▍  | 2292/3058 [05:03<01:08, 11.11it/s]\u001b[A\n",
      " 75%|███████▌  | 2294/3058 [05:03<01:07, 11.27it/s]\u001b[A\n",
      " 75%|███████▌  | 2296/3058 [05:03<01:06, 11.46it/s]\u001b[A\n",
      " 75%|███████▌  | 2298/3058 [05:03<01:09, 10.96it/s]\u001b[A\n",
      " 75%|███████▌  | 2300/3058 [05:03<01:11, 10.65it/s]\u001b[A\n",
      " 75%|███████▌  | 2302/3058 [05:04<01:18,  9.61it/s]\u001b[A\n",
      " 75%|███████▌  | 2303/3058 [05:04<01:22,  9.13it/s]\u001b[A\n",
      " 75%|███████▌  | 2304/3058 [05:04<01:25,  8.78it/s]\u001b[A\n",
      " 75%|███████▌  | 2305/3058 [05:04<01:28,  8.51it/s]\u001b[A\n",
      " 75%|███████▌  | 2306/3058 [05:04<01:25,  8.75it/s]\u001b[A\n",
      " 75%|███████▌  | 2307/3058 [05:04<01:24,  8.84it/s]\u001b[A\n",
      " 75%|███████▌  | 2308/3058 [05:04<01:29,  8.42it/s]\u001b[A\n",
      " 76%|███████▌  | 2309/3058 [05:05<01:29,  8.38it/s]\u001b[A\n",
      " 76%|███████▌  | 2310/3058 [05:05<01:26,  8.62it/s]\u001b[A\n",
      " 76%|███████▌  | 2311/3058 [05:05<01:26,  8.67it/s]\u001b[A\n",
      " 76%|███████▌  | 2312/3058 [05:05<01:22,  9.01it/s]\u001b[A\n",
      " 76%|███████▌  | 2313/3058 [05:05<01:25,  8.66it/s]\u001b[A\n",
      " 76%|███████▌  | 2314/3058 [05:05<01:24,  8.79it/s]\u001b[A\n",
      " 76%|███████▌  | 2316/3058 [05:05<01:16,  9.76it/s]\u001b[A\n",
      " 76%|███████▌  | 2318/3058 [05:05<01:09, 10.60it/s]\u001b[A\n",
      " 76%|███████▌  | 2320/3058 [05:06<01:05, 11.23it/s]\u001b[A\n",
      " 76%|███████▌  | 2322/3058 [05:06<01:12, 10.15it/s]\u001b[A\n",
      " 76%|███████▌  | 2324/3058 [05:06<01:12, 10.17it/s]\u001b[A\n",
      " 76%|███████▌  | 2326/3058 [05:06<01:22,  8.84it/s]\u001b[A\n",
      " 76%|███████▌  | 2327/3058 [05:06<01:28,  8.23it/s]\u001b[A\n",
      " 76%|███████▌  | 2328/3058 [05:07<01:31,  8.02it/s]\u001b[A\n",
      " 76%|███████▌  | 2329/3058 [05:07<01:27,  8.30it/s]\u001b[A\n",
      " 76%|███████▌  | 2330/3058 [05:07<01:31,  7.92it/s]\u001b[A\n",
      " 76%|███████▋  | 2332/3058 [05:07<01:20,  9.00it/s]\u001b[A\n",
      " 76%|███████▋  | 2334/3058 [05:07<01:14,  9.72it/s]\u001b[A\n",
      " 76%|███████▋  | 2336/3058 [05:07<01:10, 10.31it/s]\u001b[A\n",
      " 76%|███████▋  | 2338/3058 [05:08<01:05, 10.97it/s]\u001b[A\n",
      " 77%|███████▋  | 2340/3058 [05:08<01:02, 11.40it/s]\u001b[A\n",
      " 77%|███████▋  | 2342/3058 [05:08<01:10, 10.15it/s]\u001b[A\n",
      " 77%|███████▋  | 2344/3058 [05:08<01:05, 10.96it/s]\u001b[A\n",
      " 77%|███████▋  | 2346/3058 [05:08<01:06, 10.73it/s]\u001b[A\n",
      " 77%|███████▋  | 2348/3058 [05:08<01:06, 10.68it/s]\u001b[A\n",
      " 77%|███████▋  | 2350/3058 [05:09<01:04, 10.98it/s]\u001b[A\n",
      " 77%|███████▋  | 2352/3058 [05:09<01:03, 11.11it/s]\u001b[A\n",
      " 77%|███████▋  | 2354/3058 [05:09<01:03, 11.01it/s]\u001b[A\n",
      " 77%|███████▋  | 2356/3058 [05:09<01:00, 11.57it/s]\u001b[A\n",
      " 77%|███████▋  | 2358/3058 [05:09<00:59, 11.82it/s]\u001b[A\n",
      " 77%|███████▋  | 2360/3058 [05:09<00:58, 11.91it/s]\u001b[A\n",
      " 77%|███████▋  | 2362/3058 [05:10<00:58, 12.00it/s]\u001b[A\n",
      " 77%|███████▋  | 2364/3058 [05:10<00:56, 12.25it/s]\u001b[A\n",
      " 77%|███████▋  | 2366/3058 [05:10<00:52, 13.30it/s]\u001b[A\n",
      " 77%|███████▋  | 2368/3058 [05:10<00:57, 12.07it/s]\u001b[A\n",
      " 78%|███████▊  | 2370/3058 [05:10<00:55, 12.31it/s]\u001b[A\n",
      " 78%|███████▊  | 2372/3058 [05:10<00:57, 12.00it/s]\u001b[A\n",
      " 78%|███████▊  | 2374/3058 [05:11<00:57, 11.80it/s]\u001b[A\n",
      " 78%|███████▊  | 2376/3058 [05:11<01:09,  9.78it/s]\u001b[A\n",
      " 78%|███████▊  | 2378/3058 [05:11<01:14,  9.10it/s]\u001b[A\n",
      " 78%|███████▊  | 2379/3058 [05:11<01:15,  9.05it/s]\u001b[A\n",
      " 78%|███████▊  | 2380/3058 [05:11<01:18,  8.63it/s]\u001b[A\n",
      " 78%|███████▊  | 2381/3058 [05:12<01:17,  8.69it/s]\u001b[A\n",
      " 78%|███████▊  | 2382/3058 [05:12<01:19,  8.46it/s]\u001b[A\n",
      " 78%|███████▊  | 2383/3058 [05:12<01:23,  8.12it/s]\u001b[A\n",
      " 78%|███████▊  | 2384/3058 [05:12<01:19,  8.52it/s]\u001b[A\n",
      " 78%|███████▊  | 2385/3058 [05:12<01:18,  8.59it/s]\u001b[A\n",
      " 78%|███████▊  | 2386/3058 [05:12<01:23,  8.07it/s]\u001b[A\n",
      " 78%|███████▊  | 2387/3058 [05:12<01:21,  8.27it/s]\u001b[A\n",
      " 78%|███████▊  | 2389/3058 [05:12<01:09,  9.64it/s]\u001b[A\n",
      " 78%|███████▊  | 2390/3058 [05:13<01:12,  9.15it/s]\u001b[A\n",
      " 78%|███████▊  | 2392/3058 [05:13<01:08,  9.72it/s]\u001b[A\n",
      " 78%|███████▊  | 2394/3058 [05:13<01:00, 10.96it/s]\u001b[A\n",
      " 78%|███████▊  | 2396/3058 [05:13<00:55, 11.96it/s]\u001b[A\n",
      " 78%|███████▊  | 2398/3058 [05:13<00:51, 12.70it/s]\u001b[A\n",
      " 78%|███████▊  | 2400/3058 [05:13<00:53, 12.23it/s]\u001b[A\n",
      " 79%|███████▊  | 2402/3058 [05:14<00:53, 12.26it/s]\u001b[A\n",
      " 79%|███████▊  | 2404/3058 [05:14<00:51, 12.68it/s]\u001b[A\n",
      " 79%|███████▊  | 2406/3058 [05:14<00:52, 12.33it/s]\u001b[A\n",
      " 79%|███████▊  | 2408/3058 [05:14<01:05,  9.90it/s]\u001b[A\n",
      " 79%|███████▉  | 2410/3058 [05:14<01:02, 10.29it/s]\u001b[A\n",
      " 79%|███████▉  | 2412/3058 [05:14<00:56, 11.50it/s]\u001b[A\n",
      " 79%|███████▉  | 2414/3058 [05:15<00:53, 12.11it/s]\u001b[A\n",
      " 79%|███████▉  | 2416/3058 [05:15<00:49, 13.10it/s]\u001b[A\n",
      " 79%|███████▉  | 2418/3058 [05:15<00:49, 12.90it/s]\u001b[A\n",
      " 79%|███████▉  | 2420/3058 [05:15<00:49, 12.86it/s]\u001b[A\n",
      " 79%|███████▉  | 2422/3058 [05:15<00:48, 13.20it/s]\u001b[A\n",
      " 79%|███████▉  | 2424/3058 [05:15<00:51, 12.42it/s]\u001b[A\n",
      " 79%|███████▉  | 2426/3058 [05:16<01:05,  9.60it/s]\u001b[A\n",
      " 79%|███████▉  | 2428/3058 [05:16<01:07,  9.35it/s]\u001b[A\n",
      " 79%|███████▉  | 2430/3058 [05:16<01:06,  9.39it/s]\u001b[A\n",
      " 80%|███████▉  | 2432/3058 [05:16<01:05,  9.62it/s]\u001b[A\n",
      " 80%|███████▉  | 2434/3058 [05:17<01:07,  9.19it/s]\u001b[A\n",
      " 80%|███████▉  | 2435/3058 [05:17<01:07,  9.22it/s]\u001b[A\n",
      " 80%|███████▉  | 2437/3058 [05:17<01:03,  9.85it/s]\u001b[A\n",
      " 80%|███████▉  | 2439/3058 [05:17<00:58, 10.58it/s]\u001b[A\n",
      " 80%|███████▉  | 2441/3058 [05:17<00:55, 11.10it/s]\u001b[A\n",
      " 80%|███████▉  | 2443/3058 [05:17<01:00, 10.18it/s]\u001b[A\n",
      " 80%|███████▉  | 2445/3058 [05:18<01:06,  9.28it/s]\u001b[A\n",
      " 80%|███████▉  | 2446/3058 [05:18<01:05,  9.38it/s]\u001b[A\n",
      " 80%|████████  | 2448/3058 [05:18<01:01,  9.90it/s]\u001b[A\n",
      " 80%|████████  | 2450/3058 [05:18<00:57, 10.52it/s]\u001b[A\n",
      " 80%|████████  | 2452/3058 [05:18<00:55, 10.84it/s]\u001b[A\n",
      " 80%|████████  | 2454/3058 [05:18<01:00, 10.03it/s]\u001b[A\n",
      " 80%|████████  | 2456/3058 [05:19<00:58, 10.31it/s]\u001b[A\n",
      " 80%|████████  | 2458/3058 [05:19<01:00,  9.95it/s]\u001b[A\n",
      " 80%|████████  | 2460/3058 [05:19<01:07,  8.91it/s]\u001b[A\n",
      " 80%|████████  | 2461/3058 [05:19<01:09,  8.59it/s]\u001b[A\n",
      " 81%|████████  | 2462/3058 [05:19<01:10,  8.40it/s]\u001b[A\n",
      " 81%|████████  | 2463/3058 [05:20<01:13,  8.08it/s]\u001b[A\n",
      " 81%|████████  | 2464/3058 [05:20<01:15,  7.84it/s]\u001b[A\n",
      " 81%|████████  | 2465/3058 [05:20<01:12,  8.23it/s]\u001b[A\n",
      " 81%|████████  | 2466/3058 [05:20<01:16,  7.73it/s]\u001b[A\n",
      " 81%|████████  | 2467/3058 [05:20<01:11,  8.23it/s]\u001b[A\n",
      " 81%|████████  | 2469/3058 [05:20<01:02,  9.41it/s]\u001b[A\n",
      " 81%|████████  | 2471/3058 [05:20<00:55, 10.54it/s]\u001b[A\n",
      " 81%|████████  | 2473/3058 [05:21<00:56, 10.42it/s]\u001b[A\n",
      " 81%|████████  | 2475/3058 [05:21<01:00,  9.62it/s]\u001b[A\n",
      " 81%|████████  | 2476/3058 [05:21<01:03,  9.23it/s]\u001b[A\n",
      " 81%|████████  | 2477/3058 [05:21<01:02,  9.35it/s]\u001b[A\n",
      " 81%|████████  | 2479/3058 [05:21<00:58,  9.89it/s]\u001b[A\n",
      " 81%|████████  | 2480/3058 [05:21<01:00,  9.56it/s]\u001b[A\n",
      " 81%|████████  | 2481/3058 [05:21<01:04,  8.95it/s]\u001b[A\n",
      " 81%|████████  | 2482/3058 [05:22<01:04,  8.97it/s]\u001b[A\n",
      " 81%|████████  | 2484/3058 [05:22<00:57, 10.02it/s]\u001b[A\n",
      " 81%|████████▏ | 2486/3058 [05:22<00:55, 10.25it/s]\u001b[A\n",
      " 81%|████████▏ | 2488/3058 [05:22<00:56, 10.17it/s]\u001b[A\n",
      " 81%|████████▏ | 2490/3058 [05:22<00:53, 10.57it/s]\u001b[A\n",
      " 81%|████████▏ | 2492/3058 [05:23<00:57,  9.79it/s]\u001b[A\n",
      " 82%|████████▏ | 2493/3058 [05:23<00:58,  9.66it/s]\u001b[A\n",
      " 82%|████████▏ | 2494/3058 [05:23<01:01,  9.21it/s]\u001b[A\n",
      " 82%|████████▏ | 2495/3058 [05:23<01:05,  8.63it/s]\u001b[A\n",
      " 82%|████████▏ | 2496/3058 [05:23<01:08,  8.22it/s]\u001b[A\n",
      " 82%|████████▏ | 2498/3058 [05:23<01:00,  9.22it/s]\u001b[A\n",
      " 82%|████████▏ | 2500/3058 [05:24<01:15,  7.40it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 82%|████████▏ | 2500/3058 [05:24<01:15,  7.40it/s]\u001b[A\n",
      " 82%|████████▏ | 2501/3058 [05:24<01:20,  6.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.349, 'learning_rate': 0.0002010377288129468, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 2502/3058 [05:24<01:15,  7.39it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 70.76it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2502\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2502/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2935769855976105, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.1851, 'eval_samples_per_second': 303.457, 'eval_steps_per_second': 75.984, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2502/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2502/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-8/checkpoint-2502/special_tokens_map.json\n",
      "\n",
      " 82%|████████▏ | 2503/3058 [05:31<18:11,  1.97s/it]\u001b[A\n",
      " 82%|████████▏ | 2504/3058 [05:32<13:49,  1.50s/it]\u001b[A\n",
      " 82%|████████▏ | 2505/3058 [05:32<10:22,  1.13s/it]\u001b[A\n",
      " 82%|████████▏ | 2506/3058 [05:32<07:46,  1.18it/s]\u001b[A\n",
      " 82%|████████▏ | 2507/3058 [05:32<05:49,  1.58it/s]\u001b[A\n",
      " 82%|████████▏ | 2508/3058 [05:32<04:23,  2.09it/s]\u001b[A\n",
      " 82%|████████▏ | 2510/3058 [05:32<02:46,  3.28it/s]\u001b[A\n",
      " 82%|████████▏ | 2512/3058 [05:32<02:00,  4.54it/s]\u001b[A\n",
      " 82%|████████▏ | 2513/3058 [05:33<01:48,  5.01it/s]\u001b[A\n",
      " 82%|████████▏ | 2514/3058 [05:33<01:36,  5.66it/s]\u001b[A\n",
      " 82%|████████▏ | 2516/3058 [05:33<01:14,  7.27it/s]\u001b[A\n",
      " 82%|████████▏ | 2518/3058 [05:33<01:06,  8.16it/s]\u001b[A\n",
      " 82%|████████▏ | 2520/3058 [05:33<01:10,  7.65it/s]\u001b[A\n",
      " 82%|████████▏ | 2521/3058 [05:33<01:11,  7.55it/s]\u001b[A\n",
      " 82%|████████▏ | 2522/3058 [05:34<01:11,  7.46it/s]\u001b[A\n",
      " 83%|████████▎ | 2523/3058 [05:34<01:09,  7.68it/s]\u001b[A\n",
      " 83%|████████▎ | 2525/3058 [05:34<00:58,  9.15it/s]\u001b[A\n",
      " 83%|████████▎ | 2526/3058 [05:34<00:58,  9.06it/s]\u001b[A\n",
      " 83%|████████▎ | 2528/3058 [05:34<00:53,  9.88it/s]\u001b[A\n",
      " 83%|████████▎ | 2530/3058 [05:34<00:48, 10.97it/s]\u001b[A\n",
      " 83%|████████▎ | 2532/3058 [05:34<00:46, 11.43it/s]\u001b[A\n",
      " 83%|████████▎ | 2534/3058 [05:35<00:54,  9.69it/s]\u001b[A\n",
      " 83%|████████▎ | 2536/3058 [05:35<00:51, 10.16it/s]\u001b[A\n",
      " 83%|████████▎ | 2538/3058 [05:35<00:54,  9.52it/s]\u001b[A\n",
      " 83%|████████▎ | 2540/3058 [05:35<00:52,  9.85it/s]\u001b[A\n",
      " 83%|████████▎ | 2542/3058 [05:35<00:48, 10.55it/s]\u001b[A\n",
      " 83%|████████▎ | 2544/3058 [05:36<00:47, 10.73it/s]\u001b[A\n",
      " 83%|████████▎ | 2546/3058 [05:36<00:45, 11.17it/s]\u001b[A\n",
      " 83%|████████▎ | 2548/3058 [05:36<00:44, 11.40it/s]\u001b[A\n",
      " 83%|████████▎ | 2550/3058 [05:36<00:44, 11.38it/s]\u001b[A\n",
      " 83%|████████▎ | 2552/3058 [05:36<00:42, 11.81it/s]\u001b[A\n",
      " 84%|████████▎ | 2554/3058 [05:37<00:55,  9.16it/s]\u001b[A\n",
      " 84%|████████▎ | 2556/3058 [05:37<00:59,  8.42it/s]\u001b[A\n",
      " 84%|████████▎ | 2557/3058 [05:37<00:58,  8.62it/s]\u001b[A\n",
      " 84%|████████▎ | 2559/3058 [05:37<00:54,  9.20it/s]\u001b[A\n",
      " 84%|████████▎ | 2560/3058 [05:37<00:56,  8.79it/s]\u001b[A\n",
      " 84%|████████▎ | 2561/3058 [05:38<01:02,  8.01it/s]\u001b[A\n",
      " 84%|████████▍ | 2562/3058 [05:38<01:01,  8.09it/s]\u001b[A\n",
      " 84%|████████▍ | 2563/3058 [05:38<00:58,  8.47it/s]\u001b[A\n",
      " 84%|████████▍ | 2564/3058 [05:38<01:03,  7.80it/s]\u001b[A\n",
      " 84%|████████▍ | 2565/3058 [05:38<00:59,  8.24it/s]\u001b[A\n",
      " 84%|████████▍ | 2567/3058 [05:38<00:51,  9.53it/s]\u001b[A\n",
      " 84%|████████▍ | 2568/3058 [05:38<00:52,  9.33it/s]\u001b[A\n",
      " 84%|████████▍ | 2570/3058 [05:38<00:50,  9.65it/s]\u001b[A\n",
      " 84%|████████▍ | 2572/3058 [05:39<00:46, 10.41it/s]\u001b[A\n",
      " 84%|████████▍ | 2574/3058 [05:39<00:43, 11.15it/s]\u001b[A\n",
      " 84%|████████▍ | 2576/3058 [05:39<00:43, 11.11it/s]\u001b[A\n",
      " 84%|████████▍ | 2578/3058 [05:39<00:41, 11.52it/s]\u001b[A\n",
      " 84%|████████▍ | 2580/3058 [05:39<00:40, 11.94it/s]\u001b[A\n",
      " 84%|████████▍ | 2582/3058 [05:40<00:44, 10.68it/s]\u001b[A\n",
      " 84%|████████▍ | 2584/3058 [05:40<00:43, 10.98it/s]\u001b[A\n",
      " 85%|████████▍ | 2586/3058 [05:40<00:40, 11.56it/s]\u001b[A\n",
      " 85%|████████▍ | 2588/3058 [05:40<00:40, 11.74it/s]\u001b[A\n",
      " 85%|████████▍ | 2590/3058 [05:40<00:39, 11.97it/s]\u001b[A\n",
      " 85%|████████▍ | 2592/3058 [05:40<00:40, 11.44it/s]\u001b[A\n",
      " 85%|████████▍ | 2594/3058 [05:41<00:40, 11.38it/s]\u001b[A\n",
      " 85%|████████▍ | 2596/3058 [05:41<00:39, 11.65it/s]\u001b[A\n",
      " 85%|████████▍ | 2598/3058 [05:41<00:38, 11.95it/s]\u001b[A\n",
      " 85%|████████▌ | 2600/3058 [05:41<00:40, 11.36it/s]\u001b[A\n",
      " 85%|████████▌ | 2602/3058 [05:41<00:40, 11.27it/s]\u001b[A\n",
      " 85%|████████▌ | 2604/3058 [05:42<00:47,  9.46it/s]\u001b[A\n",
      " 85%|████████▌ | 2606/3058 [05:42<00:50,  8.87it/s]\u001b[A\n",
      " 85%|████████▌ | 2607/3058 [05:42<00:53,  8.45it/s]\u001b[A\n",
      " 85%|████████▌ | 2608/3058 [05:42<00:53,  8.34it/s]\u001b[A\n",
      " 85%|████████▌ | 2609/3058 [05:42<00:53,  8.43it/s]\u001b[A\n",
      " 85%|████████▌ | 2611/3058 [05:42<00:48,  9.23it/s]\u001b[A\n",
      " 85%|████████▌ | 2612/3058 [05:42<00:48,  9.10it/s]\u001b[A\n",
      " 85%|████████▌ | 2613/3058 [05:43<00:53,  8.34it/s]\u001b[A\n",
      " 85%|████████▌ | 2614/3058 [05:43<00:56,  7.83it/s]\u001b[A\n",
      " 86%|████████▌ | 2615/3058 [05:43<01:00,  7.33it/s]\u001b[A\n",
      " 86%|████████▌ | 2616/3058 [05:43<00:58,  7.58it/s]\u001b[A\n",
      " 86%|████████▌ | 2618/3058 [05:43<00:48,  9.16it/s]\u001b[A\n",
      " 86%|████████▌ | 2620/3058 [05:43<00:44,  9.80it/s]\u001b[A\n",
      " 86%|████████▌ | 2621/3058 [05:44<00:45,  9.65it/s]\u001b[A\n",
      " 86%|████████▌ | 2623/3058 [05:44<00:41, 10.38it/s]\u001b[A\n",
      " 86%|████████▌ | 2625/3058 [05:44<00:42, 10.18it/s]\u001b[A\n",
      " 86%|████████▌ | 2627/3058 [05:44<00:42, 10.05it/s]\u001b[A\n",
      " 86%|████████▌ | 2629/3058 [05:44<00:40, 10.58it/s]\u001b[A\n",
      " 86%|████████▌ | 2631/3058 [05:44<00:38, 11.06it/s]\u001b[A\n",
      " 86%|████████▌ | 2633/3058 [05:45<00:37, 11.20it/s]\u001b[A\n",
      " 86%|████████▌ | 2635/3058 [05:45<00:37, 11.27it/s]\u001b[A\n",
      " 86%|████████▌ | 2637/3058 [05:45<00:38, 11.00it/s]\u001b[A\n",
      " 86%|████████▋ | 2639/3058 [05:45<00:37, 11.25it/s]\u001b[A\n",
      " 86%|████████▋ | 2641/3058 [05:45<00:40, 10.39it/s]\u001b[A\n",
      " 86%|████████▋ | 2643/3058 [05:46<00:39, 10.57it/s]\u001b[A\n",
      " 86%|████████▋ | 2645/3058 [05:46<00:37, 10.97it/s]\u001b[A\n",
      " 87%|████████▋ | 2647/3058 [05:46<00:35, 11.50it/s]\u001b[A\n",
      " 87%|████████▋ | 2649/3058 [05:46<00:35, 11.44it/s]\u001b[A\n",
      " 87%|████████▋ | 2651/3058 [05:46<00:38, 10.45it/s]\u001b[A\n",
      " 87%|████████▋ | 2653/3058 [05:47<00:45,  8.84it/s]\u001b[A\n",
      " 87%|████████▋ | 2654/3058 [05:47<00:48,  8.38it/s]\u001b[A\n",
      " 87%|████████▋ | 2655/3058 [05:47<00:48,  8.39it/s]\u001b[A\n",
      " 87%|████████▋ | 2656/3058 [05:47<00:47,  8.44it/s]\u001b[A\n",
      " 87%|████████▋ | 2657/3058 [05:47<00:46,  8.55it/s]\u001b[A\n",
      " 87%|████████▋ | 2659/3058 [05:47<00:43,  9.28it/s]\u001b[A\n",
      " 87%|████████▋ | 2660/3058 [05:47<00:45,  8.71it/s]\u001b[A\n",
      " 87%|████████▋ | 2661/3058 [05:48<00:50,  7.93it/s]\u001b[A\n",
      " 87%|████████▋ | 2662/3058 [05:48<00:47,  8.30it/s]\u001b[A\n",
      " 87%|████████▋ | 2664/3058 [05:48<00:42,  9.38it/s]\u001b[A\n",
      " 87%|████████▋ | 2666/3058 [05:48<00:38, 10.26it/s]\u001b[A\n",
      " 87%|████████▋ | 2668/3058 [05:48<00:36, 10.65it/s]\u001b[A\n",
      " 87%|████████▋ | 2670/3058 [05:48<00:35, 11.07it/s]\u001b[A\n",
      " 87%|████████▋ | 2672/3058 [05:49<00:34, 11.23it/s]\u001b[A\n",
      " 87%|████████▋ | 2674/3058 [05:49<00:34, 11.01it/s]\u001b[A\n",
      " 88%|████████▊ | 2676/3058 [05:49<00:32, 11.79it/s]\u001b[A\n",
      " 88%|████████▊ | 2678/3058 [05:49<00:32, 11.58it/s]\u001b[A\n",
      " 88%|████████▊ | 2680/3058 [05:49<00:32, 11.74it/s]\u001b[A\n",
      " 88%|████████▊ | 2682/3058 [05:49<00:35, 10.45it/s]\u001b[A\n",
      " 88%|████████▊ | 2684/3058 [05:50<00:36, 10.27it/s]\u001b[A\n",
      " 88%|████████▊ | 2686/3058 [05:50<00:37,  9.85it/s]\u001b[A\n",
      " 88%|████████▊ | 2688/3058 [05:50<00:36, 10.03it/s]\u001b[A\n",
      " 88%|████████▊ | 2690/3058 [05:50<00:36, 10.09it/s]\u001b[A\n",
      " 88%|████████▊ | 2692/3058 [05:50<00:34, 10.46it/s]\u001b[A\n",
      " 88%|████████▊ | 2694/3058 [05:51<00:31, 11.40it/s]\u001b[A\n",
      " 88%|████████▊ | 2696/3058 [05:51<00:32, 11.16it/s]\u001b[A\n",
      " 88%|████████▊ | 2698/3058 [05:51<00:31, 11.58it/s]\u001b[A\n",
      " 88%|████████▊ | 2700/3058 [05:51<00:30, 11.73it/s]\u001b[A\n",
      " 88%|████████▊ | 2702/3058 [05:51<00:29, 11.89it/s]\u001b[A\n",
      " 88%|████████▊ | 2704/3058 [05:52<00:40,  8.70it/s]\u001b[A\n",
      " 88%|████████▊ | 2706/3058 [05:52<00:44,  7.96it/s]\u001b[A\n",
      " 89%|████████▊ | 2707/3058 [05:52<00:44,  7.94it/s]\u001b[A\n",
      " 89%|████████▊ | 2708/3058 [05:52<00:43,  8.12it/s]\u001b[A\n",
      " 89%|████████▊ | 2710/3058 [05:52<00:39,  8.90it/s]\u001b[A\n",
      " 89%|████████▊ | 2712/3058 [05:53<00:35,  9.65it/s]\u001b[A\n",
      " 89%|████████▊ | 2713/3058 [05:53<00:36,  9.43it/s]\u001b[A\n",
      " 89%|████████▉ | 2714/3058 [05:53<00:36,  9.31it/s]\u001b[A\n",
      " 89%|████████▉ | 2716/3058 [05:53<00:37,  9.20it/s]\u001b[A\n",
      " 89%|████████▉ | 2717/3058 [05:53<00:39,  8.64it/s]\u001b[A\n",
      " 89%|████████▉ | 2718/3058 [05:53<00:38,  8.77it/s]\u001b[A\n",
      " 89%|████████▉ | 2720/3058 [05:53<00:34,  9.67it/s]\u001b[A\n",
      " 89%|████████▉ | 2721/3058 [05:54<00:37,  9.07it/s]\u001b[A\n",
      " 89%|████████▉ | 2722/3058 [05:54<00:37,  9.02it/s]\u001b[A\n",
      " 89%|████████▉ | 2724/3058 [05:54<00:34,  9.76it/s]\u001b[A\n",
      " 89%|████████▉ | 2726/3058 [05:54<00:32, 10.15it/s]\u001b[A\n",
      " 89%|████████▉ | 2728/3058 [05:54<00:33,  9.82it/s]\u001b[A\n",
      " 89%|████████▉ | 2729/3058 [05:54<00:34,  9.59it/s]\u001b[A\n",
      " 89%|████████▉ | 2731/3058 [05:54<00:30, 10.65it/s]\u001b[A\n",
      " 89%|████████▉ | 2733/3058 [05:55<00:28, 11.38it/s]\u001b[A\n",
      " 89%|████████▉ | 2735/3058 [05:55<00:27, 11.64it/s]\u001b[A\n",
      " 90%|████████▉ | 2737/3058 [05:55<00:27, 11.65it/s]\u001b[A\n",
      " 90%|████████▉ | 2739/3058 [05:55<00:27, 11.45it/s]\u001b[A\n",
      " 90%|████████▉ | 2741/3058 [05:55<00:28, 11.07it/s]\u001b[A\n",
      " 90%|████████▉ | 2743/3058 [05:56<00:28, 11.17it/s]\u001b[A\n",
      " 90%|████████▉ | 2745/3058 [05:56<00:30, 10.40it/s]\u001b[A\n",
      " 90%|████████▉ | 2747/3058 [05:56<00:28, 10.82it/s]\u001b[A\n",
      " 90%|████████▉ | 2749/3058 [05:56<00:27, 11.07it/s]\u001b[A\n",
      " 90%|████████▉ | 2751/3058 [05:56<00:27, 11.19it/s]\u001b[A\n",
      " 90%|█████████ | 2753/3058 [05:57<00:31,  9.68it/s]\u001b[A\n",
      " 90%|█████████ | 2755/3058 [05:57<00:32,  9.39it/s]\u001b[A\n",
      " 90%|█████████ | 2757/3058 [05:57<00:31,  9.60it/s]\u001b[A\n",
      " 90%|█████████ | 2759/3058 [05:57<00:30,  9.78it/s]\u001b[A\n",
      " 90%|█████████ | 2760/3058 [05:57<00:30,  9.76it/s]\u001b[A\n",
      " 90%|█████████ | 2762/3058 [05:57<00:28, 10.44it/s]\u001b[A\n",
      " 90%|█████████ | 2764/3058 [05:58<00:27, 10.87it/s]\u001b[A\n",
      " 90%|█████████ | 2766/3058 [05:58<00:26, 11.18it/s]\u001b[A\n",
      " 91%|█████████ | 2768/3058 [05:58<00:25, 11.38it/s]\u001b[A\n",
      " 91%|█████████ | 2770/3058 [05:58<00:24, 11.67it/s]\u001b[A\n",
      " 91%|█████████ | 2772/3058 [05:58<00:24, 11.52it/s]\u001b[A\n",
      " 91%|█████████ | 2774/3058 [05:59<00:27, 10.32it/s]\u001b[A\n",
      " 91%|█████████ | 2776/3058 [05:59<00:28,  9.83it/s]\u001b[A\n",
      " 91%|█████████ | 2778/3058 [05:59<00:26, 10.50it/s]\u001b[A\n",
      " 91%|█████████ | 2780/3058 [05:59<00:26, 10.42it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 77.52it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      "\u001b[32m[I 2022-03-29 18:13:33,153]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2929116487503052, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4691, 'eval_samples_per_second': 284.172, 'eval_steps_per_second': 71.155, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22730<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 2780/3058 [06:11<00:26, 10.42it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_180726-1z3vt49b/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_180726-1z3vt49b/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.29291</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.4691</td></tr><tr><td>eval/samples_per_second</td><td>284.172</td></tr><tr><td>eval/steps_per_second</td><td>71.155</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>2780</td></tr><tr><td>_runtime</td><td>367</td></tr><tr><td>_timestamp</td><td>1648570413</td></tr><tr><td>_step</td><td>14</td></tr><tr><td>train/loss</td><td>0.349</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▅█▆▃▁▁▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▇▇█▄▃▂▁▂▃▇</td></tr><tr><td>eval/samples_per_second</td><td>▂▂▁▄▆▇█▇▆▂</td></tr><tr><td>eval/steps_per_second</td><td>▂▂▁▄▆▇█▇▆▂</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▇▇█</td></tr><tr><td>_runtime</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train/loss</td><td>██▆▃▁</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lilac-firefly-19</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/1z3vt49b\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/1z3vt49b</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">colorful-violet-20</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/3v7gsuzt\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/3v7gsuzt</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_181343-3v7gsuzt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 2780/3058 [06:17<00:37,  7.37it/s]\n",
      "  7%|▋         | 278/4170 [00:27<06:58,  9.31it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 81.87it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 70.72it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 63.97it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:04, 65.53it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:04, 68.46it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:03, 71.22it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 69.59it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 66.67it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:01<00:03, 65.60it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 67.51it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 70.15it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 72.64it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 74.55it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 75.11it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 77.19it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 76.90it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 76.70it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 77.57it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 76.74it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:01, 78.05it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:01, 77.90it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 74.45it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 74.16it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 74.01it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 70.49it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 71.33it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:03<00:01, 73.03it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 72.80it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 69.53it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 71.70it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 73.29it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 74.64it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 68.14it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 70.92it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 66.54it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:04<00:00, 68.20it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 69.49it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 71.67it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 72.58it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "  7%|▋         | 278/4170 [00:32<06:58,  9.31it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44414544105529785, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5333, 'eval_samples_per_second': 280.147, 'eval_steps_per_second': 70.147, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-278/special_tokens_map.json\n",
      " 12%|█▏        | 501/4170 [00:57<08:20,  7.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4041, 'learning_rate': 0.0009642917661573285, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 555/4170 [01:03<05:55, 10.17it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 88.69it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 81.64it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:04, 65.48it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 62.41it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:04, 64.67it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 69.83it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 71.88it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 72.36it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 71.37it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 71.90it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 68.81it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:03, 63.57it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:03, 66.53it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:03, 67.29it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 70.42it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 67.78it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:01<00:02, 65.38it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:02<00:02, 63.56it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 62.12it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 66.57it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 69.67it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 65.75it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 68.96it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 67.00it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 70.47it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 72.70it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 73.35it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 73.93it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 71.75it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 72.51it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 74.23it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 75.20it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 76.80it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 75.58it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 75.67it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:04<00:00, 76.27it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 63.91it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 67.71it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 70.61it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 72.38it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 13%|█▎        | 556/4170 [01:07<05:55, 10.17it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33677247166633606, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.6774, 'eval_samples_per_second': 271.516, 'eval_steps_per_second': 67.986, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-556/special_tokens_map.json\n",
      " 20%|█▉        | 833/4170 [01:38<04:40, 11.88it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 68.53it/s]\u001b[A\n",
      "  4%|▍         | 14/318 [00:00<00:04, 69.24it/s]\u001b[A\n",
      "  7%|▋         | 22/318 [00:00<00:04, 72.01it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:03, 75.31it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 76.24it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 78.29it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 78.49it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 79.29it/s]\u001b[A\n",
      " 23%|██▎       | 73/318 [00:00<00:03, 79.01it/s]\u001b[A\n",
      " 25%|██▌       | 81/318 [00:01<00:03, 78.36it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:02, 77.63it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:03, 73.37it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:02, 75.15it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 77.53it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 78.12it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 75.85it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 76.69it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 76.72it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 77.14it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 76.53it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:01, 77.23it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 78.39it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 78.80it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 77.08it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 77.13it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 70.08it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 73.18it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 75.52it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 76.60it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 69.16it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 71.42it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 70.85it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 73.42it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 74.41it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 73.11it/s]\u001b[A\n",
      " 93%|█████████▎| 296/318 [00:03<00:00, 75.33it/s]\u001b[A\n",
      " 96%|█████████▌| 304/318 [00:04<00:00, 75.57it/s]\u001b[A\n",
      " 98%|█████████▊| 312/318 [00:04<00:00, 76.62it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      " 20%|██        | 834/4170 [01:43<04:40, 11.88it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39360731840133667, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2875, 'eval_samples_per_second': 296.213, 'eval_steps_per_second': 74.17, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-834/special_tokens_map.json\n",
      " 24%|██▍       | 1001/4170 [02:04<09:57,  5.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.399, 'learning_rate': 0.0008329168661358942, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1112/4170 [02:18<05:30,  9.24it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 88.53it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:04, 70.11it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 71.44it/s]\u001b[A\n",
      " 11%|█         | 35/318 [00:00<00:03, 75.41it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 73.26it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 76.48it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 70.29it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:00<00:03, 73.48it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 67.45it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 67.31it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 70.49it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 72.61it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:02, 74.44it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 73.43it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 75.62it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 75.22it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 73.08it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 73.41it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 74.43it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 75.97it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:01, 76.31it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 73.81it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 75.49it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 71.28it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 70.99it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 70.02it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 71.49it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 74.74it/s]\u001b[A\n",
      " 75%|███████▍  | 238/318 [00:03<00:01, 75.33it/s]\u001b[A\n",
      " 77%|███████▋  | 246/318 [00:03<00:01, 59.74it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:01, 61.28it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 61.10it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 65.64it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 68.41it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:03<00:00, 70.69it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 65.86it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 70.13it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 70.64it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 71.84it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 27%|██▋       | 1112/4170 [02:22<05:30,  9.24it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1112\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45661672949790955, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5682, 'eval_samples_per_second': 278.012, 'eval_steps_per_second': 69.612, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1112/special_tokens_map.json\n",
      " 33%|███▎      | 1390/4170 [02:51<04:05, 11.32it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 81.89it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 78.06it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 74.44it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 70.97it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 74.54it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 77.37it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 77.16it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 77.44it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 78.74it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:03, 76.86it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:02, 77.68it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:02, 79.78it/s]\u001b[A\n",
      " 35%|███▍      | 110/318 [00:01<00:02, 79.74it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 78.80it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 80.16it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 79.03it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 78.61it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:01<00:02, 77.51it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 75.76it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 75.75it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 76.60it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 76.61it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 77.19it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 73.85it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 75.52it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 77.23it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:02<00:01, 77.39it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 74.24it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 75.00it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 76.38it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 77.70it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 76.37it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 76.64it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 74.60it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 76.05it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 76.93it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 77.86it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 77.44it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 33%|███▎      | 1390/4170 [02:55<04:05, 11.32it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1390\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1390/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31645363569259644, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.2297, 'eval_samples_per_second': 300.258, 'eval_steps_per_second': 75.183, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1390/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1390/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1390/special_tokens_map.json\n",
      " 36%|███▌      | 1501/4170 [03:09<05:58,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3932, 'learning_rate': 0.0007015419661144597, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1668/4170 [03:24<03:29, 11.96it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 69.58it/s]\u001b[A\n",
      "  5%|▍         | 15/318 [00:00<00:05, 60.27it/s]\u001b[A\n",
      "  7%|▋         | 22/318 [00:00<00:04, 61.14it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:04, 63.51it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:04, 69.87it/s]\u001b[A\n",
      " 14%|█▍        | 46/318 [00:00<00:03, 72.69it/s]\u001b[A\n",
      " 17%|█▋        | 54/318 [00:00<00:03, 73.95it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 75.69it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:00<00:03, 75.69it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 75.41it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:02, 77.20it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:02, 77.92it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 77.85it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 78.22it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 77.98it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 77.91it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 78.23it/s]\u001b[A\n",
      " 45%|████▌     | 144/318 [00:01<00:02, 77.80it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 79.48it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:01, 80.89it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:01, 79.02it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 79.60it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 80.65it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 81.02it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:02<00:01, 79.62it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:02<00:01, 79.07it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:02<00:01, 76.58it/s]\u001b[A\n",
      " 73%|███████▎  | 231/318 [00:03<00:01, 77.43it/s]\u001b[A\n",
      " 75%|███████▌  | 240/318 [00:03<00:01, 74.09it/s]\u001b[A\n",
      " 78%|███████▊  | 248/318 [00:03<00:00, 73.07it/s]\u001b[A\n",
      " 81%|████████  | 256/318 [00:03<00:00, 74.95it/s]\u001b[A\n",
      " 83%|████████▎ | 264/318 [00:03<00:00, 73.52it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 72.10it/s]\u001b[A\n",
      " 88%|████████▊ | 280/318 [00:03<00:00, 66.69it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 62.97it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 67.34it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 65.90it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 69.34it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 69.07it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 40%|████      | 1668/4170 [03:28<03:29, 11.96it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1668\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3023732900619507, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3882, 'eval_samples_per_second': 289.413, 'eval_steps_per_second': 72.467, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1668/special_tokens_map.json\n",
      " 47%|████▋     | 1946/4170 [03:57<03:00, 12.35it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 66.12it/s]\u001b[A\n",
      "  4%|▍         | 14/318 [00:00<00:04, 64.98it/s]\u001b[A\n",
      "  7%|▋         | 21/318 [00:00<00:04, 64.65it/s]\u001b[A\n",
      "  9%|▉         | 30/318 [00:00<00:04, 71.70it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 75.94it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 72.00it/s]\u001b[A\n",
      " 17%|█▋        | 55/318 [00:00<00:03, 65.78it/s]\u001b[A\n",
      " 19%|█▉        | 62/318 [00:00<00:03, 65.40it/s]\u001b[A\n",
      " 22%|██▏       | 69/318 [00:01<00:03, 66.21it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 66.55it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 65.90it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 63.85it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 68.03it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 72.05it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 72.28it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 69.36it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 71.47it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:02<00:02, 74.46it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 74.67it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 74.73it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 73.09it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:01, 74.78it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 77.90it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 77.17it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 71.60it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 73.78it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 75.46it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 76.72it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 77.50it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 69.10it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 67.98it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:01, 65.86it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 70.17it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 68.56it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 72.09it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 70.06it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 72.23it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 74.64it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 75.93it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 47%|████▋     | 1946/4170 [04:01<03:00, 12.35it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1946\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1946/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2932775914669037, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.5639, 'eval_samples_per_second': 278.271, 'eval_steps_per_second': 69.677, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-1946/special_tokens_map.json\n",
      " 48%|████▊     | 2001/4170 [04:10<04:58,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3905, 'learning_rate': 0.0005701670660930253, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2223/4170 [04:30<02:56, 11.00it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 85.98it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 86.68it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 85.27it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 77.86it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 77.91it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 77.44it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 78.83it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 80.58it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:00<00:02, 81.35it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:02, 81.10it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 80.61it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 79.42it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 79.82it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 77.19it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 78.41it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:01<00:02, 80.28it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:01<00:02, 80.51it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:01<00:01, 81.08it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:02, 73.58it/s]\u001b[A\n",
      " 55%|█████▌    | 176/318 [00:02<00:01, 73.20it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 71.94it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 73.32it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 73.05it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 75.83it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 77.83it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:02<00:01, 80.74it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 80.05it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 80.31it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 77.15it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 78.29it/s]\u001b[A\n",
      " 86%|████████▌ | 272/318 [00:03<00:00, 79.88it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 79.15it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 79.80it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:03<00:00, 78.97it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:03<00:00, 73.54it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 75.26it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 53%|█████▎    | 2224/4170 [04:34<02:56, 11.00it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2224\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2934713661670685, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.1814, 'eval_samples_per_second': 303.728, 'eval_steps_per_second': 76.052, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2224/special_tokens_map.json\n",
      " 60%|█████▉    | 2501/4170 [05:03<03:05,  8.98it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3676, 'learning_rate': 0.0004387921660715909, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 93.05it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 77.28it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 79.51it/s]\u001b[A\n",
      " 12%|█▏        | 38/318 [00:00<00:03, 81.82it/s]\u001b[A\n",
      " 15%|█▍        | 47/318 [00:00<00:03, 82.14it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 81.68it/s]\u001b[A\n",
      " 20%|██        | 65/318 [00:00<00:03, 81.40it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 77.13it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 74.99it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 71.10it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 66.66it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 71.48it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 72.77it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 72.97it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 75.24it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 75.88it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:01<00:02, 74.22it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 74.03it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 73.61it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:01, 73.36it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 75.08it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:01, 76.61it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 72.23it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 71.79it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:02<00:01, 72.51it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:02<00:01, 73.78it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 74.26it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 74.41it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 74.98it/s]\u001b[A\n",
      " 80%|███████▉  | 254/318 [00:03<00:00, 76.67it/s]\u001b[A\n",
      " 83%|████████▎ | 263/318 [00:03<00:00, 78.08it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 78.19it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 77.89it/s]\u001b[A\n",
      " 90%|█████████ | 287/318 [00:03<00:00, 74.34it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:03<00:00, 71.72it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 64.96it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 65.74it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 69.17it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 60%|██████    | 2502/4170 [05:07<03:05,  8.98it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2502\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2502/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29388463497161865, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.3801, 'eval_samples_per_second': 289.95, 'eval_steps_per_second': 72.602, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2502/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2502/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-9/checkpoint-2502/special_tokens_map.json\n",
      " 67%|██████▋   | 2779/4170 [05:38<02:10, 10.69it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.78it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 85.70it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 75.38it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:03, 73.46it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 70.56it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:04, 63.61it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 67.57it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 66.72it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 66.98it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 62.37it/s]\u001b[A\n",
      " 28%|██▊       | 89/318 [00:01<00:03, 63.47it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 64.88it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:03, 63.26it/s]\u001b[A\n",
      " 35%|███▍      | 111/318 [00:01<00:03, 65.78it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:03, 65.01it/s]\u001b[A\n",
      " 40%|███▉      | 126/318 [00:01<00:02, 67.36it/s]\u001b[A\n",
      " 42%|████▏     | 133/318 [00:01<00:02, 63.79it/s]\u001b[A\n",
      " 44%|████▍     | 141/318 [00:02<00:02, 66.56it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 69.21it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 65.60it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 68.39it/s]\u001b[A\n",
      " 54%|█████▍    | 171/318 [00:02<00:02, 68.49it/s]\u001b[A\n",
      " 56%|█████▋    | 179/318 [00:02<00:01, 71.14it/s]\u001b[A\n",
      " 59%|█████▉    | 187/318 [00:02<00:01, 69.99it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 70.00it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:03<00:01, 62.32it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 67.33it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:03<00:01, 64.10it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 67.95it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 70.64it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:01, 72.71it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 74.30it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 70.20it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 72.46it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:04<00:00, 72.98it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:04<00:00, 73.70it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 71.44it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 60.59it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 64.23it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 67.77it/s]\u001b[A/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                   \n",
      " 67%|██████▋   | 2780/4170 [05:43<02:10, 10.69it/s]A\n",
      "                                                 \u001b[A\u001b[32m[I 2022-03-29 18:19:29,582]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2930953800678253, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.7571, 'eval_samples_per_second': 266.969, 'eval_steps_per_second': 66.847, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 24\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24079<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2780/4170 [05:54<02:10, 10.69it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_181343-3v7gsuzt/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_181343-3v7gsuzt/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.2931</td></tr><tr><td>eval/f1</td><td>0.47758</td></tr><tr><td>eval/recall</td><td>0.5</td></tr><tr><td>eval/precision</td><td>0.45709</td></tr><tr><td>eval/runtime</td><td>4.7571</td></tr><tr><td>eval/samples_per_second</td><td>266.969</td></tr><tr><td>eval/steps_per_second</td><td>66.847</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>2780</td></tr><tr><td>_runtime</td><td>346</td></tr><tr><td>_timestamp</td><td>1648570769</td></tr><tr><td>_step</td><td>14</td></tr><tr><td>train/loss</td><td>0.3676</td></tr><tr><td>train/learning_rate</td><td>0.00044</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>▇▃▅█▂▁▁▁▁▁</td></tr><tr><td>eval/f1</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/recall</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▇▂▆▂▄▆▁▃█</td></tr><tr><td>eval/samples_per_second</td><td>▄▂▇▃▇▅▃█▅▁</td></tr><tr><td>eval/steps_per_second</td><td>▄▂▇▃▇▅▃█▅▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▇▇█</td></tr><tr><td>_runtime</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇▇█</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train/loss</td><td>█▇▆▅▁</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">colorful-violet-20</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/3v7gsuzt\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/3v7gsuzt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">deep-oath-21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/1wetux90\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/1wetux90</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_181940-1wetux90</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2780/4170 [05:58<02:59,  7.76it/s]\n",
      "\n",
      "  0%|          | 1/6672 [00:00<25:20,  4.39it/s]\u001b[A\n",
      "  0%|          | 2/6672 [00:00<22:21,  4.97it/s]\u001b[A\n",
      "  0%|          | 3/6672 [00:00<20:33,  5.41it/s]\u001b[A\n",
      "  0%|          | 4/6672 [00:00<19:43,  5.64it/s]\u001b[A\n",
      "  0%|          | 5/6672 [00:00<18:40,  5.95it/s]\u001b[A\n",
      "  0%|          | 6/6672 [00:01<18:05,  6.14it/s]\u001b[A\n",
      "  0%|          | 7/6672 [00:01<17:15,  6.43it/s]\u001b[A\n",
      "  0%|          | 8/6672 [00:01<17:07,  6.48it/s]\u001b[A\n",
      "  0%|          | 9/6672 [00:01<15:47,  7.03it/s]\u001b[A\n",
      "  0%|          | 10/6672 [00:01<15:20,  7.23it/s]\u001b[A\n",
      "  0%|          | 11/6672 [00:01<15:26,  7.19it/s]\u001b[A\n",
      "  0%|          | 12/6672 [00:01<15:37,  7.10it/s]\u001b[A\n",
      "  0%|          | 13/6672 [00:02<15:52,  6.99it/s]\u001b[A\n",
      "  0%|          | 14/6672 [00:02<16:01,  6.93it/s]\u001b[A\n",
      "  0%|          | 15/6672 [00:02<16:38,  6.67it/s]\u001b[A\n",
      "  0%|          | 16/6672 [00:02<16:09,  6.87it/s]\u001b[A\n",
      "  0%|          | 17/6672 [00:02<15:33,  7.13it/s]\u001b[A\n",
      "  0%|          | 18/6672 [00:02<15:33,  7.13it/s]\u001b[A\n",
      "  0%|          | 19/6672 [00:02<15:34,  7.12it/s]\u001b[A\n",
      "  0%|          | 21/6672 [00:03<14:04,  7.87it/s]\u001b[A\n",
      "  0%|          | 22/6672 [00:03<13:42,  8.08it/s]\u001b[A\n",
      "  0%|          | 23/6672 [00:03<14:10,  7.82it/s]\u001b[A\n",
      "  0%|          | 24/6672 [00:03<14:41,  7.54it/s]\u001b[A\n",
      "  0%|          | 25/6672 [00:03<14:17,  7.75it/s]\u001b[A\n",
      "  0%|          | 26/6672 [00:03<13:56,  7.94it/s]\u001b[A\n",
      "  0%|          | 28/6672 [00:03<12:39,  8.75it/s]\u001b[A\n",
      "  0%|          | 29/6672 [00:04<12:25,  8.92it/s]\u001b[A\n",
      "  0%|          | 30/6672 [00:04<12:25,  8.91it/s]\u001b[A\n",
      "  0%|          | 32/6672 [00:04<11:00, 10.06it/s]\u001b[A\n",
      "  1%|          | 34/6672 [00:04<10:17, 10.75it/s]\u001b[A\n",
      "  1%|          | 36/6672 [00:04<10:40, 10.36it/s]\u001b[A\n",
      "  1%|          | 38/6672 [00:04<12:15,  9.02it/s]\u001b[A\n",
      "  1%|          | 39/6672 [00:05<12:58,  8.52it/s]\u001b[A\n",
      "  1%|          | 40/6672 [00:05<13:38,  8.10it/s]\u001b[A\n",
      "  1%|          | 41/6672 [00:05<14:11,  7.78it/s]\u001b[A\n",
      "  1%|          | 42/6672 [00:05<14:31,  7.61it/s]\u001b[A\n",
      "  1%|          | 43/6672 [00:05<14:46,  7.47it/s]\u001b[A\n",
      "  1%|          | 44/6672 [00:05<14:56,  7.40it/s]\u001b[A\n",
      "  1%|          | 45/6672 [00:05<14:25,  7.66it/s]\u001b[A\n",
      "  1%|          | 46/6672 [00:06<14:36,  7.56it/s]\u001b[A\n",
      "  1%|          | 47/6672 [00:06<14:43,  7.50it/s]\u001b[A\n",
      "  1%|          | 48/6672 [00:06<14:48,  7.45it/s]\u001b[A\n",
      "  1%|          | 49/6672 [00:06<14:56,  7.39it/s]\u001b[A\n",
      "  1%|          | 50/6672 [00:06<15:10,  7.27it/s]\u001b[A\n",
      "  1%|          | 51/6672 [00:06<17:55,  6.16it/s]\u001b[A\n",
      "  1%|          | 52/6672 [00:07<18:28,  5.97it/s]\u001b[A\n",
      "  1%|          | 53/6672 [00:07<18:22,  6.00it/s]\u001b[A\n",
      "  1%|          | 54/6672 [00:07<18:03,  6.11it/s]\u001b[A\n",
      "  1%|          | 55/6672 [00:07<17:44,  6.21it/s]\u001b[A\n",
      "  1%|          | 56/6672 [00:07<17:17,  6.37it/s]\u001b[A\n",
      "  1%|          | 57/6672 [00:07<17:02,  6.47it/s]\u001b[A\n",
      "  1%|          | 58/6672 [00:07<16:54,  6.52it/s]\u001b[A\n",
      "  1%|          | 59/6672 [00:08<16:40,  6.61it/s]\u001b[A\n",
      "  1%|          | 60/6672 [00:08<16:33,  6.66it/s]\u001b[A\n",
      "  1%|          | 61/6672 [00:08<16:11,  6.81it/s]\u001b[A\n",
      "  1%|          | 62/6672 [00:08<15:41,  7.02it/s]\u001b[A\n",
      "  1%|          | 63/6672 [00:08<14:22,  7.67it/s]\u001b[A\n",
      "  1%|          | 65/6672 [00:08<12:36,  8.73it/s]\u001b[A\n",
      "  1%|          | 67/6672 [00:08<11:33,  9.53it/s]\u001b[A\n",
      "  1%|          | 68/6672 [00:09<12:06,  9.09it/s]\u001b[A\n",
      "  1%|          | 69/6672 [00:09<12:54,  8.53it/s]\u001b[A\n",
      "  1%|          | 70/6672 [00:09<13:34,  8.10it/s]\u001b[A\n",
      "  1%|          | 71/6672 [00:09<13:04,  8.42it/s]\u001b[A\n",
      "  1%|          | 73/6672 [00:09<12:44,  8.63it/s]\u001b[A\n",
      "  1%|          | 74/6672 [00:09<12:41,  8.66it/s]\u001b[A\n",
      "  1%|          | 75/6672 [00:09<12:46,  8.61it/s]\u001b[A\n",
      "  1%|          | 76/6672 [00:10<14:15,  7.71it/s]\u001b[A\n",
      "  1%|          | 77/6672 [00:10<15:09,  7.25it/s]\u001b[A\n",
      "  1%|          | 78/6672 [00:10<15:35,  7.05it/s]\u001b[A\n",
      "  1%|          | 79/6672 [00:10<16:10,  6.79it/s]\u001b[A\n",
      "  1%|          | 80/6672 [00:10<14:46,  7.43it/s]\u001b[A\n",
      "  1%|          | 82/6672 [00:10<11:32,  9.51it/s]\u001b[A\n",
      "  1%|          | 83/6672 [00:10<11:37,  9.45it/s]\u001b[A\n",
      "  1%|▏         | 84/6672 [00:11<12:10,  9.01it/s]\u001b[A\n",
      "  1%|▏         | 85/6672 [00:11<12:04,  9.09it/s]\u001b[A\n",
      "  1%|▏         | 87/6672 [00:11<11:15,  9.75it/s]\u001b[A\n",
      "  1%|▏         | 89/6672 [00:11<10:56, 10.02it/s]\u001b[A\n",
      "  1%|▏         | 91/6672 [00:11<10:11, 10.77it/s]\u001b[A\n",
      "  1%|▏         | 93/6672 [00:11<09:31, 11.51it/s]\u001b[A\n",
      "  1%|▏         | 95/6672 [00:12<09:27, 11.59it/s]\u001b[A\n",
      "  1%|▏         | 97/6672 [00:12<11:12,  9.78it/s]\u001b[A\n",
      "  1%|▏         | 99/6672 [00:12<12:33,  8.73it/s]\u001b[A\n",
      "  1%|▏         | 100/6672 [00:12<13:10,  8.32it/s]\u001b[A\n",
      "  2%|▏         | 101/6672 [00:12<15:19,  7.14it/s]\u001b[A\n",
      "  2%|▏         | 102/6672 [00:13<16:28,  6.65it/s]\u001b[A\n",
      "  2%|▏         | 103/6672 [00:13<16:57,  6.46it/s]\u001b[A\n",
      "  2%|▏         | 104/6672 [00:13<17:04,  6.41it/s]\u001b[A\n",
      "  2%|▏         | 105/6672 [00:13<16:58,  6.45it/s]\u001b[A\n",
      "  2%|▏         | 106/6672 [00:13<16:55,  6.47it/s]\u001b[A\n",
      "  2%|▏         | 107/6672 [00:13<16:28,  6.64it/s]\u001b[A\n",
      "  2%|▏         | 108/6672 [00:14<16:09,  6.77it/s]\u001b[A\n",
      "  2%|▏         | 109/6672 [00:14<15:57,  6.85it/s]\u001b[A\n",
      "  2%|▏         | 110/6672 [00:14<15:59,  6.84it/s]\u001b[A\n",
      "  2%|▏         | 111/6672 [00:14<15:00,  7.28it/s]\u001b[A\n",
      "  2%|▏         | 112/6672 [00:14<14:28,  7.55it/s]\u001b[A\n",
      "  2%|▏         | 113/6672 [00:14<14:40,  7.45it/s]\u001b[A\n",
      "  2%|▏         | 114/6672 [00:14<15:00,  7.28it/s]\u001b[A\n",
      "  2%|▏         | 115/6672 [00:15<15:07,  7.22it/s]\u001b[A\n",
      "  2%|▏         | 116/6672 [00:15<14:40,  7.44it/s]\u001b[A\n",
      "  2%|▏         | 117/6672 [00:15<14:47,  7.38it/s]\u001b[A\n",
      "  2%|▏         | 118/6672 [00:15<14:54,  7.33it/s]\u001b[A\n",
      "  2%|▏         | 119/6672 [00:15<14:56,  7.31it/s]\u001b[A\n",
      "  2%|▏         | 120/6672 [00:15<15:18,  7.14it/s]\u001b[A\n",
      "  2%|▏         | 121/6672 [00:15<15:30,  7.04it/s]\u001b[A\n",
      "  2%|▏         | 122/6672 [00:15<15:23,  7.10it/s]\u001b[A\n",
      "  2%|▏         | 123/6672 [00:16<15:41,  6.96it/s]\u001b[A\n",
      "  2%|▏         | 124/6672 [00:16<15:41,  6.95it/s]\u001b[A\n",
      "  2%|▏         | 125/6672 [00:16<14:37,  7.46it/s]\u001b[A\n",
      "  2%|▏         | 127/6672 [00:16<12:22,  8.81it/s]\u001b[A\n",
      "  2%|▏         | 128/6672 [00:16<12:36,  8.65it/s]\u001b[A\n",
      "  2%|▏         | 129/6672 [00:16<13:15,  8.22it/s]\u001b[A\n",
      "  2%|▏         | 130/6672 [00:16<13:34,  8.04it/s]\u001b[A\n",
      "  2%|▏         | 131/6672 [00:17<14:02,  7.76it/s]\u001b[A\n",
      "  2%|▏         | 132/6672 [00:17<14:16,  7.63it/s]\u001b[A\n",
      "  2%|▏         | 133/6672 [00:17<15:30,  7.03it/s]\u001b[A\n",
      "  2%|▏         | 134/6672 [00:17<16:17,  6.69it/s]\u001b[A\n",
      "  2%|▏         | 135/6672 [00:17<16:51,  6.46it/s]\u001b[A\n",
      "  2%|▏         | 136/6672 [00:17<17:06,  6.36it/s]\u001b[A\n",
      "  2%|▏         | 137/6672 [00:18<17:10,  6.34it/s]\u001b[A\n",
      "  2%|▏         | 139/6672 [00:18<14:29,  7.52it/s]\u001b[A\n",
      "  2%|▏         | 140/6672 [00:18<15:27,  7.04it/s]\u001b[A\n",
      "  2%|▏         | 141/6672 [00:18<15:57,  6.82it/s]\u001b[A\n",
      "  2%|▏         | 142/6672 [00:18<15:13,  7.15it/s]\u001b[A\n",
      "  2%|▏         | 144/6672 [00:18<12:40,  8.59it/s]\u001b[A\n",
      "  2%|▏         | 145/6672 [00:19<12:29,  8.71it/s]\u001b[A\n",
      "  2%|▏         | 146/6672 [00:19<13:05,  8.31it/s]\u001b[A\n",
      "  2%|▏         | 147/6672 [00:19<12:49,  8.48it/s]\u001b[A\n",
      "  2%|▏         | 149/6672 [00:19<11:19,  9.60it/s]\u001b[A\n",
      "  2%|▏         | 150/6672 [00:19<12:22,  8.78it/s]\u001b[A\n",
      "  2%|▏         | 151/6672 [00:19<15:07,  7.18it/s]\u001b[A\n",
      "  2%|▏         | 152/6672 [00:19<15:18,  7.10it/s]\u001b[A\n",
      "  2%|▏         | 153/6672 [00:20<15:45,  6.89it/s]\u001b[A\n",
      "  2%|▏         | 154/6672 [00:20<16:11,  6.71it/s]\u001b[A\n",
      "  2%|▏         | 155/6672 [00:20<15:15,  7.12it/s]\u001b[A\n",
      "  2%|▏         | 156/6672 [00:20<14:32,  7.46it/s]\u001b[A\n",
      "  2%|▏         | 157/6672 [00:20<14:14,  7.63it/s]\u001b[A\n",
      "  2%|▏         | 158/6672 [00:20<13:38,  7.96it/s]\u001b[A\n",
      "  2%|▏         | 160/6672 [00:20<12:03,  9.00it/s]\u001b[A\n",
      "  2%|▏         | 162/6672 [00:21<11:04,  9.79it/s]\u001b[A\n",
      "  2%|▏         | 164/6672 [00:21<10:45, 10.08it/s]\u001b[A\n",
      "  2%|▏         | 165/6672 [00:21<11:13,  9.66it/s]\u001b[A\n",
      "  2%|▏         | 166/6672 [00:21<11:31,  9.41it/s]\u001b[A\n",
      "  3%|▎         | 168/6672 [00:21<10:41, 10.14it/s]\u001b[A\n",
      "  3%|▎         | 169/6672 [00:21<11:21,  9.54it/s]\u001b[A\n",
      "  3%|▎         | 170/6672 [00:21<11:24,  9.50it/s]\u001b[A\n",
      "  3%|▎         | 172/6672 [00:22<10:48, 10.03it/s]\u001b[A\n",
      "  3%|▎         | 173/6672 [00:22<10:53,  9.94it/s]\u001b[A\n",
      "  3%|▎         | 174/6672 [00:22<10:55,  9.91it/s]\u001b[A\n",
      "  3%|▎         | 176/6672 [00:22<10:22, 10.43it/s]\u001b[A\n",
      "  3%|▎         | 178/6672 [00:22<11:07,  9.72it/s]\u001b[A\n",
      "  3%|▎         | 179/6672 [00:22<11:59,  9.02it/s]\u001b[A\n",
      "  3%|▎         | 180/6672 [00:22<11:43,  9.23it/s]\u001b[A\n",
      "  3%|▎         | 182/6672 [00:23<10:37, 10.19it/s]\u001b[A\n",
      "  3%|▎         | 184/6672 [00:23<10:03, 10.74it/s]\u001b[A\n",
      "  3%|▎         | 186/6672 [00:23<09:29, 11.38it/s]\u001b[A\n",
      "  3%|▎         | 188/6672 [00:23<10:20, 10.46it/s]\u001b[A\n",
      "  3%|▎         | 190/6672 [00:23<10:34, 10.22it/s]\u001b[A\n",
      "  3%|▎         | 192/6672 [00:24<10:12, 10.58it/s]\u001b[A\n",
      "  3%|▎         | 194/6672 [00:24<10:48,  9.99it/s]\u001b[A\n",
      "  3%|▎         | 196/6672 [00:24<10:32, 10.24it/s]\u001b[A\n",
      "  3%|▎         | 198/6672 [00:24<10:02, 10.74it/s]\u001b[A\n",
      "  3%|▎         | 200/6672 [00:24<10:00, 10.77it/s]\u001b[A\n",
      "  3%|▎         | 202/6672 [00:25<12:18,  8.76it/s]\u001b[A\n",
      "  3%|▎         | 203/6672 [00:25<13:06,  8.22it/s]\u001b[A\n",
      "  3%|▎         | 204/6672 [00:25<13:48,  7.81it/s]\u001b[A\n",
      "  3%|▎         | 205/6672 [00:25<13:17,  8.11it/s]\u001b[A\n",
      "  3%|▎         | 207/6672 [00:25<12:07,  8.88it/s]\u001b[A\n",
      "  3%|▎         | 208/6672 [00:25<12:36,  8.55it/s]\u001b[A\n",
      "  3%|▎         | 209/6672 [00:26<13:18,  8.10it/s]\u001b[A\n",
      "  3%|▎         | 210/6672 [00:26<14:11,  7.59it/s]\u001b[A\n",
      "  3%|▎         | 211/6672 [00:26<14:35,  7.38it/s]\u001b[A\n",
      "  3%|▎         | 212/6672 [00:26<14:54,  7.23it/s]\u001b[A\n",
      "  3%|▎         | 213/6672 [00:26<14:26,  7.45it/s]\u001b[A\n",
      "  3%|▎         | 215/6672 [00:26<12:01,  8.95it/s]\u001b[A\n",
      "  3%|▎         | 216/6672 [00:26<11:47,  9.12it/s]\u001b[A\n",
      "  3%|▎         | 217/6672 [00:26<11:32,  9.32it/s]\u001b[A\n",
      "  3%|▎         | 219/6672 [00:27<10:34, 10.16it/s]\u001b[A\n",
      "  3%|▎         | 221/6672 [00:27<10:03, 10.69it/s]\u001b[A\n",
      "  3%|▎         | 223/6672 [00:27<10:43, 10.02it/s]\u001b[A\n",
      "  3%|▎         | 225/6672 [00:27<10:25, 10.30it/s]\u001b[A\n",
      "  3%|▎         | 227/6672 [00:27<10:46,  9.97it/s]\u001b[A\n",
      "  3%|▎         | 229/6672 [00:28<10:56,  9.82it/s]\u001b[A\n",
      "  3%|▎         | 231/6672 [00:28<10:11, 10.53it/s]\u001b[A\n",
      "  3%|▎         | 233/6672 [00:28<10:38, 10.08it/s]\u001b[A\n",
      "  4%|▎         | 235/6672 [00:28<10:54,  9.84it/s]\u001b[A\n",
      "  4%|▎         | 237/6672 [00:28<10:16, 10.44it/s]\u001b[A\n",
      "  4%|▎         | 239/6672 [00:29<09:45, 10.99it/s]\u001b[A\n",
      "  4%|▎         | 241/6672 [00:29<10:19, 10.38it/s]\u001b[A\n",
      "  4%|▎         | 243/6672 [00:29<09:56, 10.78it/s]\u001b[A\n",
      "  4%|▎         | 245/6672 [00:29<10:30, 10.20it/s]\u001b[A\n",
      "  4%|▎         | 247/6672 [00:29<09:14, 11.58it/s]\u001b[A\n",
      "  4%|▎         | 249/6672 [00:29<08:41, 12.33it/s]\u001b[A\n",
      "  4%|▍         | 251/6672 [00:30<10:49,  9.89it/s]\u001b[A\n",
      "  4%|▍         | 253/6672 [00:30<11:25,  9.36it/s]\u001b[A\n",
      "  4%|▍         | 255/6672 [00:30<11:41,  9.15it/s]\u001b[A\n",
      "  4%|▍         | 257/6672 [00:30<10:58,  9.74it/s]\u001b[A\n",
      "  4%|▍         | 259/6672 [00:31<10:28, 10.20it/s]\u001b[A\n",
      "  4%|▍         | 261/6672 [00:31<10:16, 10.39it/s]\u001b[A\n",
      "  4%|▍         | 263/6672 [00:31<10:22, 10.30it/s]\u001b[A\n",
      "  4%|▍         | 265/6672 [00:31<09:58, 10.71it/s]\u001b[A\n",
      "  4%|▍         | 267/6672 [00:31<10:04, 10.59it/s]\u001b[A\n",
      "  4%|▍         | 269/6672 [00:32<11:19,  9.42it/s]\u001b[A\n",
      "  4%|▍         | 270/6672 [00:32<12:00,  8.89it/s]\u001b[A\n",
      "  4%|▍         | 271/6672 [00:32<12:02,  8.86it/s]\u001b[A\n",
      "  4%|▍         | 273/6672 [00:32<11:41,  9.12it/s]\u001b[A\n",
      "  4%|▍         | 274/6672 [00:32<11:56,  8.93it/s]\u001b[A\n",
      "  4%|▍         | 275/6672 [00:32<12:15,  8.70it/s]\u001b[A\n",
      "  4%|▍         | 277/6672 [00:32<11:09,  9.55it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 77.28it/s]\n",
      "                                                  \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49367186427116394, 'eval_f1': 0.6792768738701155, 'eval_recall': 0.8606745213316581, 'eval_precision': 0.6514044794735027, 'eval_runtime': 4.3574, 'eval_samples_per_second': 291.461, 'eval_steps_per_second': 72.98, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-278/special_tokens_map.json\n",
      "\n",
      "  4%|▍         | 279/6672 [00:40<2:36:29,  1.47s/it]\u001b[A\n",
      "  4%|▍         | 280/6672 [00:40<2:07:57,  1.20s/it]\u001b[A\n",
      "  4%|▍         | 281/6672 [00:40<1:41:51,  1.05it/s]\u001b[A\n",
      "  4%|▍         | 282/6672 [00:41<1:20:17,  1.33it/s]\u001b[A\n",
      "  4%|▍         | 283/6672 [00:41<1:03:38,  1.67it/s]\u001b[A\n",
      "  4%|▍         | 284/6672 [00:41<50:10,  2.12it/s]  \u001b[A\n",
      "  4%|▍         | 285/6672 [00:41<39:20,  2.71it/s]\u001b[A\n",
      "  4%|▍         | 287/6672 [00:41<26:34,  4.00it/s]\u001b[A\n",
      "  4%|▍         | 288/6672 [00:41<23:32,  4.52it/s]\u001b[A\n",
      "  4%|▍         | 289/6672 [00:41<21:31,  4.94it/s]\u001b[A\n",
      "  4%|▍         | 290/6672 [00:42<20:11,  5.27it/s]\u001b[A\n",
      "  4%|▍         | 291/6672 [00:42<18:18,  5.81it/s]\u001b[A\n",
      "  4%|▍         | 292/6672 [00:42<17:04,  6.23it/s]\u001b[A\n",
      "  4%|▍         | 293/6672 [00:42<17:03,  6.23it/s]\u001b[A\n",
      "  4%|▍         | 294/6672 [00:42<16:44,  6.35it/s]\u001b[A\n",
      "  4%|▍         | 295/6672 [00:42<16:13,  6.55it/s]\u001b[A\n",
      "  4%|▍         | 296/6672 [00:42<14:44,  7.21it/s]\u001b[A\n",
      "  4%|▍         | 298/6672 [00:43<12:11,  8.71it/s]\u001b[A\n",
      "  4%|▍         | 300/6672 [00:43<11:12,  9.48it/s]\u001b[A\n",
      "  5%|▍         | 301/6672 [00:43<11:17,  9.40it/s]\u001b[A\n",
      "  5%|▍         | 303/6672 [00:43<10:35, 10.02it/s]\u001b[A\n",
      "  5%|▍         | 305/6672 [00:43<10:01, 10.59it/s]\u001b[A\n",
      "  5%|▍         | 307/6672 [00:43<10:06, 10.49it/s]\u001b[A\n",
      "  5%|▍         | 309/6672 [00:44<10:18, 10.29it/s]\u001b[A\n",
      "  5%|▍         | 311/6672 [00:44<09:49, 10.80it/s]\u001b[A\n",
      "  5%|▍         | 313/6672 [00:44<09:59, 10.61it/s]\u001b[A\n",
      "  5%|▍         | 315/6672 [00:44<09:59, 10.61it/s]\u001b[A\n",
      "  5%|▍         | 317/6672 [00:44<09:58, 10.62it/s]\u001b[A\n",
      "  5%|▍         | 319/6672 [00:45<09:07, 11.60it/s]\u001b[A\n",
      "  5%|▍         | 321/6672 [00:45<08:18, 12.74it/s]\u001b[A\n",
      "  5%|▍         | 323/6672 [00:45<08:04, 13.11it/s]\u001b[A\n",
      "  5%|▍         | 325/6672 [00:45<08:13, 12.85it/s]\u001b[A\n",
      "  5%|▍         | 327/6672 [00:45<08:13, 12.85it/s]\u001b[A\n",
      "  5%|▍         | 329/6672 [00:45<10:18, 10.26it/s]\u001b[A\n",
      "  5%|▍         | 331/6672 [00:46<12:35,  8.39it/s]\u001b[A\n",
      "  5%|▍         | 332/6672 [00:46<13:01,  8.12it/s]\u001b[A\n",
      "  5%|▍         | 333/6672 [00:46<12:48,  8.25it/s]\u001b[A\n",
      "  5%|▌         | 334/6672 [00:46<13:25,  7.87it/s]\u001b[A\n",
      "  5%|▌         | 335/6672 [00:46<13:25,  7.87it/s]\u001b[A\n",
      "  5%|▌         | 337/6672 [00:46<12:45,  8.28it/s]\u001b[A\n",
      "  5%|▌         | 338/6672 [00:47<13:13,  7.99it/s]\u001b[A\n",
      "  5%|▌         | 339/6672 [00:47<13:33,  7.79it/s]\u001b[A\n",
      "  5%|▌         | 341/6672 [00:47<11:56,  8.84it/s]\u001b[A\n",
      "  5%|▌         | 343/6672 [00:47<10:35,  9.96it/s]\u001b[A\n",
      "  5%|▌         | 345/6672 [00:47<09:59, 10.55it/s]\u001b[A\n",
      "  5%|▌         | 347/6672 [00:47<10:32,  9.99it/s]\u001b[A\n",
      "  5%|▌         | 349/6672 [00:48<11:10,  9.43it/s]\u001b[A\n",
      "  5%|▌         | 351/6672 [00:48<10:59,  9.59it/s]\u001b[A\n",
      "  5%|▌         | 352/6672 [00:48<11:50,  8.89it/s]\u001b[A\n",
      "  5%|▌         | 353/6672 [00:48<12:32,  8.40it/s]\u001b[A\n",
      "  5%|▌         | 354/6672 [00:48<12:59,  8.10it/s]\u001b[A\n",
      "  5%|▌         | 355/6672 [00:49<13:29,  7.81it/s]\u001b[A\n",
      "  5%|▌         | 356/6672 [00:49<13:32,  7.78it/s]\u001b[A\n",
      "  5%|▌         | 357/6672 [00:49<13:23,  7.86it/s]\u001b[A\n",
      "  5%|▌         | 358/6672 [00:49<13:53,  7.58it/s]\u001b[A\n",
      "  5%|▌         | 359/6672 [00:49<13:08,  8.01it/s]\u001b[A\n",
      "  5%|▌         | 360/6672 [00:49<13:05,  8.03it/s]\u001b[A\n",
      "  5%|▌         | 362/6672 [00:49<11:31,  9.13it/s]\u001b[A\n",
      "  5%|▌         | 363/6672 [00:49<11:45,  8.95it/s]\u001b[A\n",
      "  5%|▌         | 364/6672 [00:50<11:36,  9.06it/s]\u001b[A\n",
      "  5%|▌         | 365/6672 [00:50<11:44,  8.95it/s]\u001b[A\n",
      "  5%|▌         | 366/6672 [00:50<11:54,  8.82it/s]\u001b[A\n",
      "  6%|▌         | 368/6672 [00:50<11:24,  9.21it/s]\u001b[A\n",
      "  6%|▌         | 369/6672 [00:50<12:00,  8.75it/s]\u001b[A\n",
      "  6%|▌         | 371/6672 [00:50<10:37,  9.89it/s]\u001b[A\n",
      "  6%|▌         | 373/6672 [00:50<09:52, 10.63it/s]\u001b[A\n",
      "  6%|▌         | 375/6672 [00:51<11:12,  9.36it/s]\u001b[A\n",
      "  6%|▌         | 376/6672 [00:51<11:52,  8.83it/s]\u001b[A\n",
      "  6%|▌         | 378/6672 [00:51<10:15, 10.22it/s]\u001b[A\n",
      "  6%|▌         | 380/6672 [00:51<12:06,  8.66it/s]\u001b[A\n",
      "  6%|▌         | 381/6672 [00:51<12:15,  8.56it/s]\u001b[A\n",
      "  6%|▌         | 382/6672 [00:52<12:30,  8.39it/s]\u001b[A\n",
      "  6%|▌         | 383/6672 [00:52<12:49,  8.18it/s]\u001b[A\n",
      "  6%|▌         | 384/6672 [00:52<12:15,  8.55it/s]\u001b[A\n",
      "  6%|▌         | 386/6672 [00:52<11:14,  9.32it/s]\u001b[A\n",
      "  6%|▌         | 388/6672 [00:52<10:32,  9.94it/s]\u001b[A\n",
      "  6%|▌         | 389/6672 [00:52<10:37,  9.86it/s]\u001b[A\n",
      "  6%|▌         | 390/6672 [00:52<11:24,  9.17it/s]\u001b[A\n",
      "  6%|▌         | 392/6672 [00:53<10:18, 10.15it/s]\u001b[A\n",
      "  6%|▌         | 394/6672 [00:53<09:49, 10.66it/s]\u001b[A\n",
      "  6%|▌         | 396/6672 [00:53<09:01, 11.59it/s]\u001b[A\n",
      "  6%|▌         | 398/6672 [00:53<08:53, 11.77it/s]\u001b[A\n",
      "  6%|▌         | 400/6672 [00:53<08:38, 12.11it/s]\u001b[A\n",
      "  6%|▌         | 402/6672 [00:53<08:47, 11.90it/s]\u001b[A\n",
      "  6%|▌         | 404/6672 [00:54<09:35, 10.89it/s]\u001b[A\n",
      "  6%|▌         | 406/6672 [00:54<10:08, 10.30it/s]\u001b[A\n",
      "  6%|▌         | 408/6672 [00:54<10:17, 10.14it/s]\u001b[A\n",
      "  6%|▌         | 410/6672 [00:54<09:46, 10.68it/s]\u001b[A\n",
      "  6%|▌         | 412/6672 [00:54<09:50, 10.60it/s]\u001b[A\n",
      "  6%|▌         | 414/6672 [00:55<09:58, 10.45it/s]\u001b[A\n",
      "  6%|▌         | 416/6672 [00:55<09:37, 10.83it/s]\u001b[A\n",
      "  6%|▋         | 418/6672 [00:55<10:30,  9.91it/s]\u001b[A\n",
      "  6%|▋         | 420/6672 [00:55<10:08, 10.28it/s]\u001b[A\n",
      "  6%|▋         | 422/6672 [00:55<09:28, 11.00it/s]\u001b[A\n",
      "  6%|▋         | 424/6672 [00:55<09:08, 11.40it/s]\u001b[A\n",
      "  6%|▋         | 426/6672 [00:56<09:17, 11.20it/s]\u001b[A\n",
      "  6%|▋         | 428/6672 [00:56<10:45,  9.67it/s]\u001b[A\n",
      "  6%|▋         | 430/6672 [00:56<13:39,  7.61it/s]\u001b[A\n",
      "  6%|▋         | 431/6672 [00:56<13:48,  7.53it/s]\u001b[A\n",
      "  6%|▋         | 432/6672 [00:57<13:41,  7.60it/s]\u001b[A\n",
      "  6%|▋         | 433/6672 [00:57<14:10,  7.34it/s]\u001b[A\n",
      "  7%|▋         | 434/6672 [00:57<13:57,  7.45it/s]\u001b[A\n",
      "  7%|▋         | 436/6672 [00:57<12:57,  8.02it/s]\u001b[A\n",
      "  7%|▋         | 437/6672 [00:57<13:23,  7.76it/s]\u001b[A\n",
      "  7%|▋         | 438/6672 [00:57<13:09,  7.90it/s]\u001b[A\n",
      "  7%|▋         | 440/6672 [00:58<11:37,  8.94it/s]\u001b[A\n",
      "  7%|▋         | 441/6672 [00:58<11:58,  8.67it/s]\u001b[A\n",
      "  7%|▋         | 442/6672 [00:58<12:22,  8.39it/s]\u001b[A\n",
      "  7%|▋         | 443/6672 [00:58<12:07,  8.56it/s]\u001b[A\n",
      "  7%|▋         | 444/6672 [00:58<11:55,  8.71it/s]\u001b[A\n",
      "  7%|▋         | 445/6672 [00:58<11:41,  8.88it/s]\u001b[A\n",
      "  7%|▋         | 446/6672 [00:58<11:31,  9.01it/s]\u001b[A\n",
      "  7%|▋         | 448/6672 [00:58<10:17, 10.08it/s]\u001b[A\n",
      "  7%|▋         | 450/6672 [00:59<09:37, 10.77it/s]\u001b[A\n",
      "  7%|▋         | 452/6672 [00:59<09:35, 10.81it/s]\u001b[A\n",
      "  7%|▋         | 454/6672 [00:59<09:35, 10.80it/s]\u001b[A\n",
      "  7%|▋         | 456/6672 [00:59<11:47,  8.79it/s]\u001b[A\n",
      "  7%|▋         | 457/6672 [00:59<12:32,  8.26it/s]\u001b[A\n",
      "  7%|▋         | 458/6672 [01:00<13:13,  7.83it/s]\u001b[A\n",
      "  7%|▋         | 459/6672 [01:00<12:38,  8.19it/s]\u001b[A\n",
      "  7%|▋         | 460/6672 [01:00<12:05,  8.56it/s]\u001b[A\n",
      "  7%|▋         | 461/6672 [01:00<12:05,  8.56it/s]\u001b[A\n",
      "  7%|▋         | 463/6672 [01:00<10:18, 10.04it/s]\u001b[A\n",
      "  7%|▋         | 465/6672 [01:00<09:51, 10.49it/s]\u001b[A\n",
      "  7%|▋         | 467/6672 [01:00<09:01, 11.46it/s]\u001b[A\n",
      "  7%|▋         | 469/6672 [01:00<08:59, 11.50it/s]\u001b[A\n",
      "  7%|▋         | 471/6672 [01:01<08:53, 11.62it/s]\u001b[A\n",
      "  7%|▋         | 473/6672 [01:01<08:49, 11.71it/s]\u001b[A\n",
      "  7%|▋         | 475/6672 [01:01<09:57, 10.37it/s]\u001b[A\n",
      "  7%|▋         | 477/6672 [01:01<09:58, 10.34it/s]\u001b[A\n",
      "  7%|▋         | 479/6672 [01:02<11:43,  8.80it/s]\u001b[A\n",
      "  7%|▋         | 480/6672 [01:02<12:15,  8.41it/s]\u001b[A\n",
      "  7%|▋         | 481/6672 [01:02<12:41,  8.13it/s]\u001b[A\n",
      "  7%|▋         | 482/6672 [01:02<13:06,  7.87it/s]\u001b[A\n",
      "  7%|▋         | 483/6672 [01:02<13:04,  7.88it/s]\u001b[A\n",
      "  7%|▋         | 484/6672 [01:02<12:24,  8.31it/s]\u001b[A\n",
      "  7%|▋         | 485/6672 [01:02<12:09,  8.48it/s]\u001b[A\n",
      "  7%|▋         | 486/6672 [01:02<13:19,  7.74it/s]\u001b[A\n",
      "  7%|▋         | 487/6672 [01:03<13:50,  7.44it/s]\u001b[A\n",
      "  7%|▋         | 488/6672 [01:03<12:49,  8.03it/s]\u001b[A\n",
      "  7%|▋         | 489/6672 [01:03<13:30,  7.63it/s]\u001b[A\n",
      "  7%|▋         | 490/6672 [01:03<13:57,  7.38it/s]\u001b[A\n",
      "  7%|▋         | 491/6672 [01:03<14:00,  7.36it/s]\u001b[A\n",
      "  7%|▋         | 493/6672 [01:03<12:18,  8.36it/s]\u001b[A\n",
      "  7%|▋         | 495/6672 [01:04<11:05,  9.28it/s]\u001b[A\n",
      "  7%|▋         | 497/6672 [01:04<10:13, 10.07it/s]\u001b[A\n",
      "  7%|▋         | 498/6672 [01:04<10:18,  9.99it/s]\u001b[A\n",
      "  7%|▋         | 500/6672 [01:04<13:01,  7.90it/s]\u001b[A\n",
      "\u001b[A                                               \n",
      "  7%|▋         | 500/6672 [01:04<13:01,  7.90it/s]\u001b[A\n",
      "  8%|▊         | 501/6672 [01:04<14:04,  7.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2274, 'learning_rate': 6.466333415114697e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 503/6672 [01:05<12:04,  8.51it/s]\u001b[A\n",
      "  8%|▊         | 504/6672 [01:05<11:57,  8.60it/s]\u001b[A\n",
      "  8%|▊         | 506/6672 [01:05<10:35,  9.71it/s]\u001b[A\n",
      "  8%|▊         | 508/6672 [01:05<09:22, 10.96it/s]\u001b[A\n",
      "  8%|▊         | 510/6672 [01:05<09:10, 11.19it/s]\u001b[A\n",
      "  8%|▊         | 512/6672 [01:05<09:13, 11.12it/s]\u001b[A\n",
      "  8%|▊         | 514/6672 [01:05<09:28, 10.82it/s]\u001b[A\n",
      "  8%|▊         | 516/6672 [01:06<09:34, 10.71it/s]\u001b[A\n",
      "  8%|▊         | 518/6672 [01:06<09:04, 11.29it/s]\u001b[A\n",
      "  8%|▊         | 520/6672 [01:06<09:00, 11.38it/s]\u001b[A\n",
      "  8%|▊         | 522/6672 [01:06<09:46, 10.49it/s]\u001b[A\n",
      "  8%|▊         | 524/6672 [01:06<09:50, 10.41it/s]\u001b[A\n",
      "  8%|▊         | 526/6672 [01:07<09:30, 10.77it/s]\u001b[A\n",
      "  8%|▊         | 528/6672 [01:07<09:23, 10.91it/s]\u001b[A\n",
      "  8%|▊         | 530/6672 [01:07<11:48,  8.68it/s]\u001b[A\n",
      "  8%|▊         | 531/6672 [01:07<12:25,  8.24it/s]\u001b[A\n",
      "  8%|▊         | 532/6672 [01:07<13:00,  7.87it/s]\u001b[A\n",
      "  8%|▊         | 533/6672 [01:08<13:36,  7.52it/s]\u001b[A\n",
      "  8%|▊         | 534/6672 [01:08<13:43,  7.46it/s]\u001b[A\n",
      "  8%|▊         | 536/6672 [01:08<11:34,  8.83it/s]\u001b[A\n",
      "  8%|▊         | 537/6672 [01:08<11:31,  8.88it/s]\u001b[A\n",
      "  8%|▊         | 539/6672 [01:08<10:23,  9.84it/s]\u001b[A\n",
      "  8%|▊         | 541/6672 [01:08<09:46, 10.45it/s]\u001b[A\n",
      "  8%|▊         | 543/6672 [01:08<09:23, 10.88it/s]\u001b[A\n",
      "  8%|▊         | 545/6672 [01:09<10:05, 10.12it/s]\u001b[A\n",
      "  8%|▊         | 547/6672 [01:09<09:08, 11.16it/s]\u001b[A\n",
      "  8%|▊         | 549/6672 [01:09<08:17, 12.32it/s]\u001b[A\n",
      "  8%|▊         | 551/6672 [01:09<07:47, 13.09it/s]\u001b[A\n",
      "  8%|▊         | 553/6672 [01:09<07:21, 13.85it/s]\u001b[A\n",
      "  8%|▊         | 555/6672 [01:09<07:53, 12.91it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 76.24it/s]/cm/shared/ebtree/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "                                                  \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19515880942344666, 'eval_f1': 0.4775812422871246, 'eval_recall': 0.5, 'eval_precision': 0.4570866141732283, 'eval_runtime': 4.4378, 'eval_samples_per_second': 286.177, 'eval_steps_per_second': 71.657, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-556/special_tokens_map.json\n",
      "\n",
      "  8%|▊         | 557/6672 [01:17<2:07:37,  1.25s/it]\u001b[A\n",
      "  8%|▊         | 558/6672 [01:17<1:47:31,  1.06s/it]\u001b[A\n",
      "  8%|▊         | 559/6672 [01:18<1:28:13,  1.15it/s]\u001b[A\n",
      "  8%|▊         | 560/6672 [01:18<1:11:07,  1.43it/s]\u001b[A\n",
      "  8%|▊         | 561/6672 [01:18<56:48,  1.79it/s]  \u001b[A\n",
      "  8%|▊         | 562/6672 [01:18<45:22,  2.24it/s]\u001b[A\n",
      "  8%|▊         | 563/6672 [01:18<36:53,  2.76it/s]\u001b[A\n",
      "  8%|▊         | 564/6672 [01:18<30:41,  3.32it/s]\u001b[A\n",
      "  8%|▊         | 565/6672 [01:18<26:08,  3.89it/s]\u001b[A\n",
      "  8%|▊         | 566/6672 [01:18<22:23,  4.54it/s]\u001b[A\n",
      "  9%|▊         | 568/6672 [01:19<16:35,  6.13it/s]\u001b[A\n",
      "  9%|▊         | 570/6672 [01:19<13:22,  7.60it/s]\u001b[A\n",
      "  9%|▊         | 572/6672 [01:19<11:25,  8.90it/s]\u001b[A\n",
      "  9%|▊         | 574/6672 [01:19<11:58,  8.48it/s]\u001b[A\n",
      "  9%|▊         | 576/6672 [01:19<11:04,  9.17it/s]\u001b[A\n",
      "  9%|▊         | 578/6672 [01:20<10:14,  9.91it/s]\u001b[A\n",
      "  9%|▊         | 580/6672 [01:20<10:50,  9.37it/s]\u001b[A\n",
      "  9%|▊         | 581/6672 [01:20<10:54,  9.31it/s]\u001b[A\n",
      "  9%|▊         | 583/6672 [01:20<09:58, 10.17it/s]\u001b[A\n",
      "  9%|▉         | 585/6672 [01:20<09:54, 10.23it/s]\u001b[A\n",
      "  9%|▉         | 587/6672 [01:20<09:16, 10.94it/s]\u001b[A\n",
      "  9%|▉         | 589/6672 [01:21<09:03, 11.19it/s]\u001b[A\n",
      "  9%|▉         | 591/6672 [01:21<08:53, 11.41it/s]\u001b[A\n",
      "  9%|▉         | 593/6672 [01:21<08:33, 11.85it/s]\u001b[A\n",
      "  9%|▉         | 595/6672 [01:21<08:04, 12.54it/s]\u001b[A\n",
      "  9%|▉         | 597/6672 [01:21<07:36, 13.30it/s]\u001b[A\n",
      "  9%|▉         | 599/6672 [01:21<07:32, 13.42it/s]\u001b[A\n",
      "  9%|▉         | 601/6672 [01:22<09:26, 10.72it/s]\u001b[A\n",
      "  9%|▉         | 603/6672 [01:22<09:47, 10.33it/s]\u001b[A\n",
      "  9%|▉         | 605/6672 [01:22<10:33,  9.58it/s]\u001b[A\n",
      "  9%|▉         | 607/6672 [01:22<11:47,  8.57it/s]\u001b[A\n",
      "  9%|▉         | 608/6672 [01:23<12:44,  7.93it/s]\u001b[A\n",
      "  9%|▉         | 609/6672 [01:23<12:46,  7.91it/s]\u001b[A\n",
      "  9%|▉         | 610/6672 [01:23<12:24,  8.14it/s]\u001b[A\n",
      "  9%|▉         | 611/6672 [01:23<11:54,  8.48it/s]\u001b[A\n",
      "  9%|▉         | 612/6672 [01:23<11:33,  8.74it/s]\u001b[A\n",
      "  9%|▉         | 614/6672 [01:23<10:41,  9.44it/s]\u001b[A\n",
      "  9%|▉         | 616/6672 [01:23<10:04, 10.02it/s]\u001b[A\n",
      "  9%|▉         | 617/6672 [01:23<10:27,  9.64it/s]\u001b[A\n",
      "  9%|▉         | 618/6672 [01:24<11:24,  8.84it/s]\u001b[A\n",
      "  9%|▉         | 619/6672 [01:24<11:11,  9.01it/s]\u001b[A\n",
      "  9%|▉         | 621/6672 [01:24<10:16,  9.81it/s]\u001b[A\n",
      "  9%|▉         | 622/6672 [01:24<10:47,  9.35it/s]\u001b[A\n",
      "  9%|▉         | 623/6672 [01:24<11:20,  8.88it/s]\u001b[A\n",
      "  9%|▉         | 625/6672 [01:24<10:37,  9.48it/s]\u001b[A\n",
      "  9%|▉         | 627/6672 [01:25<09:44, 10.35it/s]\u001b[A\n",
      "  9%|▉         | 629/6672 [01:25<08:50, 11.39it/s]\u001b[A\n",
      "  9%|▉         | 631/6672 [01:25<08:43, 11.54it/s]\u001b[A\n",
      "  9%|▉         | 633/6672 [01:25<08:37, 11.67it/s]\u001b[A\n",
      " 10%|▉         | 635/6672 [01:25<08:47, 11.44it/s]\u001b[A\n",
      " 10%|▉         | 637/6672 [01:25<09:58, 10.08it/s]\u001b[A\n",
      " 10%|▉         | 639/6672 [01:26<11:04,  9.07it/s]\u001b[A\n",
      " 10%|▉         | 640/6672 [01:26<11:30,  8.74it/s]\u001b[A\n",
      " 10%|▉         | 642/6672 [01:26<10:28,  9.59it/s]\u001b[A\n",
      " 10%|▉         | 643/6672 [01:26<10:31,  9.55it/s]\u001b[A\n",
      " 10%|▉         | 644/6672 [01:26<11:13,  8.96it/s]\u001b[A\n",
      " 10%|▉         | 646/6672 [01:26<10:21,  9.70it/s]\u001b[A\n",
      " 10%|▉         | 648/6672 [01:27<09:32, 10.53it/s]\u001b[A\n",
      " 10%|▉         | 650/6672 [01:27<09:43, 10.32it/s]\u001b[A\n",
      " 10%|▉         | 652/6672 [01:27<09:48, 10.23it/s]\u001b[A\n",
      " 10%|▉         | 654/6672 [01:27<09:02, 11.10it/s]\u001b[A\n",
      " 10%|▉         | 656/6672 [01:27<09:11, 10.91it/s]\u001b[A\n",
      " 10%|▉         | 658/6672 [01:28<11:02,  9.08it/s]\u001b[A\n",
      " 10%|▉         | 659/6672 [01:28<11:29,  8.72it/s]\u001b[A\n",
      " 10%|▉         | 660/6672 [01:28<11:25,  8.77it/s]\u001b[A\n",
      " 10%|▉         | 661/6672 [01:28<11:57,  8.38it/s]\u001b[A\n",
      " 10%|▉         | 662/6672 [01:28<12:19,  8.12it/s]\u001b[A\n",
      " 10%|▉         | 663/6672 [01:28<11:59,  8.35it/s]\u001b[A\n",
      " 10%|▉         | 665/6672 [01:28<10:43,  9.34it/s]\u001b[A\n",
      " 10%|▉         | 667/6672 [01:29<09:59, 10.01it/s]\u001b[A\n",
      " 10%|█         | 669/6672 [01:29<09:35, 10.43it/s]\u001b[A\n",
      " 10%|█         | 671/6672 [01:29<09:44, 10.26it/s]\u001b[A\n",
      " 10%|█         | 673/6672 [01:29<11:26,  8.73it/s]\u001b[A\n",
      " 10%|█         | 674/6672 [01:29<12:00,  8.33it/s]\u001b[A\n",
      " 10%|█         | 675/6672 [01:30<12:14,  8.17it/s]\u001b[A\n",
      " 10%|█         | 676/6672 [01:30<12:47,  7.81it/s]\u001b[A\n",
      " 10%|█         | 677/6672 [01:30<12:15,  8.15it/s]\u001b[A\n",
      " 10%|█         | 679/6672 [01:30<11:01,  9.06it/s]\u001b[A\n",
      " 10%|█         | 680/6672 [01:30<12:07,  8.24it/s]\u001b[A\n",
      " 10%|█         | 681/6672 [01:30<12:41,  7.87it/s]\u001b[A\n",
      " 10%|█         | 682/6672 [01:30<12:58,  7.70it/s]\u001b[A\n",
      " 10%|█         | 683/6672 [01:31<13:24,  7.45it/s]\u001b[A\n",
      " 10%|█         | 684/6672 [01:31<13:37,  7.32it/s]\u001b[A\n",
      " 10%|█         | 685/6672 [01:31<12:45,  7.82it/s]\u001b[A\n",
      " 10%|█         | 686/6672 [01:31<12:51,  7.76it/s]\u001b[A\n",
      " 10%|█         | 687/6672 [01:31<12:08,  8.21it/s]\u001b[A\n",
      " 10%|█         | 689/6672 [01:31<10:25,  9.56it/s]\u001b[A\n",
      " 10%|█         | 690/6672 [01:31<11:04,  9.00it/s]\u001b[A\n",
      " 10%|█         | 692/6672 [01:32<09:45, 10.21it/s]\u001b[A\n",
      " 10%|█         | 694/6672 [01:32<09:14, 10.78it/s]\u001b[A\n",
      " 10%|█         | 696/6672 [01:32<10:43,  9.28it/s]\u001b[A\n",
      " 10%|█         | 698/6672 [01:32<09:47, 10.16it/s]\u001b[A\n",
      " 10%|█         | 700/6672 [01:32<09:16, 10.73it/s]\u001b[A\n",
      " 11%|█         | 702/6672 [01:32<09:08, 10.88it/s]\u001b[A\n",
      " 11%|█         | 704/6672 [01:33<09:15, 10.74it/s]\u001b[A\n",
      " 11%|█         | 706/6672 [01:33<09:15, 10.73it/s]\u001b[A\n",
      " 11%|█         | 708/6672 [01:33<10:51,  9.16it/s]\u001b[A\n",
      " 11%|█         | 709/6672 [01:33<11:07,  8.93it/s]\u001b[A\n",
      " 11%|█         | 710/6672 [01:33<11:08,  8.92it/s]\u001b[A\n",
      " 11%|█         | 711/6672 [01:33<10:55,  9.09it/s]\u001b[A\n",
      " 11%|█         | 712/6672 [01:34<10:56,  9.07it/s]\u001b[A\n",
      " 11%|█         | 713/6672 [01:34<11:03,  8.98it/s]\u001b[A\n",
      " 11%|█         | 714/6672 [01:34<11:14,  8.84it/s]\u001b[A\n",
      " 11%|█         | 715/6672 [01:34<11:41,  8.49it/s]\u001b[A\n",
      " 11%|█         | 716/6672 [01:34<11:30,  8.63it/s]\u001b[A\n",
      " 11%|█         | 717/6672 [01:34<11:06,  8.93it/s]\u001b[A\n",
      " 11%|█         | 719/6672 [01:34<10:23,  9.55it/s]\u001b[A\n",
      " 11%|█         | 721/6672 [01:35<09:51, 10.05it/s]\u001b[A\n",
      " 11%|█         | 722/6672 [01:35<10:37,  9.34it/s]\u001b[A\n",
      " 11%|█         | 723/6672 [01:35<10:35,  9.37it/s]\u001b[A\n",
      " 11%|█         | 724/6672 [01:35<10:29,  9.45it/s]\u001b[A\n",
      " 11%|█         | 726/6672 [01:35<09:15, 10.70it/s]\u001b[A\n",
      " 11%|█         | 728/6672 [01:35<08:18, 11.92it/s]\u001b[A\n",
      " 11%|█         | 730/6672 [01:35<09:11, 10.78it/s]\u001b[A\n",
      " 11%|█         | 732/6672 [01:36<08:36, 11.49it/s]\u001b[A\n",
      " 11%|█         | 734/6672 [01:36<07:55, 12.50it/s]\u001b[A\n",
      " 11%|█         | 736/6672 [01:36<07:57, 12.42it/s]\u001b[A\n",
      " 11%|█         | 738/6672 [01:36<08:21, 11.83it/s]\u001b[A\n",
      " 11%|█         | 740/6672 [01:36<08:44, 11.32it/s]\u001b[A\n",
      " 11%|█         | 742/6672 [01:36<08:34, 11.52it/s]\u001b[A\n",
      " 11%|█         | 744/6672 [01:37<10:00,  9.88it/s]\u001b[A\n",
      " 11%|█         | 746/6672 [01:37<09:11, 10.75it/s]\u001b[A\n",
      " 11%|█         | 748/6672 [01:37<09:39, 10.23it/s]\u001b[A\n",
      " 11%|█         | 750/6672 [01:37<09:43, 10.15it/s]\u001b[A\n",
      " 11%|█▏        | 752/6672 [01:37<10:05,  9.78it/s]\u001b[A\n",
      " 11%|█▏        | 754/6672 [01:38<10:27,  9.42it/s]\u001b[A\n",
      " 11%|█▏        | 756/6672 [01:38<10:12,  9.66it/s]\u001b[A\n",
      " 11%|█▏        | 757/6672 [01:38<11:28,  8.59it/s]\u001b[A\n",
      " 11%|█▏        | 758/6672 [01:38<11:52,  8.30it/s]\u001b[A\n",
      " 11%|█▏        | 759/6672 [01:38<12:37,  7.81it/s]\u001b[A\n",
      " 11%|█▏        | 760/6672 [01:39<14:02,  7.02it/s]\u001b[A\n",
      " 11%|█▏        | 761/6672 [01:39<13:34,  7.26it/s]\u001b[A\n",
      " 11%|█▏        | 762/6672 [01:39<12:40,  7.77it/s]\u001b[A\n",
      " 11%|█▏        | 763/6672 [01:39<12:49,  7.68it/s]\u001b[A\n",
      " 11%|█▏        | 764/6672 [01:39<13:24,  7.34it/s]\u001b[A\n",
      " 11%|█▏        | 765/6672 [01:39<13:41,  7.19it/s]\u001b[A\n",
      " 11%|█▏        | 766/6672 [01:39<13:58,  7.05it/s]\u001b[A\n",
      " 11%|█▏        | 767/6672 [01:39<12:57,  7.59it/s]\u001b[A\n",
      " 12%|█▏        | 768/6672 [01:40<12:53,  7.63it/s]\u001b[A\n",
      " 12%|█▏        | 769/6672 [01:40<12:19,  7.98it/s]\u001b[A\n",
      " 12%|█▏        | 771/6672 [01:40<11:10,  8.81it/s]\u001b[A\n",
      " 12%|█▏        | 772/6672 [01:40<12:07,  8.11it/s]\u001b[A\n",
      " 12%|█▏        | 773/6672 [01:40<12:40,  7.75it/s]\u001b[A\n",
      " 12%|█▏        | 774/6672 [01:40<13:02,  7.53it/s]\u001b[A\n",
      " 12%|█▏        | 775/6672 [01:40<12:16,  8.01it/s]\u001b[A\n",
      " 12%|█▏        | 777/6672 [01:41<11:26,  8.59it/s]\u001b[A\n",
      " 12%|█▏        | 778/6672 [01:41<11:28,  8.57it/s]\u001b[A\n",
      " 12%|█▏        | 779/6672 [01:41<11:26,  8.58it/s]\u001b[A\n",
      " 12%|█▏        | 781/6672 [01:41<10:18,  9.53it/s]\u001b[A\n",
      " 12%|█▏        | 783/6672 [01:41<09:43, 10.10it/s]\u001b[A\n",
      " 12%|█▏        | 784/6672 [01:41<10:32,  9.30it/s]\u001b[A\n",
      " 12%|█▏        | 785/6672 [01:41<10:27,  9.38it/s]\u001b[A\n",
      " 12%|█▏        | 787/6672 [01:42<09:30, 10.31it/s]\u001b[A\n",
      " 12%|█▏        | 789/6672 [01:42<10:49,  9.05it/s]\u001b[A\n",
      " 12%|█▏        | 790/6672 [01:42<10:44,  9.12it/s]\u001b[A\n",
      " 12%|█▏        | 792/6672 [01:42<09:58,  9.82it/s]\u001b[A\n",
      " 12%|█▏        | 794/6672 [01:42<09:33, 10.24it/s]\u001b[A\n",
      " 12%|█▏        | 796/6672 [01:43<09:03, 10.81it/s]\u001b[A\n",
      " 12%|█▏        | 798/6672 [01:43<08:44, 11.20it/s]\u001b[A\n",
      " 12%|█▏        | 800/6672 [01:43<08:54, 10.98it/s]\u001b[A\n",
      " 12%|█▏        | 802/6672 [01:43<08:41, 11.26it/s]\u001b[A\n",
      " 12%|█▏        | 804/6672 [01:43<08:44, 11.18it/s]\u001b[A\n",
      " 12%|█▏        | 806/6672 [01:43<08:28, 11.54it/s]\u001b[A\n",
      " 12%|█▏        | 808/6672 [01:44<10:22,  9.41it/s]\u001b[A\n",
      " 12%|█▏        | 810/6672 [01:44<10:58,  8.90it/s]\u001b[A\n",
      " 12%|█▏        | 811/6672 [01:44<11:34,  8.44it/s]\u001b[A\n",
      " 12%|█▏        | 812/6672 [01:44<12:09,  8.03it/s]\u001b[A\n",
      " 12%|█▏        | 813/6672 [01:44<11:41,  8.35it/s]\u001b[A\n",
      " 12%|█▏        | 815/6672 [01:45<10:19,  9.46it/s]\u001b[A\n",
      " 12%|█▏        | 816/6672 [01:45<10:13,  9.55it/s]\u001b[A\n",
      " 12%|█▏        | 817/6672 [01:45<10:09,  9.61it/s]\u001b[A\n",
      " 12%|█▏        | 819/6672 [01:45<09:29, 10.28it/s]\u001b[A\n",
      " 12%|█▏        | 821/6672 [01:45<09:11, 10.62it/s]\u001b[A\n",
      " 12%|█▏        | 823/6672 [01:45<08:51, 11.01it/s]\u001b[A\n",
      " 12%|█▏        | 825/6672 [01:45<08:46, 11.12it/s]\u001b[A\n",
      " 12%|█▏        | 827/6672 [01:46<09:32, 10.21it/s]\u001b[A\n",
      " 12%|█▏        | 829/6672 [01:46<09:07, 10.68it/s]\u001b[A\n",
      " 12%|█▏        | 831/6672 [01:46<09:26, 10.32it/s]\u001b[A\n",
      " 12%|█▏        | 833/6672 [01:46<09:20, 10.41it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 72.66it/s]\n",
      "                                                  \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23252610862255096, 'eval_f1': 0.7463616392111891, 'eval_recall': 0.8052770073252258, 'eval_precision': 0.7118881118881119, 'eval_runtime': 4.7381, 'eval_samples_per_second': 268.04, 'eval_steps_per_second': 67.116, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-834/special_tokens_map.json\n",
      "\n",
      " 13%|█▎        | 835/6672 [01:54<2:07:46,  1.31s/it]\u001b[A\n",
      " 13%|█▎        | 836/6672 [01:55<1:47:14,  1.10s/it]\u001b[A\n",
      " 13%|█▎        | 837/6672 [01:55<1:28:37,  1.10it/s]\u001b[A\n",
      " 13%|█▎        | 838/6672 [01:55<1:12:04,  1.35it/s]\u001b[A\n",
      " 13%|█▎        | 839/6672 [01:55<57:04,  1.70it/s]  \u001b[A\n",
      " 13%|█▎        | 840/6672 [01:55<45:26,  2.14it/s]\u001b[A\n",
      " 13%|█▎        | 842/6672 [01:55<30:06,  3.23it/s]\u001b[A\n",
      " 13%|█▎        | 843/6672 [01:55<25:29,  3.81it/s]\u001b[A\n",
      " 13%|█▎        | 845/6672 [01:56<19:22,  5.01it/s]\u001b[A\n",
      " 13%|█▎        | 846/6672 [01:56<17:26,  5.57it/s]\u001b[A\n",
      " 13%|█▎        | 848/6672 [01:56<15:10,  6.40it/s]\u001b[A\n",
      " 13%|█▎        | 849/6672 [01:56<14:41,  6.61it/s]\u001b[A\n",
      " 13%|█▎        | 851/6672 [01:56<13:14,  7.32it/s]\u001b[A\n",
      " 13%|█▎        | 853/6672 [01:56<11:39,  8.32it/s]\u001b[A\n",
      " 13%|█▎        | 855/6672 [01:57<09:58,  9.72it/s]\u001b[A\n",
      " 13%|█▎        | 857/6672 [01:57<08:54, 10.89it/s]\u001b[A\n",
      " 13%|█▎        | 859/6672 [01:57<08:42, 11.12it/s]\u001b[A\n",
      " 13%|█▎        | 861/6672 [01:57<09:08, 10.59it/s]\u001b[A\n",
      " 13%|█▎        | 863/6672 [01:57<09:49,  9.86it/s]\u001b[A\n",
      " 13%|█▎        | 865/6672 [01:58<09:16, 10.44it/s]\u001b[A\n",
      " 13%|█▎        | 867/6672 [01:58<10:00,  9.67it/s]\u001b[A\n",
      " 13%|█▎        | 869/6672 [01:58<09:03, 10.67it/s]\u001b[A\n",
      " 13%|█▎        | 871/6672 [01:58<08:05, 11.96it/s]\u001b[A\n",
      " 13%|█▎        | 873/6672 [01:58<07:26, 13.00it/s]\u001b[A\n",
      " 13%|█▎        | 875/6672 [01:58<08:01, 12.03it/s]\u001b[A\n",
      " 13%|█▎        | 877/6672 [01:59<07:58, 12.12it/s]\u001b[A\n",
      " 13%|█▎        | 879/6672 [01:59<08:00, 12.05it/s]\u001b[A\n",
      " 13%|█▎        | 881/6672 [01:59<08:50, 10.92it/s]\u001b[A\n",
      " 13%|█▎        | 883/6672 [01:59<09:02, 10.67it/s]\u001b[A\n",
      " 13%|█▎        | 885/6672 [01:59<10:15,  9.41it/s]\u001b[A\n",
      " 13%|█▎        | 886/6672 [02:00<10:47,  8.93it/s]\u001b[A\n",
      " 13%|█▎        | 887/6672 [02:00<11:42,  8.24it/s]\u001b[A\n",
      " 13%|█▎        | 888/6672 [02:00<12:24,  7.77it/s]\u001b[A\n",
      " 13%|█▎        | 889/6672 [02:00<12:52,  7.48it/s]\u001b[A\n",
      " 13%|█▎        | 890/6672 [02:00<12:16,  7.85it/s]\u001b[A\n",
      " 13%|█▎        | 892/6672 [02:00<10:52,  8.86it/s]\u001b[A\n",
      " 13%|█▎        | 893/6672 [02:00<11:15,  8.56it/s]\u001b[A\n",
      " 13%|█▎        | 894/6672 [02:01<10:51,  8.87it/s]\u001b[A\n",
      " 13%|█▎        | 896/6672 [02:01<09:47,  9.84it/s]\u001b[A\n",
      " 13%|█▎        | 897/6672 [02:01<10:17,  9.35it/s]\u001b[A\n",
      " 13%|█▎        | 898/6672 [02:01<10:12,  9.43it/s]\u001b[A\n",
      " 13%|█▎        | 900/6672 [02:01<08:58, 10.71it/s]\u001b[A\n",
      " 14%|█▎        | 902/6672 [02:01<08:30, 11.31it/s]\u001b[A\n",
      " 14%|█▎        | 904/6672 [02:01<08:21, 11.50it/s]\u001b[A\n",
      " 14%|█▎        | 906/6672 [02:02<08:54, 10.79it/s]\u001b[A\n",
      " 14%|█▎        | 908/6672 [02:02<08:58, 10.70it/s]\u001b[A\n",
      " 14%|█▎        | 910/6672 [02:02<09:14, 10.39it/s]\u001b[A\n",
      " 14%|█▎        | 912/6672 [02:02<09:16, 10.35it/s]\u001b[A\n",
      " 14%|█▎        | 914/6672 [02:02<09:00, 10.65it/s]\u001b[A\n",
      " 14%|█▎        | 916/6672 [02:03<09:21, 10.24it/s]\u001b[A\n",
      " 14%|█▍        | 918/6672 [02:03<09:42,  9.87it/s]\u001b[A\n",
      " 14%|█▍        | 919/6672 [02:03<10:22,  9.24it/s]\u001b[A\n",
      " 14%|█▍        | 920/6672 [02:03<10:15,  9.34it/s]\u001b[A\n",
      " 14%|█▍        | 921/6672 [02:03<10:30,  9.13it/s]\u001b[A\n",
      " 14%|█▍        | 922/6672 [02:03<11:23,  8.41it/s]\u001b[A\n",
      " 14%|█▍        | 923/6672 [02:03<11:10,  8.57it/s]\u001b[A\n",
      " 14%|█▍        | 925/6672 [02:04<09:48,  9.76it/s]\u001b[A\n",
      " 14%|█▍        | 927/6672 [02:04<09:13, 10.38it/s]\u001b[A\n",
      " 14%|█▍        | 929/6672 [02:04<08:43, 10.96it/s]\u001b[A\n",
      " 14%|█▍        | 931/6672 [02:04<08:50, 10.82it/s]\u001b[A\n",
      " 14%|█▍        | 933/6672 [02:04<09:39,  9.90it/s]\u001b[A\n",
      " 14%|█▍        | 935/6672 [02:05<10:32,  9.07it/s]\u001b[A\n",
      " 14%|█▍        | 936/6672 [02:05<11:00,  8.68it/s]\u001b[A\n",
      " 14%|█▍        | 937/6672 [02:05<11:12,  8.53it/s]\u001b[A\n",
      " 14%|█▍        | 938/6672 [02:05<11:07,  8.59it/s]\u001b[A\n",
      " 14%|█▍        | 939/6672 [02:05<11:07,  8.59it/s]\u001b[A\n",
      " 14%|█▍        | 940/6672 [02:05<10:47,  8.85it/s]\u001b[A\n",
      " 14%|█▍        | 941/6672 [02:05<10:47,  8.85it/s]\u001b[A\n",
      " 14%|█▍        | 942/6672 [02:05<10:47,  8.85it/s]\u001b[A\n",
      " 14%|█▍        | 943/6672 [02:06<11:23,  8.38it/s]\u001b[A\n",
      " 14%|█▍        | 944/6672 [02:06<11:00,  8.68it/s]\u001b[A\n",
      " 14%|█▍        | 945/6672 [02:06<11:33,  8.26it/s]\u001b[A\n",
      " 14%|█▍        | 946/6672 [02:06<11:18,  8.43it/s]\u001b[A\n",
      " 14%|█▍        | 947/6672 [02:06<11:37,  8.21it/s]\u001b[A\n",
      " 14%|█▍        | 948/6672 [02:06<11:37,  8.21it/s]\u001b[A\n",
      " 14%|█▍        | 949/6672 [02:06<11:40,  8.17it/s]\u001b[A\n",
      " 14%|█▍        | 950/6672 [02:06<11:21,  8.39it/s]\u001b[A\n",
      " 14%|█▍        | 951/6672 [02:07<11:05,  8.60it/s]\u001b[A\n",
      " 14%|█▍        | 953/6672 [02:07<10:47,  8.83it/s]\u001b[A\n",
      " 14%|█▍        | 954/6672 [02:07<10:36,  8.99it/s]\u001b[A\n",
      " 14%|█▍        | 955/6672 [02:07<10:29,  9.08it/s]\u001b[A\n",
      " 14%|█▍        | 957/6672 [02:07<09:38,  9.87it/s]\u001b[A\n",
      " 14%|█▍        | 959/6672 [02:07<08:50, 10.77it/s]\u001b[A\n",
      " 14%|█▍        | 961/6672 [02:07<09:07, 10.42it/s]\u001b[A\n",
      " 14%|█▍        | 963/6672 [02:08<09:41,  9.81it/s]\u001b[A\n",
      " 14%|█▍        | 965/6672 [02:08<09:16, 10.26it/s]\u001b[A\n",
      " 14%|█▍        | 967/6672 [02:08<08:52, 10.72it/s]\u001b[A\n",
      " 15%|█▍        | 969/6672 [02:08<09:32,  9.96it/s]\u001b[A\n",
      " 15%|█▍        | 971/6672 [02:09<09:38,  9.86it/s]\u001b[A\n",
      " 15%|█▍        | 972/6672 [02:09<10:04,  9.43it/s]\u001b[A\n",
      " 15%|█▍        | 973/6672 [02:09<10:44,  8.85it/s]\u001b[A\n",
      " 15%|█▍        | 975/6672 [02:09<09:30,  9.99it/s]\u001b[A\n",
      " 15%|█▍        | 977/6672 [02:09<08:25, 11.27it/s]\u001b[A\n",
      " 15%|█▍        | 979/6672 [02:09<09:08, 10.38it/s]\u001b[A\n",
      " 15%|█▍        | 981/6672 [02:09<08:50, 10.73it/s]\u001b[A\n",
      " 15%|█▍        | 983/6672 [02:10<08:43, 10.87it/s]\u001b[A\n",
      " 15%|█▍        | 985/6672 [02:10<09:57,  9.53it/s]\u001b[A\n",
      " 15%|█▍        | 986/6672 [02:10<10:33,  8.98it/s]\u001b[A\n",
      " 15%|█▍        | 987/6672 [02:10<10:52,  8.71it/s]\u001b[A\n",
      " 15%|█▍        | 988/6672 [02:10<10:47,  8.77it/s]\u001b[A\n",
      " 15%|█▍        | 989/6672 [02:10<10:59,  8.61it/s]\u001b[A\n",
      " 15%|█▍        | 990/6672 [02:11<11:00,  8.60it/s]\u001b[A\n",
      " 15%|█▍        | 991/6672 [02:11<10:44,  8.81it/s]\u001b[A\n",
      " 15%|█▍        | 992/6672 [02:11<10:50,  8.74it/s]\u001b[A\n",
      " 15%|█▍        | 993/6672 [02:11<11:25,  8.28it/s]\u001b[A\n",
      " 15%|█▍        | 994/6672 [02:11<12:21,  7.65it/s]\u001b[A\n",
      " 15%|█▍        | 995/6672 [02:11<11:52,  7.96it/s]\u001b[A\n",
      " 15%|█▍        | 997/6672 [02:11<10:09,  9.32it/s]\u001b[A\n",
      " 15%|█▍        | 998/6672 [02:11<10:18,  9.18it/s]\u001b[A\n",
      " 15%|█▍        | 1000/6672 [02:12<13:02,  7.25it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 15%|█▍        | 1000/6672 [02:12<13:02,  7.25it/s]\u001b[A\n",
      " 15%|█▌        | 1001/6672 [02:12<13:06,  7.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1092, 'learning_rate': 5.942489165672483e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 1003/6672 [02:12<10:48,  8.74it/s]\u001b[A\n",
      " 15%|█▌        | 1005/6672 [02:12<09:28,  9.98it/s]\u001b[A\n",
      " 15%|█▌        | 1007/6672 [02:12<09:15, 10.20it/s]\u001b[A\n",
      " 15%|█▌        | 1009/6672 [02:13<09:06, 10.35it/s]\u001b[A\n",
      " 15%|█▌        | 1011/6672 [02:13<09:37,  9.81it/s]\u001b[A\n",
      " 15%|█▌        | 1013/6672 [02:13<09:05, 10.37it/s]\u001b[A\n",
      " 15%|█▌        | 1015/6672 [02:13<08:44, 10.79it/s]\u001b[A\n",
      " 15%|█▌        | 1017/6672 [02:13<07:59, 11.80it/s]\u001b[A\n",
      " 15%|█▌        | 1019/6672 [02:14<08:42, 10.82it/s]\u001b[A\n",
      " 15%|█▌        | 1021/6672 [02:14<09:12, 10.22it/s]\u001b[A\n",
      " 15%|█▌        | 1023/6672 [02:14<08:53, 10.58it/s]\u001b[A\n",
      " 15%|█▌        | 1025/6672 [02:14<09:56,  9.47it/s]\u001b[A\n",
      " 15%|█▌        | 1026/6672 [02:14<10:43,  8.77it/s]\u001b[A\n",
      " 15%|█▌        | 1027/6672 [02:14<11:10,  8.42it/s]\u001b[A\n",
      " 15%|█▌        | 1029/6672 [02:15<09:56,  9.46it/s]\u001b[A\n",
      " 15%|█▌        | 1031/6672 [02:15<08:57, 10.50it/s]\u001b[A\n",
      " 15%|█▌        | 1033/6672 [02:15<08:37, 10.89it/s]\u001b[A\n",
      " 16%|█▌        | 1035/6672 [02:15<11:08,  8.43it/s]\u001b[A\n",
      " 16%|█▌        | 1036/6672 [02:16<12:27,  7.54it/s]\u001b[A\n",
      " 16%|█▌        | 1037/6672 [02:16<13:30,  6.95it/s]\u001b[A\n",
      " 16%|█▌        | 1038/6672 [02:16<13:48,  6.80it/s]\u001b[A\n",
      " 16%|█▌        | 1039/6672 [02:16<13:21,  7.03it/s]\u001b[A\n",
      " 16%|█▌        | 1040/6672 [02:16<12:51,  7.30it/s]\u001b[A\n",
      " 16%|█▌        | 1042/6672 [02:16<11:09,  8.41it/s]\u001b[A\n",
      " 16%|█▌        | 1044/6672 [02:16<10:18,  9.10it/s]\u001b[A\n",
      " 16%|█▌        | 1046/6672 [02:17<09:43,  9.64it/s]\u001b[A\n",
      " 16%|█▌        | 1047/6672 [02:17<10:05,  9.30it/s]\u001b[A\n",
      " 16%|█▌        | 1048/6672 [02:17<10:02,  9.33it/s]\u001b[A\n",
      " 16%|█▌        | 1050/6672 [02:17<09:01, 10.38it/s]\u001b[A\n",
      " 16%|█▌        | 1052/6672 [02:17<10:14,  9.15it/s]\u001b[A\n",
      " 16%|█▌        | 1053/6672 [02:17<10:04,  9.29it/s]\u001b[A\n",
      " 16%|█▌        | 1054/6672 [02:18<10:25,  8.99it/s]\u001b[A\n",
      " 16%|█▌        | 1055/6672 [02:18<10:55,  8.57it/s]\u001b[A\n",
      " 16%|█▌        | 1056/6672 [02:18<10:50,  8.63it/s]\u001b[A\n",
      " 16%|█▌        | 1058/6672 [02:18<09:30,  9.85it/s]\u001b[A\n",
      " 16%|█▌        | 1060/6672 [02:18<08:54, 10.51it/s]\u001b[A\n",
      " 16%|█▌        | 1062/6672 [02:18<08:40, 10.78it/s]\u001b[A\n",
      " 16%|█▌        | 1064/6672 [02:18<07:49, 11.94it/s]\u001b[A\n",
      " 16%|█▌        | 1066/6672 [02:19<07:38, 12.22it/s]\u001b[A\n",
      " 16%|█▌        | 1068/6672 [02:19<07:23, 12.63it/s]\u001b[A\n",
      " 16%|█▌        | 1070/6672 [02:19<07:24, 12.60it/s]\u001b[A\n",
      " 16%|█▌        | 1072/6672 [02:19<07:29, 12.46it/s]\u001b[A\n",
      " 16%|█▌        | 1074/6672 [02:19<07:47, 11.96it/s]\u001b[A\n",
      " 16%|█▌        | 1076/6672 [02:19<08:21, 11.15it/s]\u001b[A\n",
      " 16%|█▌        | 1078/6672 [02:20<09:08, 10.19it/s]\u001b[A\n",
      " 16%|█▌        | 1080/6672 [02:20<10:08,  9.20it/s]\u001b[A\n",
      " 16%|█▌        | 1081/6672 [02:20<10:37,  8.77it/s]\u001b[A\n",
      " 16%|█▌        | 1082/6672 [02:20<11:06,  8.38it/s]\u001b[A\n",
      " 16%|█▌        | 1084/6672 [02:20<10:09,  9.17it/s]\u001b[A\n",
      " 16%|█▋        | 1085/6672 [02:21<11:54,  7.82it/s]\u001b[A\n",
      " 16%|█▋        | 1086/6672 [02:21<12:05,  7.70it/s]\u001b[A\n",
      " 16%|█▋        | 1087/6672 [02:21<11:56,  7.80it/s]\u001b[A\n",
      " 16%|█▋        | 1088/6672 [02:21<12:06,  7.69it/s]\u001b[A\n",
      " 16%|█▋        | 1089/6672 [02:21<12:28,  7.46it/s]\u001b[A\n",
      " 16%|█▋        | 1090/6672 [02:21<11:45,  7.91it/s]\u001b[A\n",
      " 16%|█▋        | 1091/6672 [02:21<12:01,  7.74it/s]\u001b[A\n",
      " 16%|█▋        | 1092/6672 [02:22<11:56,  7.79it/s]\u001b[A\n",
      " 16%|█▋        | 1093/6672 [02:22<11:54,  7.81it/s]\u001b[A\n",
      " 16%|█▋        | 1094/6672 [02:22<11:40,  7.96it/s]\u001b[A\n",
      " 16%|█▋        | 1096/6672 [02:22<09:39,  9.62it/s]\u001b[A\n",
      " 16%|█▋        | 1098/6672 [02:22<08:50, 10.51it/s]\u001b[A\n",
      " 16%|█▋        | 1100/6672 [02:22<08:31, 10.89it/s]\u001b[A\n",
      " 17%|█▋        | 1102/6672 [02:22<08:11, 11.33it/s]\u001b[A\n",
      " 17%|█▋        | 1104/6672 [02:23<07:53, 11.76it/s]\u001b[A\n",
      " 17%|█▋        | 1106/6672 [02:23<07:48, 11.89it/s]\u001b[A\n",
      " 17%|█▋        | 1108/6672 [02:23<07:34, 12.25it/s]\u001b[A\n",
      " 17%|█▋        | 1110/6672 [02:23<08:33, 10.83it/s]\u001b[A\n",
      " 17%|█▋        | 1112/6672 [02:23<09:24,  9.85it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 74.71it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1112\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34790492057800293, 'eval_f1': 0.7367086840771051, 'eval_recall': 0.7278959138357475, 'eval_precision': 0.7464957264957265, 'eval_runtime': 4.3176, 'eval_samples_per_second': 294.148, 'eval_steps_per_second': 73.653, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1112/special_tokens_map.json\n",
      "\n",
      " 17%|█▋        | 1114/6672 [02:31<1:59:17,  1.29s/it]\u001b[A\n",
      " 17%|█▋        | 1115/6672 [02:32<1:40:45,  1.09s/it]\u001b[A\n",
      " 17%|█▋        | 1116/6672 [02:32<1:23:17,  1.11it/s]\u001b[A\n",
      " 17%|█▋        | 1117/6672 [02:32<1:06:54,  1.38it/s]\u001b[A\n",
      " 17%|█▋        | 1118/6672 [02:32<52:55,  1.75it/s]  \u001b[A\n",
      " 17%|█▋        | 1120/6672 [02:32<34:47,  2.66it/s]\u001b[A\n",
      " 17%|█▋        | 1121/6672 [02:32<29:46,  3.11it/s]\u001b[A\n",
      " 17%|█▋        | 1122/6672 [02:32<24:53,  3.72it/s]\u001b[A\n",
      " 17%|█▋        | 1124/6672 [02:33<18:05,  5.11it/s]\u001b[A\n",
      " 17%|█▋        | 1126/6672 [02:33<14:16,  6.47it/s]\u001b[A\n",
      " 17%|█▋        | 1128/6672 [02:33<11:58,  7.71it/s]\u001b[A\n",
      " 17%|█▋        | 1130/6672 [02:33<10:42,  8.63it/s]\u001b[A\n",
      " 17%|█▋        | 1132/6672 [02:33<10:31,  8.78it/s]\u001b[A\n",
      " 17%|█▋        | 1134/6672 [02:33<10:07,  9.12it/s]\u001b[A\n",
      " 17%|█▋        | 1136/6672 [02:34<09:34,  9.64it/s]\u001b[A\n",
      " 17%|█▋        | 1138/6672 [02:34<09:15,  9.96it/s]\u001b[A\n",
      " 17%|█▋        | 1140/6672 [02:34<08:34, 10.76it/s]\u001b[A\n",
      " 17%|█▋        | 1142/6672 [02:34<08:13, 11.21it/s]\u001b[A\n",
      " 17%|█▋        | 1144/6672 [02:34<08:02, 11.45it/s]\u001b[A\n",
      " 17%|█▋        | 1146/6672 [02:34<07:59, 11.53it/s]\u001b[A\n",
      " 17%|█▋        | 1148/6672 [02:35<07:33, 12.18it/s]\u001b[A\n",
      " 17%|█▋        | 1150/6672 [02:35<08:30, 10.82it/s]\u001b[A\n",
      " 17%|█▋        | 1152/6672 [02:35<08:40, 10.60it/s]\u001b[A\n",
      " 17%|█▋        | 1154/6672 [02:35<08:26, 10.89it/s]\u001b[A\n",
      " 17%|█▋        | 1156/6672 [02:35<08:36, 10.68it/s]\u001b[A\n",
      " 17%|█▋        | 1158/6672 [02:36<08:39, 10.62it/s]\u001b[A\n",
      " 17%|█▋        | 1160/6672 [02:36<09:45,  9.41it/s]\u001b[A\n",
      " 17%|█▋        | 1161/6672 [02:36<09:48,  9.37it/s]\u001b[A\n",
      " 17%|█▋        | 1163/6672 [02:36<10:08,  9.06it/s]\u001b[A\n",
      " 17%|█▋        | 1164/6672 [02:36<10:52,  8.44it/s]\u001b[A\n",
      " 17%|█▋        | 1165/6672 [02:37<10:56,  8.39it/s]\u001b[A\n",
      " 17%|█▋        | 1166/6672 [02:37<10:43,  8.56it/s]\u001b[A\n",
      " 17%|█▋        | 1167/6672 [02:37<11:19,  8.10it/s]\u001b[A\n",
      " 18%|█▊        | 1168/6672 [02:37<10:55,  8.40it/s]\u001b[A\n",
      " 18%|█▊        | 1170/6672 [02:37<09:48,  9.34it/s]\u001b[A\n",
      " 18%|█▊        | 1172/6672 [02:37<09:18,  9.85it/s]\u001b[A\n",
      " 18%|█▊        | 1174/6672 [02:37<09:17,  9.87it/s]\u001b[A\n",
      " 18%|█▊        | 1175/6672 [02:38<09:27,  9.69it/s]\u001b[A\n",
      " 18%|█▊        | 1176/6672 [02:38<09:41,  9.46it/s]\u001b[A\n",
      " 18%|█▊        | 1177/6672 [02:38<10:11,  8.99it/s]\u001b[A\n",
      " 18%|█▊        | 1178/6672 [02:38<10:55,  8.39it/s]\u001b[A\n",
      " 18%|█▊        | 1179/6672 [02:38<11:27,  7.98it/s]\u001b[A\n",
      " 18%|█▊        | 1180/6672 [02:38<11:19,  8.08it/s]\u001b[A\n",
      " 18%|█▊        | 1182/6672 [02:38<09:42,  9.42it/s]\u001b[A\n",
      " 18%|█▊        | 1183/6672 [02:38<10:18,  8.88it/s]\u001b[A\n",
      " 18%|█▊        | 1184/6672 [02:39<10:56,  8.36it/s]\u001b[A\n",
      " 18%|█▊        | 1185/6672 [02:39<11:03,  8.27it/s]\u001b[A\n",
      " 18%|█▊        | 1186/6672 [02:39<11:16,  8.11it/s]\u001b[A\n",
      " 18%|█▊        | 1187/6672 [02:39<10:49,  8.44it/s]\u001b[A\n",
      " 18%|█▊        | 1189/6672 [02:39<09:30,  9.61it/s]\u001b[A\n",
      " 18%|█▊        | 1191/6672 [02:39<09:41,  9.42it/s]\u001b[A\n",
      " 18%|█▊        | 1192/6672 [02:40<10:22,  8.80it/s]\u001b[A\n",
      " 18%|█▊        | 1193/6672 [02:40<10:51,  8.41it/s]\u001b[A\n",
      " 18%|█▊        | 1194/6672 [02:40<11:18,  8.08it/s]\u001b[A\n",
      " 18%|█▊        | 1196/6672 [02:40<09:55,  9.19it/s]\u001b[A\n",
      " 18%|█▊        | 1198/6672 [02:40<09:05, 10.04it/s]\u001b[A\n",
      " 18%|█▊        | 1200/6672 [02:40<08:52, 10.27it/s]\u001b[A\n",
      " 18%|█▊        | 1202/6672 [02:40<08:13, 11.09it/s]\u001b[A\n",
      " 18%|█▊        | 1204/6672 [02:41<08:32, 10.66it/s]\u001b[A\n",
      " 18%|█▊        | 1206/6672 [02:41<09:36,  9.48it/s]\u001b[A\n",
      " 18%|█▊        | 1207/6672 [02:41<09:48,  9.29it/s]\u001b[A\n",
      " 18%|█▊        | 1208/6672 [02:41<10:36,  8.59it/s]\u001b[A\n",
      " 18%|█▊        | 1210/6672 [02:41<09:30,  9.58it/s]\u001b[A\n",
      " 18%|█▊        | 1212/6672 [02:42<08:45, 10.39it/s]\u001b[A\n",
      " 18%|█▊        | 1214/6672 [02:42<11:06,  8.19it/s]\u001b[A\n",
      " 18%|█▊        | 1215/6672 [02:42<11:02,  8.24it/s]\u001b[A\n",
      " 18%|█▊        | 1216/6672 [02:42<10:48,  8.41it/s]\u001b[A\n",
      " 18%|█▊        | 1217/6672 [02:42<11:31,  7.89it/s]\u001b[A\n",
      " 18%|█▊        | 1218/6672 [02:42<11:25,  7.96it/s]\u001b[A\n",
      " 18%|█▊        | 1219/6672 [02:43<12:04,  7.52it/s]\u001b[A\n",
      " 18%|█▊        | 1220/6672 [02:43<11:21,  8.00it/s]\u001b[A\n",
      " 18%|█▊        | 1221/6672 [02:43<11:20,  8.01it/s]\u001b[A\n",
      " 18%|█▊        | 1223/6672 [02:43<09:47,  9.27it/s]\u001b[A\n",
      " 18%|█▊        | 1225/6672 [02:43<09:04, 10.00it/s]\u001b[A\n",
      " 18%|█▊        | 1227/6672 [02:43<08:33, 10.61it/s]\u001b[A\n",
      " 18%|█▊        | 1229/6672 [02:43<08:21, 10.86it/s]\u001b[A\n",
      " 18%|█▊        | 1231/6672 [02:44<08:33, 10.59it/s]\u001b[A\n",
      " 18%|█▊        | 1233/6672 [02:44<08:36, 10.53it/s]\u001b[A\n",
      " 19%|█▊        | 1235/6672 [02:44<08:22, 10.82it/s]\u001b[A\n",
      " 19%|█▊        | 1237/6672 [02:44<08:05, 11.20it/s]\u001b[A\n",
      " 19%|█▊        | 1239/6672 [02:44<08:02, 11.27it/s]\u001b[A\n",
      " 19%|█▊        | 1241/6672 [02:45<07:48, 11.58it/s]\u001b[A\n",
      " 19%|█▊        | 1243/6672 [02:45<07:44, 11.69it/s]\u001b[A\n",
      " 19%|█▊        | 1245/6672 [02:45<07:44, 11.68it/s]\u001b[A\n",
      " 19%|█▊        | 1247/6672 [02:45<08:16, 10.92it/s]\u001b[A\n",
      " 19%|█▊        | 1249/6672 [02:45<08:10, 11.05it/s]\u001b[A\n",
      " 19%|█▉        | 1251/6672 [02:46<09:14,  9.77it/s]\u001b[A\n",
      " 19%|█▉        | 1253/6672 [02:46<08:06, 11.14it/s]\u001b[A\n",
      " 19%|█▉        | 1255/6672 [02:46<07:21, 12.28it/s]\u001b[A\n",
      " 19%|█▉        | 1257/6672 [02:46<06:47, 13.28it/s]\u001b[A\n",
      " 19%|█▉        | 1259/6672 [02:46<06:40, 13.52it/s]\u001b[A\n",
      " 19%|█▉        | 1261/6672 [02:46<06:54, 13.05it/s]\u001b[A\n",
      " 19%|█▉        | 1263/6672 [02:46<08:34, 10.52it/s]\u001b[A\n",
      " 19%|█▉        | 1265/6672 [02:47<09:47,  9.20it/s]\u001b[A\n",
      " 19%|█▉        | 1267/6672 [02:47<10:23,  8.67it/s]\u001b[A\n",
      " 19%|█▉        | 1268/6672 [02:47<10:14,  8.80it/s]\u001b[A\n",
      " 19%|█▉        | 1270/6672 [02:47<09:36,  9.37it/s]\u001b[A\n",
      " 19%|█▉        | 1271/6672 [02:47<10:06,  8.91it/s]\u001b[A\n",
      " 19%|█▉        | 1272/6672 [02:48<10:12,  8.82it/s]\u001b[A\n",
      " 19%|█▉        | 1274/6672 [02:48<09:17,  9.69it/s]\u001b[A\n",
      " 19%|█▉        | 1276/6672 [02:48<08:34, 10.50it/s]\u001b[A\n",
      " 19%|█▉        | 1278/6672 [02:48<08:46, 10.25it/s]\u001b[A\n",
      " 19%|█▉        | 1280/6672 [02:48<08:40, 10.35it/s]\u001b[A\n",
      " 19%|█▉        | 1282/6672 [02:48<08:24, 10.68it/s]\u001b[A\n",
      " 19%|█▉        | 1284/6672 [02:49<08:17, 10.83it/s]\u001b[A\n",
      " 19%|█▉        | 1286/6672 [02:49<08:39, 10.36it/s]\u001b[A\n",
      " 19%|█▉        | 1288/6672 [02:49<08:59,  9.97it/s]\u001b[A\n",
      " 19%|█▉        | 1290/6672 [02:49<08:34, 10.45it/s]\u001b[A\n",
      " 19%|█▉        | 1292/6672 [02:49<09:23,  9.54it/s]\u001b[A\n",
      " 19%|█▉        | 1294/6672 [02:50<09:28,  9.47it/s]\u001b[A\n",
      " 19%|█▉        | 1295/6672 [02:50<10:03,  8.91it/s]\u001b[A\n",
      " 19%|█▉        | 1297/6672 [02:50<09:06,  9.83it/s]\u001b[A\n",
      " 19%|█▉        | 1299/6672 [02:50<09:09,  9.77it/s]\u001b[A\n",
      " 19%|█▉        | 1300/6672 [02:50<09:26,  9.48it/s]\u001b[A\n",
      " 20%|█▉        | 1302/6672 [02:50<08:43, 10.26it/s]\u001b[A\n",
      " 20%|█▉        | 1304/6672 [02:51<08:10, 10.94it/s]\u001b[A\n",
      " 20%|█▉        | 1306/6672 [02:51<07:44, 11.55it/s]\u001b[A\n",
      " 20%|█▉        | 1308/6672 [02:51<07:42, 11.60it/s]\u001b[A\n",
      " 20%|█▉        | 1310/6672 [02:51<07:55, 11.27it/s]\u001b[A\n",
      " 20%|█▉        | 1312/6672 [02:51<07:59, 11.19it/s]\u001b[A\n",
      " 20%|█▉        | 1314/6672 [02:52<09:56,  8.99it/s]\u001b[A\n",
      " 20%|█▉        | 1315/6672 [02:52<10:52,  8.21it/s]\u001b[A\n",
      " 20%|█▉        | 1316/6672 [02:52<11:35,  7.70it/s]\u001b[A\n",
      " 20%|█▉        | 1317/6672 [02:52<12:00,  7.43it/s]\u001b[A\n",
      " 20%|█▉        | 1318/6672 [02:52<12:29,  7.14it/s]\u001b[A\n",
      " 20%|█▉        | 1319/6672 [02:52<13:05,  6.81it/s]\u001b[A\n",
      " 20%|█▉        | 1320/6672 [02:53<13:03,  6.83it/s]\u001b[A\n",
      " 20%|█▉        | 1321/6672 [02:53<12:59,  6.87it/s]\u001b[A\n",
      " 20%|█▉        | 1322/6672 [02:53<12:04,  7.38it/s]\u001b[A\n",
      " 20%|█▉        | 1323/6672 [02:53<11:14,  7.93it/s]\u001b[A\n",
      " 20%|█▉        | 1324/6672 [02:53<11:02,  8.08it/s]\u001b[A\n",
      " 20%|█▉        | 1326/6672 [02:53<09:20,  9.53it/s]\u001b[A\n",
      " 20%|█▉        | 1327/6672 [02:53<10:17,  8.66it/s]\u001b[A\n",
      " 20%|█▉        | 1329/6672 [02:54<09:21,  9.51it/s]\u001b[A\n",
      " 20%|█▉        | 1331/6672 [02:54<08:40, 10.26it/s]\u001b[A\n",
      " 20%|█▉        | 1333/6672 [02:54<08:02, 11.07it/s]\u001b[A\n",
      " 20%|██        | 1335/6672 [02:54<08:07, 10.95it/s]\u001b[A\n",
      " 20%|██        | 1337/6672 [02:54<08:30, 10.45it/s]\u001b[A\n",
      " 20%|██        | 1339/6672 [02:54<08:03, 11.03it/s]\u001b[A\n",
      " 20%|██        | 1341/6672 [02:55<07:42, 11.53it/s]\u001b[A\n",
      " 20%|██        | 1343/6672 [02:55<07:37, 11.65it/s]\u001b[A\n",
      " 20%|██        | 1345/6672 [02:55<07:47, 11.40it/s]\u001b[A\n",
      " 20%|██        | 1347/6672 [02:55<08:18, 10.68it/s]\u001b[A\n",
      " 20%|██        | 1349/6672 [02:55<08:14, 10.77it/s]\u001b[A\n",
      " 20%|██        | 1351/6672 [02:56<07:56, 11.16it/s]\u001b[A\n",
      " 20%|██        | 1353/6672 [02:56<07:47, 11.37it/s]\u001b[A\n",
      " 20%|██        | 1355/6672 [02:56<07:50, 11.30it/s]\u001b[A\n",
      " 20%|██        | 1357/6672 [02:56<08:02, 11.01it/s]\u001b[A\n",
      " 20%|██        | 1359/6672 [02:56<07:46, 11.40it/s]\u001b[A\n",
      " 20%|██        | 1361/6672 [02:56<08:21, 10.60it/s]\u001b[A\n",
      " 20%|██        | 1363/6672 [02:57<10:15,  8.63it/s]\u001b[A\n",
      " 20%|██        | 1364/6672 [02:57<10:39,  8.30it/s]\u001b[A\n",
      " 20%|██        | 1365/6672 [02:57<10:35,  8.35it/s]\u001b[A\n",
      " 20%|██        | 1366/6672 [02:57<10:32,  8.39it/s]\u001b[A\n",
      " 20%|██        | 1367/6672 [02:57<10:56,  8.09it/s]\u001b[A\n",
      " 21%|██        | 1369/6672 [02:57<09:33,  9.24it/s]\u001b[A\n",
      " 21%|██        | 1370/6672 [02:58<09:41,  9.12it/s]\u001b[A\n",
      " 21%|██        | 1371/6672 [02:58<10:16,  8.60it/s]\u001b[A\n",
      " 21%|██        | 1372/6672 [02:58<10:43,  8.24it/s]\u001b[A\n",
      " 21%|██        | 1373/6672 [02:58<11:08,  7.92it/s]\u001b[A\n",
      " 21%|██        | 1375/6672 [02:58<10:19,  8.56it/s]\u001b[A\n",
      " 21%|██        | 1377/6672 [02:58<09:20,  9.45it/s]\u001b[A\n",
      " 21%|██        | 1379/6672 [02:59<08:47, 10.04it/s]\u001b[A\n",
      " 21%|██        | 1381/6672 [02:59<08:05, 10.89it/s]\u001b[A\n",
      " 21%|██        | 1383/6672 [02:59<07:55, 11.12it/s]\u001b[A\n",
      " 21%|██        | 1385/6672 [02:59<08:04, 10.91it/s]\u001b[A\n",
      " 21%|██        | 1387/6672 [02:59<08:01, 10.98it/s]\u001b[A\n",
      " 21%|██        | 1389/6672 [02:59<08:11, 10.75it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|█████████▉| 317/318 [00:03<00:00, 80.08it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1390\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1390/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3672434091567993, 'eval_f1': 0.7077942778573982, 'eval_recall': 0.6525179969814064, 'eval_precision': 0.8742244454785171, 'eval_runtime': 4.026, 'eval_samples_per_second': 315.449, 'eval_steps_per_second': 78.986, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1390/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1390/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1390/special_tokens_map.json\n",
      "\n",
      " 21%|██        | 1391/6672 [03:07<1:51:31,  1.27s/it]\u001b[A\n",
      " 21%|██        | 1392/6672 [03:07<1:33:59,  1.07s/it]\u001b[A\n",
      " 21%|██        | 1393/6672 [03:08<1:17:01,  1.14it/s]\u001b[A\n",
      " 21%|██        | 1394/6672 [03:08<1:02:10,  1.41it/s]\u001b[A\n",
      " 21%|██        | 1395/6672 [03:08<49:11,  1.79it/s]  \u001b[A\n",
      " 21%|██        | 1396/6672 [03:08<39:04,  2.25it/s]\u001b[A\n",
      " 21%|██        | 1397/6672 [03:08<31:01,  2.83it/s]\u001b[A\n",
      " 21%|██        | 1399/6672 [03:08<21:23,  4.11it/s]\u001b[A\n",
      " 21%|██        | 1400/6672 [03:08<18:26,  4.77it/s]\u001b[A\n",
      " 21%|██        | 1402/6672 [03:09<14:10,  6.19it/s]\u001b[A\n",
      " 21%|██        | 1404/6672 [03:09<11:41,  7.51it/s]\u001b[A\n",
      " 21%|██        | 1406/6672 [03:09<09:58,  8.80it/s]\u001b[A\n",
      " 21%|██        | 1408/6672 [03:09<08:50,  9.93it/s]\u001b[A\n",
      " 21%|██        | 1410/6672 [03:09<08:01, 10.93it/s]\u001b[A\n",
      " 21%|██        | 1412/6672 [03:09<08:27, 10.37it/s]\u001b[A\n",
      " 21%|██        | 1414/6672 [03:10<08:06, 10.81it/s]\u001b[A\n",
      " 21%|██        | 1416/6672 [03:10<07:45, 11.28it/s]\u001b[A\n",
      " 21%|██▏       | 1418/6672 [03:10<07:24, 11.81it/s]\u001b[A\n",
      " 21%|██▏       | 1420/6672 [03:10<07:35, 11.52it/s]\u001b[A\n",
      " 21%|██▏       | 1422/6672 [03:10<07:35, 11.53it/s]\u001b[A\n",
      " 21%|██▏       | 1424/6672 [03:10<07:26, 11.76it/s]\u001b[A\n",
      " 21%|██▏       | 1426/6672 [03:11<07:43, 11.33it/s]\u001b[A\n",
      " 21%|██▏       | 1428/6672 [03:11<07:42, 11.34it/s]\u001b[A\n",
      " 21%|██▏       | 1430/6672 [03:11<07:54, 11.04it/s]\u001b[A\n",
      " 21%|██▏       | 1432/6672 [03:11<07:51, 11.10it/s]\u001b[A\n",
      " 21%|██▏       | 1434/6672 [03:11<07:27, 11.70it/s]\u001b[A\n",
      " 22%|██▏       | 1436/6672 [03:11<07:10, 12.16it/s]\u001b[A\n",
      " 22%|██▏       | 1438/6672 [03:12<07:18, 11.94it/s]\u001b[A\n",
      " 22%|██▏       | 1440/6672 [03:12<07:26, 11.71it/s]\u001b[A\n",
      " 22%|██▏       | 1442/6672 [03:12<08:56,  9.75it/s]\u001b[A\n",
      " 22%|██▏       | 1444/6672 [03:12<09:11,  9.47it/s]\u001b[A\n",
      " 22%|██▏       | 1445/6672 [03:12<09:08,  9.54it/s]\u001b[A\n",
      " 22%|██▏       | 1446/6672 [03:12<09:03,  9.62it/s]\u001b[A\n",
      " 22%|██▏       | 1447/6672 [03:13<09:11,  9.48it/s]\u001b[A\n",
      " 22%|██▏       | 1449/6672 [03:13<08:54,  9.77it/s]\u001b[A\n",
      " 22%|██▏       | 1451/6672 [03:13<08:18, 10.46it/s]\u001b[A\n",
      " 22%|██▏       | 1453/6672 [03:13<08:53,  9.78it/s]\u001b[A\n",
      " 22%|██▏       | 1455/6672 [03:13<08:19, 10.45it/s]\u001b[A\n",
      " 22%|██▏       | 1457/6672 [03:14<08:49,  9.86it/s]\u001b[A\n",
      " 22%|██▏       | 1459/6672 [03:14<09:09,  9.48it/s]\u001b[A\n",
      " 22%|██▏       | 1460/6672 [03:14<09:54,  8.77it/s]\u001b[A\n",
      " 22%|██▏       | 1462/6672 [03:14<09:14,  9.39it/s]\u001b[A\n",
      " 22%|██▏       | 1464/6672 [03:14<08:19, 10.42it/s]\u001b[A\n",
      " 22%|██▏       | 1466/6672 [03:14<07:55, 10.94it/s]\u001b[A\n",
      " 22%|██▏       | 1468/6672 [03:15<07:31, 11.54it/s]\u001b[A\n",
      " 22%|██▏       | 1470/6672 [03:15<07:13, 12.00it/s]\u001b[A\n",
      " 22%|██▏       | 1472/6672 [03:15<07:06, 12.20it/s]\u001b[A\n",
      " 22%|██▏       | 1474/6672 [03:15<06:51, 12.63it/s]\u001b[A\n",
      " 22%|██▏       | 1476/6672 [03:15<06:28, 13.39it/s]\u001b[A\n",
      " 22%|██▏       | 1478/6672 [03:15<06:59, 12.38it/s]\u001b[A\n",
      " 22%|██▏       | 1480/6672 [03:16<07:16, 11.89it/s]\u001b[A\n",
      " 22%|██▏       | 1482/6672 [03:16<06:57, 12.43it/s]\u001b[A\n",
      " 22%|██▏       | 1484/6672 [03:16<07:42, 11.21it/s]\u001b[A\n",
      " 22%|██▏       | 1486/6672 [03:16<07:15, 11.91it/s]\u001b[A\n",
      " 22%|██▏       | 1488/6672 [03:16<07:04, 12.23it/s]\u001b[A\n",
      " 22%|██▏       | 1490/6672 [03:16<07:08, 12.11it/s]\u001b[A\n",
      " 22%|██▏       | 1492/6672 [03:17<09:55,  8.70it/s]\u001b[A\n",
      " 22%|██▏       | 1494/6672 [03:17<10:12,  8.45it/s]\u001b[A\n",
      " 22%|██▏       | 1495/6672 [03:17<10:17,  8.38it/s]\u001b[A\n",
      " 22%|██▏       | 1496/6672 [03:17<10:50,  7.96it/s]\u001b[A\n",
      " 22%|██▏       | 1497/6672 [03:17<11:09,  7.73it/s]\u001b[A\n",
      " 22%|██▏       | 1499/6672 [03:18<09:58,  8.65it/s]\u001b[A\n",
      " 22%|██▏       | 1500/6672 [03:18<13:09,  6.55it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 22%|██▏       | 1500/6672 [03:18<13:09,  6.55it/s]\u001b[A\n",
      " 22%|██▏       | 1501/6672 [03:18<13:22,  6.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0903, 'learning_rate': 5.4186449162302674e-05, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 1503/6672 [03:18<10:50,  7.94it/s]\u001b[A\n",
      " 23%|██▎       | 1505/6672 [03:18<09:33,  9.01it/s]\u001b[A\n",
      " 23%|██▎       | 1507/6672 [03:19<09:00,  9.56it/s]\u001b[A\n",
      " 23%|██▎       | 1509/6672 [03:19<08:32, 10.08it/s]\u001b[A\n",
      " 23%|██▎       | 1511/6672 [03:19<09:11,  9.36it/s]\u001b[A\n",
      " 23%|██▎       | 1512/6672 [03:19<09:56,  8.65it/s]\u001b[A\n",
      " 23%|██▎       | 1513/6672 [03:19<09:55,  8.66it/s]\u001b[A\n",
      " 23%|██▎       | 1515/6672 [03:19<09:00,  9.54it/s]\u001b[A\n",
      " 23%|██▎       | 1517/6672 [03:20<08:19, 10.32it/s]\u001b[A\n",
      " 23%|██▎       | 1519/6672 [03:20<07:51, 10.93it/s]\u001b[A\n",
      " 23%|██▎       | 1521/6672 [03:20<07:30, 11.43it/s]\u001b[A\n",
      " 23%|██▎       | 1523/6672 [03:20<08:02, 10.67it/s]\u001b[A\n",
      " 23%|██▎       | 1525/6672 [03:20<08:23, 10.22it/s]\u001b[A\n",
      " 23%|██▎       | 1527/6672 [03:21<08:28, 10.12it/s]\u001b[A\n",
      " 23%|██▎       | 1529/6672 [03:21<08:03, 10.63it/s]\u001b[A\n",
      " 23%|██▎       | 1531/6672 [03:21<07:34, 11.30it/s]\u001b[A\n",
      " 23%|██▎       | 1533/6672 [03:21<07:19, 11.69it/s]\u001b[A\n",
      " 23%|██▎       | 1535/6672 [03:21<07:46, 11.02it/s]\u001b[A\n",
      " 23%|██▎       | 1537/6672 [03:21<07:28, 11.45it/s]\u001b[A\n",
      " 23%|██▎       | 1539/6672 [03:22<08:10, 10.47it/s]\u001b[A\n",
      " 23%|██▎       | 1541/6672 [03:22<09:28,  9.03it/s]\u001b[A\n",
      " 23%|██▎       | 1542/6672 [03:22<09:58,  8.57it/s]\u001b[A\n",
      " 23%|██▎       | 1543/6672 [03:22<10:04,  8.49it/s]\u001b[A\n",
      " 23%|██▎       | 1544/6672 [03:22<09:57,  8.59it/s]\u001b[A\n",
      " 23%|██▎       | 1545/6672 [03:22<10:26,  8.19it/s]\u001b[A\n",
      " 23%|██▎       | 1546/6672 [03:23<10:57,  7.80it/s]\u001b[A\n",
      " 23%|██▎       | 1547/6672 [03:23<11:19,  7.54it/s]\u001b[A\n",
      " 23%|██▎       | 1548/6672 [03:23<10:39,  8.01it/s]\u001b[A\n",
      " 23%|██▎       | 1549/6672 [03:23<10:16,  8.31it/s]\u001b[A\n",
      " 23%|██▎       | 1551/6672 [03:23<08:58,  9.51it/s]\u001b[A\n",
      " 23%|██▎       | 1553/6672 [03:23<08:15, 10.33it/s]\u001b[A\n",
      " 23%|██▎       | 1555/6672 [03:23<08:03, 10.59it/s]\u001b[A\n",
      " 23%|██▎       | 1557/6672 [03:24<07:51, 10.85it/s]\u001b[A\n",
      " 23%|██▎       | 1559/6672 [03:24<09:00,  9.46it/s]\u001b[A\n",
      " 23%|██▎       | 1560/6672 [03:24<09:07,  9.34it/s]\u001b[A\n",
      " 23%|██▎       | 1562/6672 [03:24<09:22,  9.08it/s]\u001b[A\n",
      " 23%|██▎       | 1564/6672 [03:24<08:38,  9.86it/s]\u001b[A\n",
      " 23%|██▎       | 1566/6672 [03:25<09:47,  8.69it/s]\u001b[A\n",
      " 23%|██▎       | 1567/6672 [03:25<09:49,  8.65it/s]\u001b[A\n",
      " 24%|██▎       | 1569/6672 [03:25<09:01,  9.42it/s]\u001b[A\n",
      " 24%|██▎       | 1571/6672 [03:25<08:22, 10.16it/s]\u001b[A\n",
      " 24%|██▎       | 1573/6672 [03:25<08:34,  9.91it/s]\u001b[A\n",
      " 24%|██▎       | 1575/6672 [03:26<08:27, 10.05it/s]\u001b[A\n",
      " 24%|██▎       | 1577/6672 [03:26<08:29, 10.00it/s]\u001b[A\n",
      " 24%|██▎       | 1579/6672 [03:26<08:12, 10.34it/s]\u001b[A\n",
      " 24%|██▎       | 1581/6672 [03:26<08:04, 10.50it/s]\u001b[A\n",
      " 24%|██▎       | 1583/6672 [03:26<08:12, 10.33it/s]\u001b[A\n",
      " 24%|██▍       | 1585/6672 [03:27<09:12,  9.21it/s]\u001b[A\n",
      " 24%|██▍       | 1586/6672 [03:27<09:10,  9.23it/s]\u001b[A\n",
      " 24%|██▍       | 1588/6672 [03:27<08:33,  9.89it/s]\u001b[A\n",
      " 24%|██▍       | 1590/6672 [03:27<09:25,  8.99it/s]\u001b[A\n",
      " 24%|██▍       | 1591/6672 [03:27<10:54,  7.77it/s]\u001b[A\n",
      " 24%|██▍       | 1592/6672 [03:28<11:11,  7.56it/s]\u001b[A\n",
      " 24%|██▍       | 1593/6672 [03:28<11:47,  7.18it/s]\u001b[A\n",
      " 24%|██▍       | 1594/6672 [03:28<11:29,  7.36it/s]\u001b[A\n",
      " 24%|██▍       | 1595/6672 [03:28<11:50,  7.15it/s]\u001b[A\n",
      " 24%|██▍       | 1596/6672 [03:28<11:34,  7.31it/s]\u001b[A\n",
      " 24%|██▍       | 1597/6672 [03:28<11:08,  7.59it/s]\u001b[A\n",
      " 24%|██▍       | 1599/6672 [03:28<09:49,  8.60it/s]\u001b[A\n",
      " 24%|██▍       | 1601/6672 [03:29<08:53,  9.50it/s]\u001b[A\n",
      " 24%|██▍       | 1603/6672 [03:29<08:16, 10.20it/s]\u001b[A\n",
      " 24%|██▍       | 1605/6672 [03:29<08:05, 10.44it/s]\u001b[A\n",
      " 24%|██▍       | 1607/6672 [03:29<08:06, 10.41it/s]\u001b[A\n",
      " 24%|██▍       | 1609/6672 [03:29<07:54, 10.67it/s]\u001b[A\n",
      " 24%|██▍       | 1611/6672 [03:29<07:36, 11.10it/s]\u001b[A\n",
      " 24%|██▍       | 1613/6672 [03:30<07:57, 10.59it/s]\u001b[A\n",
      " 24%|██▍       | 1615/6672 [03:30<07:41, 10.95it/s]\u001b[A\n",
      " 24%|██▍       | 1617/6672 [03:30<08:01, 10.51it/s]\u001b[A\n",
      " 24%|██▍       | 1619/6672 [03:30<07:42, 10.93it/s]\u001b[A\n",
      " 24%|██▍       | 1621/6672 [03:30<07:36, 11.06it/s]\u001b[A\n",
      " 24%|██▍       | 1623/6672 [03:31<07:46, 10.82it/s]\u001b[A\n",
      " 24%|██▍       | 1625/6672 [03:31<07:50, 10.72it/s]\u001b[A\n",
      " 24%|██▍       | 1627/6672 [03:31<07:40, 10.95it/s]\u001b[A\n",
      " 24%|██▍       | 1629/6672 [03:31<07:21, 11.43it/s]\u001b[A\n",
      " 24%|██▍       | 1631/6672 [03:31<07:10, 11.71it/s]\u001b[A\n",
      " 24%|██▍       | 1633/6672 [03:32<08:05, 10.38it/s]\u001b[A\n",
      " 25%|██▍       | 1635/6672 [03:32<07:40, 10.94it/s]\u001b[A\n",
      " 25%|██▍       | 1637/6672 [03:32<07:28, 11.22it/s]\u001b[A\n",
      " 25%|██▍       | 1639/6672 [03:32<07:49, 10.71it/s]\u001b[A\n",
      " 25%|██▍       | 1641/6672 [03:32<09:17,  9.02it/s]\u001b[A\n",
      " 25%|██▍       | 1642/6672 [03:32<09:25,  8.90it/s]\u001b[A\n",
      " 25%|██▍       | 1643/6672 [03:33<09:13,  9.08it/s]\u001b[A\n",
      " 25%|██▍       | 1645/6672 [03:33<08:43,  9.60it/s]\u001b[A\n",
      " 25%|██▍       | 1646/6672 [03:33<08:46,  9.54it/s]\u001b[A\n",
      " 25%|██▍       | 1648/6672 [03:33<08:11, 10.22it/s]\u001b[A\n",
      " 25%|██▍       | 1650/6672 [03:33<08:13, 10.19it/s]\u001b[A\n",
      " 25%|██▍       | 1652/6672 [03:33<08:32,  9.80it/s]\u001b[A\n",
      " 25%|██▍       | 1653/6672 [03:34<08:42,  9.60it/s]\u001b[A\n",
      " 25%|██▍       | 1655/6672 [03:34<08:17, 10.09it/s]\u001b[A\n",
      " 25%|██▍       | 1657/6672 [03:34<07:55, 10.54it/s]\u001b[A\n",
      " 25%|██▍       | 1659/6672 [03:34<07:43, 10.82it/s]\u001b[A\n",
      " 25%|██▍       | 1661/6672 [03:34<07:34, 11.02it/s]\u001b[A\n",
      " 25%|██▍       | 1663/6672 [03:34<06:41, 12.46it/s]\u001b[A\n",
      " 25%|██▍       | 1665/6672 [03:35<06:37, 12.58it/s]\u001b[A\n",
      " 25%|██▍       | 1667/6672 [03:35<06:00, 13.89it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 77.06it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1668\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3000377416610718, 'eval_f1': 0.7785067918255253, 'eval_recall': 0.7498399829315127, 'eval_precision': 0.8173632859551916, 'eval_runtime': 4.3589, 'eval_samples_per_second': 291.355, 'eval_steps_per_second': 72.953, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1668/special_tokens_map.json\n",
      "\n",
      " 25%|██▌       | 1669/6672 [03:43<1:51:59,  1.34s/it]\u001b[A\n",
      " 25%|██▌       | 1671/6672 [03:43<1:21:20,  1.02it/s]\u001b[A\n",
      " 25%|██▌       | 1672/6672 [03:44<1:08:26,  1.22it/s]\u001b[A\n",
      " 25%|██▌       | 1673/6672 [03:44<56:29,  1.48it/s]  \u001b[A\n",
      " 25%|██▌       | 1675/6672 [03:44<38:32,  2.16it/s]\u001b[A\n",
      " 25%|██▌       | 1677/6672 [03:44<27:52,  2.99it/s]\u001b[A\n",
      " 25%|██▌       | 1679/6672 [03:44<21:02,  3.96it/s]\u001b[A\n",
      " 25%|██▌       | 1681/6672 [03:44<16:36,  5.01it/s]\u001b[A\n",
      " 25%|██▌       | 1683/6672 [03:45<13:39,  6.09it/s]\u001b[A\n",
      " 25%|██▌       | 1685/6672 [03:45<12:17,  6.77it/s]\u001b[A\n",
      " 25%|██▌       | 1687/6672 [03:45<10:53,  7.62it/s]\u001b[A\n",
      " 25%|██▌       | 1689/6672 [03:45<10:33,  7.87it/s]\u001b[A\n",
      " 25%|██▌       | 1690/6672 [03:45<10:16,  8.09it/s]\u001b[A\n",
      " 25%|██▌       | 1692/6672 [03:45<09:09,  9.05it/s]\u001b[A\n",
      " 25%|██▌       | 1694/6672 [03:46<09:52,  8.41it/s]\u001b[A\n",
      " 25%|██▌       | 1695/6672 [03:46<10:03,  8.25it/s]\u001b[A\n",
      " 25%|██▌       | 1697/6672 [03:46<09:13,  8.98it/s]\u001b[A\n",
      " 25%|██▌       | 1698/6672 [03:46<09:29,  8.74it/s]\u001b[A\n",
      " 25%|██▌       | 1700/6672 [03:46<08:39,  9.58it/s]\u001b[A\n",
      " 26%|██▌       | 1702/6672 [03:46<07:41, 10.77it/s]\u001b[A\n",
      " 26%|██▌       | 1704/6672 [03:47<07:05, 11.68it/s]\u001b[A\n",
      " 26%|██▌       | 1706/6672 [03:47<06:58, 11.87it/s]\u001b[A\n",
      " 26%|██▌       | 1708/6672 [03:47<07:04, 11.70it/s]\u001b[A\n",
      " 26%|██▌       | 1710/6672 [03:47<07:28, 11.07it/s]\u001b[A\n",
      " 26%|██▌       | 1712/6672 [03:47<07:15, 11.40it/s]\u001b[A\n",
      " 26%|██▌       | 1714/6672 [03:47<07:07, 11.60it/s]\u001b[A\n",
      " 26%|██▌       | 1716/6672 [03:48<08:04, 10.23it/s]\u001b[A\n",
      " 26%|██▌       | 1718/6672 [03:48<08:03, 10.25it/s]\u001b[A\n",
      " 26%|██▌       | 1720/6672 [03:48<09:56,  8.30it/s]\u001b[A\n",
      " 26%|██▌       | 1721/6672 [03:48<09:58,  8.27it/s]\u001b[A\n",
      " 26%|██▌       | 1722/6672 [03:48<09:48,  8.41it/s]\u001b[A\n",
      " 26%|██▌       | 1724/6672 [03:49<09:06,  9.06it/s]\u001b[A\n",
      " 26%|██▌       | 1726/6672 [03:49<08:33,  9.63it/s]\u001b[A\n",
      " 26%|██▌       | 1728/6672 [03:49<08:04, 10.20it/s]\u001b[A\n",
      " 26%|██▌       | 1730/6672 [03:49<07:37, 10.80it/s]\u001b[A\n",
      " 26%|██▌       | 1732/6672 [03:49<07:44, 10.64it/s]\u001b[A\n",
      " 26%|██▌       | 1734/6672 [03:50<07:37, 10.80it/s]\u001b[A\n",
      " 26%|██▌       | 1736/6672 [03:50<08:14,  9.98it/s]\u001b[A\n",
      " 26%|██▌       | 1738/6672 [03:50<07:49, 10.50it/s]\u001b[A\n",
      " 26%|██▌       | 1740/6672 [03:50<07:42, 10.67it/s]\u001b[A\n",
      " 26%|██▌       | 1742/6672 [03:50<07:28, 10.99it/s]\u001b[A\n",
      " 26%|██▌       | 1744/6672 [03:51<07:18, 11.23it/s]\u001b[A\n",
      " 26%|██▌       | 1746/6672 [03:51<07:21, 11.16it/s]\u001b[A\n",
      " 26%|██▌       | 1748/6672 [03:51<07:26, 11.03it/s]\u001b[A\n",
      " 26%|██▌       | 1750/6672 [03:51<07:23, 11.10it/s]\u001b[A\n",
      " 26%|██▋       | 1752/6672 [03:51<07:08, 11.49it/s]\u001b[A\n",
      " 26%|██▋       | 1754/6672 [03:51<06:58, 11.74it/s]\u001b[A\n",
      " 26%|██▋       | 1756/6672 [03:52<07:08, 11.47it/s]\u001b[A\n",
      " 26%|██▋       | 1758/6672 [03:52<07:25, 11.03it/s]\u001b[A\n",
      " 26%|██▋       | 1760/6672 [03:52<07:22, 11.11it/s]\u001b[A\n",
      " 26%|██▋       | 1762/6672 [03:52<07:24, 11.04it/s]\u001b[A\n",
      " 26%|██▋       | 1764/6672 [03:52<07:51, 10.41it/s]\u001b[A\n",
      " 26%|██▋       | 1766/6672 [03:53<08:01, 10.18it/s]\u001b[A\n",
      " 26%|██▋       | 1768/6672 [03:53<08:14,  9.91it/s]\u001b[A\n",
      " 27%|██▋       | 1769/6672 [03:53<09:43,  8.40it/s]\u001b[A\n",
      " 27%|██▋       | 1770/6672 [03:53<10:51,  7.52it/s]\u001b[A\n",
      " 27%|██▋       | 1771/6672 [03:53<11:07,  7.34it/s]\u001b[A\n",
      " 27%|██▋       | 1772/6672 [03:53<11:17,  7.23it/s]\u001b[A\n",
      " 27%|██▋       | 1773/6672 [03:54<11:03,  7.38it/s]\u001b[A\n",
      " 27%|██▋       | 1774/6672 [03:54<10:18,  7.91it/s]\u001b[A\n",
      " 27%|██▋       | 1775/6672 [03:54<09:55,  8.22it/s]\u001b[A\n",
      " 27%|██▋       | 1776/6672 [03:54<09:27,  8.63it/s]\u001b[A\n",
      " 27%|██▋       | 1777/6672 [03:54<09:56,  8.21it/s]\u001b[A\n",
      " 27%|██▋       | 1779/6672 [03:54<08:38,  9.45it/s]\u001b[A\n",
      " 27%|██▋       | 1781/6672 [03:54<07:52, 10.35it/s]\u001b[A\n",
      " 27%|██▋       | 1783/6672 [03:55<08:21,  9.75it/s]\u001b[A\n",
      " 27%|██▋       | 1784/6672 [03:55<08:23,  9.71it/s]\u001b[A\n",
      " 27%|██▋       | 1786/6672 [03:55<07:44, 10.52it/s]\u001b[A\n",
      " 27%|██▋       | 1788/6672 [03:55<07:12, 11.28it/s]\u001b[A\n",
      " 27%|██▋       | 1790/6672 [03:55<06:53, 11.81it/s]\u001b[A\n",
      " 27%|██▋       | 1792/6672 [03:55<07:12, 11.28it/s]\u001b[A\n",
      " 27%|██▋       | 1794/6672 [03:55<06:39, 12.21it/s]\u001b[A\n",
      " 27%|██▋       | 1796/6672 [03:56<06:32, 12.43it/s]\u001b[A\n",
      " 27%|██▋       | 1798/6672 [03:56<06:41, 12.14it/s]\u001b[A\n",
      " 27%|██▋       | 1800/6672 [03:56<06:33, 12.37it/s]\u001b[A\n",
      " 27%|██▋       | 1802/6672 [03:56<07:01, 11.55it/s]\u001b[A\n",
      " 27%|██▋       | 1804/6672 [03:56<07:04, 11.48it/s]\u001b[A\n",
      " 27%|██▋       | 1806/6672 [03:57<08:01, 10.11it/s]\u001b[A\n",
      " 27%|██▋       | 1808/6672 [03:57<08:23,  9.65it/s]\u001b[A\n",
      " 27%|██▋       | 1810/6672 [03:57<07:40, 10.56it/s]\u001b[A\n",
      " 27%|██▋       | 1812/6672 [03:57<07:18, 11.07it/s]\u001b[A\n",
      " 27%|██▋       | 1814/6672 [03:57<07:14, 11.17it/s]\u001b[A\n",
      " 27%|██▋       | 1816/6672 [03:57<07:08, 11.34it/s]\u001b[A\n",
      " 27%|██▋       | 1818/6672 [03:58<06:56, 11.65it/s]\u001b[A\n",
      " 27%|██▋       | 1820/6672 [03:58<08:29,  9.52it/s]\u001b[A\n",
      " 27%|██▋       | 1822/6672 [03:58<08:55,  9.06it/s]\u001b[A\n",
      " 27%|██▋       | 1823/6672 [03:58<08:53,  9.09it/s]\u001b[A\n",
      " 27%|██▋       | 1824/6672 [03:58<09:01,  8.95it/s]\u001b[A\n",
      " 27%|██▋       | 1825/6672 [03:59<09:07,  8.86it/s]\u001b[A\n",
      " 27%|██▋       | 1826/6672 [03:59<09:06,  8.87it/s]\u001b[A\n",
      " 27%|██▋       | 1827/6672 [03:59<08:57,  9.01it/s]\u001b[A\n",
      " 27%|██▋       | 1829/6672 [03:59<08:12,  9.84it/s]\u001b[A\n",
      " 27%|██▋       | 1831/6672 [03:59<07:59, 10.11it/s]\u001b[A\n",
      " 27%|██▋       | 1833/6672 [03:59<08:22,  9.63it/s]\u001b[A\n",
      " 28%|██▊       | 1835/6672 [03:59<07:44, 10.40it/s]\u001b[A\n",
      " 28%|██▊       | 1837/6672 [04:00<07:33, 10.66it/s]\u001b[A\n",
      " 28%|██▊       | 1839/6672 [04:00<08:29,  9.49it/s]\u001b[A\n",
      " 28%|██▊       | 1841/6672 [04:00<07:55, 10.17it/s]\u001b[A\n",
      " 28%|██▊       | 1843/6672 [04:00<07:14, 11.11it/s]\u001b[A\n",
      " 28%|██▊       | 1845/6672 [04:00<06:57, 11.56it/s]\u001b[A\n",
      " 28%|██▊       | 1847/6672 [04:01<06:52, 11.69it/s]\u001b[A\n",
      " 28%|██▊       | 1849/6672 [04:01<06:26, 12.49it/s]\u001b[A\n",
      " 28%|██▊       | 1851/6672 [04:01<06:26, 12.46it/s]\u001b[A\n",
      " 28%|██▊       | 1853/6672 [04:01<06:19, 12.71it/s]\u001b[A\n",
      " 28%|██▊       | 1855/6672 [04:01<06:24, 12.53it/s]\u001b[A\n",
      " 28%|██▊       | 1857/6672 [04:01<07:10, 11.18it/s]\u001b[A\n",
      " 28%|██▊       | 1859/6672 [04:02<07:24, 10.83it/s]\u001b[A\n",
      " 28%|██▊       | 1861/6672 [04:02<06:48, 11.76it/s]\u001b[A\n",
      " 28%|██▊       | 1863/6672 [04:02<06:07, 13.09it/s]\u001b[A\n",
      " 28%|██▊       | 1865/6672 [04:02<06:11, 12.93it/s]\u001b[A\n",
      " 28%|██▊       | 1867/6672 [04:02<06:16, 12.75it/s]\u001b[A\n",
      " 28%|██▊       | 1869/6672 [04:02<07:05, 11.30it/s]\u001b[A\n",
      " 28%|██▊       | 1871/6672 [04:03<07:56, 10.07it/s]\u001b[A\n",
      " 28%|██▊       | 1873/6672 [04:03<08:14,  9.71it/s]\u001b[A\n",
      " 28%|██▊       | 1875/6672 [04:03<08:09,  9.80it/s]\u001b[A\n",
      " 28%|██▊       | 1877/6672 [04:03<08:44,  9.14it/s]\u001b[A\n",
      " 28%|██▊       | 1878/6672 [04:03<09:18,  8.58it/s]\u001b[A\n",
      " 28%|██▊       | 1880/6672 [04:04<08:51,  9.02it/s]\u001b[A\n",
      " 28%|██▊       | 1881/6672 [04:04<09:28,  8.43it/s]\u001b[A\n",
      " 28%|██▊       | 1883/6672 [04:04<08:38,  9.24it/s]\u001b[A\n",
      " 28%|██▊       | 1885/6672 [04:04<08:05,  9.86it/s]\u001b[A\n",
      " 28%|██▊       | 1886/6672 [04:04<08:27,  9.43it/s]\u001b[A\n",
      " 28%|██▊       | 1888/6672 [04:04<08:06,  9.84it/s]\u001b[A\n",
      " 28%|██▊       | 1889/6672 [04:05<08:10,  9.76it/s]\u001b[A\n",
      " 28%|██▊       | 1890/6672 [04:05<08:09,  9.76it/s]\u001b[A\n",
      " 28%|██▊       | 1891/6672 [04:05<08:29,  9.38it/s]\u001b[A\n",
      " 28%|██▊       | 1893/6672 [04:05<07:48, 10.20it/s]\u001b[A\n",
      " 28%|██▊       | 1895/6672 [04:05<07:26, 10.71it/s]\u001b[A\n",
      " 28%|██▊       | 1897/6672 [04:05<07:05, 11.23it/s]\u001b[A\n",
      " 28%|██▊       | 1899/6672 [04:06<07:15, 10.97it/s]\u001b[A\n",
      " 28%|██▊       | 1901/6672 [04:06<07:32, 10.55it/s]\u001b[A\n",
      " 29%|██▊       | 1903/6672 [04:06<07:18, 10.87it/s]\u001b[A\n",
      " 29%|██▊       | 1905/6672 [04:06<07:05, 11.20it/s]\u001b[A\n",
      " 29%|██▊       | 1907/6672 [04:06<07:24, 10.73it/s]\u001b[A\n",
      " 29%|██▊       | 1909/6672 [04:06<07:12, 11.00it/s]\u001b[A\n",
      " 29%|██▊       | 1911/6672 [04:07<07:12, 11.00it/s]\u001b[A\n",
      " 29%|██▊       | 1913/6672 [04:07<07:06, 11.16it/s]\u001b[A\n",
      " 29%|██▊       | 1915/6672 [04:07<06:55, 11.44it/s]\u001b[A\n",
      " 29%|██▊       | 1917/6672 [04:07<06:48, 11.64it/s]\u001b[A\n",
      " 29%|██▉       | 1919/6672 [04:07<07:17, 10.87it/s]\u001b[A\n",
      " 29%|██▉       | 1921/6672 [04:08<08:01,  9.87it/s]\u001b[A\n",
      " 29%|██▉       | 1923/6672 [04:08<07:48, 10.14it/s]\u001b[A\n",
      " 29%|██▉       | 1925/6672 [04:08<07:30, 10.53it/s]\u001b[A\n",
      " 29%|██▉       | 1927/6672 [04:08<08:03,  9.81it/s]\u001b[A\n",
      " 29%|██▉       | 1929/6672 [04:08<07:47, 10.14it/s]\u001b[A\n",
      " 29%|██▉       | 1931/6672 [04:08<07:18, 10.82it/s]\u001b[A\n",
      " 29%|██▉       | 1933/6672 [04:09<07:45, 10.17it/s]\u001b[A\n",
      " 29%|██▉       | 1935/6672 [04:09<07:47, 10.12it/s]\u001b[A\n",
      " 29%|██▉       | 1937/6672 [04:09<07:22, 10.69it/s]\u001b[A\n",
      " 29%|██▉       | 1939/6672 [04:09<07:29, 10.53it/s]\u001b[A\n",
      " 29%|██▉       | 1941/6672 [04:10<08:08,  9.69it/s]\u001b[A\n",
      " 29%|██▉       | 1942/6672 [04:10<08:13,  9.59it/s]\u001b[A\n",
      " 29%|██▉       | 1943/6672 [04:10<08:09,  9.65it/s]\u001b[A\n",
      " 29%|██▉       | 1945/6672 [04:10<07:56,  9.93it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 72.42it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1946\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1946/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.288420706987381, 'eval_f1': 0.7804962359809495, 'eval_recall': 0.8495760535444769, 'eval_precision': 0.7401642770668997, 'eval_runtime': 4.304, 'eval_samples_per_second': 295.077, 'eval_steps_per_second': 73.885, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-1946/special_tokens_map.json\n",
      "\n",
      " 29%|██▉       | 1947/6672 [04:18<1:54:14,  1.45s/it]\u001b[A\n",
      " 29%|██▉       | 1948/6672 [04:18<1:33:57,  1.19s/it]\u001b[A\n",
      " 29%|██▉       | 1949/6672 [04:18<1:16:24,  1.03it/s]\u001b[A\n",
      " 29%|██▉       | 1950/6672 [04:18<1:01:01,  1.29it/s]\u001b[A\n",
      " 29%|██▉       | 1951/6672 [04:19<47:46,  1.65it/s]  \u001b[A\n",
      " 29%|██▉       | 1952/6672 [04:19<37:20,  2.11it/s]\u001b[A\n",
      " 29%|██▉       | 1953/6672 [04:19<29:33,  2.66it/s]\u001b[A\n",
      " 29%|██▉       | 1954/6672 [04:19<24:28,  3.21it/s]\u001b[A\n",
      " 29%|██▉       | 1955/6672 [04:19<19:47,  3.97it/s]\u001b[A\n",
      " 29%|██▉       | 1956/6672 [04:19<17:33,  4.48it/s]\u001b[A\n",
      " 29%|██▉       | 1957/6672 [04:19<15:08,  5.19it/s]\u001b[A\n",
      " 29%|██▉       | 1958/6672 [04:19<14:00,  5.61it/s]\u001b[A\n",
      " 29%|██▉       | 1960/6672 [04:20<10:40,  7.36it/s]\u001b[A\n",
      " 29%|██▉       | 1962/6672 [04:20<09:14,  8.49it/s]\u001b[A\n",
      " 29%|██▉       | 1964/6672 [04:20<08:24,  9.34it/s]\u001b[A\n",
      " 29%|██▉       | 1966/6672 [04:20<07:51,  9.98it/s]\u001b[A\n",
      " 29%|██▉       | 1968/6672 [04:20<07:52,  9.96it/s]\u001b[A\n",
      " 30%|██▉       | 1970/6672 [04:21<08:12,  9.55it/s]\u001b[A\n",
      " 30%|██▉       | 1972/6672 [04:21<07:43, 10.13it/s]\u001b[A\n",
      " 30%|██▉       | 1974/6672 [04:21<08:36,  9.10it/s]\u001b[A\n",
      " 30%|██▉       | 1975/6672 [04:21<08:34,  9.13it/s]\u001b[A\n",
      " 30%|██▉       | 1977/6672 [04:21<07:53,  9.91it/s]\u001b[A\n",
      " 30%|██▉       | 1979/6672 [04:22<07:53,  9.91it/s]\u001b[A\n",
      " 30%|██▉       | 1981/6672 [04:22<08:20,  9.37it/s]\u001b[A\n",
      " 30%|██▉       | 1983/6672 [04:22<07:48, 10.01it/s]\u001b[A\n",
      " 30%|██▉       | 1985/6672 [04:22<07:22, 10.60it/s]\u001b[A\n",
      " 30%|██▉       | 1987/6672 [04:22<08:08,  9.58it/s]\u001b[A\n",
      " 30%|██▉       | 1989/6672 [04:23<07:46, 10.04it/s]\u001b[A\n",
      " 30%|██▉       | 1991/6672 [04:23<08:00,  9.74it/s]\u001b[A\n",
      " 30%|██▉       | 1992/6672 [04:23<08:29,  9.18it/s]\u001b[A\n",
      " 30%|██▉       | 1993/6672 [04:23<08:30,  9.17it/s]\u001b[A\n",
      " 30%|██▉       | 1995/6672 [04:23<07:45, 10.06it/s]\u001b[A\n",
      " 30%|██▉       | 1997/6672 [04:23<08:15,  9.43it/s]\u001b[A\n",
      " 30%|██▉       | 1998/6672 [04:24<09:05,  8.57it/s]\u001b[A\n",
      " 30%|██▉       | 1999/6672 [04:24<09:11,  8.47it/s]\u001b[A\n",
      " 30%|██▉       | 2000/6672 [04:24<12:27,  6.25it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 30%|██▉       | 2000/6672 [04:24<12:27,  6.25it/s]\u001b[A\n",
      " 30%|██▉       | 2001/6672 [04:24<12:46,  6.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0577, 'learning_rate': 4.894800666788053e-05, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 2002/6672 [04:24<11:46,  6.61it/s]\u001b[A\n",
      " 30%|███       | 2003/6672 [04:24<10:44,  7.24it/s]\u001b[A\n",
      " 30%|███       | 2005/6672 [04:25<09:08,  8.51it/s]\u001b[A\n",
      " 30%|███       | 2007/6672 [04:25<08:10,  9.50it/s]\u001b[A\n",
      " 30%|███       | 2008/6672 [04:25<08:13,  9.45it/s]\u001b[A\n",
      " 30%|███       | 2010/6672 [04:25<07:34, 10.27it/s]\u001b[A\n",
      " 30%|███       | 2012/6672 [04:25<07:14, 10.72it/s]\u001b[A\n",
      " 30%|███       | 2014/6672 [04:25<07:31, 10.31it/s]\u001b[A\n",
      " 30%|███       | 2016/6672 [04:26<07:12, 10.77it/s]\u001b[A\n",
      " 30%|███       | 2018/6672 [04:26<06:58, 11.12it/s]\u001b[A\n",
      " 30%|███       | 2020/6672 [04:26<06:56, 11.16it/s]\u001b[A\n",
      " 30%|███       | 2022/6672 [04:26<07:25, 10.43it/s]\u001b[A\n",
      " 30%|███       | 2024/6672 [04:26<07:08, 10.84it/s]\u001b[A\n",
      " 30%|███       | 2026/6672 [04:26<06:30, 11.91it/s]\u001b[A\n",
      " 30%|███       | 2028/6672 [04:27<06:45, 11.45it/s]\u001b[A\n",
      " 30%|███       | 2030/6672 [04:27<07:05, 10.92it/s]\u001b[A\n",
      " 30%|███       | 2032/6672 [04:27<06:58, 11.09it/s]\u001b[A\n",
      " 30%|███       | 2034/6672 [04:27<06:39, 11.62it/s]\u001b[A\n",
      " 31%|███       | 2036/6672 [04:27<06:30, 11.86it/s]\u001b[A\n",
      " 31%|███       | 2038/6672 [04:27<06:36, 11.69it/s]\u001b[A\n",
      " 31%|███       | 2040/6672 [04:28<06:30, 11.87it/s]\u001b[A\n",
      " 31%|███       | 2042/6672 [04:28<06:19, 12.19it/s]\u001b[A\n",
      " 31%|███       | 2044/6672 [04:28<06:17, 12.27it/s]\u001b[A\n",
      " 31%|███       | 2046/6672 [04:28<06:18, 12.21it/s]\u001b[A\n",
      " 31%|███       | 2048/6672 [04:28<08:23,  9.18it/s]\u001b[A\n",
      " 31%|███       | 2050/6672 [04:29<08:41,  8.86it/s]\u001b[A\n",
      " 31%|███       | 2052/6672 [04:29<08:17,  9.29it/s]\u001b[A\n",
      " 31%|███       | 2053/6672 [04:29<09:04,  8.48it/s]\u001b[A\n",
      " 31%|███       | 2054/6672 [04:29<08:53,  8.66it/s]\u001b[A\n",
      " 31%|███       | 2056/6672 [04:29<08:18,  9.26it/s]\u001b[A\n",
      " 31%|███       | 2058/6672 [04:30<08:05,  9.50it/s]\u001b[A\n",
      " 31%|███       | 2060/6672 [04:30<07:28, 10.28it/s]\u001b[A\n",
      " 31%|███       | 2062/6672 [04:30<07:07, 10.78it/s]\u001b[A\n",
      " 31%|███       | 2064/6672 [04:30<07:29, 10.24it/s]\u001b[A\n",
      " 31%|███       | 2066/6672 [04:30<07:11, 10.68it/s]\u001b[A\n",
      " 31%|███       | 2068/6672 [04:30<07:15, 10.57it/s]\u001b[A\n",
      " 31%|███       | 2070/6672 [04:31<07:27, 10.29it/s]\u001b[A\n",
      " 31%|███       | 2072/6672 [04:31<08:25,  9.09it/s]\u001b[A\n",
      " 31%|███       | 2073/6672 [04:31<08:27,  9.05it/s]\u001b[A\n",
      " 31%|███       | 2075/6672 [04:31<07:30, 10.20it/s]\u001b[A\n",
      " 31%|███       | 2077/6672 [04:31<07:19, 10.46it/s]\u001b[A\n",
      " 31%|███       | 2079/6672 [04:32<07:29, 10.22it/s]\u001b[A\n",
      " 31%|███       | 2081/6672 [04:32<07:32, 10.15it/s]\u001b[A\n",
      " 31%|███       | 2083/6672 [04:32<07:11, 10.63it/s]\u001b[A\n",
      " 31%|███▏      | 2085/6672 [04:32<07:29, 10.20it/s]\u001b[A\n",
      " 31%|███▏      | 2087/6672 [04:32<07:50,  9.75it/s]\u001b[A\n",
      " 31%|███▏      | 2089/6672 [04:33<07:24, 10.31it/s]\u001b[A\n",
      " 31%|███▏      | 2091/6672 [04:33<07:27, 10.25it/s]\u001b[A\n",
      " 31%|███▏      | 2093/6672 [04:33<07:36, 10.03it/s]\u001b[A\n",
      " 31%|███▏      | 2095/6672 [04:33<07:11, 10.62it/s]\u001b[A\n",
      " 31%|███▏      | 2097/6672 [04:33<07:58,  9.57it/s]\u001b[A\n",
      " 31%|███▏      | 2098/6672 [04:34<08:20,  9.13it/s]\u001b[A\n",
      " 31%|███▏      | 2099/6672 [04:34<08:39,  8.80it/s]\u001b[A\n",
      " 31%|███▏      | 2100/6672 [04:34<08:39,  8.80it/s]\u001b[A\n",
      " 31%|███▏      | 2101/6672 [04:34<08:28,  8.99it/s]\u001b[A\n",
      " 32%|███▏      | 2103/6672 [04:34<07:58,  9.56it/s]\u001b[A\n",
      " 32%|███▏      | 2104/6672 [04:34<08:15,  9.21it/s]\u001b[A\n",
      " 32%|███▏      | 2105/6672 [04:34<09:00,  8.46it/s]\u001b[A\n",
      " 32%|███▏      | 2106/6672 [04:34<09:28,  8.03it/s]\u001b[A\n",
      " 32%|███▏      | 2108/6672 [04:35<08:20,  9.12it/s]\u001b[A\n",
      " 32%|███▏      | 2109/6672 [04:35<08:54,  8.53it/s]\u001b[A\n",
      " 32%|███▏      | 2110/6672 [04:35<09:16,  8.20it/s]\u001b[A\n",
      " 32%|███▏      | 2111/6672 [04:35<09:08,  8.31it/s]\u001b[A\n",
      " 32%|███▏      | 2113/6672 [04:35<07:49,  9.70it/s]\u001b[A\n",
      " 32%|███▏      | 2114/6672 [04:35<08:51,  8.57it/s]\u001b[A\n",
      " 32%|███▏      | 2115/6672 [04:36<09:20,  8.13it/s]\u001b[A\n",
      " 32%|███▏      | 2116/6672 [04:36<09:20,  8.13it/s]\u001b[A\n",
      " 32%|███▏      | 2118/6672 [04:36<07:56,  9.55it/s]\u001b[A\n",
      " 32%|███▏      | 2120/6672 [04:36<07:52,  9.62it/s]\u001b[A\n",
      " 32%|███▏      | 2121/6672 [04:36<08:26,  8.99it/s]\u001b[A\n",
      " 32%|███▏      | 2123/6672 [04:36<07:41,  9.85it/s]\u001b[A\n",
      " 32%|███▏      | 2124/6672 [04:36<08:02,  9.42it/s]\u001b[A\n",
      " 32%|███▏      | 2125/6672 [04:37<08:41,  8.73it/s]\u001b[A\n",
      " 32%|███▏      | 2126/6672 [04:37<08:37,  8.78it/s]\u001b[A\n",
      " 32%|███▏      | 2128/6672 [04:37<07:34,  9.99it/s]\u001b[A\n",
      " 32%|███▏      | 2129/6672 [04:37<07:54,  9.57it/s]\u001b[A\n",
      " 32%|███▏      | 2130/6672 [04:37<08:05,  9.35it/s]\u001b[A\n",
      " 32%|███▏      | 2131/6672 [04:37<08:08,  9.30it/s]\u001b[A\n",
      " 32%|███▏      | 2133/6672 [04:37<07:19, 10.32it/s]\u001b[A\n",
      " 32%|███▏      | 2135/6672 [04:38<07:07, 10.60it/s]\u001b[A\n",
      " 32%|███▏      | 2137/6672 [04:38<06:45, 11.19it/s]\u001b[A\n",
      " 32%|███▏      | 2139/6672 [04:38<06:38, 11.37it/s]\u001b[A\n",
      " 32%|███▏      | 2141/6672 [04:38<06:31, 11.57it/s]\u001b[A\n",
      " 32%|███▏      | 2143/6672 [04:38<06:24, 11.79it/s]\u001b[A\n",
      " 32%|███▏      | 2145/6672 [04:38<06:41, 11.27it/s]\u001b[A\n",
      " 32%|███▏      | 2147/6672 [04:39<07:48,  9.65it/s]\u001b[A\n",
      " 32%|███▏      | 2149/6672 [04:39<08:21,  9.03it/s]\u001b[A\n",
      " 32%|███▏      | 2150/6672 [04:39<08:25,  8.95it/s]\u001b[A\n",
      " 32%|███▏      | 2151/6672 [04:39<08:16,  9.10it/s]\u001b[A\n",
      " 32%|███▏      | 2152/6672 [04:39<08:15,  9.12it/s]\u001b[A\n",
      " 32%|███▏      | 2154/6672 [04:39<07:47,  9.67it/s]\u001b[A\n",
      " 32%|███▏      | 2155/6672 [04:40<08:19,  9.04it/s]\u001b[A\n",
      " 32%|███▏      | 2156/6672 [04:40<08:59,  8.36it/s]\u001b[A\n",
      " 32%|███▏      | 2157/6672 [04:40<08:40,  8.67it/s]\u001b[A\n",
      " 32%|███▏      | 2158/6672 [04:40<08:44,  8.61it/s]\u001b[A\n",
      " 32%|███▏      | 2159/6672 [04:40<09:38,  7.80it/s]\u001b[A\n",
      " 32%|███▏      | 2160/6672 [04:40<09:10,  8.19it/s]\u001b[A\n",
      " 32%|███▏      | 2162/6672 [04:40<07:55,  9.48it/s]\u001b[A\n",
      " 32%|███▏      | 2163/6672 [04:41<08:44,  8.60it/s]\u001b[A\n",
      " 32%|███▏      | 2164/6672 [04:41<08:47,  8.55it/s]\u001b[A\n",
      " 32%|███▏      | 2165/6672 [04:41<09:09,  8.20it/s]\u001b[A\n",
      " 32%|███▏      | 2166/6672 [04:41<09:06,  8.24it/s]\u001b[A\n",
      " 32%|███▏      | 2168/6672 [04:41<07:52,  9.54it/s]\u001b[A\n",
      " 33%|███▎      | 2170/6672 [04:41<07:22, 10.18it/s]\u001b[A\n",
      " 33%|███▎      | 2172/6672 [04:41<07:27, 10.06it/s]\u001b[A\n",
      " 33%|███▎      | 2174/6672 [04:42<07:08, 10.50it/s]\u001b[A\n",
      " 33%|███▎      | 2176/6672 [04:42<06:55, 10.82it/s]\u001b[A\n",
      " 33%|███▎      | 2178/6672 [04:42<06:39, 11.25it/s]\u001b[A\n",
      " 33%|███▎      | 2180/6672 [04:42<06:35, 11.37it/s]\u001b[A\n",
      " 33%|███▎      | 2182/6672 [04:42<06:49, 10.97it/s]\u001b[A\n",
      " 33%|███▎      | 2184/6672 [04:43<06:43, 11.13it/s]\u001b[A\n",
      " 33%|███▎      | 2186/6672 [04:43<07:04, 10.57it/s]\u001b[A\n",
      " 33%|███▎      | 2188/6672 [04:43<07:15, 10.29it/s]\u001b[A\n",
      " 33%|███▎      | 2190/6672 [04:43<06:54, 10.80it/s]\u001b[A\n",
      " 33%|███▎      | 2192/6672 [04:43<06:26, 11.58it/s]\u001b[A\n",
      " 33%|███▎      | 2194/6672 [04:43<06:01, 12.39it/s]\u001b[A\n",
      " 33%|███▎      | 2196/6672 [04:44<05:51, 12.72it/s]\u001b[A\n",
      " 33%|███▎      | 2198/6672 [04:44<07:34,  9.85it/s]\u001b[A\n",
      " 33%|███▎      | 2200/6672 [04:44<07:41,  9.69it/s]\u001b[A\n",
      " 33%|███▎      | 2202/6672 [04:44<07:25, 10.03it/s]\u001b[A\n",
      " 33%|███▎      | 2204/6672 [04:44<06:59, 10.65it/s]\u001b[A\n",
      " 33%|███▎      | 2206/6672 [04:45<07:01, 10.59it/s]\u001b[A\n",
      " 33%|███▎      | 2208/6672 [04:45<07:02, 10.57it/s]\u001b[A\n",
      " 33%|███▎      | 2210/6672 [04:45<06:57, 10.69it/s]\u001b[A\n",
      " 33%|███▎      | 2212/6672 [04:45<06:41, 11.10it/s]\u001b[A\n",
      " 33%|███▎      | 2214/6672 [04:45<06:32, 11.36it/s]\u001b[A\n",
      " 33%|███▎      | 2216/6672 [04:45<06:18, 11.77it/s]\u001b[A\n",
      " 33%|███▎      | 2218/6672 [04:46<05:56, 12.50it/s]\u001b[A\n",
      " 33%|███▎      | 2220/6672 [04:46<05:44, 12.93it/s]\u001b[A\n",
      " 33%|███▎      | 2222/6672 [04:46<05:46, 12.83it/s]\u001b[A\n",
      " 33%|███▎      | 2224/6672 [04:46<05:50, 12.69it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 69.90it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2224\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3105565905570984, 'eval_f1': 0.805722764855707, 'eval_recall': 0.8159132035812215, 'eval_precision': 0.796354363570322, 'eval_runtime': 4.3438, 'eval_samples_per_second': 292.372, 'eval_steps_per_second': 73.208, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2224/special_tokens_map.json\n",
      "\n",
      " 33%|███▎      | 2226/6672 [04:54<1:33:30,  1.26s/it]\u001b[A\n",
      " 33%|███▎      | 2227/6672 [04:54<1:18:53,  1.06s/it]\u001b[A\n",
      " 33%|███▎      | 2228/6672 [04:54<1:04:40,  1.15it/s]\u001b[A\n",
      " 33%|███▎      | 2229/6672 [04:54<52:16,  1.42it/s]  \u001b[A\n",
      " 33%|███▎      | 2230/6672 [04:55<42:14,  1.75it/s]\u001b[A\n",
      " 33%|███▎      | 2231/6672 [04:55<34:06,  2.17it/s]\u001b[A\n",
      " 33%|███▎      | 2232/6672 [04:55<27:05,  2.73it/s]\u001b[A\n",
      " 33%|███▎      | 2233/6672 [04:55<22:09,  3.34it/s]\u001b[A\n",
      " 33%|███▎      | 2234/6672 [04:55<17:58,  4.11it/s]\u001b[A\n",
      " 33%|███▎      | 2235/6672 [04:55<15:57,  4.63it/s]\u001b[A\n",
      " 34%|███▎      | 2236/6672 [04:55<13:54,  5.32it/s]\u001b[A\n",
      " 34%|███▎      | 2237/6672 [04:55<12:14,  6.04it/s]\u001b[A\n",
      " 34%|███▎      | 2239/6672 [04:56<09:31,  7.76it/s]\u001b[A\n",
      " 34%|███▎      | 2240/6672 [04:56<09:10,  8.05it/s]\u001b[A\n",
      " 34%|███▎      | 2241/6672 [04:56<09:10,  8.04it/s]\u001b[A\n",
      " 34%|███▎      | 2242/6672 [04:56<09:05,  8.12it/s]\u001b[A\n",
      " 34%|███▎      | 2244/6672 [04:56<07:45,  9.52it/s]\u001b[A\n",
      " 34%|███▎      | 2245/6672 [04:56<07:55,  9.30it/s]\u001b[A\n",
      " 34%|███▎      | 2247/6672 [04:56<07:16, 10.15it/s]\u001b[A\n",
      " 34%|███▎      | 2249/6672 [04:57<07:26,  9.90it/s]\u001b[A\n",
      " 34%|███▎      | 2250/6672 [04:57<07:26,  9.91it/s]\u001b[A\n",
      " 34%|███▎      | 2251/6672 [04:57<08:17,  8.89it/s]\u001b[A\n",
      " 34%|███▍      | 2252/6672 [04:57<08:17,  8.88it/s]\u001b[A\n",
      " 34%|███▍      | 2253/6672 [04:57<08:20,  8.83it/s]\u001b[A\n",
      " 34%|███▍      | 2255/6672 [04:57<07:18, 10.07it/s]\u001b[A\n",
      " 34%|███▍      | 2257/6672 [04:57<06:30, 11.31it/s]\u001b[A\n",
      " 34%|███▍      | 2259/6672 [04:58<06:06, 12.04it/s]\u001b[A\n",
      " 34%|███▍      | 2261/6672 [04:58<07:02, 10.44it/s]\u001b[A\n",
      " 34%|███▍      | 2263/6672 [04:58<07:07, 10.31it/s]\u001b[A\n",
      " 34%|███▍      | 2265/6672 [04:58<06:48, 10.79it/s]\u001b[A\n",
      " 34%|███▍      | 2267/6672 [04:58<07:24,  9.90it/s]\u001b[A\n",
      " 34%|███▍      | 2269/6672 [04:59<07:24,  9.91it/s]\u001b[A\n",
      " 34%|███▍      | 2271/6672 [04:59<06:49, 10.74it/s]\u001b[A\n",
      " 34%|███▍      | 2273/6672 [04:59<06:28, 11.32it/s]\u001b[A\n",
      " 34%|███▍      | 2275/6672 [04:59<07:17, 10.06it/s]\u001b[A\n",
      " 34%|███▍      | 2277/6672 [04:59<08:07,  9.01it/s]\u001b[A\n",
      " 34%|███▍      | 2278/6672 [05:00<08:06,  9.04it/s]\u001b[A\n",
      " 34%|███▍      | 2279/6672 [05:00<08:22,  8.75it/s]\u001b[A\n",
      " 34%|███▍      | 2280/6672 [05:00<08:10,  8.95it/s]\u001b[A\n",
      " 34%|███▍      | 2282/6672 [05:00<07:40,  9.54it/s]\u001b[A\n",
      " 34%|███▍      | 2283/6672 [05:00<08:18,  8.80it/s]\u001b[A\n",
      " 34%|███▍      | 2284/6672 [05:00<08:43,  8.39it/s]\u001b[A\n",
      " 34%|███▍      | 2285/6672 [05:00<08:28,  8.62it/s]\u001b[A\n",
      " 34%|███▍      | 2286/6672 [05:00<08:20,  8.76it/s]\u001b[A\n",
      " 34%|███▍      | 2287/6672 [05:01<08:38,  8.47it/s]\u001b[A\n",
      " 34%|███▍      | 2289/6672 [05:01<07:35,  9.63it/s]\u001b[A\n",
      " 34%|███▍      | 2290/6672 [05:01<07:32,  9.68it/s]\u001b[A\n",
      " 34%|███▍      | 2292/6672 [05:01<06:43, 10.85it/s]\u001b[A\n",
      " 34%|███▍      | 2294/6672 [05:01<06:10, 11.82it/s]\u001b[A\n",
      " 34%|███▍      | 2296/6672 [05:01<06:53, 10.57it/s]\u001b[A\n",
      " 34%|███▍      | 2298/6672 [05:02<07:01, 10.38it/s]\u001b[A\n",
      " 34%|███▍      | 2300/6672 [05:02<06:55, 10.52it/s]\u001b[A\n",
      " 35%|███▍      | 2302/6672 [05:02<06:19, 11.53it/s]\u001b[A\n",
      " 35%|███▍      | 2304/6672 [05:02<05:55, 12.30it/s]\u001b[A\n",
      " 35%|███▍      | 2306/6672 [05:02<06:03, 12.03it/s]\u001b[A\n",
      " 35%|███▍      | 2308/6672 [05:02<05:49, 12.49it/s]\u001b[A\n",
      " 35%|███▍      | 2310/6672 [05:03<05:27, 13.33it/s]\u001b[A\n",
      " 35%|███▍      | 2312/6672 [05:03<05:19, 13.67it/s]\u001b[A\n",
      " 35%|███▍      | 2314/6672 [05:03<05:39, 12.84it/s]\u001b[A\n",
      " 35%|███▍      | 2316/6672 [05:03<06:43, 10.80it/s]\u001b[A\n",
      " 35%|███▍      | 2318/6672 [05:03<06:20, 11.46it/s]\u001b[A\n",
      " 35%|███▍      | 2320/6672 [05:03<06:03, 11.97it/s]\u001b[A\n",
      " 35%|███▍      | 2322/6672 [05:04<06:09, 11.78it/s]\u001b[A\n",
      " 35%|███▍      | 2324/6672 [05:04<07:39,  9.47it/s]\u001b[A\n",
      " 35%|███▍      | 2326/6672 [05:04<09:15,  7.82it/s]\u001b[A\n",
      " 35%|███▍      | 2327/6672 [05:04<09:14,  7.84it/s]\u001b[A\n",
      " 35%|███▍      | 2328/6672 [05:04<09:00,  8.04it/s]\u001b[A\n",
      " 35%|███▍      | 2329/6672 [05:05<08:40,  8.34it/s]\u001b[A\n",
      " 35%|███▍      | 2330/6672 [05:05<08:38,  8.37it/s]\u001b[A\n",
      " 35%|███▍      | 2332/6672 [05:05<07:52,  9.18it/s]\u001b[A\n",
      " 35%|███▍      | 2334/6672 [05:05<07:16,  9.95it/s]\u001b[A\n",
      " 35%|███▌      | 2336/6672 [05:05<06:55, 10.43it/s]\u001b[A\n",
      " 35%|███▌      | 2338/6672 [05:05<06:29, 11.11it/s]\u001b[A\n",
      " 35%|███▌      | 2340/6672 [05:06<06:15, 11.54it/s]\u001b[A\n",
      " 35%|███▌      | 2342/6672 [05:06<06:07, 11.78it/s]\u001b[A\n",
      " 35%|███▌      | 2344/6672 [05:06<06:47, 10.62it/s]\u001b[A\n",
      " 35%|███▌      | 2346/6672 [05:06<06:26, 11.20it/s]\u001b[A\n",
      " 35%|███▌      | 2348/6672 [05:06<06:23, 11.28it/s]\u001b[A\n",
      " 35%|███▌      | 2350/6672 [05:06<06:50, 10.53it/s]\u001b[A\n",
      " 35%|███▌      | 2352/6672 [05:07<06:59, 10.31it/s]\u001b[A\n",
      " 35%|███▌      | 2354/6672 [05:07<06:54, 10.41it/s]\u001b[A\n",
      " 35%|███▌      | 2356/6672 [05:07<06:52, 10.47it/s]\u001b[A\n",
      " 35%|███▌      | 2358/6672 [05:07<06:38, 10.82it/s]\u001b[A\n",
      " 35%|███▌      | 2360/6672 [05:07<06:10, 11.65it/s]\u001b[A\n",
      " 35%|███▌      | 2362/6672 [05:08<05:55, 12.13it/s]\u001b[A\n",
      " 35%|███▌      | 2364/6672 [05:08<05:55, 12.11it/s]\u001b[A\n",
      " 35%|███▌      | 2366/6672 [05:08<06:28, 11.09it/s]\u001b[A\n",
      " 35%|███▌      | 2368/6672 [05:08<05:58, 11.99it/s]\u001b[A\n",
      " 36%|███▌      | 2370/6672 [05:08<05:50, 12.26it/s]\u001b[A\n",
      " 36%|███▌      | 2372/6672 [05:08<06:48, 10.53it/s]\u001b[A\n",
      " 36%|███▌      | 2374/6672 [05:09<06:42, 10.69it/s]\u001b[A\n",
      " 36%|███▌      | 2376/6672 [05:09<08:25,  8.49it/s]\u001b[A\n",
      " 36%|███▌      | 2377/6672 [05:09<08:34,  8.34it/s]\u001b[A\n",
      " 36%|███▌      | 2378/6672 [05:09<08:30,  8.40it/s]\u001b[A\n",
      " 36%|███▌      | 2379/6672 [05:09<08:13,  8.71it/s]\u001b[A\n",
      " 36%|███▌      | 2381/6672 [05:10<07:37,  9.37it/s]\u001b[A\n",
      " 36%|███▌      | 2383/6672 [05:10<07:08, 10.01it/s]\u001b[A\n",
      " 36%|███▌      | 2385/6672 [05:10<06:47, 10.51it/s]\u001b[A\n",
      " 36%|███▌      | 2387/6672 [05:10<06:29, 11.01it/s]\u001b[A\n",
      " 36%|███▌      | 2389/6672 [05:10<06:18, 11.32it/s]\u001b[A\n",
      " 36%|███▌      | 2391/6672 [05:10<06:23, 11.17it/s]\u001b[A\n",
      " 36%|███▌      | 2393/6672 [05:11<06:51, 10.39it/s]\u001b[A\n",
      " 36%|███▌      | 2395/6672 [05:11<06:42, 10.62it/s]\u001b[A\n",
      " 36%|███▌      | 2397/6672 [05:11<06:23, 11.13it/s]\u001b[A\n",
      " 36%|███▌      | 2399/6672 [05:11<06:04, 11.72it/s]\u001b[A\n",
      " 36%|███▌      | 2401/6672 [05:11<05:38, 12.63it/s]\u001b[A\n",
      " 36%|███▌      | 2403/6672 [05:11<05:28, 13.00it/s]\u001b[A\n",
      " 36%|███▌      | 2405/6672 [05:12<05:26, 13.08it/s]\u001b[A\n",
      " 36%|███▌      | 2407/6672 [05:12<05:53, 12.06it/s]\u001b[A\n",
      " 36%|███▌      | 2409/6672 [05:12<05:59, 11.86it/s]\u001b[A\n",
      " 36%|███▌      | 2411/6672 [05:12<06:18, 11.25it/s]\u001b[A\n",
      " 36%|███▌      | 2413/6672 [05:12<06:17, 11.28it/s]\u001b[A\n",
      " 36%|███▌      | 2415/6672 [05:12<06:26, 11.03it/s]\u001b[A\n",
      " 36%|███▌      | 2417/6672 [05:13<06:40, 10.63it/s]\u001b[A\n",
      " 36%|███▋      | 2419/6672 [05:13<07:16,  9.74it/s]\u001b[A\n",
      " 36%|███▋      | 2420/6672 [05:13<07:45,  9.13it/s]\u001b[A\n",
      " 36%|███▋      | 2422/6672 [05:13<07:18,  9.70it/s]\u001b[A\n",
      " 36%|███▋      | 2424/6672 [05:13<06:52, 10.30it/s]\u001b[A\n",
      " 36%|███▋      | 2426/6672 [05:14<08:43,  8.11it/s]\u001b[A\n",
      " 36%|███▋      | 2427/6672 [05:14<09:05,  7.79it/s]\u001b[A\n",
      " 36%|███▋      | 2428/6672 [05:14<08:52,  7.97it/s]\u001b[A\n",
      " 36%|███▋      | 2429/6672 [05:14<08:28,  8.35it/s]\u001b[A\n",
      " 36%|███▋      | 2431/6672 [05:14<07:44,  9.13it/s]\u001b[A\n",
      " 36%|███▋      | 2432/6672 [05:14<08:07,  8.70it/s]\u001b[A\n",
      " 36%|███▋      | 2434/6672 [05:15<07:29,  9.43it/s]\u001b[A\n",
      " 36%|███▋      | 2435/6672 [05:15<07:57,  8.87it/s]\u001b[A\n",
      " 37%|███▋      | 2436/6672 [05:15<07:53,  8.95it/s]\u001b[A\n",
      " 37%|███▋      | 2438/6672 [05:15<07:03,  9.99it/s]\u001b[A\n",
      " 37%|███▋      | 2440/6672 [05:15<06:39, 10.59it/s]\u001b[A\n",
      " 37%|███▋      | 2442/6672 [05:15<06:45, 10.42it/s]\u001b[A\n",
      " 37%|███▋      | 2444/6672 [05:16<06:38, 10.61it/s]\u001b[A\n",
      " 37%|███▋      | 2446/6672 [05:16<06:33, 10.74it/s]\u001b[A\n",
      " 37%|███▋      | 2448/6672 [05:16<06:38, 10.60it/s]\u001b[A\n",
      " 37%|███▋      | 2450/6672 [05:16<07:23,  9.52it/s]\u001b[A\n",
      " 37%|███▋      | 2451/6672 [05:16<07:50,  8.97it/s]\u001b[A\n",
      " 37%|███▋      | 2452/6672 [05:16<07:56,  8.85it/s]\u001b[A\n",
      " 37%|███▋      | 2454/6672 [05:17<07:10,  9.80it/s]\u001b[A\n",
      " 37%|███▋      | 2456/6672 [05:17<06:44, 10.43it/s]\u001b[A\n",
      " 37%|███▋      | 2458/6672 [05:17<07:06,  9.88it/s]\u001b[A\n",
      " 37%|███▋      | 2460/6672 [05:17<06:45, 10.39it/s]\u001b[A\n",
      " 37%|███▋      | 2462/6672 [05:17<06:26, 10.88it/s]\u001b[A\n",
      " 37%|███▋      | 2464/6672 [05:18<06:48, 10.31it/s]\u001b[A\n",
      " 37%|███▋      | 2466/6672 [05:18<06:40, 10.49it/s]\u001b[A\n",
      " 37%|███▋      | 2468/6672 [05:18<06:17, 11.14it/s]\u001b[A\n",
      " 37%|███▋      | 2470/6672 [05:18<06:05, 11.50it/s]\u001b[A\n",
      " 37%|███▋      | 2472/6672 [05:18<06:17, 11.12it/s]\u001b[A\n",
      " 37%|███▋      | 2474/6672 [05:18<06:08, 11.38it/s]\u001b[A\n",
      " 37%|███▋      | 2476/6672 [05:19<07:22,  9.48it/s]\u001b[A\n",
      " 37%|███▋      | 2478/6672 [05:19<07:18,  9.57it/s]\u001b[A\n",
      " 37%|███▋      | 2480/6672 [05:19<07:00,  9.96it/s]\u001b[A\n",
      " 37%|███▋      | 2482/6672 [05:19<06:36, 10.57it/s]\u001b[A\n",
      " 37%|███▋      | 2484/6672 [05:20<07:15,  9.61it/s]\u001b[A\n",
      " 37%|███▋      | 2486/6672 [05:20<06:51, 10.17it/s]\u001b[A\n",
      " 37%|███▋      | 2488/6672 [05:20<06:32, 10.67it/s]\u001b[A\n",
      " 37%|███▋      | 2490/6672 [05:20<06:17, 11.07it/s]\u001b[A\n",
      " 37%|███▋      | 2492/6672 [05:20<06:05, 11.43it/s]\u001b[A\n",
      " 37%|███▋      | 2494/6672 [05:20<06:55, 10.07it/s]\u001b[A\n",
      " 37%|███▋      | 2496/6672 [05:21<06:50, 10.16it/s]\u001b[A\n",
      " 37%|███▋      | 2498/6672 [05:21<07:39,  9.08it/s]\u001b[A\n",
      " 37%|███▋      | 2499/6672 [05:21<07:41,  9.04it/s]\u001b[A\n",
      " 37%|███▋      | 2500/6672 [05:21<09:44,  7.14it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 37%|███▋      | 2500/6672 [05:21<09:44,  7.14it/s]\u001b[A\n",
      " 37%|███▋      | 2501/6672 [05:21<10:47,  6.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0425, 'learning_rate': 4.370956417345838e-05, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 2502/6672 [05:22<09:56,  6.99it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 78.21it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2502\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2502/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3509623408317566, 'eval_f1': 0.7829059829059829, 'eval_recall': 0.7618787979359773, 'eval_precision': 0.8088900073632899, 'eval_runtime': 4.1937, 'eval_samples_per_second': 302.835, 'eval_steps_per_second': 75.828, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2502/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2502/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2502/special_tokens_map.json\n",
      "\n",
      " 38%|███▊      | 2503/6672 [05:29<2:22:28,  2.05s/it]\u001b[A\n",
      " 38%|███▊      | 2504/6672 [05:29<1:47:43,  1.55s/it]\u001b[A\n",
      " 38%|███▊      | 2505/6672 [05:30<1:20:43,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 2506/6672 [05:30<59:59,  1.16it/s]  \u001b[A\n",
      " 38%|███▊      | 2507/6672 [05:30<44:56,  1.54it/s]\u001b[A\n",
      " 38%|███▊      | 2508/6672 [05:30<34:28,  2.01it/s]\u001b[A\n",
      " 38%|███▊      | 2510/6672 [05:30<21:56,  3.16it/s]\u001b[A\n",
      " 38%|███▊      | 2511/6672 [05:30<19:06,  3.63it/s]\u001b[A\n",
      " 38%|███▊      | 2512/6672 [05:30<16:01,  4.33it/s]\u001b[A\n",
      " 38%|███▊      | 2513/6672 [05:30<14:03,  4.93it/s]\u001b[A\n",
      " 38%|███▊      | 2514/6672 [05:31<12:37,  5.49it/s]\u001b[A\n",
      " 38%|███▊      | 2515/6672 [05:31<11:10,  6.20it/s]\u001b[A\n",
      " 38%|███▊      | 2516/6672 [05:31<09:58,  6.95it/s]\u001b[A\n",
      " 38%|███▊      | 2517/6672 [05:31<09:12,  7.52it/s]\u001b[A\n",
      " 38%|███▊      | 2518/6672 [05:31<08:32,  8.10it/s]\u001b[A\n",
      " 38%|███▊      | 2519/6672 [05:31<08:34,  8.07it/s]\u001b[A\n",
      " 38%|███▊      | 2520/6672 [05:31<08:21,  8.28it/s]\u001b[A\n",
      " 38%|███▊      | 2522/6672 [05:31<07:33,  9.15it/s]\u001b[A\n",
      " 38%|███▊      | 2523/6672 [05:32<07:24,  9.34it/s]\u001b[A\n",
      " 38%|███▊      | 2525/6672 [05:32<06:49, 10.13it/s]\u001b[A\n",
      " 38%|███▊      | 2527/6672 [05:32<06:43, 10.27it/s]\u001b[A\n",
      " 38%|███▊      | 2529/6672 [05:32<06:27, 10.68it/s]\u001b[A\n",
      " 38%|███▊      | 2531/6672 [05:32<06:15, 11.02it/s]\u001b[A\n",
      " 38%|███▊      | 2533/6672 [05:32<06:03, 11.39it/s]\u001b[A\n",
      " 38%|███▊      | 2535/6672 [05:33<05:50, 11.79it/s]\u001b[A\n",
      " 38%|███▊      | 2537/6672 [05:33<06:09, 11.19it/s]\u001b[A\n",
      " 38%|███▊      | 2539/6672 [05:33<06:08, 11.23it/s]\u001b[A\n",
      " 38%|███▊      | 2541/6672 [05:33<06:01, 11.42it/s]\u001b[A\n",
      " 38%|███▊      | 2543/6672 [05:33<05:47, 11.89it/s]\u001b[A\n",
      " 38%|███▊      | 2545/6672 [05:33<05:58, 11.51it/s]\u001b[A\n",
      " 38%|███▊      | 2547/6672 [05:34<05:47, 11.86it/s]\u001b[A\n",
      " 38%|███▊      | 2549/6672 [05:34<06:01, 11.40it/s]\u001b[A\n",
      " 38%|███▊      | 2551/6672 [05:34<05:55, 11.58it/s]\u001b[A\n",
      " 38%|███▊      | 2553/6672 [05:34<06:42, 10.24it/s]\u001b[A\n",
      " 38%|███▊      | 2555/6672 [05:34<07:29,  9.16it/s]\u001b[A\n",
      " 38%|███▊      | 2556/6672 [05:35<07:33,  9.07it/s]\u001b[A\n",
      " 38%|███▊      | 2557/6672 [05:35<08:16,  8.29it/s]\u001b[A\n",
      " 38%|███▊      | 2558/6672 [05:35<08:40,  7.90it/s]\u001b[A\n",
      " 38%|███▊      | 2559/6672 [05:35<09:03,  7.56it/s]\u001b[A\n",
      " 38%|███▊      | 2560/6672 [05:35<08:35,  7.97it/s]\u001b[A\n",
      " 38%|███▊      | 2561/6672 [05:35<08:16,  8.29it/s]\u001b[A\n",
      " 38%|███▊      | 2562/6672 [05:35<08:25,  8.12it/s]\u001b[A\n",
      " 38%|███▊      | 2564/6672 [05:36<07:33,  9.06it/s]\u001b[A\n",
      " 38%|███▊      | 2566/6672 [05:36<06:55,  9.89it/s]\u001b[A\n",
      " 38%|███▊      | 2567/6672 [05:36<06:55,  9.88it/s]\u001b[A\n",
      " 39%|███▊      | 2569/6672 [05:36<06:26, 10.62it/s]\u001b[A\n",
      " 39%|███▊      | 2571/6672 [05:36<06:41, 10.20it/s]\u001b[A\n",
      " 39%|███▊      | 2573/6672 [05:36<06:33, 10.42it/s]\u001b[A\n",
      " 39%|███▊      | 2575/6672 [05:37<06:42, 10.17it/s]\u001b[A\n",
      " 39%|███▊      | 2577/6672 [05:37<06:49,  9.99it/s]\u001b[A\n",
      " 39%|███▊      | 2579/6672 [05:37<07:02,  9.69it/s]\u001b[A\n",
      " 39%|███▊      | 2580/6672 [05:37<07:28,  9.13it/s]\u001b[A\n",
      " 39%|███▊      | 2581/6672 [05:37<07:23,  9.22it/s]\u001b[A\n",
      " 39%|███▊      | 2583/6672 [05:37<07:01,  9.70it/s]\u001b[A\n",
      " 39%|███▊      | 2585/6672 [05:38<06:43, 10.14it/s]\u001b[A\n",
      " 39%|███▉      | 2587/6672 [05:38<06:24, 10.63it/s]\u001b[A\n",
      " 39%|███▉      | 2589/6672 [05:38<06:17, 10.81it/s]\u001b[A\n",
      " 39%|███▉      | 2591/6672 [05:38<06:24, 10.62it/s]\u001b[A\n",
      " 39%|███▉      | 2593/6672 [05:38<06:10, 11.02it/s]\u001b[A\n",
      " 39%|███▉      | 2595/6672 [05:39<06:12, 10.95it/s]\u001b[A\n",
      " 39%|███▉      | 2597/6672 [05:39<06:02, 11.23it/s]\u001b[A\n",
      " 39%|███▉      | 2599/6672 [05:39<05:57, 11.41it/s]\u001b[A\n",
      " 39%|███▉      | 2601/6672 [05:39<05:47, 11.71it/s]\u001b[A\n",
      " 39%|███▉      | 2603/6672 [05:39<06:41, 10.14it/s]\u001b[A\n",
      " 39%|███▉      | 2605/6672 [05:40<07:52,  8.61it/s]\u001b[A\n",
      " 39%|███▉      | 2606/6672 [05:40<07:45,  8.74it/s]\u001b[A\n",
      " 39%|███▉      | 2607/6672 [05:40<07:34,  8.94it/s]\u001b[A\n",
      " 39%|███▉      | 2608/6672 [05:40<07:52,  8.61it/s]\u001b[A\n",
      " 39%|███▉      | 2609/6672 [05:40<07:42,  8.79it/s]\u001b[A\n",
      " 39%|███▉      | 2610/6672 [05:40<07:41,  8.80it/s]\u001b[A\n",
      " 39%|███▉      | 2611/6672 [05:40<08:17,  8.15it/s]\u001b[A\n",
      " 39%|███▉      | 2612/6672 [05:40<08:18,  8.14it/s]\u001b[A\n",
      " 39%|███▉      | 2613/6672 [05:41<08:32,  7.92it/s]\u001b[A\n",
      " 39%|███▉      | 2614/6672 [05:41<08:30,  7.94it/s]\u001b[A\n",
      " 39%|███▉      | 2615/6672 [05:41<09:04,  7.45it/s]\u001b[A\n",
      " 39%|███▉      | 2617/6672 [05:41<07:29,  9.03it/s]\u001b[A\n",
      " 39%|███▉      | 2619/6672 [05:41<06:37, 10.19it/s]\u001b[A\n",
      " 39%|███▉      | 2621/6672 [05:41<06:17, 10.73it/s]\u001b[A\n",
      " 39%|███▉      | 2623/6672 [05:41<05:53, 11.47it/s]\u001b[A\n",
      " 39%|███▉      | 2625/6672 [05:42<06:13, 10.82it/s]\u001b[A\n",
      " 39%|███▉      | 2627/6672 [05:42<06:50,  9.85it/s]\u001b[A\n",
      " 39%|███▉      | 2629/6672 [05:42<06:35, 10.21it/s]\u001b[A\n",
      " 39%|███▉      | 2631/6672 [05:42<06:12, 10.84it/s]\u001b[A\n",
      " 39%|███▉      | 2633/6672 [05:43<06:36, 10.19it/s]\u001b[A\n",
      " 39%|███▉      | 2635/6672 [05:43<06:34, 10.24it/s]\u001b[A\n",
      " 40%|███▉      | 2637/6672 [05:43<06:15, 10.74it/s]\u001b[A\n",
      " 40%|███▉      | 2639/6672 [05:43<06:05, 11.04it/s]\u001b[A\n",
      " 40%|███▉      | 2641/6672 [05:43<06:14, 10.77it/s]\u001b[A\n",
      " 40%|███▉      | 2643/6672 [05:43<06:02, 11.12it/s]\u001b[A\n",
      " 40%|███▉      | 2645/6672 [05:44<05:51, 11.45it/s]\u001b[A\n",
      " 40%|███▉      | 2647/6672 [05:44<05:43, 11.71it/s]\u001b[A\n",
      " 40%|███▉      | 2649/6672 [05:44<05:42, 11.74it/s]\u001b[A\n",
      " 40%|███▉      | 2651/6672 [05:44<05:33, 12.04it/s]\u001b[A\n",
      " 40%|███▉      | 2653/6672 [05:44<06:08, 10.90it/s]\u001b[A\n",
      " 40%|███▉      | 2655/6672 [05:45<06:46,  9.87it/s]\u001b[A\n",
      " 40%|███▉      | 2657/6672 [05:45<07:44,  8.64it/s]\u001b[A\n",
      " 40%|███▉      | 2658/6672 [05:45<07:49,  8.55it/s]\u001b[A\n",
      " 40%|███▉      | 2659/6672 [05:45<07:44,  8.63it/s]\u001b[A\n",
      " 40%|███▉      | 2661/6672 [05:45<07:06,  9.41it/s]\u001b[A\n",
      " 40%|███▉      | 2662/6672 [05:45<07:17,  9.16it/s]\u001b[A\n",
      " 40%|███▉      | 2663/6672 [05:45<07:13,  9.24it/s]\u001b[A\n",
      " 40%|███▉      | 2665/6672 [05:46<06:32, 10.22it/s]\u001b[A\n",
      " 40%|███▉      | 2667/6672 [05:46<05:59, 11.13it/s]\u001b[A\n",
      " 40%|████      | 2669/6672 [05:46<05:36, 11.91it/s]\u001b[A\n",
      " 40%|████      | 2671/6672 [05:46<05:23, 12.38it/s]\u001b[A\n",
      " 40%|████      | 2673/6672 [05:46<05:09, 12.94it/s]\u001b[A\n",
      " 40%|████      | 2675/6672 [05:46<05:02, 13.21it/s]\u001b[A\n",
      " 40%|████      | 2677/6672 [05:46<04:52, 13.65it/s]\u001b[A\n",
      " 40%|████      | 2679/6672 [05:47<04:42, 14.12it/s]\u001b[A\n",
      " 40%|████      | 2681/6672 [05:47<04:33, 14.61it/s]\u001b[A\n",
      " 40%|████      | 2683/6672 [05:47<04:49, 13.78it/s]\u001b[A\n",
      " 40%|████      | 2685/6672 [05:47<06:00, 11.06it/s]\u001b[A\n",
      " 40%|████      | 2687/6672 [05:47<05:55, 11.20it/s]\u001b[A\n",
      " 40%|████      | 2689/6672 [05:48<05:53, 11.26it/s]\u001b[A\n",
      " 40%|████      | 2691/6672 [05:48<05:58, 11.11it/s]\u001b[A\n",
      " 40%|████      | 2693/6672 [05:48<06:30, 10.19it/s]\u001b[A\n",
      " 40%|████      | 2695/6672 [05:48<06:21, 10.42it/s]\u001b[A\n",
      " 40%|████      | 2697/6672 [05:48<06:04, 10.90it/s]\u001b[A\n",
      " 40%|████      | 2699/6672 [05:48<06:06, 10.85it/s]\u001b[A\n",
      " 40%|████      | 2701/6672 [05:49<05:44, 11.53it/s]\u001b[A\n",
      " 41%|████      | 2703/6672 [05:49<06:26, 10.26it/s]\u001b[A\n",
      " 41%|████      | 2705/6672 [05:49<07:08,  9.26it/s]\u001b[A\n",
      " 41%|████      | 2706/6672 [05:49<07:29,  8.82it/s]\u001b[A\n",
      " 41%|████      | 2707/6672 [05:49<07:31,  8.78it/s]\u001b[A\n",
      " 41%|████      | 2708/6672 [05:49<07:21,  8.99it/s]\u001b[A\n",
      " 41%|████      | 2710/6672 [05:50<06:52,  9.61it/s]\u001b[A\n",
      " 41%|████      | 2711/6672 [05:50<07:01,  9.40it/s]\u001b[A\n",
      " 41%|████      | 2712/6672 [05:50<07:27,  8.85it/s]\u001b[A\n",
      " 41%|████      | 2713/6672 [05:50<07:59,  8.26it/s]\u001b[A\n",
      " 41%|████      | 2714/6672 [05:50<07:57,  8.30it/s]\u001b[A\n",
      " 41%|████      | 2716/6672 [05:50<06:56,  9.50it/s]\u001b[A\n",
      " 41%|████      | 2717/6672 [05:50<07:26,  8.86it/s]\u001b[A\n",
      " 41%|████      | 2718/6672 [05:51<07:56,  8.30it/s]\u001b[A\n",
      " 41%|████      | 2719/6672 [05:51<08:15,  7.97it/s]\u001b[A\n",
      " 41%|████      | 2720/6672 [05:51<08:34,  7.68it/s]\u001b[A\n",
      " 41%|████      | 2721/6672 [05:51<08:37,  7.64it/s]\u001b[A\n",
      " 41%|████      | 2722/6672 [05:51<08:06,  8.13it/s]\u001b[A\n",
      " 41%|████      | 2724/6672 [05:51<06:34, 10.02it/s]\u001b[A\n",
      " 41%|████      | 2726/6672 [05:51<06:01, 10.92it/s]\u001b[A\n",
      " 41%|████      | 2728/6672 [05:52<05:45, 11.43it/s]\u001b[A\n",
      " 41%|████      | 2730/6672 [05:52<05:38, 11.64it/s]\u001b[A\n",
      " 41%|████      | 2732/6672 [05:52<05:35, 11.74it/s]\u001b[A\n",
      " 41%|████      | 2734/6672 [05:52<05:24, 12.12it/s]\u001b[A\n",
      " 41%|████      | 2736/6672 [05:52<04:56, 13.26it/s]\u001b[A\n",
      " 41%|████      | 2738/6672 [05:52<04:39, 14.07it/s]\u001b[A\n",
      " 41%|████      | 2740/6672 [05:52<04:38, 14.14it/s]\u001b[A\n",
      " 41%|████      | 2742/6672 [05:53<05:00, 13.09it/s]\u001b[A\n",
      " 41%|████      | 2744/6672 [05:53<04:57, 13.21it/s]\u001b[A\n",
      " 41%|████      | 2746/6672 [05:53<05:09, 12.69it/s]\u001b[A\n",
      " 41%|████      | 2748/6672 [05:53<05:06, 12.82it/s]\u001b[A\n",
      " 41%|████      | 2750/6672 [05:53<05:12, 12.54it/s]\u001b[A\n",
      " 41%|████      | 2752/6672 [05:53<05:17, 12.36it/s]\u001b[A\n",
      " 41%|████▏     | 2754/6672 [05:54<06:31, 10.02it/s]\u001b[A\n",
      " 41%|████▏     | 2756/6672 [05:54<06:32,  9.98it/s]\u001b[A\n",
      " 41%|████▏     | 2758/6672 [05:54<06:38,  9.82it/s]\u001b[A\n",
      " 41%|████▏     | 2760/6672 [05:54<06:32,  9.96it/s]\u001b[A\n",
      " 41%|████▏     | 2762/6672 [05:55<06:21, 10.25it/s]\u001b[A\n",
      " 41%|████▏     | 2764/6672 [05:55<06:07, 10.65it/s]\u001b[A\n",
      " 41%|████▏     | 2766/6672 [05:55<06:03, 10.75it/s]\u001b[A\n",
      " 41%|████▏     | 2768/6672 [05:55<05:51, 11.10it/s]\u001b[A\n",
      " 42%|████▏     | 2770/6672 [05:55<05:40, 11.46it/s]\u001b[A\n",
      " 42%|████▏     | 2772/6672 [05:55<05:25, 12.00it/s]\u001b[A\n",
      " 42%|████▏     | 2774/6672 [05:56<05:24, 12.03it/s]\u001b[A\n",
      " 42%|████▏     | 2776/6672 [05:56<05:22, 12.09it/s]\u001b[A\n",
      " 42%|████▏     | 2778/6672 [05:56<05:24, 12.01it/s]\u001b[A\n",
      " 42%|████▏     | 2780/6672 [05:56<05:23, 12.03it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 73.06it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2780\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2780/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3201620876789093, 'eval_f1': 0.7678866478977247, 'eval_recall': 0.7869481386656552, 'eval_precision': 0.7519216894216894, 'eval_runtime': 4.5549, 'eval_samples_per_second': 278.819, 'eval_steps_per_second': 69.815, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2780/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2780/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2780/special_tokens_map.json\n",
      "\n",
      " 42%|████▏     | 2782/6672 [06:04<1:25:31,  1.32s/it]\u001b[A\n",
      " 42%|████▏     | 2783/6672 [06:05<1:11:51,  1.11s/it]\u001b[A\n",
      " 42%|████▏     | 2784/6672 [06:05<58:46,  1.10it/s]  \u001b[A\n",
      " 42%|████▏     | 2785/6672 [06:05<47:06,  1.38it/s]\u001b[A\n",
      " 42%|████▏     | 2786/6672 [06:05<37:19,  1.74it/s]\u001b[A\n",
      " 42%|████▏     | 2787/6672 [06:05<29:49,  2.17it/s]\u001b[A\n",
      " 42%|████▏     | 2788/6672 [06:05<24:19,  2.66it/s]\u001b[A\n",
      " 42%|████▏     | 2789/6672 [06:05<20:09,  3.21it/s]\u001b[A\n",
      " 42%|████▏     | 2790/6672 [06:05<17:03,  3.79it/s]\u001b[A\n",
      " 42%|████▏     | 2791/6672 [06:06<14:47,  4.38it/s]\u001b[A\n",
      " 42%|████▏     | 2792/6672 [06:06<13:19,  4.85it/s]\u001b[A\n",
      " 42%|████▏     | 2793/6672 [06:06<11:57,  5.41it/s]\u001b[A\n",
      " 42%|████▏     | 2795/6672 [06:06<09:23,  6.88it/s]\u001b[A\n",
      " 42%|████▏     | 2796/6672 [06:06<09:14,  6.99it/s]\u001b[A\n",
      " 42%|████▏     | 2797/6672 [06:06<09:14,  6.99it/s]\u001b[A\n",
      " 42%|████▏     | 2798/6672 [06:06<08:32,  7.56it/s]\u001b[A\n",
      " 42%|████▏     | 2800/6672 [06:07<07:34,  8.52it/s]\u001b[A\n",
      " 42%|████▏     | 2802/6672 [06:07<06:53,  9.36it/s]\u001b[A\n",
      " 42%|████▏     | 2803/6672 [06:07<07:14,  8.91it/s]\u001b[A\n",
      " 42%|████▏     | 2805/6672 [06:07<06:41,  9.63it/s]\u001b[A\n",
      " 42%|████▏     | 2807/6672 [06:07<06:15, 10.29it/s]\u001b[A\n",
      " 42%|████▏     | 2809/6672 [06:08<06:29,  9.92it/s]\u001b[A\n",
      " 42%|████▏     | 2811/6672 [06:08<06:04, 10.58it/s]\u001b[A\n",
      " 42%|████▏     | 2813/6672 [06:08<06:10, 10.41it/s]\u001b[A\n",
      " 42%|████▏     | 2815/6672 [06:08<06:42,  9.59it/s]\u001b[A\n",
      " 42%|████▏     | 2816/6672 [06:08<06:40,  9.64it/s]\u001b[A\n",
      " 42%|████▏     | 2818/6672 [06:08<06:17, 10.21it/s]\u001b[A\n",
      " 42%|████▏     | 2820/6672 [06:09<06:19, 10.16it/s]\u001b[A\n",
      " 42%|████▏     | 2822/6672 [06:09<06:37,  9.69it/s]\u001b[A\n",
      " 42%|████▏     | 2823/6672 [06:09<06:42,  9.56it/s]\u001b[A\n",
      " 42%|████▏     | 2825/6672 [06:09<06:16, 10.20it/s]\u001b[A\n",
      " 42%|████▏     | 2827/6672 [06:09<06:08, 10.43it/s]\u001b[A\n",
      " 42%|████▏     | 2829/6672 [06:09<05:23, 11.86it/s]\u001b[A\n",
      " 42%|████▏     | 2831/6672 [06:10<06:15, 10.22it/s]\u001b[A\n",
      " 42%|████▏     | 2833/6672 [06:10<07:12,  8.87it/s]\u001b[A\n",
      " 42%|████▏     | 2834/6672 [06:10<07:20,  8.72it/s]\u001b[A\n",
      " 42%|████▏     | 2835/6672 [06:10<07:11,  8.88it/s]\u001b[A\n",
      " 43%|████▎     | 2837/6672 [06:10<06:44,  9.49it/s]\u001b[A\n",
      " 43%|████▎     | 2838/6672 [06:10<06:40,  9.58it/s]\u001b[A\n",
      " 43%|████▎     | 2839/6672 [06:11<06:54,  9.25it/s]\u001b[A\n",
      " 43%|████▎     | 2840/6672 [06:11<07:27,  8.57it/s]\u001b[A\n",
      " 43%|████▎     | 2841/6672 [06:11<07:40,  8.32it/s]\u001b[A\n",
      " 43%|████▎     | 2842/6672 [06:11<07:51,  8.13it/s]\u001b[A\n",
      " 43%|████▎     | 2843/6672 [06:11<08:04,  7.90it/s]\u001b[A\n",
      " 43%|████▎     | 2844/6672 [06:11<08:17,  7.70it/s]\u001b[A\n",
      " 43%|████▎     | 2845/6672 [06:11<08:08,  7.84it/s]\u001b[A\n",
      " 43%|████▎     | 2847/6672 [06:12<07:20,  8.68it/s]\u001b[A\n",
      " 43%|████▎     | 2848/6672 [06:12<07:10,  8.89it/s]\u001b[A\n",
      " 43%|████▎     | 2850/6672 [06:12<06:31,  9.77it/s]\u001b[A\n",
      " 43%|████▎     | 2851/6672 [06:12<06:29,  9.80it/s]\u001b[A\n",
      " 43%|████▎     | 2852/6672 [06:12<06:34,  9.69it/s]\u001b[A\n",
      " 43%|████▎     | 2853/6672 [06:12<06:47,  9.37it/s]\u001b[A\n",
      " 43%|████▎     | 2855/6672 [06:12<06:46,  9.39it/s]\u001b[A\n",
      " 43%|████▎     | 2856/6672 [06:13<06:40,  9.52it/s]\u001b[A\n",
      " 43%|████▎     | 2857/6672 [06:13<06:49,  9.32it/s]\u001b[A\n",
      " 43%|████▎     | 2858/6672 [06:13<07:23,  8.61it/s]\u001b[A\n",
      " 43%|████▎     | 2859/6672 [06:13<07:53,  8.05it/s]\u001b[A\n",
      " 43%|████▎     | 2860/6672 [06:13<08:03,  7.88it/s]\u001b[A\n",
      " 43%|████▎     | 2862/6672 [06:13<06:59,  9.08it/s]\u001b[A\n",
      " 43%|████▎     | 2864/6672 [06:13<06:22,  9.96it/s]\u001b[A\n",
      " 43%|████▎     | 2865/6672 [06:14<06:37,  9.58it/s]\u001b[A\n",
      " 43%|████▎     | 2866/6672 [06:14<06:40,  9.51it/s]\u001b[A\n",
      " 43%|████▎     | 2868/6672 [06:14<06:11, 10.24it/s]\u001b[A\n",
      " 43%|████▎     | 2870/6672 [06:14<05:55, 10.69it/s]\u001b[A\n",
      " 43%|████▎     | 2872/6672 [06:14<05:42, 11.08it/s]\u001b[A\n",
      " 43%|████▎     | 2874/6672 [06:14<05:31, 11.44it/s]\u001b[A\n",
      " 43%|████▎     | 2876/6672 [06:15<06:09, 10.29it/s]\u001b[A\n",
      " 43%|████▎     | 2878/6672 [06:15<06:09, 10.26it/s]\u001b[A\n",
      " 43%|████▎     | 2880/6672 [06:15<06:15, 10.11it/s]\u001b[A\n",
      " 43%|████▎     | 2882/6672 [06:15<07:18,  8.63it/s]\u001b[A\n",
      " 43%|████▎     | 2883/6672 [06:15<07:22,  8.57it/s]\u001b[A\n",
      " 43%|████▎     | 2884/6672 [06:15<07:21,  8.58it/s]\u001b[A\n",
      " 43%|████▎     | 2885/6672 [06:16<07:11,  8.78it/s]\u001b[A\n",
      " 43%|████▎     | 2887/6672 [06:16<07:12,  8.76it/s]\u001b[A\n",
      " 43%|████▎     | 2888/6672 [06:16<07:04,  8.91it/s]\u001b[A\n",
      " 43%|████▎     | 2889/6672 [06:16<06:54,  9.12it/s]\u001b[A\n",
      " 43%|████▎     | 2891/6672 [06:16<06:16, 10.03it/s]\u001b[A\n",
      " 43%|████▎     | 2893/6672 [06:16<05:59, 10.52it/s]\u001b[A\n",
      " 43%|████▎     | 2895/6672 [06:17<05:55, 10.63it/s]\u001b[A\n",
      " 43%|████▎     | 2897/6672 [06:17<06:46,  9.28it/s]\u001b[A\n",
      " 43%|████▎     | 2898/6672 [06:17<06:55,  9.08it/s]\u001b[A\n",
      " 43%|████▎     | 2899/6672 [06:17<07:03,  8.90it/s]\u001b[A\n",
      " 43%|████▎     | 2900/6672 [06:17<07:12,  8.73it/s]\u001b[A\n",
      " 43%|████▎     | 2901/6672 [06:17<07:19,  8.57it/s]\u001b[A\n",
      " 43%|████▎     | 2902/6672 [06:17<07:31,  8.35it/s]\u001b[A\n",
      " 44%|████▎     | 2904/6672 [06:18<06:42,  9.36it/s]\u001b[A\n",
      " 44%|████▎     | 2906/6672 [06:18<06:02, 10.40it/s]\u001b[A\n",
      " 44%|████▎     | 2908/6672 [06:18<05:45, 10.90it/s]\u001b[A\n",
      " 44%|████▎     | 2910/6672 [06:18<05:33, 11.29it/s]\u001b[A\n",
      " 44%|████▎     | 2912/6672 [06:18<05:53, 10.62it/s]\u001b[A\n",
      " 44%|████▎     | 2914/6672 [06:19<06:00, 10.41it/s]\u001b[A\n",
      " 44%|████▎     | 2916/6672 [06:19<05:47, 10.80it/s]\u001b[A\n",
      " 44%|████▎     | 2918/6672 [06:19<05:40, 11.02it/s]\u001b[A\n",
      " 44%|████▍     | 2920/6672 [06:19<05:32, 11.30it/s]\u001b[A\n",
      " 44%|████▍     | 2922/6672 [06:19<06:07, 10.21it/s]\u001b[A\n",
      " 44%|████▍     | 2924/6672 [06:19<06:02, 10.33it/s]\u001b[A\n",
      " 44%|████▍     | 2926/6672 [06:20<06:25,  9.71it/s]\u001b[A\n",
      " 44%|████▍     | 2928/6672 [06:20<06:06, 10.22it/s]\u001b[A\n",
      " 44%|████▍     | 2930/6672 [06:20<06:11, 10.06it/s]\u001b[A\n",
      " 44%|████▍     | 2932/6672 [06:20<07:52,  7.92it/s]\u001b[A\n",
      " 44%|████▍     | 2933/6672 [06:21<07:59,  7.80it/s]\u001b[A\n",
      " 44%|████▍     | 2934/6672 [06:21<07:47,  7.99it/s]\u001b[A\n",
      " 44%|████▍     | 2935/6672 [06:21<07:28,  8.33it/s]\u001b[A\n",
      " 44%|████▍     | 2936/6672 [06:21<07:43,  8.06it/s]\u001b[A\n",
      " 44%|████▍     | 2937/6672 [06:21<07:41,  8.10it/s]\u001b[A\n",
      " 44%|████▍     | 2939/6672 [06:21<06:46,  9.18it/s]\u001b[A\n",
      " 44%|████▍     | 2940/6672 [06:21<07:22,  8.44it/s]\u001b[A\n",
      " 44%|████▍     | 2941/6672 [06:21<07:10,  8.67it/s]\u001b[A\n",
      " 44%|████▍     | 2943/6672 [06:22<06:22,  9.74it/s]\u001b[A\n",
      " 44%|████▍     | 2944/6672 [06:22<06:26,  9.66it/s]\u001b[A\n",
      " 44%|████▍     | 2946/6672 [06:22<06:02, 10.27it/s]\u001b[A\n",
      " 44%|████▍     | 2948/6672 [06:22<06:01, 10.30it/s]\u001b[A\n",
      " 44%|████▍     | 2950/6672 [06:22<05:40, 10.94it/s]\u001b[A\n",
      " 44%|████▍     | 2952/6672 [06:23<06:05, 10.18it/s]\u001b[A\n",
      " 44%|████▍     | 2954/6672 [06:23<05:58, 10.38it/s]\u001b[A\n",
      " 44%|████▍     | 2956/6672 [06:23<05:54, 10.48it/s]\u001b[A\n",
      " 44%|████▍     | 2958/6672 [06:23<05:30, 11.24it/s]\u001b[A\n",
      " 44%|████▍     | 2960/6672 [06:23<05:22, 11.52it/s]\u001b[A\n",
      " 44%|████▍     | 2962/6672 [06:23<05:17, 11.69it/s]\u001b[A\n",
      " 44%|████▍     | 2964/6672 [06:24<04:58, 12.41it/s]\u001b[A\n",
      " 44%|████▍     | 2966/6672 [06:24<04:55, 12.56it/s]\u001b[A\n",
      " 44%|████▍     | 2968/6672 [06:24<05:29, 11.23it/s]\u001b[A\n",
      " 45%|████▍     | 2970/6672 [06:24<05:26, 11.34it/s]\u001b[A\n",
      " 45%|████▍     | 2972/6672 [06:24<06:11,  9.96it/s]\u001b[A\n",
      " 45%|████▍     | 2974/6672 [06:25<06:10,  9.98it/s]\u001b[A\n",
      " 45%|████▍     | 2976/6672 [06:25<06:10,  9.99it/s]\u001b[A\n",
      " 45%|████▍     | 2978/6672 [06:25<05:44, 10.71it/s]\u001b[A\n",
      " 45%|████▍     | 2980/6672 [06:25<05:30, 11.17it/s]\u001b[A\n",
      " 45%|████▍     | 2982/6672 [06:25<06:50,  8.98it/s]\u001b[A\n",
      " 45%|████▍     | 2983/6672 [06:25<07:03,  8.72it/s]\u001b[A\n",
      " 45%|████▍     | 2984/6672 [06:26<07:20,  8.37it/s]\u001b[A\n",
      " 45%|████▍     | 2985/6672 [06:26<07:32,  8.14it/s]\u001b[A\n",
      " 45%|████▍     | 2986/6672 [06:26<07:39,  8.01it/s]\u001b[A\n",
      " 45%|████▍     | 2987/6672 [06:26<07:18,  8.40it/s]\u001b[A\n",
      " 45%|████▍     | 2988/6672 [06:26<07:22,  8.32it/s]\u001b[A\n",
      " 45%|████▍     | 2989/6672 [06:26<07:08,  8.59it/s]\u001b[A\n",
      " 45%|████▍     | 2990/6672 [06:26<07:15,  8.46it/s]\u001b[A\n",
      " 45%|████▍     | 2991/6672 [06:26<06:56,  8.84it/s]\u001b[A\n",
      " 45%|████▍     | 2993/6672 [06:27<06:49,  8.97it/s]\u001b[A\n",
      " 45%|████▍     | 2994/6672 [06:27<06:46,  9.06it/s]\u001b[A\n",
      " 45%|████▍     | 2995/6672 [06:27<06:40,  9.18it/s]\u001b[A\n",
      " 45%|████▍     | 2997/6672 [06:27<05:55, 10.35it/s]\u001b[A\n",
      " 45%|████▍     | 2999/6672 [06:27<06:31,  9.37it/s]\u001b[A\n",
      " 45%|████▍     | 3000/6672 [06:28<09:01,  6.78it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 45%|████▍     | 3000/6672 [06:28<09:01,  6.78it/s]\u001b[A\n",
      " 45%|████▍     | 3001/6672 [06:28<09:37,  6.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0333, 'learning_rate': 3.8471121679036236e-05, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▍     | 3002/6672 [06:28<09:00,  6.79it/s]\u001b[A\n",
      " 45%|████▌     | 3003/6672 [06:28<08:39,  7.07it/s]\u001b[A\n",
      " 45%|████▌     | 3005/6672 [06:28<07:42,  7.92it/s]\u001b[A\n",
      " 45%|████▌     | 3007/6672 [06:28<06:42,  9.10it/s]\u001b[A\n",
      " 45%|████▌     | 3008/6672 [06:29<06:58,  8.75it/s]\u001b[A\n",
      " 45%|████▌     | 3009/6672 [06:29<06:51,  8.91it/s]\u001b[A\n",
      " 45%|████▌     | 3011/6672 [06:29<06:19,  9.66it/s]\u001b[A\n",
      " 45%|████▌     | 3013/6672 [06:29<05:47, 10.54it/s]\u001b[A\n",
      " 45%|████▌     | 3015/6672 [06:29<05:15, 11.59it/s]\u001b[A\n",
      " 45%|████▌     | 3017/6672 [06:29<04:58, 12.25it/s]\u001b[A\n",
      " 45%|████▌     | 3019/6672 [06:29<05:19, 11.43it/s]\u001b[A\n",
      " 45%|████▌     | 3021/6672 [06:30<05:47, 10.51it/s]\u001b[A\n",
      " 45%|████▌     | 3023/6672 [06:30<05:34, 10.89it/s]\u001b[A\n",
      " 45%|████▌     | 3025/6672 [06:30<05:25, 11.21it/s]\u001b[A\n",
      " 45%|████▌     | 3027/6672 [06:30<05:15, 11.55it/s]\u001b[A\n",
      " 45%|████▌     | 3029/6672 [06:30<05:13, 11.62it/s]\u001b[A\n",
      " 45%|████▌     | 3031/6672 [06:31<06:02, 10.03it/s]\u001b[A\n",
      " 45%|████▌     | 3033/6672 [06:31<06:20,  9.56it/s]\u001b[A\n",
      " 45%|████▌     | 3035/6672 [06:31<06:12,  9.76it/s]\u001b[A\n",
      " 46%|████▌     | 3037/6672 [06:31<06:31,  9.28it/s]\u001b[A\n",
      " 46%|████▌     | 3039/6672 [06:31<06:06,  9.91it/s]\u001b[A\n",
      " 46%|████▌     | 3041/6672 [06:32<05:43, 10.56it/s]\u001b[A\n",
      " 46%|████▌     | 3043/6672 [06:32<05:41, 10.63it/s]\u001b[A\n",
      " 46%|████▌     | 3045/6672 [06:32<05:14, 11.51it/s]\u001b[A\n",
      " 46%|████▌     | 3047/6672 [06:32<04:48, 12.55it/s]\u001b[A\n",
      " 46%|████▌     | 3049/6672 [06:32<04:31, 13.37it/s]\u001b[A\n",
      " 46%|████▌     | 3051/6672 [06:32<05:14, 11.52it/s]\u001b[A\n",
      " 46%|████▌     | 3053/6672 [06:33<05:19, 11.33it/s]\u001b[A\n",
      " 46%|████▌     | 3055/6672 [06:33<05:13, 11.52it/s]\u001b[A\n",
      " 46%|████▌     | 3057/6672 [06:33<05:05, 11.84it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 66.57it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3058\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3058/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4093826413154602, 'eval_f1': 0.7661248215334153, 'eval_recall': 0.7430995108614055, 'eval_precision': 0.7957621904322412, 'eval_runtime': 4.3987, 'eval_samples_per_second': 288.719, 'eval_steps_per_second': 72.293, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3058/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3058/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3058/special_tokens_map.json\n",
      "\n",
      " 46%|████▌     | 3059/6672 [06:41<1:20:36,  1.34s/it]\u001b[A\n",
      " 46%|████▌     | 3060/6672 [06:42<1:07:48,  1.13s/it]\u001b[A\n",
      " 46%|████▌     | 3061/6672 [06:42<55:42,  1.08it/s]  \u001b[A\n",
      " 46%|████▌     | 3062/6672 [06:42<44:56,  1.34it/s]\u001b[A\n",
      " 46%|████▌     | 3063/6672 [06:42<35:35,  1.69it/s]\u001b[A\n",
      " 46%|████▌     | 3065/6672 [06:42<23:58,  2.51it/s]\u001b[A\n",
      " 46%|████▌     | 3066/6672 [06:42<20:31,  2.93it/s]\u001b[A\n",
      " 46%|████▌     | 3067/6672 [06:42<17:17,  3.47it/s]\u001b[A\n",
      " 46%|████▌     | 3069/6672 [06:43<12:29,  4.81it/s]\u001b[A\n",
      " 46%|████▌     | 3070/6672 [06:43<11:06,  5.40it/s]\u001b[A\n",
      " 46%|████▌     | 3072/6672 [06:43<08:44,  6.87it/s]\u001b[A\n",
      " 46%|████▌     | 3074/6672 [06:43<07:17,  8.22it/s]\u001b[A\n",
      " 46%|████▌     | 3076/6672 [06:43<06:20,  9.45it/s]\u001b[A\n",
      " 46%|████▌     | 3078/6672 [06:43<05:45, 10.40it/s]\u001b[A\n",
      " 46%|████▌     | 3080/6672 [06:44<05:26, 11.01it/s]\u001b[A\n",
      " 46%|████▌     | 3082/6672 [06:44<05:43, 10.45it/s]\u001b[A\n",
      " 46%|████▌     | 3084/6672 [06:44<05:43, 10.44it/s]\u001b[A\n",
      " 46%|████▋     | 3086/6672 [06:44<05:36, 10.67it/s]\u001b[A\n",
      " 46%|████▋     | 3088/6672 [06:44<05:24, 11.05it/s]\u001b[A\n",
      " 46%|████▋     | 3090/6672 [06:44<05:14, 11.39it/s]\u001b[A\n",
      " 46%|████▋     | 3092/6672 [06:45<05:16, 11.30it/s]\u001b[A\n",
      " 46%|████▋     | 3094/6672 [06:45<05:17, 11.27it/s]\u001b[A\n",
      " 46%|████▋     | 3096/6672 [06:45<05:52, 10.15it/s]\u001b[A\n",
      " 46%|████▋     | 3098/6672 [06:45<05:40, 10.49it/s]\u001b[A\n",
      " 46%|████▋     | 3100/6672 [06:45<05:03, 11.78it/s]\u001b[A\n",
      " 46%|████▋     | 3102/6672 [06:45<04:36, 12.90it/s]\u001b[A\n",
      " 47%|████▋     | 3104/6672 [06:46<04:35, 12.96it/s]\u001b[A\n",
      " 47%|████▋     | 3106/6672 [06:46<04:36, 12.88it/s]\u001b[A\n",
      " 47%|████▋     | 3108/6672 [06:46<04:48, 12.35it/s]\u001b[A\n",
      " 47%|████▋     | 3110/6672 [06:46<06:14,  9.50it/s]\u001b[A\n",
      " 47%|████▋     | 3112/6672 [06:47<06:33,  9.05it/s]\u001b[A\n",
      " 47%|████▋     | 3113/6672 [06:47<06:31,  9.08it/s]\u001b[A\n",
      " 47%|████▋     | 3114/6672 [06:47<06:27,  9.19it/s]\u001b[A\n",
      " 47%|████▋     | 3115/6672 [06:47<06:32,  9.05it/s]\u001b[A\n",
      " 47%|████▋     | 3116/6672 [06:47<06:54,  8.59it/s]\u001b[A\n",
      " 47%|████▋     | 3117/6672 [06:47<07:19,  8.09it/s]\u001b[A\n",
      " 47%|████▋     | 3118/6672 [06:47<07:00,  8.45it/s]\u001b[A\n",
      " 47%|████▋     | 3119/6672 [06:47<07:01,  8.43it/s]\u001b[A\n",
      " 47%|████▋     | 3120/6672 [06:47<07:17,  8.11it/s]\u001b[A\n",
      " 47%|████▋     | 3121/6672 [06:48<06:58,  8.49it/s]\u001b[A\n",
      " 47%|████▋     | 3122/6672 [06:48<06:54,  8.57it/s]\u001b[A\n",
      " 47%|████▋     | 3124/6672 [06:48<05:59,  9.87it/s]\u001b[A\n",
      " 47%|████▋     | 3126/6672 [06:48<05:25, 10.91it/s]\u001b[A\n",
      " 47%|████▋     | 3128/6672 [06:48<05:07, 11.54it/s]\u001b[A\n",
      " 47%|████▋     | 3130/6672 [06:48<05:00, 11.79it/s]\u001b[A\n",
      " 47%|████▋     | 3132/6672 [06:48<04:52, 12.12it/s]\u001b[A\n",
      " 47%|████▋     | 3134/6672 [06:49<04:47, 12.29it/s]\u001b[A\n",
      " 47%|████▋     | 3136/6672 [06:49<04:49, 12.19it/s]\u001b[A\n",
      " 47%|████▋     | 3138/6672 [06:49<05:50, 10.08it/s]\u001b[A\n",
      " 47%|████▋     | 3140/6672 [06:49<05:41, 10.33it/s]\u001b[A\n",
      " 47%|████▋     | 3142/6672 [06:49<05:36, 10.50it/s]\u001b[A\n",
      " 47%|████▋     | 3144/6672 [06:50<05:58,  9.83it/s]\u001b[A\n",
      " 47%|████▋     | 3146/6672 [06:50<06:35,  8.91it/s]\u001b[A\n",
      " 47%|████▋     | 3147/6672 [06:50<06:54,  8.51it/s]\u001b[A\n",
      " 47%|████▋     | 3148/6672 [06:50<06:44,  8.71it/s]\u001b[A\n",
      " 47%|████▋     | 3149/6672 [06:50<06:49,  8.59it/s]\u001b[A\n",
      " 47%|████▋     | 3150/6672 [06:50<07:11,  8.17it/s]\u001b[A\n",
      " 47%|████▋     | 3151/6672 [06:51<06:54,  8.49it/s]\u001b[A\n",
      " 47%|████▋     | 3152/6672 [06:51<07:03,  8.32it/s]\u001b[A\n",
      " 47%|████▋     | 3153/6672 [06:51<06:48,  8.62it/s]\u001b[A\n",
      " 47%|████▋     | 3155/6672 [06:51<05:58,  9.82it/s]\u001b[A\n",
      " 47%|████▋     | 3157/6672 [06:51<05:39, 10.35it/s]\u001b[A\n",
      " 47%|████▋     | 3159/6672 [06:51<06:08,  9.53it/s]\u001b[A\n",
      " 47%|████▋     | 3160/6672 [06:52<06:34,  8.90it/s]\u001b[A\n",
      " 47%|████▋     | 3161/6672 [06:52<06:41,  8.74it/s]\u001b[A\n",
      " 47%|████▋     | 3162/6672 [06:52<06:36,  8.86it/s]\u001b[A\n",
      " 47%|████▋     | 3164/6672 [06:52<06:10,  9.46it/s]\u001b[A\n",
      " 47%|████▋     | 3166/6672 [06:52<05:51,  9.96it/s]\u001b[A\n",
      " 47%|████▋     | 3167/6672 [06:52<06:07,  9.53it/s]\u001b[A\n",
      " 47%|████▋     | 3168/6672 [06:52<06:03,  9.63it/s]\u001b[A\n",
      " 48%|████▊     | 3170/6672 [06:53<06:19,  9.23it/s]\u001b[A\n",
      " 48%|████▊     | 3171/6672 [06:53<06:39,  8.76it/s]\u001b[A\n",
      " 48%|████▊     | 3173/6672 [06:53<06:43,  8.67it/s]\u001b[A\n",
      " 48%|████▊     | 3174/6672 [06:53<07:04,  8.24it/s]\u001b[A\n",
      " 48%|████▊     | 3175/6672 [06:53<07:00,  8.31it/s]\u001b[A\n",
      " 48%|████▊     | 3176/6672 [06:53<06:54,  8.43it/s]\u001b[A\n",
      " 48%|████▊     | 3177/6672 [06:53<06:37,  8.79it/s]\u001b[A\n",
      " 48%|████▊     | 3179/6672 [06:54<06:17,  9.25it/s]\u001b[A\n",
      " 48%|████▊     | 3181/6672 [06:54<05:44, 10.14it/s]\u001b[A\n",
      " 48%|████▊     | 3183/6672 [06:54<05:25, 10.74it/s]\u001b[A\n",
      " 48%|████▊     | 3185/6672 [06:54<05:40, 10.23it/s]\u001b[A\n",
      " 48%|████▊     | 3187/6672 [06:54<06:22,  9.10it/s]\u001b[A\n",
      " 48%|████▊     | 3188/6672 [06:55<06:16,  9.25it/s]\u001b[A\n",
      " 48%|████▊     | 3189/6672 [06:55<06:11,  9.39it/s]\u001b[A\n",
      " 48%|████▊     | 3190/6672 [06:55<06:09,  9.43it/s]\u001b[A\n",
      " 48%|████▊     | 3191/6672 [06:55<06:19,  9.17it/s]\u001b[A\n",
      " 48%|████▊     | 3192/6672 [06:55<06:34,  8.82it/s]\u001b[A\n",
      " 48%|████▊     | 3193/6672 [06:55<06:38,  8.72it/s]\u001b[A\n",
      " 48%|████▊     | 3195/6672 [06:55<05:47, 10.00it/s]\u001b[A\n",
      " 48%|████▊     | 3196/6672 [06:55<05:48,  9.98it/s]\u001b[A\n",
      " 48%|████▊     | 3198/6672 [06:56<05:27, 10.60it/s]\u001b[A\n",
      " 48%|████▊     | 3200/6672 [06:56<05:54,  9.79it/s]\u001b[A\n",
      " 48%|████▊     | 3201/6672 [06:56<06:04,  9.51it/s]\u001b[A\n",
      " 48%|████▊     | 3202/6672 [06:56<06:25,  9.01it/s]\u001b[A\n",
      " 48%|████▊     | 3204/6672 [06:56<05:58,  9.66it/s]\u001b[A\n",
      " 48%|████▊     | 3206/6672 [06:56<05:36, 10.29it/s]\u001b[A\n",
      " 48%|████▊     | 3208/6672 [06:57<05:22, 10.73it/s]\u001b[A\n",
      " 48%|████▊     | 3210/6672 [06:57<06:29,  8.88it/s]\u001b[A\n",
      " 48%|████▊     | 3211/6672 [06:57<06:58,  8.28it/s]\u001b[A\n",
      " 48%|████▊     | 3212/6672 [06:57<07:19,  7.87it/s]\u001b[A\n",
      " 48%|████▊     | 3213/6672 [06:57<07:19,  7.88it/s]\u001b[A\n",
      " 48%|████▊     | 3214/6672 [06:57<07:46,  7.42it/s]\u001b[A\n",
      " 48%|████▊     | 3215/6672 [06:58<07:54,  7.29it/s]\u001b[A\n",
      " 48%|████▊     | 3216/6672 [06:58<07:58,  7.22it/s]\u001b[A\n",
      " 48%|████▊     | 3217/6672 [06:58<08:01,  7.18it/s]\u001b[A\n",
      " 48%|████▊     | 3218/6672 [06:58<08:00,  7.19it/s]\u001b[A\n",
      " 48%|████▊     | 3219/6672 [06:58<08:00,  7.18it/s]\u001b[A\n",
      " 48%|████▊     | 3220/6672 [06:58<07:24,  7.76it/s]\u001b[A\n",
      " 48%|████▊     | 3221/6672 [06:58<07:20,  7.84it/s]\u001b[A\n",
      " 48%|████▊     | 3222/6672 [06:59<07:03,  8.15it/s]\u001b[A\n",
      " 48%|████▊     | 3224/6672 [06:59<06:07,  9.38it/s]\u001b[A\n",
      " 48%|████▊     | 3225/6672 [06:59<06:07,  9.37it/s]\u001b[A\n",
      " 48%|████▊     | 3226/6672 [06:59<06:31,  8.80it/s]\u001b[A\n",
      " 48%|████▊     | 3227/6672 [06:59<06:21,  9.03it/s]\u001b[A\n",
      " 48%|████▊     | 3229/6672 [06:59<05:30, 10.41it/s]\u001b[A\n",
      " 48%|████▊     | 3231/6672 [06:59<05:13, 10.99it/s]\u001b[A\n",
      " 48%|████▊     | 3233/6672 [07:00<05:11, 11.04it/s]\u001b[A\n",
      " 48%|████▊     | 3235/6672 [07:00<04:59, 11.47it/s]\u001b[A\n",
      " 49%|████▊     | 3237/6672 [07:00<04:38, 12.34it/s]\u001b[A\n",
      " 49%|████▊     | 3239/6672 [07:00<04:29, 12.75it/s]\u001b[A\n",
      " 49%|████▊     | 3241/6672 [07:00<04:44, 12.05it/s]\u001b[A\n",
      " 49%|████▊     | 3243/6672 [07:00<04:43, 12.10it/s]\u001b[A\n",
      " 49%|████▊     | 3245/6672 [07:00<04:41, 12.19it/s]\u001b[A\n",
      " 49%|████▊     | 3247/6672 [07:01<05:49,  9.80it/s]\u001b[A\n",
      " 49%|████▊     | 3249/6672 [07:01<06:21,  8.97it/s]\u001b[A\n",
      " 49%|████▊     | 3250/6672 [07:01<06:36,  8.62it/s]\u001b[A\n",
      " 49%|████▊     | 3251/6672 [07:01<06:33,  8.68it/s]\u001b[A\n",
      " 49%|████▊     | 3252/6672 [07:01<06:36,  8.62it/s]\u001b[A\n",
      " 49%|████▉     | 3253/6672 [07:02<06:24,  8.89it/s]\u001b[A\n",
      " 49%|████▉     | 3254/6672 [07:02<06:18,  9.03it/s]\u001b[A\n",
      " 49%|████▉     | 3256/6672 [07:02<05:48,  9.81it/s]\u001b[A\n",
      " 49%|████▉     | 3258/6672 [07:02<05:14, 10.85it/s]\u001b[A\n",
      " 49%|████▉     | 3260/6672 [07:02<06:36,  8.60it/s]\u001b[A\n",
      " 49%|████▉     | 3261/6672 [07:02<06:51,  8.30it/s]\u001b[A\n",
      " 49%|████▉     | 3262/6672 [07:03<06:58,  8.15it/s]\u001b[A\n",
      " 49%|████▉     | 3263/6672 [07:03<06:45,  8.40it/s]\u001b[A\n",
      " 49%|████▉     | 3265/6672 [07:03<06:11,  9.18it/s]\u001b[A\n",
      " 49%|████▉     | 3266/6672 [07:03<06:23,  8.89it/s]\u001b[A\n",
      " 49%|████▉     | 3267/6672 [07:03<06:13,  9.11it/s]\u001b[A\n",
      " 49%|████▉     | 3268/6672 [07:03<06:09,  9.22it/s]\u001b[A\n",
      " 49%|████▉     | 3270/6672 [07:03<05:34, 10.18it/s]\u001b[A\n",
      " 49%|████▉     | 3272/6672 [07:04<05:40,  9.97it/s]\u001b[A\n",
      " 49%|████▉     | 3274/6672 [07:04<05:19, 10.62it/s]\u001b[A\n",
      " 49%|████▉     | 3276/6672 [07:04<05:43,  9.87it/s]\u001b[A\n",
      " 49%|████▉     | 3278/6672 [07:04<05:54,  9.59it/s]\u001b[A\n",
      " 49%|████▉     | 3279/6672 [07:04<05:58,  9.47it/s]\u001b[A\n",
      " 49%|████▉     | 3280/6672 [07:04<06:09,  9.17it/s]\u001b[A\n",
      " 49%|████▉     | 3282/6672 [07:05<05:37, 10.04it/s]\u001b[A\n",
      " 49%|████▉     | 3284/6672 [07:05<05:17, 10.67it/s]\u001b[A\n",
      " 49%|████▉     | 3286/6672 [07:05<05:02, 11.20it/s]\u001b[A\n",
      " 49%|████▉     | 3288/6672 [07:05<04:54, 11.49it/s]\u001b[A\n",
      " 49%|████▉     | 3290/6672 [07:05<05:06, 11.05it/s]\u001b[A\n",
      " 49%|████▉     | 3292/6672 [07:05<05:20, 10.55it/s]\u001b[A\n",
      " 49%|████▉     | 3294/6672 [07:06<06:13,  9.04it/s]\u001b[A\n",
      " 49%|████▉     | 3295/6672 [07:06<06:38,  8.48it/s]\u001b[A\n",
      " 49%|████▉     | 3296/6672 [07:06<06:48,  8.27it/s]\u001b[A\n",
      " 49%|████▉     | 3297/6672 [07:06<06:59,  8.04it/s]\u001b[A\n",
      " 49%|████▉     | 3298/6672 [07:06<06:40,  8.43it/s]\u001b[A\n",
      " 49%|████▉     | 3300/6672 [07:06<06:05,  9.23it/s]\u001b[A\n",
      " 49%|████▉     | 3301/6672 [07:07<06:33,  8.56it/s]\u001b[A\n",
      " 50%|████▉     | 3303/6672 [07:07<05:47,  9.70it/s]\u001b[A\n",
      " 50%|████▉     | 3305/6672 [07:07<05:29, 10.22it/s]\u001b[A\n",
      " 50%|████▉     | 3307/6672 [07:07<05:21, 10.47it/s]\u001b[A\n",
      " 50%|████▉     | 3309/6672 [07:07<06:15,  8.96it/s]\u001b[A\n",
      " 50%|████▉     | 3310/6672 [07:08<06:22,  8.78it/s]\u001b[A\n",
      " 50%|████▉     | 3311/6672 [07:08<06:38,  8.42it/s]\u001b[A\n",
      " 50%|████▉     | 3312/6672 [07:08<06:58,  8.04it/s]\u001b[A\n",
      " 50%|████▉     | 3313/6672 [07:08<07:44,  7.24it/s]\u001b[A\n",
      " 50%|████▉     | 3314/6672 [07:08<07:43,  7.25it/s]\u001b[A\n",
      " 50%|████▉     | 3315/6672 [07:08<07:33,  7.40it/s]\u001b[A\n",
      " 50%|████▉     | 3316/6672 [07:08<07:54,  7.08it/s]\u001b[A\n",
      " 50%|████▉     | 3317/6672 [07:09<07:18,  7.66it/s]\u001b[A\n",
      " 50%|████▉     | 3319/6672 [07:09<06:07,  9.12it/s]\u001b[A\n",
      " 50%|████▉     | 3321/6672 [07:09<05:39,  9.88it/s]\u001b[A\n",
      " 50%|████▉     | 3323/6672 [07:09<05:24, 10.32it/s]\u001b[A\n",
      " 50%|████▉     | 3325/6672 [07:09<05:09, 10.82it/s]\u001b[A\n",
      " 50%|████▉     | 3327/6672 [07:09<05:17, 10.55it/s]\u001b[A\n",
      " 50%|████▉     | 3329/6672 [07:10<05:50,  9.54it/s]\u001b[A\n",
      " 50%|████▉     | 3330/6672 [07:10<05:54,  9.43it/s]\u001b[A\n",
      " 50%|████▉     | 3331/6672 [07:10<06:10,  9.01it/s]\u001b[A\n",
      " 50%|████▉     | 3332/6672 [07:10<06:30,  8.54it/s]\u001b[A\n",
      " 50%|████▉     | 3333/6672 [07:10<06:33,  8.48it/s]\u001b[A\n",
      " 50%|████▉     | 3335/6672 [07:10<05:52,  9.47it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 71.92it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3336\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3336/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45392075181007385, 'eval_f1': 0.7544864972660805, 'eval_recall': 0.7471058641316802, 'eval_precision': 0.7624815337093742, 'eval_runtime': 4.385, 'eval_samples_per_second': 289.623, 'eval_steps_per_second': 72.52, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3336/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3336/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3336/special_tokens_map.json\n",
      "\n",
      " 50%|█████     | 3337/6672 [07:19<1:28:16,  1.59s/it]\u001b[A\n",
      " 50%|█████     | 3338/6672 [07:19<1:11:43,  1.29s/it]\u001b[A\n",
      " 50%|█████     | 3339/6672 [07:19<56:42,  1.02s/it]  \u001b[A\n",
      " 50%|█████     | 3340/6672 [07:19<44:23,  1.25it/s]\u001b[A\n",
      " 50%|█████     | 3341/6672 [07:19<34:49,  1.59it/s]\u001b[A\n",
      " 50%|█████     | 3342/6672 [07:19<27:33,  2.01it/s]\u001b[A\n",
      " 50%|█████     | 3343/6672 [07:19<21:43,  2.55it/s]\u001b[A\n",
      " 50%|█████     | 3344/6672 [07:19<17:38,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 3345/6672 [07:20<15:11,  3.65it/s]\u001b[A\n",
      " 50%|█████     | 3346/6672 [07:20<13:10,  4.21it/s]\u001b[A\n",
      " 50%|█████     | 3347/6672 [07:20<11:33,  4.80it/s]\u001b[A\n",
      " 50%|█████     | 3348/6672 [07:20<10:44,  5.15it/s]\u001b[A\n",
      " 50%|█████     | 3349/6672 [07:20<09:13,  6.01it/s]\u001b[A\n",
      " 50%|█████     | 3351/6672 [07:20<07:07,  7.77it/s]\u001b[A\n",
      " 50%|█████     | 3353/6672 [07:21<05:52,  9.41it/s]\u001b[A\n",
      " 50%|█████     | 3355/6672 [07:21<05:16, 10.48it/s]\u001b[A\n",
      " 50%|█████     | 3357/6672 [07:21<05:05, 10.85it/s]\u001b[A\n",
      " 50%|█████     | 3359/6672 [07:21<05:31,  9.98it/s]\u001b[A\n",
      " 50%|█████     | 3361/6672 [07:21<05:24, 10.22it/s]\u001b[A\n",
      " 50%|█████     | 3363/6672 [07:21<05:07, 10.76it/s]\u001b[A\n",
      " 50%|█████     | 3365/6672 [07:22<05:18, 10.37it/s]\u001b[A\n",
      " 50%|█████     | 3367/6672 [07:22<05:45,  9.56it/s]\u001b[A\n",
      " 50%|█████     | 3368/6672 [07:22<05:53,  9.35it/s]\u001b[A\n",
      " 51%|█████     | 3370/6672 [07:22<05:13, 10.52it/s]\u001b[A\n",
      " 51%|█████     | 3372/6672 [07:22<04:53, 11.23it/s]\u001b[A\n",
      " 51%|█████     | 3374/6672 [07:23<05:37,  9.78it/s]\u001b[A\n",
      " 51%|█████     | 3376/6672 [07:23<05:52,  9.35it/s]\u001b[A\n",
      " 51%|█████     | 3378/6672 [07:23<05:26, 10.09it/s]\u001b[A\n",
      " 51%|█████     | 3380/6672 [07:23<05:04, 10.80it/s]\u001b[A\n",
      " 51%|█████     | 3382/6672 [07:23<05:16, 10.39it/s]\u001b[A\n",
      " 51%|█████     | 3384/6672 [07:24<05:22, 10.20it/s]\u001b[A\n",
      " 51%|█████     | 3386/6672 [07:24<06:04,  9.02it/s]\u001b[A\n",
      " 51%|█████     | 3387/6672 [07:24<07:09,  7.64it/s]\u001b[A\n",
      " 51%|█████     | 3388/6672 [07:24<07:15,  7.54it/s]\u001b[A\n",
      " 51%|█████     | 3389/6672 [07:24<07:03,  7.76it/s]\u001b[A\n",
      " 51%|█████     | 3390/6672 [07:24<06:47,  8.05it/s]\u001b[A\n",
      " 51%|█████     | 3391/6672 [07:24<06:27,  8.46it/s]\u001b[A\n",
      " 51%|█████     | 3393/6672 [07:25<05:51,  9.33it/s]\u001b[A\n",
      " 51%|█████     | 3395/6672 [07:25<05:28,  9.98it/s]\u001b[A\n",
      " 51%|█████     | 3397/6672 [07:25<05:12, 10.48it/s]\u001b[A\n",
      " 51%|█████     | 3399/6672 [07:25<05:27, 10.00it/s]\u001b[A\n",
      " 51%|█████     | 3401/6672 [07:25<05:17, 10.32it/s]\u001b[A\n",
      " 51%|█████     | 3403/6672 [07:26<05:35,  9.75it/s]\u001b[A\n",
      " 51%|█████     | 3405/6672 [07:26<05:19, 10.21it/s]\u001b[A\n",
      " 51%|█████     | 3407/6672 [07:26<05:02, 10.81it/s]\u001b[A\n",
      " 51%|█████     | 3409/6672 [07:26<05:27,  9.96it/s]\u001b[A\n",
      " 51%|█████     | 3411/6672 [07:26<05:10, 10.50it/s]\u001b[A\n",
      " 51%|█████     | 3413/6672 [07:27<04:58, 10.90it/s]\u001b[A\n",
      " 51%|█████     | 3415/6672 [07:27<05:30,  9.85it/s]\u001b[A\n",
      " 51%|█████     | 3417/6672 [07:27<05:32,  9.78it/s]\u001b[A\n",
      " 51%|█████     | 3419/6672 [07:27<05:22, 10.10it/s]\u001b[A\n",
      " 51%|█████▏    | 3421/6672 [07:27<05:06, 10.61it/s]\u001b[A\n",
      " 51%|█████▏    | 3423/6672 [07:28<05:22, 10.07it/s]\u001b[A\n",
      " 51%|█████▏    | 3425/6672 [07:28<05:34,  9.70it/s]\u001b[A\n",
      " 51%|█████▏    | 3426/6672 [07:28<05:33,  9.72it/s]\u001b[A\n",
      " 51%|█████▏    | 3427/6672 [07:28<05:40,  9.53it/s]\u001b[A\n",
      " 51%|█████▏    | 3429/6672 [07:28<05:17, 10.20it/s]\u001b[A\n",
      " 51%|█████▏    | 3431/6672 [07:28<04:59, 10.80it/s]\u001b[A\n",
      " 51%|█████▏    | 3433/6672 [07:29<05:48,  9.30it/s]\u001b[A\n",
      " 51%|█████▏    | 3434/6672 [07:29<05:51,  9.20it/s]\u001b[A\n",
      " 51%|█████▏    | 3435/6672 [07:29<06:00,  8.98it/s]\u001b[A\n",
      " 52%|█████▏    | 3437/6672 [07:29<06:12,  8.69it/s]\u001b[A\n",
      " 52%|█████▏    | 3438/6672 [07:29<06:25,  8.38it/s]\u001b[A\n",
      " 52%|█████▏    | 3439/6672 [07:29<06:24,  8.40it/s]\u001b[A\n",
      " 52%|█████▏    | 3440/6672 [07:29<06:15,  8.60it/s]\u001b[A\n",
      " 52%|█████▏    | 3441/6672 [07:30<06:04,  8.86it/s]\u001b[A\n",
      " 52%|█████▏    | 3442/6672 [07:30<06:16,  8.57it/s]\u001b[A\n",
      " 52%|█████▏    | 3443/6672 [07:30<06:06,  8.81it/s]\u001b[A\n",
      " 52%|█████▏    | 3445/6672 [07:30<05:38,  9.52it/s]\u001b[A\n",
      " 52%|█████▏    | 3447/6672 [07:30<05:23,  9.98it/s]\u001b[A\n",
      " 52%|█████▏    | 3448/6672 [07:30<05:36,  9.59it/s]\u001b[A\n",
      " 52%|█████▏    | 3449/6672 [07:30<05:40,  9.47it/s]\u001b[A\n",
      " 52%|█████▏    | 3451/6672 [07:31<05:02, 10.63it/s]\u001b[A\n",
      " 52%|█████▏    | 3453/6672 [07:31<05:35,  9.59it/s]\u001b[A\n",
      " 52%|█████▏    | 3455/6672 [07:31<05:13, 10.26it/s]\u001b[A\n",
      " 52%|█████▏    | 3457/6672 [07:31<04:57, 10.82it/s]\u001b[A\n",
      " 52%|█████▏    | 3459/6672 [07:31<04:48, 11.14it/s]\u001b[A\n",
      " 52%|█████▏    | 3461/6672 [07:31<04:43, 11.32it/s]\u001b[A\n",
      " 52%|█████▏    | 3463/6672 [07:32<04:34, 11.71it/s]\u001b[A\n",
      " 52%|█████▏    | 3465/6672 [07:32<04:53, 10.94it/s]\u001b[A\n",
      " 52%|█████▏    | 3467/6672 [07:32<04:45, 11.21it/s]\u001b[A\n",
      " 52%|█████▏    | 3469/6672 [07:32<04:57, 10.78it/s]\u001b[A\n",
      " 52%|█████▏    | 3471/6672 [07:33<05:41,  9.38it/s]\u001b[A\n",
      " 52%|█████▏    | 3472/6672 [07:33<05:58,  8.93it/s]\u001b[A\n",
      " 52%|█████▏    | 3473/6672 [07:33<05:54,  9.02it/s]\u001b[A\n",
      " 52%|█████▏    | 3475/6672 [07:33<05:28,  9.73it/s]\u001b[A\n",
      " 52%|█████▏    | 3476/6672 [07:33<05:34,  9.54it/s]\u001b[A\n",
      " 52%|█████▏    | 3478/6672 [07:33<05:00, 10.62it/s]\u001b[A\n",
      " 52%|█████▏    | 3480/6672 [07:33<04:51, 10.93it/s]\u001b[A\n",
      " 52%|█████▏    | 3482/6672 [07:34<05:28,  9.71it/s]\u001b[A\n",
      " 52%|█████▏    | 3484/6672 [07:34<05:00, 10.62it/s]\u001b[A\n",
      " 52%|█████▏    | 3486/6672 [07:34<05:19,  9.97it/s]\u001b[A\n",
      " 52%|█████▏    | 3488/6672 [07:34<06:44,  7.88it/s]\u001b[A\n",
      " 52%|█████▏    | 3489/6672 [07:35<06:48,  7.80it/s]\u001b[A\n",
      " 52%|█████▏    | 3490/6672 [07:35<06:37,  8.01it/s]\u001b[A\n",
      " 52%|█████▏    | 3491/6672 [07:35<06:23,  8.29it/s]\u001b[A\n",
      " 52%|█████▏    | 3493/6672 [07:35<06:01,  8.79it/s]\u001b[A\n",
      " 52%|█████▏    | 3494/6672 [07:35<06:18,  8.39it/s]\u001b[A\n",
      " 52%|█████▏    | 3495/6672 [07:35<06:08,  8.62it/s]\u001b[A\n",
      " 52%|█████▏    | 3497/6672 [07:35<05:31,  9.58it/s]\u001b[A\n",
      " 52%|█████▏    | 3498/6672 [07:35<05:36,  9.42it/s]\u001b[A\n",
      " 52%|█████▏    | 3499/6672 [07:36<06:01,  8.77it/s]\u001b[A\n",
      " 52%|█████▏    | 3500/6672 [07:36<08:28,  6.23it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 52%|█████▏    | 3500/6672 [07:36<08:28,  6.23it/s]\u001b[A\n",
      " 52%|█████▏    | 3501/6672 [07:36<07:56,  6.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0279, 'learning_rate': 3.323267918461409e-05, 'epoch': 12.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 3503/6672 [07:36<06:31,  8.09it/s]\u001b[A\n",
      " 53%|█████▎    | 3505/6672 [07:36<05:33,  9.50it/s]\u001b[A\n",
      " 53%|█████▎    | 3507/6672 [07:37<05:23,  9.79it/s]\u001b[A\n",
      " 53%|█████▎    | 3509/6672 [07:37<05:07, 10.29it/s]\u001b[A\n",
      " 53%|█████▎    | 3511/6672 [07:37<05:33,  9.49it/s]\u001b[A\n",
      " 53%|█████▎    | 3513/6672 [07:37<05:12, 10.09it/s]\u001b[A\n",
      " 53%|█████▎    | 3515/6672 [07:37<05:48,  9.05it/s]\u001b[A\n",
      " 53%|█████▎    | 3516/6672 [07:38<05:48,  9.06it/s]\u001b[A\n",
      " 53%|█████▎    | 3517/6672 [07:38<06:02,  8.70it/s]\u001b[A\n",
      " 53%|█████▎    | 3518/6672 [07:38<06:24,  8.20it/s]\u001b[A\n",
      " 53%|█████▎    | 3519/6672 [07:38<06:34,  7.99it/s]\u001b[A\n",
      " 53%|█████▎    | 3521/6672 [07:38<05:38,  9.30it/s]\u001b[A\n",
      " 53%|█████▎    | 3523/6672 [07:38<04:46, 10.98it/s]\u001b[A\n",
      " 53%|█████▎    | 3525/6672 [07:38<04:43, 11.11it/s]\u001b[A\n",
      " 53%|█████▎    | 3527/6672 [07:39<04:37, 11.35it/s]\u001b[A\n",
      " 53%|█████▎    | 3529/6672 [07:39<05:14, 10.00it/s]\u001b[A\n",
      " 53%|█████▎    | 3531/6672 [07:39<06:07,  8.54it/s]\u001b[A\n",
      " 53%|█████▎    | 3533/6672 [07:39<05:43,  9.15it/s]\u001b[A\n",
      " 53%|█████▎    | 3534/6672 [07:39<05:55,  8.84it/s]\u001b[A\n",
      " 53%|█████▎    | 3535/6672 [07:40<05:59,  8.72it/s]\u001b[A\n",
      " 53%|█████▎    | 3537/6672 [07:40<06:28,  8.06it/s]\u001b[A\n",
      " 53%|█████▎    | 3538/6672 [07:40<06:39,  7.84it/s]\u001b[A\n",
      " 53%|█████▎    | 3539/6672 [07:40<07:08,  7.31it/s]\u001b[A\n",
      " 53%|█████▎    | 3540/6672 [07:40<07:21,  7.10it/s]\u001b[A\n",
      " 53%|█████▎    | 3541/6672 [07:40<07:02,  7.41it/s]\u001b[A\n",
      " 53%|█████▎    | 3542/6672 [07:41<06:44,  7.74it/s]\u001b[A\n",
      " 53%|█████▎    | 3543/6672 [07:41<06:53,  7.57it/s]\u001b[A\n",
      " 53%|█████▎    | 3544/6672 [07:41<06:55,  7.52it/s]\u001b[A\n",
      " 53%|█████▎    | 3545/6672 [07:41<06:35,  7.91it/s]\u001b[A\n",
      " 53%|█████▎    | 3546/6672 [07:41<06:29,  8.03it/s]\u001b[A\n",
      " 53%|█████▎    | 3547/6672 [07:41<06:24,  8.13it/s]\u001b[A\n",
      " 53%|█████▎    | 3548/6672 [07:41<06:38,  7.83it/s]\u001b[A\n",
      " 53%|█████▎    | 3549/6672 [07:41<06:50,  7.61it/s]\u001b[A\n",
      " 53%|█████▎    | 3550/6672 [07:42<06:28,  8.04it/s]\u001b[A\n",
      " 53%|█████▎    | 3552/6672 [07:42<05:45,  9.03it/s]\u001b[A\n",
      " 53%|█████▎    | 3554/6672 [07:42<05:17,  9.82it/s]\u001b[A\n",
      " 53%|█████▎    | 3556/6672 [07:42<04:53, 10.62it/s]\u001b[A\n",
      " 53%|█████▎    | 3558/6672 [07:42<04:34, 11.34it/s]\u001b[A\n",
      " 53%|█████▎    | 3560/6672 [07:42<05:01, 10.32it/s]\u001b[A\n",
      " 53%|█████▎    | 3562/6672 [07:43<05:26,  9.53it/s]\u001b[A\n",
      " 53%|█████▎    | 3563/6672 [07:43<05:36,  9.24it/s]\u001b[A\n",
      " 53%|█████▎    | 3564/6672 [07:43<05:56,  8.72it/s]\u001b[A\n",
      " 53%|█████▎    | 3565/6672 [07:43<06:01,  8.60it/s]\u001b[A\n",
      " 53%|█████▎    | 3567/6672 [07:43<05:36,  9.22it/s]\u001b[A\n",
      " 53%|█████▎    | 3568/6672 [07:43<05:35,  9.27it/s]\u001b[A\n",
      " 54%|█████▎    | 3570/6672 [07:44<05:08, 10.06it/s]\u001b[A\n",
      " 54%|█████▎    | 3572/6672 [07:44<04:44, 10.90it/s]\u001b[A\n",
      " 54%|█████▎    | 3574/6672 [07:44<05:12,  9.92it/s]\u001b[A\n",
      " 54%|█████▎    | 3576/6672 [07:44<06:19,  8.16it/s]\u001b[A\n",
      " 54%|█████▎    | 3577/6672 [07:44<06:11,  8.34it/s]\u001b[A\n",
      " 54%|█████▎    | 3578/6672 [07:44<06:03,  8.50it/s]\u001b[A\n",
      " 54%|█████▎    | 3580/6672 [07:45<05:27,  9.44it/s]\u001b[A\n",
      " 54%|█████▎    | 3582/6672 [07:45<05:22,  9.57it/s]\u001b[A\n",
      " 54%|█████▎    | 3583/6672 [07:45<05:43,  9.00it/s]\u001b[A\n",
      " 54%|█████▎    | 3584/6672 [07:45<05:40,  9.08it/s]\u001b[A\n",
      " 54%|█████▎    | 3586/6672 [07:45<05:06, 10.05it/s]\u001b[A\n",
      " 54%|█████▍    | 3588/6672 [07:46<06:14,  8.23it/s]\u001b[A\n",
      " 54%|█████▍    | 3589/6672 [07:46<06:10,  8.31it/s]\u001b[A\n",
      " 54%|█████▍    | 3591/6672 [07:46<05:38,  9.11it/s]\u001b[A\n",
      " 54%|█████▍    | 3592/6672 [07:46<05:44,  8.94it/s]\u001b[A\n",
      " 54%|█████▍    | 3593/6672 [07:46<06:00,  8.53it/s]\u001b[A\n",
      " 54%|█████▍    | 3594/6672 [07:46<06:14,  8.21it/s]\u001b[A\n",
      " 54%|█████▍    | 3595/6672 [07:46<06:10,  8.30it/s]\u001b[A\n",
      " 54%|█████▍    | 3596/6672 [07:47<06:40,  7.69it/s]\u001b[A\n",
      " 54%|█████▍    | 3598/6672 [07:47<05:43,  8.95it/s]\u001b[A\n",
      " 54%|█████▍    | 3600/6672 [07:47<05:18,  9.63it/s]\u001b[A\n",
      " 54%|█████▍    | 3601/6672 [07:47<05:18,  9.64it/s]\u001b[A\n",
      " 54%|█████▍    | 3602/6672 [07:47<05:51,  8.74it/s]\u001b[A\n",
      " 54%|█████▍    | 3603/6672 [07:47<05:56,  8.60it/s]\u001b[A\n",
      " 54%|█████▍    | 3604/6672 [07:47<05:46,  8.86it/s]\u001b[A\n",
      " 54%|█████▍    | 3606/6672 [07:48<04:50, 10.55it/s]\u001b[A\n",
      " 54%|█████▍    | 3608/6672 [07:48<04:49, 10.59it/s]\u001b[A\n",
      " 54%|█████▍    | 3610/6672 [07:48<04:28, 11.41it/s]\u001b[A\n",
      " 54%|█████▍    | 3612/6672 [07:48<04:45, 10.72it/s]\u001b[A\n",
      " 54%|█████▍    | 3614/6672 [07:48<04:27, 11.44it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 72.29it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3614\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3614/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45852935314178467, 'eval_f1': 0.7577282084043158, 'eval_recall': 0.730199369414219, 'eval_precision': 0.7956882289055125, 'eval_runtime': 4.4833, 'eval_samples_per_second': 283.271, 'eval_steps_per_second': 70.929, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3614/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3614/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3614/special_tokens_map.json\n",
      "\n",
      " 54%|█████▍    | 3616/6672 [07:57<1:12:48,  1.43s/it]\u001b[A\n",
      " 54%|█████▍    | 3617/6672 [07:57<1:01:03,  1.20s/it]\u001b[A\n",
      " 54%|█████▍    | 3618/6672 [07:57<49:34,  1.03it/s]  \u001b[A\n",
      " 54%|█████▍    | 3619/6672 [07:57<39:23,  1.29it/s]\u001b[A\n",
      " 54%|█████▍    | 3620/6672 [07:57<31:17,  1.63it/s]\u001b[A\n",
      " 54%|█████▍    | 3621/6672 [07:58<24:29,  2.08it/s]\u001b[A\n",
      " 54%|█████▍    | 3623/6672 [07:58<16:30,  3.08it/s]\u001b[A\n",
      " 54%|█████▍    | 3624/6672 [07:58<13:54,  3.65it/s]\u001b[A\n",
      " 54%|█████▍    | 3626/6672 [07:58<10:11,  4.98it/s]\u001b[A\n",
      " 54%|█████▍    | 3628/6672 [07:58<08:39,  5.86it/s]\u001b[A\n",
      " 54%|█████▍    | 3629/6672 [07:58<08:05,  6.27it/s]\u001b[A\n",
      " 54%|█████▍    | 3631/6672 [07:59<06:50,  7.40it/s]\u001b[A\n",
      " 54%|█████▍    | 3632/6672 [07:59<06:30,  7.79it/s]\u001b[A\n",
      " 54%|█████▍    | 3634/6672 [07:59<05:45,  8.79it/s]\u001b[A\n",
      " 54%|█████▍    | 3636/6672 [07:59<05:37,  8.99it/s]\u001b[A\n",
      " 55%|█████▍    | 3638/6672 [07:59<05:05,  9.92it/s]\u001b[A\n",
      " 55%|█████▍    | 3640/6672 [07:59<05:12,  9.71it/s]\u001b[A\n",
      " 55%|█████▍    | 3642/6672 [08:00<04:47, 10.54it/s]\u001b[A\n",
      " 55%|█████▍    | 3644/6672 [08:00<04:36, 10.97it/s]\u001b[A\n",
      " 55%|█████▍    | 3646/6672 [08:00<04:28, 11.28it/s]\u001b[A\n",
      " 55%|█████▍    | 3648/6672 [08:00<04:33, 11.04it/s]\u001b[A\n",
      " 55%|█████▍    | 3650/6672 [08:00<04:20, 11.58it/s]\u001b[A\n",
      " 55%|█████▍    | 3652/6672 [08:00<04:25, 11.36it/s]\u001b[A\n",
      " 55%|█████▍    | 3654/6672 [08:01<04:40, 10.78it/s]\u001b[A\n",
      " 55%|█████▍    | 3656/6672 [08:01<04:34, 11.00it/s]\u001b[A\n",
      " 55%|█████▍    | 3658/6672 [08:01<04:17, 11.69it/s]\u001b[A\n",
      " 55%|█████▍    | 3660/6672 [08:01<04:20, 11.54it/s]\u001b[A\n",
      " 55%|█████▍    | 3662/6672 [08:01<04:38, 10.81it/s]\u001b[A\n",
      " 55%|█████▍    | 3664/6672 [08:02<05:06,  9.81it/s]\u001b[A\n",
      " 55%|█████▍    | 3666/6672 [08:02<05:52,  8.53it/s]\u001b[A\n",
      " 55%|█████▍    | 3667/6672 [08:02<05:51,  8.54it/s]\u001b[A\n",
      " 55%|█████▍    | 3668/6672 [08:02<05:54,  8.47it/s]\u001b[A\n",
      " 55%|█████▍    | 3669/6672 [08:02<06:14,  8.02it/s]\u001b[A\n",
      " 55%|█████▌    | 3670/6672 [08:02<06:13,  8.04it/s]\u001b[A\n",
      " 55%|█████▌    | 3671/6672 [08:03<06:23,  7.83it/s]\u001b[A\n",
      " 55%|█████▌    | 3672/6672 [08:03<06:12,  8.05it/s]\u001b[A\n",
      " 55%|█████▌    | 3674/6672 [08:03<05:26,  9.18it/s]\u001b[A\n",
      " 55%|█████▌    | 3675/6672 [08:03<05:36,  8.91it/s]\u001b[A\n",
      " 55%|█████▌    | 3676/6672 [08:03<06:01,  8.29it/s]\u001b[A\n",
      " 55%|█████▌    | 3677/6672 [08:03<06:12,  8.03it/s]\u001b[A\n",
      " 55%|█████▌    | 3678/6672 [08:03<06:03,  8.24it/s]\u001b[A\n",
      " 55%|█████▌    | 3679/6672 [08:04<06:07,  8.15it/s]\u001b[A\n",
      " 55%|█████▌    | 3680/6672 [08:04<06:21,  7.84it/s]\u001b[A\n",
      " 55%|█████▌    | 3681/6672 [08:04<06:33,  7.60it/s]\u001b[A\n",
      " 55%|█████▌    | 3682/6672 [08:04<06:07,  8.14it/s]\u001b[A\n",
      " 55%|█████▌    | 3684/6672 [08:04<05:21,  9.29it/s]\u001b[A\n",
      " 55%|█████▌    | 3686/6672 [08:04<04:53, 10.16it/s]\u001b[A\n",
      " 55%|█████▌    | 3688/6672 [08:04<04:38, 10.72it/s]\u001b[A\n",
      " 55%|█████▌    | 3690/6672 [08:05<04:39, 10.69it/s]\u001b[A\n",
      " 55%|█████▌    | 3692/6672 [08:05<05:02,  9.85it/s]\u001b[A\n",
      " 55%|█████▌    | 3694/6672 [08:05<04:56, 10.06it/s]\u001b[A\n",
      " 55%|█████▌    | 3696/6672 [08:05<05:13,  9.48it/s]\u001b[A\n",
      " 55%|█████▌    | 3697/6672 [08:05<05:30,  8.99it/s]\u001b[A\n",
      " 55%|█████▌    | 3699/6672 [08:06<05:15,  9.42it/s]\u001b[A\n",
      " 55%|█████▌    | 3701/6672 [08:06<04:52, 10.16it/s]\u001b[A\n",
      " 56%|█████▌    | 3703/6672 [08:06<04:42, 10.52it/s]\u001b[A\n",
      " 56%|█████▌    | 3705/6672 [08:06<04:29, 10.99it/s]\u001b[A\n",
      " 56%|█████▌    | 3707/6672 [08:06<04:32, 10.87it/s]\u001b[A\n",
      " 56%|█████▌    | 3709/6672 [08:07<04:42, 10.48it/s]\u001b[A\n",
      " 56%|█████▌    | 3711/6672 [08:07<04:35, 10.76it/s]\u001b[A\n",
      " 56%|█████▌    | 3713/6672 [08:07<05:09,  9.56it/s]\u001b[A\n",
      " 56%|█████▌    | 3714/6672 [08:07<05:13,  9.45it/s]\u001b[A\n",
      " 56%|█████▌    | 3715/6672 [08:07<06:03,  8.14it/s]\u001b[A\n",
      " 56%|█████▌    | 3716/6672 [08:07<06:42,  7.34it/s]\u001b[A\n",
      " 56%|█████▌    | 3717/6672 [08:08<06:44,  7.30it/s]\u001b[A\n",
      " 56%|█████▌    | 3718/6672 [08:08<06:23,  7.71it/s]\u001b[A\n",
      " 56%|█████▌    | 3719/6672 [08:08<05:59,  8.21it/s]\u001b[A\n",
      " 56%|█████▌    | 3721/6672 [08:08<05:50,  8.41it/s]\u001b[A\n",
      " 56%|█████▌    | 3722/6672 [08:08<06:06,  8.04it/s]\u001b[A\n",
      " 56%|█████▌    | 3723/6672 [08:08<06:19,  7.77it/s]\u001b[A\n",
      " 56%|█████▌    | 3724/6672 [08:08<05:58,  8.21it/s]\u001b[A\n",
      " 56%|█████▌    | 3726/6672 [08:09<05:19,  9.21it/s]\u001b[A\n",
      " 56%|█████▌    | 3727/6672 [08:09<05:37,  8.72it/s]\u001b[A\n",
      " 56%|█████▌    | 3728/6672 [08:09<05:31,  8.88it/s]\u001b[A\n",
      " 56%|█████▌    | 3729/6672 [08:09<05:42,  8.59it/s]\u001b[A\n",
      " 56%|█████▌    | 3730/6672 [08:09<05:36,  8.75it/s]\u001b[A\n",
      " 56%|█████▌    | 3732/6672 [08:09<04:52, 10.04it/s]\u001b[A\n",
      " 56%|█████▌    | 3734/6672 [08:09<04:25, 11.07it/s]\u001b[A\n",
      " 56%|█████▌    | 3736/6672 [08:10<04:22, 11.19it/s]\u001b[A\n",
      " 56%|█████▌    | 3738/6672 [08:10<04:14, 11.54it/s]\u001b[A\n",
      " 56%|█████▌    | 3740/6672 [08:10<04:34, 10.69it/s]\u001b[A\n",
      " 56%|█████▌    | 3742/6672 [08:10<04:26, 11.01it/s]\u001b[A\n",
      " 56%|█████▌    | 3744/6672 [08:10<04:14, 11.49it/s]\u001b[A\n",
      " 56%|█████▌    | 3746/6672 [08:11<04:53,  9.97it/s]\u001b[A\n",
      " 56%|█████▌    | 3748/6672 [08:11<05:15,  9.26it/s]\u001b[A\n",
      " 56%|█████▌    | 3749/6672 [08:11<05:15,  9.27it/s]\u001b[A\n",
      " 56%|█████▌    | 3750/6672 [08:11<05:23,  9.03it/s]\u001b[A\n",
      " 56%|█████▌    | 3752/6672 [08:11<05:16,  9.23it/s]\u001b[A\n",
      " 56%|█████▋    | 3754/6672 [08:11<04:58,  9.78it/s]\u001b[A\n",
      " 56%|█████▋    | 3755/6672 [08:12<05:23,  9.02it/s]\u001b[A\n",
      " 56%|█████▋    | 3757/6672 [08:12<04:43, 10.30it/s]\u001b[A\n",
      " 56%|█████▋    | 3759/6672 [08:12<04:33, 10.64it/s]\u001b[A\n",
      " 56%|█████▋    | 3761/6672 [08:12<04:25, 10.96it/s]\u001b[A\n",
      " 56%|█████▋    | 3763/6672 [08:12<04:37, 10.49it/s]\u001b[A\n",
      " 56%|█████▋    | 3765/6672 [08:12<05:05,  9.51it/s]\u001b[A\n",
      " 56%|█████▋    | 3766/6672 [08:13<05:23,  8.99it/s]\u001b[A\n",
      " 56%|█████▋    | 3767/6672 [08:13<05:33,  8.70it/s]\u001b[A\n",
      " 56%|█████▋    | 3768/6672 [08:13<05:57,  8.13it/s]\u001b[A\n",
      " 56%|█████▋    | 3769/6672 [08:13<06:23,  7.56it/s]\u001b[A\n",
      " 57%|█████▋    | 3770/6672 [08:13<06:10,  7.82it/s]\u001b[A\n",
      " 57%|█████▋    | 3772/6672 [08:13<05:29,  8.80it/s]\u001b[A\n",
      " 57%|█████▋    | 3773/6672 [08:13<05:34,  8.66it/s]\u001b[A\n",
      " 57%|█████▋    | 3775/6672 [08:14<05:10,  9.32it/s]\u001b[A\n",
      " 57%|█████▋    | 3777/6672 [08:14<04:46, 10.09it/s]\u001b[A\n",
      " 57%|█████▋    | 3779/6672 [08:14<04:41, 10.28it/s]\u001b[A\n",
      " 57%|█████▋    | 3781/6672 [08:14<04:27, 10.79it/s]\u001b[A\n",
      " 57%|█████▋    | 3783/6672 [08:14<04:20, 11.10it/s]\u001b[A\n",
      " 57%|█████▋    | 3785/6672 [08:15<04:13, 11.37it/s]\u001b[A\n",
      " 57%|█████▋    | 3787/6672 [08:15<04:23, 10.95it/s]\u001b[A\n",
      " 57%|█████▋    | 3789/6672 [08:15<04:08, 11.60it/s]\u001b[A\n",
      " 57%|█████▋    | 3791/6672 [08:15<04:13, 11.35it/s]\u001b[A\n",
      " 57%|█████▋    | 3793/6672 [08:15<04:10, 11.49it/s]\u001b[A\n",
      " 57%|█████▋    | 3795/6672 [08:15<04:40, 10.27it/s]\u001b[A\n",
      " 57%|█████▋    | 3797/6672 [08:16<04:26, 10.80it/s]\u001b[A\n",
      " 57%|█████▋    | 3799/6672 [08:16<04:20, 11.02it/s]\u001b[A\n",
      " 57%|█████▋    | 3801/6672 [08:16<04:05, 11.70it/s]\u001b[A\n",
      " 57%|█████▋    | 3803/6672 [08:16<04:00, 11.91it/s]\u001b[A\n",
      " 57%|█████▋    | 3805/6672 [08:16<03:48, 12.53it/s]\u001b[A\n",
      " 57%|█████▋    | 3807/6672 [08:16<03:38, 13.13it/s]\u001b[A\n",
      " 57%|█████▋    | 3809/6672 [08:17<03:40, 12.98it/s]\u001b[A\n",
      " 57%|█████▋    | 3811/6672 [08:17<04:13, 11.30it/s]\u001b[A\n",
      " 57%|█████▋    | 3813/6672 [08:17<03:55, 12.13it/s]\u001b[A\n",
      " 57%|█████▋    | 3815/6672 [08:17<04:35, 10.36it/s]\u001b[A\n",
      " 57%|█████▋    | 3817/6672 [08:17<05:04,  9.38it/s]\u001b[A\n",
      " 57%|█████▋    | 3819/6672 [08:18<05:02,  9.42it/s]\u001b[A\n",
      " 57%|█████▋    | 3821/6672 [08:18<04:51,  9.78it/s]\u001b[A\n",
      " 57%|█████▋    | 3823/6672 [08:18<04:46,  9.93it/s]\u001b[A\n",
      " 57%|█████▋    | 3825/6672 [08:18<04:32, 10.45it/s]\u001b[A\n",
      " 57%|█████▋    | 3827/6672 [08:18<04:20, 10.93it/s]\u001b[A\n",
      " 57%|█████▋    | 3829/6672 [08:19<04:08, 11.44it/s]\u001b[A\n",
      " 57%|█████▋    | 3831/6672 [08:19<04:39, 10.17it/s]\u001b[A\n",
      " 57%|█████▋    | 3833/6672 [08:19<04:26, 10.67it/s]\u001b[A\n",
      " 57%|█████▋    | 3835/6672 [08:19<04:23, 10.77it/s]\u001b[A\n",
      " 58%|█████▊    | 3837/6672 [08:19<04:05, 11.53it/s]\u001b[A\n",
      " 58%|█████▊    | 3839/6672 [08:19<04:16, 11.05it/s]\u001b[A\n",
      " 58%|█████▊    | 3841/6672 [08:20<04:35, 10.29it/s]\u001b[A\n",
      " 58%|█████▊    | 3843/6672 [08:20<04:24, 10.70it/s]\u001b[A\n",
      " 58%|█████▊    | 3845/6672 [08:20<04:27, 10.56it/s]\u001b[A\n",
      " 58%|█████▊    | 3847/6672 [08:20<04:59,  9.44it/s]\u001b[A\n",
      " 58%|█████▊    | 3848/6672 [08:20<05:04,  9.28it/s]\u001b[A\n",
      " 58%|█████▊    | 3850/6672 [08:21<04:27, 10.53it/s]\u001b[A\n",
      " 58%|█████▊    | 3852/6672 [08:21<04:15, 11.04it/s]\u001b[A\n",
      " 58%|█████▊    | 3854/6672 [08:21<04:39, 10.09it/s]\u001b[A\n",
      " 58%|█████▊    | 3856/6672 [08:21<04:21, 10.76it/s]\u001b[A\n",
      " 58%|█████▊    | 3858/6672 [08:21<04:40, 10.04it/s]\u001b[A\n",
      " 58%|█████▊    | 3860/6672 [08:22<05:04,  9.24it/s]\u001b[A\n",
      " 58%|█████▊    | 3861/6672 [08:22<05:02,  9.30it/s]\u001b[A\n",
      " 58%|█████▊    | 3862/6672 [08:22<05:23,  8.70it/s]\u001b[A\n",
      " 58%|█████▊    | 3864/6672 [08:22<05:03,  9.25it/s]\u001b[A\n",
      " 58%|█████▊    | 3865/6672 [08:22<05:50,  8.00it/s]\u001b[A\n",
      " 58%|█████▊    | 3866/6672 [08:22<05:54,  7.92it/s]\u001b[A\n",
      " 58%|█████▊    | 3868/6672 [08:23<05:18,  8.80it/s]\u001b[A\n",
      " 58%|█████▊    | 3870/6672 [08:23<05:02,  9.27it/s]\u001b[A\n",
      " 58%|█████▊    | 3872/6672 [08:23<05:05,  9.17it/s]\u001b[A\n",
      " 58%|█████▊    | 3873/6672 [08:23<05:23,  8.66it/s]\u001b[A\n",
      " 58%|█████▊    | 3874/6672 [08:23<05:39,  8.25it/s]\u001b[A\n",
      " 58%|█████▊    | 3875/6672 [08:23<05:30,  8.45it/s]\u001b[A\n",
      " 58%|█████▊    | 3877/6672 [08:24<04:47,  9.70it/s]\u001b[A\n",
      " 58%|█████▊    | 3878/6672 [08:24<05:02,  9.24it/s]\u001b[A\n",
      " 58%|█████▊    | 3879/6672 [08:24<04:57,  9.38it/s]\u001b[A\n",
      " 58%|█████▊    | 3881/6672 [08:24<04:31, 10.30it/s]\u001b[A\n",
      " 58%|█████▊    | 3883/6672 [08:24<04:16, 10.89it/s]\u001b[A\n",
      " 58%|█████▊    | 3885/6672 [08:24<04:07, 11.25it/s]\u001b[A\n",
      " 58%|█████▊    | 3887/6672 [08:24<04:34, 10.15it/s]\u001b[A\n",
      " 58%|█████▊    | 3889/6672 [08:25<04:18, 10.77it/s]\u001b[A\n",
      " 58%|█████▊    | 3891/6672 [08:25<04:28, 10.37it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 73.65it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3892\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3892/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46183857321739197, 'eval_f1': 0.7479743025121278, 'eval_recall': 0.7065524026266505, 'eval_precision': 0.8197978858764804, 'eval_runtime': 4.448, 'eval_samples_per_second': 285.522, 'eval_steps_per_second': 71.493, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3892/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3892/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-3892/special_tokens_map.json\n",
      "\n",
      " 58%|█████▊    | 3893/6672 [08:33<1:02:55,  1.36s/it]\u001b[A\n",
      " 58%|█████▊    | 3894/6672 [08:33<53:03,  1.15s/it]  \u001b[A\n",
      " 58%|█████▊    | 3895/6672 [08:34<43:43,  1.06it/s]\u001b[A\n",
      " 58%|█████▊    | 3896/6672 [08:34<35:09,  1.32it/s]\u001b[A\n",
      " 58%|█████▊    | 3897/6672 [08:34<27:48,  1.66it/s]\u001b[A\n",
      " 58%|█████▊    | 3898/6672 [08:34<22:06,  2.09it/s]\u001b[A\n",
      " 58%|█████▊    | 3899/6672 [08:34<17:31,  2.64it/s]\u001b[A\n",
      " 58%|█████▊    | 3901/6672 [08:34<11:49,  3.91it/s]\u001b[A\n",
      " 58%|█████▊    | 3902/6672 [08:34<10:21,  4.46it/s]\u001b[A\n",
      " 58%|█████▊    | 3903/6672 [08:35<09:29,  4.86it/s]\u001b[A\n",
      " 59%|█████▊    | 3904/6672 [08:35<08:21,  5.52it/s]\u001b[A\n",
      " 59%|█████▊    | 3906/6672 [08:35<06:19,  7.29it/s]\u001b[A\n",
      " 59%|█████▊    | 3908/6672 [08:35<05:31,  8.34it/s]\u001b[A\n",
      " 59%|█████▊    | 3909/6672 [08:35<05:36,  8.20it/s]\u001b[A\n",
      " 59%|█████▊    | 3910/6672 [08:35<05:30,  8.35it/s]\u001b[A\n",
      " 59%|█████▊    | 3912/6672 [08:35<04:52,  9.42it/s]\u001b[A\n",
      " 59%|█████▊    | 3914/6672 [08:36<04:29, 10.22it/s]\u001b[A\n",
      " 59%|█████▊    | 3916/6672 [08:36<04:27, 10.29it/s]\u001b[A\n",
      " 59%|█████▊    | 3918/6672 [08:36<04:15, 10.77it/s]\u001b[A\n",
      " 59%|█████▉    | 3920/6672 [08:36<04:21, 10.52it/s]\u001b[A\n",
      " 59%|█████▉    | 3922/6672 [08:36<04:18, 10.66it/s]\u001b[A\n",
      " 59%|█████▉    | 3924/6672 [08:36<04:02, 11.32it/s]\u001b[A\n",
      " 59%|█████▉    | 3926/6672 [08:37<04:39,  9.83it/s]\u001b[A\n",
      " 59%|█████▉    | 3928/6672 [08:37<04:38,  9.85it/s]\u001b[A\n",
      " 59%|█████▉    | 3930/6672 [08:37<04:26, 10.27it/s]\u001b[A\n",
      " 59%|█████▉    | 3932/6672 [08:37<04:32, 10.04it/s]\u001b[A\n",
      " 59%|█████▉    | 3934/6672 [08:37<04:20, 10.49it/s]\u001b[A\n",
      " 59%|█████▉    | 3936/6672 [08:38<04:03, 11.25it/s]\u001b[A\n",
      " 59%|█████▉    | 3938/6672 [08:38<04:30, 10.09it/s]\u001b[A\n",
      " 59%|█████▉    | 3940/6672 [08:38<04:19, 10.53it/s]\u001b[A\n",
      " 59%|█████▉    | 3942/6672 [08:38<04:08, 10.98it/s]\u001b[A\n",
      " 59%|█████▉    | 3944/6672 [08:38<04:52,  9.33it/s]\u001b[A\n",
      " 59%|█████▉    | 3945/6672 [08:39<04:57,  9.16it/s]\u001b[A\n",
      " 59%|█████▉    | 3946/6672 [08:39<05:30,  8.26it/s]\u001b[A\n",
      " 59%|█████▉    | 3947/6672 [08:39<05:32,  8.19it/s]\u001b[A\n",
      " 59%|█████▉    | 3948/6672 [08:39<05:21,  8.48it/s]\u001b[A\n",
      " 59%|█████▉    | 3949/6672 [08:39<05:32,  8.18it/s]\u001b[A\n",
      " 59%|█████▉    | 3950/6672 [08:39<05:51,  7.75it/s]\u001b[A\n",
      " 59%|█████▉    | 3951/6672 [08:39<05:31,  8.20it/s]\u001b[A\n",
      " 59%|█████▉    | 3953/6672 [08:40<04:51,  9.32it/s]\u001b[A\n",
      " 59%|█████▉    | 3954/6672 [08:40<04:59,  9.08it/s]\u001b[A\n",
      " 59%|█████▉    | 3956/6672 [08:40<04:37,  9.78it/s]\u001b[A\n",
      " 59%|█████▉    | 3958/6672 [08:40<04:49,  9.37it/s]\u001b[A\n",
      " 59%|█████▉    | 3959/6672 [08:40<04:46,  9.48it/s]\u001b[A\n",
      " 59%|█████▉    | 3960/6672 [08:40<04:46,  9.47it/s]\u001b[A\n",
      " 59%|█████▉    | 3961/6672 [08:40<05:07,  8.82it/s]\u001b[A\n",
      " 59%|█████▉    | 3962/6672 [08:41<05:00,  9.00it/s]\u001b[A\n",
      " 59%|█████▉    | 3964/6672 [08:41<04:49,  9.36it/s]\u001b[A\n",
      " 59%|█████▉    | 3965/6672 [08:41<04:51,  9.29it/s]\u001b[A\n",
      " 59%|█████▉    | 3967/6672 [08:41<04:25, 10.19it/s]\u001b[A\n",
      " 59%|█████▉    | 3969/6672 [08:41<04:53,  9.21it/s]\u001b[A\n",
      " 60%|█████▉    | 3970/6672 [08:41<05:13,  8.62it/s]\u001b[A\n",
      " 60%|█████▉    | 3972/6672 [08:42<04:37,  9.72it/s]\u001b[A\n",
      " 60%|█████▉    | 3974/6672 [08:42<04:03, 11.09it/s]\u001b[A\n",
      " 60%|█████▉    | 3976/6672 [08:42<03:45, 11.97it/s]\u001b[A\n",
      " 60%|█████▉    | 3978/6672 [08:42<04:10, 10.75it/s]\u001b[A\n",
      " 60%|█████▉    | 3980/6672 [08:42<03:51, 11.61it/s]\u001b[A\n",
      " 60%|█████▉    | 3982/6672 [08:42<04:12, 10.67it/s]\u001b[A\n",
      " 60%|█████▉    | 3984/6672 [08:43<04:14, 10.57it/s]\u001b[A\n",
      " 60%|█████▉    | 3986/6672 [08:43<04:39,  9.61it/s]\u001b[A\n",
      " 60%|█████▉    | 3988/6672 [08:43<04:29,  9.96it/s]\u001b[A\n",
      " 60%|█████▉    | 3990/6672 [08:43<04:13, 10.59it/s]\u001b[A\n",
      " 60%|█████▉    | 3992/6672 [08:43<03:58, 11.21it/s]\u001b[A\n",
      " 60%|█████▉    | 3994/6672 [08:44<04:48,  9.27it/s]\u001b[A\n",
      " 60%|█████▉    | 3996/6672 [08:44<05:04,  8.80it/s]\u001b[A\n",
      " 60%|█████▉    | 3997/6672 [08:44<04:59,  8.93it/s]\u001b[A\n",
      " 60%|█████▉    | 3999/6672 [08:44<04:45,  9.38it/s]\u001b[A\n",
      " 60%|█████▉    | 4000/6672 [08:44<06:07,  7.27it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 60%|█████▉    | 4000/6672 [08:45<06:07,  7.27it/s]\u001b[A\n",
      " 60%|█████▉    | 4001/6672 [08:45<06:30,  6.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0237, 'learning_rate': 2.7994236690191948e-05, 'epoch': 14.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████▉    | 4002/6672 [08:45<06:09,  7.22it/s]\u001b[A\n",
      " 60%|█████▉    | 4003/6672 [08:45<05:45,  7.72it/s]\u001b[A\n",
      " 60%|██████    | 4004/6672 [08:45<05:56,  7.49it/s]\u001b[A\n",
      " 60%|██████    | 4006/6672 [08:45<05:01,  8.83it/s]\u001b[A\n",
      " 60%|██████    | 4008/6672 [08:45<04:42,  9.43it/s]\u001b[A\n",
      " 60%|██████    | 4009/6672 [08:46<04:57,  8.96it/s]\u001b[A\n",
      " 60%|██████    | 4011/6672 [08:46<04:28,  9.91it/s]\u001b[A\n",
      " 60%|██████    | 4013/6672 [08:46<04:08, 10.70it/s]\u001b[A\n",
      " 60%|██████    | 4015/6672 [08:46<04:10, 10.62it/s]\u001b[A\n",
      " 60%|██████    | 4017/6672 [08:46<04:25,  9.99it/s]\u001b[A\n",
      " 60%|██████    | 4019/6672 [08:46<04:16, 10.34it/s]\u001b[A\n",
      " 60%|██████    | 4021/6672 [08:47<03:53, 11.35it/s]\u001b[A\n",
      " 60%|██████    | 4023/6672 [08:47<04:20, 10.17it/s]\u001b[A\n",
      " 60%|██████    | 4025/6672 [08:47<04:05, 10.77it/s]\u001b[A\n",
      " 60%|██████    | 4027/6672 [08:47<04:13, 10.43it/s]\u001b[A\n",
      " 60%|██████    | 4029/6672 [08:47<04:10, 10.53it/s]\u001b[A\n",
      " 60%|██████    | 4031/6672 [08:48<04:14, 10.39it/s]\u001b[A\n",
      " 60%|██████    | 4033/6672 [08:48<04:23, 10.01it/s]\u001b[A\n",
      " 60%|██████    | 4035/6672 [08:48<04:19, 10.16it/s]\u001b[A\n",
      " 61%|██████    | 4037/6672 [08:48<04:06, 10.68it/s]\u001b[A\n",
      " 61%|██████    | 4039/6672 [08:48<04:05, 10.71it/s]\u001b[A\n",
      " 61%|██████    | 4041/6672 [08:49<04:06, 10.66it/s]\u001b[A\n",
      " 61%|██████    | 4043/6672 [08:49<04:50,  9.06it/s]\u001b[A\n",
      " 61%|██████    | 4044/6672 [08:49<05:02,  8.70it/s]\u001b[A\n",
      " 61%|██████    | 4045/6672 [08:49<05:19,  8.23it/s]\u001b[A\n",
      " 61%|██████    | 4046/6672 [08:49<05:15,  8.33it/s]\u001b[A\n",
      " 61%|██████    | 4047/6672 [08:49<05:02,  8.67it/s]\u001b[A\n",
      " 61%|██████    | 4048/6672 [08:49<05:01,  8.70it/s]\u001b[A\n",
      " 61%|██████    | 4049/6672 [08:50<05:14,  8.34it/s]\u001b[A\n",
      " 61%|██████    | 4050/6672 [08:50<05:05,  8.57it/s]\u001b[A\n",
      " 61%|██████    | 4052/6672 [08:50<04:34,  9.56it/s]\u001b[A\n",
      " 61%|██████    | 4054/6672 [08:50<04:13, 10.34it/s]\u001b[A\n",
      " 61%|██████    | 4056/6672 [08:50<04:19, 10.06it/s]\u001b[A\n",
      " 61%|██████    | 4058/6672 [08:50<04:04, 10.70it/s]\u001b[A\n",
      " 61%|██████    | 4060/6672 [08:51<04:03, 10.74it/s]\u001b[A\n",
      " 61%|██████    | 4062/6672 [08:51<04:22,  9.95it/s]\u001b[A\n",
      " 61%|██████    | 4064/6672 [08:51<04:21,  9.99it/s]\u001b[A\n",
      " 61%|██████    | 4066/6672 [08:51<04:18, 10.10it/s]\u001b[A\n",
      " 61%|██████    | 4068/6672 [08:51<04:04, 10.63it/s]\u001b[A\n",
      " 61%|██████    | 4070/6672 [08:52<04:02, 10.71it/s]\u001b[A\n",
      " 61%|██████    | 4072/6672 [08:52<03:50, 11.30it/s]\u001b[A\n",
      " 61%|██████    | 4074/6672 [08:52<03:34, 12.12it/s]\u001b[A\n",
      " 61%|██████    | 4076/6672 [08:52<03:50, 11.25it/s]\u001b[A\n",
      " 61%|██████    | 4078/6672 [08:52<03:46, 11.47it/s]\u001b[A\n",
      " 61%|██████    | 4080/6672 [08:52<03:42, 11.68it/s]\u001b[A\n",
      " 61%|██████    | 4082/6672 [08:53<03:38, 11.87it/s]\u001b[A\n",
      " 61%|██████    | 4084/6672 [08:53<03:26, 12.51it/s]\u001b[A\n",
      " 61%|██████    | 4086/6672 [08:53<03:51, 11.18it/s]\u001b[A\n",
      " 61%|██████▏   | 4088/6672 [08:53<04:12, 10.24it/s]\u001b[A\n",
      " 61%|██████▏   | 4090/6672 [08:53<04:30,  9.54it/s]\u001b[A\n",
      " 61%|██████▏   | 4091/6672 [08:54<04:43,  9.10it/s]\u001b[A\n",
      " 61%|██████▏   | 4092/6672 [08:54<04:57,  8.66it/s]\u001b[A\n",
      " 61%|██████▏   | 4093/6672 [08:54<05:35,  7.69it/s]\u001b[A\n",
      " 61%|██████▏   | 4094/6672 [08:54<06:04,  7.08it/s]\u001b[A\n",
      " 61%|██████▏   | 4095/6672 [08:54<06:02,  7.11it/s]\u001b[A\n",
      " 61%|██████▏   | 4096/6672 [08:54<05:39,  7.59it/s]\u001b[A\n",
      " 61%|██████▏   | 4097/6672 [08:54<05:57,  7.19it/s]\u001b[A\n",
      " 61%|██████▏   | 4098/6672 [08:55<05:34,  7.69it/s]\u001b[A\n",
      " 61%|██████▏   | 4099/6672 [08:55<05:12,  8.23it/s]\u001b[A\n",
      " 61%|██████▏   | 4101/6672 [08:55<04:38,  9.23it/s]\u001b[A\n",
      " 61%|██████▏   | 4102/6672 [08:55<04:48,  8.91it/s]\u001b[A\n",
      " 61%|██████▏   | 4103/6672 [08:55<04:48,  8.92it/s]\u001b[A\n",
      " 62%|██████▏   | 4105/6672 [08:55<04:13, 10.13it/s]\u001b[A\n",
      " 62%|██████▏   | 4107/6672 [08:55<04:19,  9.89it/s]\u001b[A\n",
      " 62%|██████▏   | 4109/6672 [08:56<04:02, 10.55it/s]\u001b[A\n",
      " 62%|██████▏   | 4111/6672 [08:56<04:22,  9.75it/s]\u001b[A\n",
      " 62%|██████▏   | 4112/6672 [08:56<04:25,  9.65it/s]\u001b[A\n",
      " 62%|██████▏   | 4114/6672 [08:56<04:03, 10.49it/s]\u001b[A\n",
      " 62%|██████▏   | 4116/6672 [08:56<03:49, 11.13it/s]\u001b[A\n",
      " 62%|██████▏   | 4118/6672 [08:56<03:49, 11.12it/s]\u001b[A\n",
      " 62%|██████▏   | 4120/6672 [08:57<03:44, 11.37it/s]\u001b[A\n",
      " 62%|██████▏   | 4122/6672 [08:57<03:54, 10.89it/s]\u001b[A\n",
      " 62%|██████▏   | 4124/6672 [08:57<03:45, 11.30it/s]\u001b[A\n",
      " 62%|██████▏   | 4126/6672 [08:57<04:06, 10.31it/s]\u001b[A\n",
      " 62%|██████▏   | 4128/6672 [08:57<04:24,  9.61it/s]\u001b[A\n",
      " 62%|██████▏   | 4130/6672 [08:58<04:08, 10.25it/s]\u001b[A\n",
      " 62%|██████▏   | 4132/6672 [08:58<03:52, 10.94it/s]\u001b[A\n",
      " 62%|██████▏   | 4134/6672 [08:58<04:17,  9.85it/s]\u001b[A\n",
      " 62%|██████▏   | 4136/6672 [08:58<04:36,  9.18it/s]\u001b[A\n",
      " 62%|██████▏   | 4138/6672 [08:58<04:16,  9.89it/s]\u001b[A\n",
      " 62%|██████▏   | 4140/6672 [08:59<04:01, 10.50it/s]\u001b[A\n",
      " 62%|██████▏   | 4142/6672 [08:59<04:05, 10.30it/s]\u001b[A\n",
      " 62%|██████▏   | 4144/6672 [08:59<04:34,  9.22it/s]\u001b[A\n",
      " 62%|██████▏   | 4145/6672 [08:59<04:32,  9.29it/s]\u001b[A\n",
      " 62%|██████▏   | 4146/6672 [08:59<04:46,  8.81it/s]\u001b[A\n",
      " 62%|██████▏   | 4147/6672 [08:59<05:06,  8.24it/s]\u001b[A\n",
      " 62%|██████▏   | 4148/6672 [09:00<05:06,  8.25it/s]\u001b[A\n",
      " 62%|██████▏   | 4149/6672 [09:00<04:52,  8.63it/s]\u001b[A\n",
      " 62%|██████▏   | 4151/6672 [09:00<04:19,  9.70it/s]\u001b[A\n",
      " 62%|██████▏   | 4153/6672 [09:00<04:02, 10.38it/s]\u001b[A\n",
      " 62%|██████▏   | 4155/6672 [09:00<03:52, 10.82it/s]\u001b[A\n",
      " 62%|██████▏   | 4157/6672 [09:00<03:45, 11.16it/s]\u001b[A\n",
      " 62%|██████▏   | 4159/6672 [09:00<03:33, 11.78it/s]\u001b[A\n",
      " 62%|██████▏   | 4161/6672 [09:01<03:51, 10.84it/s]\u001b[A\n",
      " 62%|██████▏   | 4163/6672 [09:01<03:40, 11.36it/s]\u001b[A\n",
      " 62%|██████▏   | 4165/6672 [09:01<04:00, 10.44it/s]\u001b[A\n",
      " 62%|██████▏   | 4167/6672 [09:01<03:51, 10.82it/s]\u001b[A\n",
      " 62%|██████▏   | 4169/6672 [09:01<03:41, 11.31it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 72.40it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4170\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4170/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42500969767570496, 'eval_f1': 0.7687710630033702, 'eval_recall': 0.798125627227398, 'eval_precision': 0.7462228748572362, 'eval_runtime': 4.5296, 'eval_samples_per_second': 280.376, 'eval_steps_per_second': 70.204, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4170/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4170/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4170/special_tokens_map.json\n",
      "\n",
      " 63%|██████▎   | 4171/6672 [09:09<52:35,  1.26s/it]\u001b[A\n",
      " 63%|██████▎   | 4172/6672 [09:10<44:26,  1.07s/it]\u001b[A\n",
      " 63%|██████▎   | 4173/6672 [09:10<36:27,  1.14it/s]\u001b[A\n",
      " 63%|██████▎   | 4174/6672 [09:10<29:20,  1.42it/s]\u001b[A\n",
      " 63%|██████▎   | 4176/6672 [09:10<19:25,  2.14it/s]\u001b[A\n",
      " 63%|██████▎   | 4177/6672 [09:10<16:11,  2.57it/s]\u001b[A\n",
      " 63%|██████▎   | 4178/6672 [09:10<13:24,  3.10it/s]\u001b[A\n",
      " 63%|██████▎   | 4179/6672 [09:10<11:25,  3.64it/s]\u001b[A\n",
      " 63%|██████▎   | 4180/6672 [09:10<09:51,  4.21it/s]\u001b[A\n",
      " 63%|██████▎   | 4182/6672 [09:11<07:12,  5.76it/s]\u001b[A\n",
      " 63%|██████▎   | 4183/6672 [09:11<06:38,  6.25it/s]\u001b[A\n",
      " 63%|██████▎   | 4185/6672 [09:11<05:24,  7.66it/s]\u001b[A\n",
      " 63%|██████▎   | 4187/6672 [09:11<04:38,  8.93it/s]\u001b[A\n",
      " 63%|██████▎   | 4189/6672 [09:11<04:45,  8.71it/s]\u001b[A\n",
      " 63%|██████▎   | 4190/6672 [09:11<04:53,  8.44it/s]\u001b[A\n",
      " 63%|██████▎   | 4191/6672 [09:12<05:01,  8.24it/s]\u001b[A\n",
      " 63%|██████▎   | 4192/6672 [09:12<04:51,  8.52it/s]\u001b[A\n",
      " 63%|██████▎   | 4193/6672 [09:12<04:40,  8.85it/s]\u001b[A\n",
      " 63%|██████▎   | 4194/6672 [09:12<04:37,  8.94it/s]\u001b[A\n",
      " 63%|██████▎   | 4196/6672 [09:12<04:21,  9.48it/s]\u001b[A\n",
      " 63%|██████▎   | 4198/6672 [09:12<04:12,  9.78it/s]\u001b[A\n",
      " 63%|██████▎   | 4199/6672 [09:12<04:12,  9.79it/s]\u001b[A\n",
      " 63%|██████▎   | 4201/6672 [09:13<04:12,  9.79it/s]\u001b[A\n",
      " 63%|██████▎   | 4202/6672 [09:13<04:35,  8.97it/s]\u001b[A\n",
      " 63%|██████▎   | 4204/6672 [09:13<04:11,  9.81it/s]\u001b[A\n",
      " 63%|██████▎   | 4206/6672 [09:13<03:36, 11.37it/s]\u001b[A\n",
      " 63%|██████▎   | 4208/6672 [09:13<03:19, 12.38it/s]\u001b[A\n",
      " 63%|██████▎   | 4210/6672 [09:13<03:02, 13.51it/s]\u001b[A\n",
      " 63%|██████▎   | 4212/6672 [09:13<02:58, 13.76it/s]\u001b[A\n",
      " 63%|██████▎   | 4214/6672 [09:14<03:13, 12.69it/s]\u001b[A\n",
      " 63%|██████▎   | 4216/6672 [09:14<03:29, 11.73it/s]\u001b[A\n",
      " 63%|██████▎   | 4218/6672 [09:14<04:13,  9.66it/s]\u001b[A\n",
      " 63%|██████▎   | 4220/6672 [09:14<04:12,  9.72it/s]\u001b[A\n",
      " 63%|██████▎   | 4222/6672 [09:15<04:51,  8.39it/s]\u001b[A\n",
      " 63%|██████▎   | 4223/6672 [09:15<05:16,  7.74it/s]\u001b[A\n",
      " 63%|██████▎   | 4224/6672 [09:15<05:13,  7.80it/s]\u001b[A\n",
      " 63%|██████▎   | 4225/6672 [09:15<05:22,  7.58it/s]\u001b[A\n",
      " 63%|██████▎   | 4226/6672 [09:15<05:12,  7.83it/s]\u001b[A\n",
      " 63%|██████▎   | 4227/6672 [09:15<05:03,  8.06it/s]\u001b[A\n",
      " 63%|██████▎   | 4229/6672 [09:16<05:00,  8.14it/s]\u001b[A\n",
      " 63%|██████▎   | 4230/6672 [09:16<04:49,  8.43it/s]\u001b[A\n",
      " 63%|██████▎   | 4231/6672 [09:16<04:49,  8.44it/s]\u001b[A\n",
      " 63%|██████▎   | 4232/6672 [09:16<05:19,  7.63it/s]\u001b[A\n",
      " 63%|██████▎   | 4233/6672 [09:16<05:37,  7.22it/s]\u001b[A\n",
      " 63%|██████▎   | 4234/6672 [09:16<05:15,  7.72it/s]\u001b[A\n",
      " 63%|██████▎   | 4235/6672 [09:16<04:56,  8.22it/s]\u001b[A\n",
      " 63%|██████▎   | 4236/6672 [09:16<04:59,  8.12it/s]\u001b[A\n",
      " 64%|██████▎   | 4237/6672 [09:17<05:06,  7.95it/s]\u001b[A\n",
      " 64%|██████▎   | 4238/6672 [09:17<05:18,  7.65it/s]\u001b[A\n",
      " 64%|██████▎   | 4239/6672 [09:17<05:25,  7.47it/s]\u001b[A\n",
      " 64%|██████▎   | 4240/6672 [09:17<05:35,  7.25it/s]\u001b[A\n",
      " 64%|██████▎   | 4241/6672 [09:17<05:21,  7.55it/s]\u001b[A\n",
      " 64%|██████▎   | 4243/6672 [09:17<04:27,  9.07it/s]\u001b[A\n",
      " 64%|██████▎   | 4244/6672 [09:17<04:28,  9.05it/s]\u001b[A\n",
      " 64%|██████▎   | 4245/6672 [09:18<04:48,  8.42it/s]\u001b[A\n",
      " 64%|██████▎   | 4246/6672 [09:18<05:03,  8.00it/s]\u001b[A\n",
      " 64%|██████▎   | 4248/6672 [09:18<04:26,  9.09it/s]\u001b[A\n",
      " 64%|██████▎   | 4249/6672 [09:18<04:38,  8.70it/s]\u001b[A\n",
      " 64%|██████▎   | 4251/6672 [09:18<04:07,  9.77it/s]\u001b[A\n",
      " 64%|██████▎   | 4252/6672 [09:18<04:13,  9.54it/s]\u001b[A\n",
      " 64%|██████▍   | 4254/6672 [09:18<03:56, 10.24it/s]\u001b[A\n",
      " 64%|██████▍   | 4256/6672 [09:19<03:35, 11.21it/s]\u001b[A\n",
      " 64%|██████▍   | 4258/6672 [09:19<03:51, 10.42it/s]\u001b[A\n",
      " 64%|██████▍   | 4260/6672 [09:19<04:05,  9.84it/s]\u001b[A\n",
      " 64%|██████▍   | 4262/6672 [09:19<03:52, 10.36it/s]\u001b[A\n",
      " 64%|██████▍   | 4264/6672 [09:19<03:40, 10.93it/s]\u001b[A\n",
      " 64%|██████▍   | 4266/6672 [09:20<04:01,  9.98it/s]\u001b[A\n",
      " 64%|██████▍   | 4268/6672 [09:20<04:19,  9.25it/s]\u001b[A\n",
      " 64%|██████▍   | 4269/6672 [09:20<04:31,  8.85it/s]\u001b[A\n",
      " 64%|██████▍   | 4270/6672 [09:20<04:27,  8.97it/s]\u001b[A\n",
      " 64%|██████▍   | 4271/6672 [09:20<04:59,  8.02it/s]\u001b[A\n",
      " 64%|██████▍   | 4272/6672 [09:20<05:07,  7.81it/s]\u001b[A\n",
      " 64%|██████▍   | 4273/6672 [09:21<05:05,  7.85it/s]\u001b[A\n",
      " 64%|██████▍   | 4274/6672 [09:21<04:53,  8.18it/s]\u001b[A\n",
      " 64%|██████▍   | 4275/6672 [09:21<04:41,  8.50it/s]\u001b[A\n",
      " 64%|██████▍   | 4277/6672 [09:21<04:15,  9.36it/s]\u001b[A\n",
      " 64%|██████▍   | 4278/6672 [09:21<04:17,  9.31it/s]\u001b[A\n",
      " 64%|██████▍   | 4280/6672 [09:21<03:58, 10.03it/s]\u001b[A\n",
      " 64%|██████▍   | 4282/6672 [09:21<03:47, 10.52it/s]\u001b[A\n",
      " 64%|██████▍   | 4284/6672 [09:22<03:41, 10.76it/s]\u001b[A\n",
      " 64%|██████▍   | 4286/6672 [09:22<03:36, 11.04it/s]\u001b[A\n",
      " 64%|██████▍   | 4288/6672 [09:22<03:56, 10.09it/s]\u001b[A\n",
      " 64%|██████▍   | 4290/6672 [09:22<03:48, 10.44it/s]\u001b[A\n",
      " 64%|██████▍   | 4292/6672 [09:22<03:40, 10.79it/s]\u001b[A\n",
      " 64%|██████▍   | 4294/6672 [09:22<03:44, 10.62it/s]\u001b[A\n",
      " 64%|██████▍   | 4296/6672 [09:23<03:47, 10.43it/s]\u001b[A\n",
      " 64%|██████▍   | 4298/6672 [09:23<04:06,  9.65it/s]\u001b[A\n",
      " 64%|██████▍   | 4300/6672 [09:23<03:50, 10.29it/s]\u001b[A\n",
      " 64%|██████▍   | 4302/6672 [09:23<03:54, 10.09it/s]\u001b[A\n",
      " 65%|██████▍   | 4304/6672 [09:23<03:40, 10.74it/s]\u001b[A\n",
      " 65%|██████▍   | 4306/6672 [09:24<03:36, 10.91it/s]\u001b[A\n",
      " 65%|██████▍   | 4308/6672 [09:24<03:40, 10.73it/s]\u001b[A\n",
      " 65%|██████▍   | 4310/6672 [09:24<03:45, 10.46it/s]\u001b[A\n",
      " 65%|██████▍   | 4312/6672 [09:24<03:57,  9.95it/s]\u001b[A\n",
      " 65%|██████▍   | 4314/6672 [09:24<03:48, 10.31it/s]\u001b[A\n",
      " 65%|██████▍   | 4316/6672 [09:25<03:43, 10.54it/s]\u001b[A\n",
      " 65%|██████▍   | 4318/6672 [09:25<03:53, 10.07it/s]\u001b[A\n",
      " 65%|██████▍   | 4320/6672 [09:25<03:41, 10.60it/s]\u001b[A\n",
      " 65%|██████▍   | 4322/6672 [09:25<04:19,  9.04it/s]\u001b[A\n",
      " 65%|██████▍   | 4323/6672 [09:25<04:24,  8.89it/s]\u001b[A\n",
      " 65%|██████▍   | 4324/6672 [09:26<04:26,  8.81it/s]\u001b[A\n",
      " 65%|██████▍   | 4325/6672 [09:26<04:20,  9.01it/s]\u001b[A\n",
      " 65%|██████▍   | 4326/6672 [09:26<04:36,  8.50it/s]\u001b[A\n",
      " 65%|██████▍   | 4327/6672 [09:26<04:41,  8.34it/s]\u001b[A\n",
      " 65%|██████▍   | 4329/6672 [09:26<04:15,  9.17it/s]\u001b[A\n",
      " 65%|██████▍   | 4331/6672 [09:26<03:54,  9.98it/s]\u001b[A\n",
      " 65%|██████▍   | 4333/6672 [09:26<03:43, 10.48it/s]\u001b[A\n",
      " 65%|██████▍   | 4335/6672 [09:27<03:38, 10.69it/s]\u001b[A\n",
      " 65%|██████▌   | 4337/6672 [09:27<03:27, 11.26it/s]\u001b[A\n",
      " 65%|██████▌   | 4339/6672 [09:27<03:23, 11.46it/s]\u001b[A\n",
      " 65%|██████▌   | 4341/6672 [09:27<03:26, 11.29it/s]\u001b[A\n",
      " 65%|██████▌   | 4343/6672 [09:27<03:23, 11.44it/s]\u001b[A\n",
      " 65%|██████▌   | 4345/6672 [09:27<03:24, 11.40it/s]\u001b[A\n",
      " 65%|██████▌   | 4347/6672 [09:28<03:26, 11.25it/s]\u001b[A\n",
      " 65%|██████▌   | 4349/6672 [09:28<03:39, 10.57it/s]\u001b[A\n",
      " 65%|██████▌   | 4351/6672 [09:28<04:06,  9.42it/s]\u001b[A\n",
      " 65%|██████▌   | 4352/6672 [09:28<04:05,  9.45it/s]\u001b[A\n",
      " 65%|██████▌   | 4354/6672 [09:28<03:55,  9.85it/s]\u001b[A\n",
      " 65%|██████▌   | 4356/6672 [09:29<03:47, 10.19it/s]\u001b[A\n",
      " 65%|██████▌   | 4358/6672 [09:29<03:45, 10.28it/s]\u001b[A\n",
      " 65%|██████▌   | 4360/6672 [09:29<03:31, 10.93it/s]\u001b[A\n",
      " 65%|██████▌   | 4362/6672 [09:29<03:11, 12.04it/s]\u001b[A\n",
      " 65%|██████▌   | 4364/6672 [09:29<02:55, 13.17it/s]\u001b[A\n",
      " 65%|██████▌   | 4366/6672 [09:29<02:48, 13.67it/s]\u001b[A\n",
      " 65%|██████▌   | 4368/6672 [09:30<03:01, 12.69it/s]\u001b[A\n",
      " 65%|██████▌   | 4370/6672 [09:30<03:14, 11.84it/s]\u001b[A\n",
      " 66%|██████▌   | 4372/6672 [09:30<03:55,  9.77it/s]\u001b[A\n",
      " 66%|██████▌   | 4374/6672 [09:30<04:15,  8.98it/s]\u001b[A\n",
      " 66%|██████▌   | 4375/6672 [09:30<04:18,  8.90it/s]\u001b[A\n",
      " 66%|██████▌   | 4377/6672 [09:31<04:08,  9.22it/s]\u001b[A\n",
      " 66%|██████▌   | 4379/6672 [09:31<03:55,  9.72it/s]\u001b[A\n",
      " 66%|██████▌   | 4381/6672 [09:31<03:42, 10.32it/s]\u001b[A\n",
      " 66%|██████▌   | 4383/6672 [09:31<03:35, 10.63it/s]\u001b[A\n",
      " 66%|██████▌   | 4385/6672 [09:31<03:26, 11.08it/s]\u001b[A\n",
      " 66%|██████▌   | 4387/6672 [09:31<03:16, 11.63it/s]\u001b[A\n",
      " 66%|██████▌   | 4389/6672 [09:32<03:06, 12.23it/s]\u001b[A\n",
      " 66%|██████▌   | 4391/6672 [09:32<03:00, 12.61it/s]\u001b[A\n",
      " 66%|██████▌   | 4393/6672 [09:32<03:06, 12.20it/s]\u001b[A\n",
      " 66%|██████▌   | 4395/6672 [09:32<03:36, 10.51it/s]\u001b[A\n",
      " 66%|██████▌   | 4397/6672 [09:32<03:28, 10.92it/s]\u001b[A\n",
      " 66%|██████▌   | 4399/6672 [09:33<03:33, 10.67it/s]\u001b[A\n",
      " 66%|██████▌   | 4401/6672 [09:33<03:59,  9.49it/s]\u001b[A\n",
      " 66%|██████▌   | 4403/6672 [09:33<03:35, 10.53it/s]\u001b[A\n",
      " 66%|██████▌   | 4405/6672 [09:33<03:27, 10.93it/s]\u001b[A\n",
      " 66%|██████▌   | 4407/6672 [09:33<03:25, 11.01it/s]\u001b[A\n",
      " 66%|██████▌   | 4409/6672 [09:33<03:29, 10.80it/s]\u001b[A\n",
      " 66%|██████▌   | 4411/6672 [09:34<03:26, 10.94it/s]\u001b[A\n",
      " 66%|██████▌   | 4413/6672 [09:34<03:26, 10.93it/s]\u001b[A\n",
      " 66%|██████▌   | 4415/6672 [09:34<03:34, 10.50it/s]\u001b[A\n",
      " 66%|██████▌   | 4417/6672 [09:34<03:31, 10.67it/s]\u001b[A\n",
      " 66%|██████▌   | 4419/6672 [09:34<03:30, 10.72it/s]\u001b[A\n",
      " 66%|██████▋   | 4421/6672 [09:35<03:51,  9.70it/s]\u001b[A\n",
      " 66%|██████▋   | 4422/6672 [09:35<04:03,  9.26it/s]\u001b[A\n",
      " 66%|██████▋   | 4423/6672 [09:35<04:12,  8.90it/s]\u001b[A\n",
      " 66%|██████▋   | 4425/6672 [09:35<03:55,  9.53it/s]\u001b[A\n",
      " 66%|██████▋   | 4427/6672 [09:35<03:34, 10.45it/s]\u001b[A\n",
      " 66%|██████▋   | 4429/6672 [09:35<03:39, 10.21it/s]\u001b[A\n",
      " 66%|██████▋   | 4431/6672 [09:36<04:05,  9.14it/s]\u001b[A\n",
      " 66%|██████▋   | 4432/6672 [09:36<04:19,  8.63it/s]\u001b[A\n",
      " 66%|██████▋   | 4433/6672 [09:36<04:20,  8.60it/s]\u001b[A\n",
      " 66%|██████▋   | 4435/6672 [09:36<04:00,  9.31it/s]\u001b[A\n",
      " 66%|██████▋   | 4436/6672 [09:36<03:57,  9.42it/s]\u001b[A\n",
      " 67%|██████▋   | 4438/6672 [09:36<03:42, 10.04it/s]\u001b[A\n",
      " 67%|██████▋   | 4439/6672 [09:37<03:43,  9.98it/s]\u001b[A\n",
      " 67%|██████▋   | 4440/6672 [09:37<03:51,  9.62it/s]\u001b[A\n",
      " 67%|██████▋   | 4442/6672 [09:37<03:49,  9.71it/s]\u001b[A\n",
      " 67%|██████▋   | 4443/6672 [09:37<04:03,  9.14it/s]\u001b[A\n",
      " 67%|██████▋   | 4444/6672 [09:37<04:18,  8.61it/s]\u001b[A\n",
      " 67%|██████▋   | 4445/6672 [09:37<04:29,  8.25it/s]\u001b[A\n",
      " 67%|██████▋   | 4446/6672 [09:37<04:41,  7.92it/s]\u001b[A\n",
      " 67%|██████▋   | 4447/6672 [09:38<04:27,  8.33it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 98%|█████████▊| 311/318 [00:03<00:00, 90.51it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4448\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4448/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3967215120792389, 'eval_f1': 0.7566728856893379, 'eval_recall': 0.8269207974776569, 'eval_precision': 0.717996005922616, 'eval_runtime': 3.6346, 'eval_samples_per_second': 349.417, 'eval_steps_per_second': 87.492, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4448/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4448/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4448/special_tokens_map.json\n",
      "\n",
      " 67%|██████▋   | 4449/6672 [09:45<1:00:32,  1.63s/it]\u001b[A\n",
      " 67%|██████▋   | 4450/6672 [09:45<47:10,  1.27s/it]  \u001b[A\n",
      " 67%|██████▋   | 4451/6672 [09:45<36:14,  1.02it/s]\u001b[A\n",
      " 67%|██████▋   | 4452/6672 [09:45<27:49,  1.33it/s]\u001b[A\n",
      " 67%|██████▋   | 4453/6672 [09:45<21:25,  1.73it/s]\u001b[A\n",
      " 67%|██████▋   | 4454/6672 [09:45<16:25,  2.25it/s]\u001b[A\n",
      " 67%|██████▋   | 4455/6672 [09:45<13:21,  2.77it/s]\u001b[A\n",
      " 67%|██████▋   | 4456/6672 [09:46<10:46,  3.43it/s]\u001b[A\n",
      " 67%|██████▋   | 4457/6672 [09:46<09:04,  4.06it/s]\u001b[A\n",
      " 67%|██████▋   | 4458/6672 [09:46<07:32,  4.89it/s]\u001b[A\n",
      " 67%|██████▋   | 4459/6672 [09:46<06:47,  5.43it/s]\u001b[A\n",
      " 67%|██████▋   | 4460/6672 [09:46<05:55,  6.22it/s]\u001b[A\n",
      " 67%|██████▋   | 4462/6672 [09:46<04:41,  7.86it/s]\u001b[A\n",
      " 67%|██████▋   | 4464/6672 [09:46<04:05,  8.98it/s]\u001b[A\n",
      " 67%|██████▋   | 4466/6672 [09:47<03:48,  9.65it/s]\u001b[A\n",
      " 67%|██████▋   | 4468/6672 [09:47<03:36, 10.18it/s]\u001b[A\n",
      " 67%|██████▋   | 4470/6672 [09:47<03:37, 10.11it/s]\u001b[A\n",
      " 67%|██████▋   | 4472/6672 [09:47<03:32, 10.33it/s]\u001b[A\n",
      " 67%|██████▋   | 4474/6672 [09:47<03:35, 10.22it/s]\u001b[A\n",
      " 67%|██████▋   | 4476/6672 [09:48<03:43,  9.84it/s]\u001b[A\n",
      " 67%|██████▋   | 4477/6672 [09:48<03:46,  9.68it/s]\u001b[A\n",
      " 67%|██████▋   | 4478/6672 [09:48<03:46,  9.69it/s]\u001b[A\n",
      " 67%|██████▋   | 4479/6672 [09:48<03:51,  9.45it/s]\u001b[A\n",
      " 67%|██████▋   | 4480/6672 [09:48<03:50,  9.49it/s]\u001b[A\n",
      " 67%|██████▋   | 4482/6672 [09:48<03:17, 11.08it/s]\u001b[A\n",
      " 67%|██████▋   | 4484/6672 [09:48<03:09, 11.53it/s]\u001b[A\n",
      " 67%|██████▋   | 4486/6672 [09:48<03:00, 12.14it/s]\u001b[A\n",
      " 67%|██████▋   | 4488/6672 [09:49<03:11, 11.43it/s]\u001b[A\n",
      " 67%|██████▋   | 4490/6672 [09:49<03:33, 10.21it/s]\u001b[A\n",
      " 67%|██████▋   | 4492/6672 [09:49<03:12, 11.35it/s]\u001b[A\n",
      " 67%|██████▋   | 4494/6672 [09:49<02:59, 12.16it/s]\u001b[A\n",
      " 67%|██████▋   | 4496/6672 [09:49<02:47, 12.97it/s]\u001b[A\n",
      " 67%|██████▋   | 4498/6672 [09:49<02:45, 13.15it/s]\u001b[A\n",
      " 67%|██████▋   | 4500/6672 [09:50<04:18,  8.41it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 67%|██████▋   | 4500/6672 [09:50<04:18,  8.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.015, 'learning_rate': 2.27557941957698e-05, 'epoch': 16.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 4502/6672 [09:50<04:40,  7.72it/s]\u001b[A\n",
      " 67%|██████▋   | 4503/6672 [09:50<04:36,  7.84it/s]\u001b[A\n",
      " 68%|██████▊   | 4504/6672 [09:50<04:49,  7.49it/s]\u001b[A\n",
      " 68%|██████▊   | 4505/6672 [09:51<04:57,  7.30it/s]\u001b[A\n",
      " 68%|██████▊   | 4506/6672 [09:51<04:41,  7.69it/s]\u001b[A\n",
      " 68%|██████▊   | 4507/6672 [09:51<04:39,  7.76it/s]\u001b[A\n",
      " 68%|██████▊   | 4508/6672 [09:51<04:22,  8.25it/s]\u001b[A\n",
      " 68%|██████▊   | 4509/6672 [09:51<04:14,  8.50it/s]\u001b[A\n",
      " 68%|██████▊   | 4510/6672 [09:51<04:05,  8.82it/s]\u001b[A\n",
      " 68%|██████▊   | 4511/6672 [09:51<04:14,  8.48it/s]\u001b[A\n",
      " 68%|██████▊   | 4512/6672 [09:51<04:36,  7.82it/s]\u001b[A\n",
      " 68%|██████▊   | 4513/6672 [09:51<04:19,  8.33it/s]\u001b[A\n",
      " 68%|██████▊   | 4514/6672 [09:52<04:26,  8.10it/s]\u001b[A\n",
      " 68%|██████▊   | 4516/6672 [09:52<03:39,  9.83it/s]\u001b[A\n",
      " 68%|██████▊   | 4518/6672 [09:52<03:26, 10.43it/s]\u001b[A\n",
      " 68%|██████▊   | 4520/6672 [09:52<03:17, 10.91it/s]\u001b[A\n",
      " 68%|██████▊   | 4522/6672 [09:52<03:08, 11.43it/s]\u001b[A\n",
      " 68%|██████▊   | 4524/6672 [09:52<03:06, 11.51it/s]\u001b[A\n",
      " 68%|██████▊   | 4526/6672 [09:53<03:29, 10.22it/s]\u001b[A\n",
      " 68%|██████▊   | 4528/6672 [09:53<03:37,  9.87it/s]\u001b[A\n",
      " 68%|██████▊   | 4530/6672 [09:53<03:55,  9.11it/s]\u001b[A\n",
      " 68%|██████▊   | 4532/6672 [09:53<03:38,  9.77it/s]\u001b[A\n",
      " 68%|██████▊   | 4534/6672 [09:53<03:25, 10.40it/s]\u001b[A\n",
      " 68%|██████▊   | 4536/6672 [09:54<03:18, 10.78it/s]\u001b[A\n",
      " 68%|██████▊   | 4538/6672 [09:54<03:11, 11.14it/s]\u001b[A\n",
      " 68%|██████▊   | 4540/6672 [09:54<03:09, 11.25it/s]\u001b[A\n",
      " 68%|██████▊   | 4542/6672 [09:54<03:21, 10.57it/s]\u001b[A\n",
      " 68%|██████▊   | 4544/6672 [09:54<03:08, 11.27it/s]\u001b[A\n",
      " 68%|██████▊   | 4546/6672 [09:55<03:03, 11.59it/s]\u001b[A\n",
      " 68%|██████▊   | 4548/6672 [09:55<03:05, 11.44it/s]\u001b[A\n",
      " 68%|██████▊   | 4550/6672 [09:55<03:50,  9.21it/s]\u001b[A\n",
      " 68%|██████▊   | 4552/6672 [09:55<03:51,  9.17it/s]\u001b[A\n",
      " 68%|██████▊   | 4554/6672 [09:55<03:42,  9.53it/s]\u001b[A\n",
      " 68%|██████▊   | 4555/6672 [09:56<03:41,  9.58it/s]\u001b[A\n",
      " 68%|██████▊   | 4556/6672 [09:56<03:39,  9.64it/s]\u001b[A\n",
      " 68%|██████▊   | 4558/6672 [09:56<03:28, 10.15it/s]\u001b[A\n",
      " 68%|██████▊   | 4560/6672 [09:56<03:42,  9.50it/s]\u001b[A\n",
      " 68%|██████▊   | 4561/6672 [09:56<03:43,  9.44it/s]\u001b[A\n",
      " 68%|██████▊   | 4562/6672 [09:56<03:44,  9.39it/s]\u001b[A\n",
      " 68%|██████▊   | 4563/6672 [09:56<03:43,  9.42it/s]\u001b[A\n",
      " 68%|██████▊   | 4564/6672 [09:56<03:40,  9.56it/s]\u001b[A\n",
      " 68%|██████▊   | 4566/6672 [09:57<03:15, 10.76it/s]\u001b[A\n",
      " 68%|██████▊   | 4568/6672 [09:57<03:30,  9.97it/s]\u001b[A\n",
      " 68%|██████▊   | 4570/6672 [09:57<03:11, 10.97it/s]\u001b[A\n",
      " 69%|██████▊   | 4572/6672 [09:57<03:03, 11.47it/s]\u001b[A\n",
      " 69%|██████▊   | 4574/6672 [09:57<03:24, 10.28it/s]\u001b[A\n",
      " 69%|██████▊   | 4576/6672 [09:58<03:12, 10.87it/s]\u001b[A\n",
      " 69%|██████▊   | 4578/6672 [09:58<03:01, 11.54it/s]\u001b[A\n",
      " 69%|██████▊   | 4580/6672 [09:58<02:47, 12.49it/s]\u001b[A\n",
      " 69%|██████▊   | 4582/6672 [09:58<02:37, 13.29it/s]\u001b[A\n",
      " 69%|██████▊   | 4584/6672 [09:58<02:30, 13.84it/s]\u001b[A\n",
      " 69%|██████▊   | 4586/6672 [09:58<02:49, 12.30it/s]\u001b[A\n",
      " 69%|██████▉   | 4588/6672 [09:58<03:02, 11.42it/s]\u001b[A\n",
      " 69%|██████▉   | 4590/6672 [09:59<03:04, 11.28it/s]\u001b[A\n",
      " 69%|██████▉   | 4592/6672 [09:59<02:58, 11.65it/s]\u001b[A\n",
      " 69%|██████▉   | 4594/6672 [09:59<02:55, 11.82it/s]\u001b[A\n",
      " 69%|██████▉   | 4596/6672 [09:59<03:13, 10.73it/s]\u001b[A\n",
      " 69%|██████▉   | 4598/6672 [09:59<03:05, 11.16it/s]\u001b[A\n",
      " 69%|██████▉   | 4600/6672 [10:00<03:39,  9.46it/s]\u001b[A\n",
      " 69%|██████▉   | 4602/6672 [10:00<03:42,  9.31it/s]\u001b[A\n",
      " 69%|██████▉   | 4604/6672 [10:00<03:34,  9.65it/s]\u001b[A\n",
      " 69%|██████▉   | 4605/6672 [10:00<03:42,  9.28it/s]\u001b[A\n",
      " 69%|██████▉   | 4607/6672 [10:00<03:29,  9.87it/s]\u001b[A\n",
      " 69%|██████▉   | 4609/6672 [10:01<03:18, 10.39it/s]\u001b[A\n",
      " 69%|██████▉   | 4611/6672 [10:01<03:09, 10.89it/s]\u001b[A\n",
      " 69%|██████▉   | 4613/6672 [10:01<03:03, 11.22it/s]\u001b[A\n",
      " 69%|██████▉   | 4615/6672 [10:01<03:08, 10.89it/s]\u001b[A\n",
      " 69%|██████▉   | 4617/6672 [10:01<03:01, 11.30it/s]\u001b[A\n",
      " 69%|██████▉   | 4619/6672 [10:01<03:10, 10.75it/s]\u001b[A\n",
      " 69%|██████▉   | 4621/6672 [10:02<03:08, 10.90it/s]\u001b[A\n",
      " 69%|██████▉   | 4623/6672 [10:02<03:00, 11.37it/s]\u001b[A\n",
      " 69%|██████▉   | 4625/6672 [10:02<02:58, 11.44it/s]\u001b[A\n",
      " 69%|██████▉   | 4627/6672 [10:02<02:55, 11.66it/s]\u001b[A\n",
      " 69%|██████▉   | 4629/6672 [10:02<03:03, 11.16it/s]\u001b[A\n",
      " 69%|██████▉   | 4631/6672 [10:03<03:08, 10.82it/s]\u001b[A\n",
      " 69%|██████▉   | 4633/6672 [10:03<03:09, 10.75it/s]\u001b[A\n",
      " 69%|██████▉   | 4635/6672 [10:03<03:03, 11.10it/s]\u001b[A\n",
      " 69%|██████▉   | 4637/6672 [10:03<03:08, 10.77it/s]\u001b[A\n",
      " 70%|██████▉   | 4639/6672 [10:03<03:34,  9.46it/s]\u001b[A\n",
      " 70%|██████▉   | 4640/6672 [10:03<03:34,  9.48it/s]\u001b[A\n",
      " 70%|██████▉   | 4642/6672 [10:04<03:09, 10.73it/s]\u001b[A\n",
      " 70%|██████▉   | 4644/6672 [10:04<03:09, 10.68it/s]\u001b[A\n",
      " 70%|██████▉   | 4646/6672 [10:04<02:57, 11.41it/s]\u001b[A\n",
      " 70%|██████▉   | 4648/6672 [10:04<02:43, 12.35it/s]\u001b[A\n",
      " 70%|██████▉   | 4650/6672 [10:04<03:29,  9.65it/s]\u001b[A\n",
      " 70%|██████▉   | 4652/6672 [10:05<03:36,  9.31it/s]\u001b[A\n",
      " 70%|██████▉   | 4654/6672 [10:05<03:39,  9.20it/s]\u001b[A\n",
      " 70%|██████▉   | 4656/6672 [10:05<03:30,  9.59it/s]\u001b[A\n",
      " 70%|██████▉   | 4658/6672 [10:05<03:32,  9.50it/s]\u001b[A\n",
      " 70%|██████▉   | 4659/6672 [10:05<03:42,  9.04it/s]\u001b[A\n",
      " 70%|██████▉   | 4660/6672 [10:05<03:38,  9.21it/s]\u001b[A\n",
      " 70%|██████▉   | 4662/6672 [10:06<03:17, 10.15it/s]\u001b[A\n",
      " 70%|██████▉   | 4664/6672 [10:06<03:13, 10.39it/s]\u001b[A\n",
      " 70%|██████▉   | 4666/6672 [10:06<02:56, 11.39it/s]\u001b[A\n",
      " 70%|██████▉   | 4668/6672 [10:06<02:46, 12.00it/s]\u001b[A\n",
      " 70%|██████▉   | 4670/6672 [10:06<02:40, 12.44it/s]\u001b[A\n",
      " 70%|███████   | 4672/6672 [10:06<02:32, 13.14it/s]\u001b[A\n",
      " 70%|███████   | 4674/6672 [10:07<02:26, 13.66it/s]\u001b[A\n",
      " 70%|███████   | 4676/6672 [10:07<02:32, 13.08it/s]\u001b[A\n",
      " 70%|███████   | 4678/6672 [10:07<02:36, 12.70it/s]\u001b[A\n",
      " 70%|███████   | 4680/6672 [10:07<02:45, 12.05it/s]\u001b[A\n",
      " 70%|███████   | 4682/6672 [10:07<02:46, 11.94it/s]\u001b[A\n",
      " 70%|███████   | 4684/6672 [10:07<02:47, 11.87it/s]\u001b[A\n",
      " 70%|███████   | 4686/6672 [10:08<02:44, 12.07it/s]\u001b[A\n",
      " 70%|███████   | 4688/6672 [10:08<02:46, 11.94it/s]\u001b[A\n",
      " 70%|███████   | 4690/6672 [10:08<03:06, 10.62it/s]\u001b[A\n",
      " 70%|███████   | 4692/6672 [10:08<03:11, 10.36it/s]\u001b[A\n",
      " 70%|███████   | 4694/6672 [10:08<03:08, 10.52it/s]\u001b[A\n",
      " 70%|███████   | 4696/6672 [10:08<03:02, 10.83it/s]\u001b[A\n",
      " 70%|███████   | 4698/6672 [10:09<02:54, 11.32it/s]\u001b[A\n",
      " 70%|███████   | 4700/6672 [10:09<03:22,  9.76it/s]\u001b[A\n",
      " 70%|███████   | 4702/6672 [10:09<03:17,  9.97it/s]\u001b[A\n",
      " 71%|███████   | 4704/6672 [10:09<03:23,  9.66it/s]\u001b[A\n",
      " 71%|███████   | 4706/6672 [10:10<03:22,  9.71it/s]\u001b[A\n",
      " 71%|███████   | 4708/6672 [10:10<03:23,  9.67it/s]\u001b[A\n",
      " 71%|███████   | 4710/6672 [10:10<03:10, 10.27it/s]\u001b[A\n",
      " 71%|███████   | 4712/6672 [10:10<03:09, 10.33it/s]\u001b[A\n",
      " 71%|███████   | 4714/6672 [10:10<03:03, 10.64it/s]\u001b[A\n",
      " 71%|███████   | 4716/6672 [10:10<03:00, 10.84it/s]\u001b[A\n",
      " 71%|███████   | 4718/6672 [10:11<02:56, 11.05it/s]\u001b[A\n",
      " 71%|███████   | 4720/6672 [10:11<02:58, 10.95it/s]\u001b[A\n",
      " 71%|███████   | 4722/6672 [10:11<02:57, 10.97it/s]\u001b[A\n",
      " 71%|███████   | 4724/6672 [10:11<02:56, 11.04it/s]\u001b[A\n",
      " 71%|███████   | 4726/6672 [10:11<02:55, 11.10it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 75.94it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4726\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4726/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44790539145469666, 'eval_f1': 0.7502434821696135, 'eval_recall': 0.8210416518502714, 'eval_precision': 0.7120156555772994, 'eval_runtime': 4.3354, 'eval_samples_per_second': 292.937, 'eval_steps_per_second': 73.35, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4726/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4726/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-4726/special_tokens_map.json\n",
      "\n",
      " 71%|███████   | 4728/6672 [10:19<39:45,  1.23s/it]\u001b[A\n",
      " 71%|███████   | 4729/6672 [10:19<33:39,  1.04s/it]\u001b[A\n",
      " 71%|███████   | 4730/6672 [10:19<27:50,  1.16it/s]\u001b[A\n",
      " 71%|███████   | 4731/6672 [10:20<22:22,  1.45it/s]\u001b[A\n",
      " 71%|███████   | 4732/6672 [10:20<17:48,  1.82it/s]\u001b[A\n",
      " 71%|███████   | 4733/6672 [10:20<14:11,  2.28it/s]\u001b[A\n",
      " 71%|███████   | 4734/6672 [10:20<11:23,  2.84it/s]\u001b[A\n",
      " 71%|███████   | 4735/6672 [10:20<09:18,  3.47it/s]\u001b[A\n",
      " 71%|███████   | 4736/6672 [10:20<07:46,  4.15it/s]\u001b[A\n",
      " 71%|███████   | 4738/6672 [10:20<05:35,  5.77it/s]\u001b[A\n",
      " 71%|███████   | 4740/6672 [10:20<04:28,  7.19it/s]\u001b[A\n",
      " 71%|███████   | 4741/6672 [10:21<04:22,  7.34it/s]\u001b[A\n",
      " 71%|███████   | 4742/6672 [10:21<04:32,  7.08it/s]\u001b[A\n",
      " 71%|███████   | 4744/6672 [10:21<03:57,  8.13it/s]\u001b[A\n",
      " 71%|███████   | 4746/6672 [10:21<03:30,  9.14it/s]\u001b[A\n",
      " 71%|███████   | 4747/6672 [10:21<03:31,  9.09it/s]\u001b[A\n",
      " 71%|███████   | 4748/6672 [10:21<03:30,  9.15it/s]\u001b[A\n",
      " 71%|███████   | 4750/6672 [10:22<03:13,  9.92it/s]\u001b[A\n",
      " 71%|███████   | 4752/6672 [10:22<03:01, 10.59it/s]\u001b[A\n",
      " 71%|███████▏  | 4754/6672 [10:22<02:53, 11.02it/s]\u001b[A\n",
      " 71%|███████▏  | 4756/6672 [10:22<02:48, 11.35it/s]\u001b[A\n",
      " 71%|███████▏  | 4758/6672 [10:22<02:40, 11.91it/s]\u001b[A\n",
      " 71%|███████▏  | 4760/6672 [10:22<02:55, 10.87it/s]\u001b[A\n",
      " 71%|███████▏  | 4762/6672 [10:23<03:11,  9.98it/s]\u001b[A\n",
      " 71%|███████▏  | 4764/6672 [10:23<03:27,  9.20it/s]\u001b[A\n",
      " 71%|███████▏  | 4765/6672 [10:23<03:24,  9.33it/s]\u001b[A\n",
      " 71%|███████▏  | 4766/6672 [10:23<03:28,  9.12it/s]\u001b[A\n",
      " 71%|███████▏  | 4768/6672 [10:23<03:11,  9.96it/s]\u001b[A\n",
      " 71%|███████▏  | 4770/6672 [10:23<03:07, 10.17it/s]\u001b[A\n",
      " 72%|███████▏  | 4772/6672 [10:24<03:01, 10.46it/s]\u001b[A\n",
      " 72%|███████▏  | 4774/6672 [10:24<02:54, 10.87it/s]\u001b[A\n",
      " 72%|███████▏  | 4776/6672 [10:24<03:01, 10.45it/s]\u001b[A\n",
      " 72%|███████▏  | 4778/6672 [10:24<03:28,  9.09it/s]\u001b[A\n",
      " 72%|███████▏  | 4779/6672 [10:24<03:34,  8.82it/s]\u001b[A\n",
      " 72%|███████▏  | 4780/6672 [10:25<03:47,  8.31it/s]\u001b[A\n",
      " 72%|███████▏  | 4781/6672 [10:25<03:41,  8.53it/s]\u001b[A\n",
      " 72%|███████▏  | 4783/6672 [10:25<03:22,  9.34it/s]\u001b[A\n",
      " 72%|███████▏  | 4785/6672 [10:25<03:10,  9.92it/s]\u001b[A\n",
      " 72%|███████▏  | 4787/6672 [10:25<02:59, 10.52it/s]\u001b[A\n",
      " 72%|███████▏  | 4789/6672 [10:25<02:53, 10.83it/s]\u001b[A\n",
      " 72%|███████▏  | 4791/6672 [10:26<02:43, 11.49it/s]\u001b[A\n",
      " 72%|███████▏  | 4793/6672 [10:26<02:38, 11.83it/s]\u001b[A\n",
      " 72%|███████▏  | 4795/6672 [10:26<02:36, 12.03it/s]\u001b[A\n",
      " 72%|███████▏  | 4797/6672 [10:26<02:31, 12.40it/s]\u001b[A\n",
      " 72%|███████▏  | 4799/6672 [10:26<02:26, 12.81it/s]\u001b[A\n",
      " 72%|███████▏  | 4801/6672 [10:26<02:29, 12.54it/s]\u001b[A\n",
      " 72%|███████▏  | 4803/6672 [10:26<02:35, 12.05it/s]\u001b[A\n",
      " 72%|███████▏  | 4805/6672 [10:27<02:35, 12.01it/s]\u001b[A\n",
      " 72%|███████▏  | 4807/6672 [10:27<02:31, 12.28it/s]\u001b[A\n",
      " 72%|███████▏  | 4809/6672 [10:27<02:29, 12.44it/s]\u001b[A\n",
      " 72%|███████▏  | 4811/6672 [10:27<02:40, 11.60it/s]\u001b[A\n",
      " 72%|███████▏  | 4813/6672 [10:27<02:33, 12.15it/s]\u001b[A\n",
      " 72%|███████▏  | 4815/6672 [10:27<02:22, 13.00it/s]\u001b[A\n",
      " 72%|███████▏  | 4817/6672 [10:28<02:31, 12.26it/s]\u001b[A\n",
      " 72%|███████▏  | 4819/6672 [10:28<02:30, 12.33it/s]\u001b[A\n",
      " 72%|███████▏  | 4821/6672 [10:28<02:44, 11.25it/s]\u001b[A\n",
      " 72%|███████▏  | 4823/6672 [10:28<02:52, 10.74it/s]\u001b[A\n",
      " 72%|███████▏  | 4825/6672 [10:28<02:52, 10.72it/s]\u001b[A\n",
      " 72%|███████▏  | 4827/6672 [10:29<03:22,  9.13it/s]\u001b[A\n",
      " 72%|███████▏  | 4828/6672 [10:29<03:34,  8.59it/s]\u001b[A\n",
      " 72%|███████▏  | 4829/6672 [10:29<03:51,  7.98it/s]\u001b[A\n",
      " 72%|███████▏  | 4830/6672 [10:29<04:02,  7.59it/s]\u001b[A\n",
      " 72%|███████▏  | 4831/6672 [10:29<04:08,  7.42it/s]\u001b[A\n",
      " 72%|███████▏  | 4832/6672 [10:29<04:02,  7.59it/s]\u001b[A\n",
      " 72%|███████▏  | 4833/6672 [10:30<04:01,  7.63it/s]\u001b[A\n",
      " 72%|███████▏  | 4835/6672 [10:30<03:28,  8.83it/s]\u001b[A\n",
      " 72%|███████▏  | 4836/6672 [10:30<03:22,  9.06it/s]\u001b[A\n",
      " 72%|███████▏  | 4837/6672 [10:30<03:21,  9.09it/s]\u001b[A\n",
      " 73%|███████▎  | 4839/6672 [10:30<03:02, 10.02it/s]\u001b[A\n",
      " 73%|███████▎  | 4840/6672 [10:30<03:07,  9.79it/s]\u001b[A\n",
      " 73%|███████▎  | 4842/6672 [10:30<02:52, 10.58it/s]\u001b[A\n",
      " 73%|███████▎  | 4844/6672 [10:31<02:44, 11.13it/s]\u001b[A\n",
      " 73%|███████▎  | 4846/6672 [10:31<02:51, 10.65it/s]\u001b[A\n",
      " 73%|███████▎  | 4848/6672 [10:31<02:59, 10.18it/s]\u001b[A\n",
      " 73%|███████▎  | 4850/6672 [10:31<02:51, 10.62it/s]\u001b[A\n",
      " 73%|███████▎  | 4852/6672 [10:31<03:02,  9.99it/s]\u001b[A\n",
      " 73%|███████▎  | 4854/6672 [10:32<02:54, 10.44it/s]\u001b[A\n",
      " 73%|███████▎  | 4856/6672 [10:32<03:04,  9.84it/s]\u001b[A\n",
      " 73%|███████▎  | 4858/6672 [10:32<02:53, 10.46it/s]\u001b[A\n",
      " 73%|███████▎  | 4860/6672 [10:32<02:46, 10.87it/s]\u001b[A\n",
      " 73%|███████▎  | 4862/6672 [10:32<02:36, 11.57it/s]\u001b[A\n",
      " 73%|███████▎  | 4864/6672 [10:32<02:33, 11.77it/s]\u001b[A\n",
      " 73%|███████▎  | 4866/6672 [10:33<02:50, 10.61it/s]\u001b[A\n",
      " 73%|███████▎  | 4868/6672 [10:33<02:45, 10.91it/s]\u001b[A\n",
      " 73%|███████▎  | 4870/6672 [10:33<02:34, 11.67it/s]\u001b[A\n",
      " 73%|███████▎  | 4872/6672 [10:33<02:18, 12.98it/s]\u001b[A\n",
      " 73%|███████▎  | 4874/6672 [10:33<02:16, 13.16it/s]\u001b[A\n",
      " 73%|███████▎  | 4876/6672 [10:33<02:20, 12.76it/s]\u001b[A\n",
      " 73%|███████▎  | 4878/6672 [10:34<03:12,  9.31it/s]\u001b[A\n",
      " 73%|███████▎  | 4880/6672 [10:34<03:16,  9.12it/s]\u001b[A\n",
      " 73%|███████▎  | 4882/6672 [10:34<03:09,  9.45it/s]\u001b[A\n",
      " 73%|███████▎  | 4884/6672 [10:34<03:02,  9.81it/s]\u001b[A\n",
      " 73%|███████▎  | 4886/6672 [10:35<02:58, 10.00it/s]\u001b[A\n",
      " 73%|███████▎  | 4888/6672 [10:35<02:48, 10.59it/s]\u001b[A\n",
      " 73%|███████▎  | 4890/6672 [10:35<02:42, 10.97it/s]\u001b[A\n",
      " 73%|███████▎  | 4892/6672 [10:35<02:36, 11.34it/s]\u001b[A\n",
      " 73%|███████▎  | 4894/6672 [10:35<02:47, 10.63it/s]\u001b[A\n",
      " 73%|███████▎  | 4896/6672 [10:36<03:08,  9.42it/s]\u001b[A\n",
      " 73%|███████▎  | 4897/6672 [10:36<03:20,  8.85it/s]\u001b[A\n",
      " 73%|███████▎  | 4898/6672 [10:36<03:16,  9.05it/s]\u001b[A\n",
      " 73%|███████▎  | 4900/6672 [10:36<03:00,  9.84it/s]\u001b[A\n",
      " 73%|███████▎  | 4902/6672 [10:36<02:47, 10.55it/s]\u001b[A\n",
      " 74%|███████▎  | 4904/6672 [10:36<02:40, 11.03it/s]\u001b[A\n",
      " 74%|███████▎  | 4906/6672 [10:36<02:25, 12.10it/s]\u001b[A\n",
      " 74%|███████▎  | 4908/6672 [10:37<02:19, 12.66it/s]\u001b[A\n",
      " 74%|███████▎  | 4910/6672 [10:37<02:20, 12.53it/s]\u001b[A\n",
      " 74%|███████▎  | 4912/6672 [10:37<02:20, 12.50it/s]\u001b[A\n",
      " 74%|███████▎  | 4914/6672 [10:37<02:26, 12.02it/s]\u001b[A\n",
      " 74%|███████▎  | 4916/6672 [10:37<02:19, 12.55it/s]\u001b[A\n",
      " 74%|███████▎  | 4918/6672 [10:37<02:24, 12.17it/s]\u001b[A\n",
      " 74%|███████▎  | 4920/6672 [10:38<02:23, 12.20it/s]\u001b[A\n",
      " 74%|███████▍  | 4922/6672 [10:38<02:18, 12.63it/s]\u001b[A\n",
      " 74%|███████▍  | 4924/6672 [10:38<02:25, 12.05it/s]\u001b[A\n",
      " 74%|███████▍  | 4926/6672 [10:38<02:31, 11.51it/s]\u001b[A\n",
      " 74%|███████▍  | 4928/6672 [10:38<03:04,  9.48it/s]\u001b[A\n",
      " 74%|███████▍  | 4930/6672 [10:39<03:07,  9.30it/s]\u001b[A\n",
      " 74%|███████▍  | 4931/6672 [10:39<03:05,  9.40it/s]\u001b[A\n",
      " 74%|███████▍  | 4932/6672 [10:39<03:18,  8.79it/s]\u001b[A\n",
      " 74%|███████▍  | 4933/6672 [10:39<03:14,  8.95it/s]\u001b[A\n",
      " 74%|███████▍  | 4935/6672 [10:39<02:58,  9.72it/s]\u001b[A\n",
      " 74%|███████▍  | 4937/6672 [10:39<02:47, 10.35it/s]\u001b[A\n",
      " 74%|███████▍  | 4939/6672 [10:39<02:45, 10.48it/s]\u001b[A\n",
      " 74%|███████▍  | 4941/6672 [10:40<02:42, 10.64it/s]\u001b[A\n",
      " 74%|███████▍  | 4943/6672 [10:40<02:34, 11.18it/s]\u001b[A\n",
      " 74%|███████▍  | 4945/6672 [10:40<02:29, 11.56it/s]\u001b[A\n",
      " 74%|███████▍  | 4947/6672 [10:40<02:26, 11.75it/s]\u001b[A\n",
      " 74%|███████▍  | 4949/6672 [10:40<02:23, 11.97it/s]\u001b[A\n",
      " 74%|███████▍  | 4951/6672 [10:40<02:18, 12.41it/s]\u001b[A\n",
      " 74%|███████▍  | 4953/6672 [10:41<02:30, 11.44it/s]\u001b[A\n",
      " 74%|███████▍  | 4955/6672 [10:41<02:30, 11.43it/s]\u001b[A\n",
      " 74%|███████▍  | 4957/6672 [10:41<02:37, 10.86it/s]\u001b[A\n",
      " 74%|███████▍  | 4959/6672 [10:41<02:32, 11.27it/s]\u001b[A\n",
      " 74%|███████▍  | 4961/6672 [10:41<02:31, 11.28it/s]\u001b[A\n",
      " 74%|███████▍  | 4963/6672 [10:42<02:32, 11.22it/s]\u001b[A\n",
      " 74%|███████▍  | 4965/6672 [10:42<02:24, 11.78it/s]\u001b[A\n",
      " 74%|███████▍  | 4967/6672 [10:42<02:26, 11.67it/s]\u001b[A\n",
      " 74%|███████▍  | 4969/6672 [10:42<02:20, 12.09it/s]\u001b[A\n",
      " 75%|███████▍  | 4971/6672 [10:42<02:22, 11.95it/s]\u001b[A\n",
      " 75%|███████▍  | 4973/6672 [10:42<02:23, 11.86it/s]\u001b[A\n",
      " 75%|███████▍  | 4975/6672 [10:43<02:20, 12.10it/s]\u001b[A\n",
      " 75%|███████▍  | 4977/6672 [10:43<02:36, 10.86it/s]\u001b[A\n",
      " 75%|███████▍  | 4979/6672 [10:43<02:44, 10.30it/s]\u001b[A\n",
      " 75%|███████▍  | 4981/6672 [10:43<02:55,  9.64it/s]\u001b[A\n",
      " 75%|███████▍  | 4983/6672 [10:43<02:45, 10.17it/s]\u001b[A\n",
      " 75%|███████▍  | 4985/6672 [10:44<02:38, 10.66it/s]\u001b[A\n",
      " 75%|███████▍  | 4987/6672 [10:44<02:50,  9.88it/s]\u001b[A\n",
      " 75%|███████▍  | 4989/6672 [10:44<02:40, 10.52it/s]\u001b[A\n",
      " 75%|███████▍  | 4991/6672 [10:44<02:32, 11.05it/s]\u001b[A\n",
      " 75%|███████▍  | 4993/6672 [10:44<02:32, 11.03it/s]\u001b[A\n",
      " 75%|███████▍  | 4995/6672 [10:44<02:23, 11.67it/s]\u001b[A\n",
      " 75%|███████▍  | 4997/6672 [10:45<02:24, 11.59it/s]\u001b[A\n",
      " 75%|███████▍  | 4999/6672 [10:45<02:23, 11.69it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 75%|███████▍  | 5000/6672 [10:45<02:22, 11.69it/s]\u001b[A\n",
      " 75%|███████▍  | 5001/6672 [10:45<03:19,  8.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.019, 'learning_rate': 1.7517351701347656e-05, 'epoch': 17.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▍  | 5003/6672 [10:45<02:58,  9.35it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 76.46it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5004\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5004/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3882524073123932, 'eval_f1': 0.780813384884872, 'eval_recall': 0.7796466190961604, 'eval_precision': 0.7819930515713649, 'eval_runtime': 4.2904, 'eval_samples_per_second': 296.007, 'eval_steps_per_second': 74.118, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5004/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5004/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5004/special_tokens_map.json\n",
      "\n",
      " 75%|███████▌  | 5005/6672 [10:53<34:25,  1.24s/it]\u001b[A\n",
      " 75%|███████▌  | 5006/6672 [10:53<28:59,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 5007/6672 [10:53<23:52,  1.16it/s]\u001b[A\n",
      " 75%|███████▌  | 5008/6672 [10:53<19:13,  1.44it/s]\u001b[A\n",
      " 75%|███████▌  | 5009/6672 [10:54<15:16,  1.81it/s]\u001b[A\n",
      " 75%|███████▌  | 5011/6672 [10:54<10:04,  2.75it/s]\u001b[A\n",
      " 75%|███████▌  | 5013/6672 [10:54<07:15,  3.81it/s]\u001b[A\n",
      " 75%|███████▌  | 5014/6672 [10:54<06:25,  4.30it/s]\u001b[A\n",
      " 75%|███████▌  | 5016/6672 [10:54<04:54,  5.62it/s]\u001b[A\n",
      " 75%|███████▌  | 5018/6672 [10:54<04:00,  6.87it/s]\u001b[A\n",
      " 75%|███████▌  | 5020/6672 [10:55<03:31,  7.81it/s]\u001b[A\n",
      " 75%|███████▌  | 5022/6672 [10:55<03:09,  8.70it/s]\u001b[A\n",
      " 75%|███████▌  | 5024/6672 [10:55<03:12,  8.58it/s]\u001b[A\n",
      " 75%|███████▌  | 5026/6672 [10:55<02:53,  9.49it/s]\u001b[A\n",
      " 75%|███████▌  | 5028/6672 [10:55<02:38, 10.39it/s]\u001b[A\n",
      " 75%|███████▌  | 5030/6672 [10:55<02:28, 11.07it/s]\u001b[A\n",
      " 75%|███████▌  | 5032/6672 [10:56<02:33, 10.69it/s]\u001b[A\n",
      " 75%|███████▌  | 5034/6672 [10:56<02:24, 11.37it/s]\u001b[A\n",
      " 75%|███████▌  | 5036/6672 [10:56<02:21, 11.54it/s]\u001b[A\n",
      " 76%|███████▌  | 5038/6672 [10:56<02:18, 11.84it/s]\u001b[A\n",
      " 76%|███████▌  | 5040/6672 [10:56<02:14, 12.10it/s]\u001b[A\n",
      " 76%|███████▌  | 5042/6672 [10:56<02:17, 11.89it/s]\u001b[A\n",
      " 76%|███████▌  | 5044/6672 [10:57<02:19, 11.71it/s]\u001b[A\n",
      " 76%|███████▌  | 5046/6672 [10:57<02:36, 10.40it/s]\u001b[A\n",
      " 76%|███████▌  | 5048/6672 [10:57<02:37, 10.33it/s]\u001b[A\n",
      " 76%|███████▌  | 5050/6672 [10:57<02:27, 11.02it/s]\u001b[A\n",
      " 76%|███████▌  | 5052/6672 [10:57<02:22, 11.40it/s]\u001b[A\n",
      " 76%|███████▌  | 5054/6672 [10:58<02:22, 11.38it/s]\u001b[A\n",
      " 76%|███████▌  | 5056/6672 [10:58<02:49,  9.54it/s]\u001b[A\n",
      " 76%|███████▌  | 5058/6672 [10:58<02:59,  9.01it/s]\u001b[A\n",
      " 76%|███████▌  | 5059/6672 [10:58<03:03,  8.81it/s]\u001b[A\n",
      " 76%|███████▌  | 5061/6672 [10:58<02:52,  9.34it/s]\u001b[A\n",
      " 76%|███████▌  | 5062/6672 [10:59<02:57,  9.08it/s]\u001b[A\n",
      " 76%|███████▌  | 5064/6672 [10:59<02:45,  9.72it/s]\u001b[A\n",
      " 76%|███████▌  | 5065/6672 [10:59<02:56,  9.08it/s]\u001b[A\n",
      " 76%|███████▌  | 5066/6672 [10:59<03:09,  8.49it/s]\u001b[A\n",
      " 76%|███████▌  | 5067/6672 [10:59<03:19,  8.04it/s]\u001b[A\n",
      " 76%|███████▌  | 5068/6672 [10:59<03:26,  7.78it/s]\u001b[A\n",
      " 76%|███████▌  | 5069/6672 [10:59<03:29,  7.64it/s]\u001b[A\n",
      " 76%|███████▌  | 5070/6672 [11:00<03:22,  7.93it/s]\u001b[A\n",
      " 76%|███████▌  | 5072/6672 [11:00<02:54,  9.17it/s]\u001b[A\n",
      " 76%|███████▌  | 5074/6672 [11:00<02:43,  9.79it/s]\u001b[A\n",
      " 76%|███████▌  | 5076/6672 [11:00<02:29, 10.65it/s]\u001b[A\n",
      " 76%|███████▌  | 5078/6672 [11:00<02:23, 11.12it/s]\u001b[A\n",
      " 76%|███████▌  | 5080/6672 [11:00<02:17, 11.58it/s]\u001b[A\n",
      " 76%|███████▌  | 5082/6672 [11:01<02:23, 11.09it/s]\u001b[A\n",
      " 76%|███████▌  | 5084/6672 [11:01<02:29, 10.60it/s]\u001b[A\n",
      " 76%|███████▌  | 5086/6672 [11:01<02:35, 10.18it/s]\u001b[A\n",
      " 76%|███████▋  | 5088/6672 [11:01<02:24, 10.94it/s]\u001b[A\n",
      " 76%|███████▋  | 5090/6672 [11:01<02:19, 11.33it/s]\u001b[A\n",
      " 76%|███████▋  | 5092/6672 [11:01<02:12, 11.97it/s]\u001b[A\n",
      " 76%|███████▋  | 5094/6672 [11:02<02:06, 12.43it/s]\u001b[A\n",
      " 76%|███████▋  | 5096/6672 [11:02<02:07, 12.39it/s]\u001b[A\n",
      " 76%|███████▋  | 5098/6672 [11:02<02:09, 12.16it/s]\u001b[A\n",
      " 76%|███████▋  | 5100/6672 [11:02<02:11, 12.00it/s]\u001b[A\n",
      " 76%|███████▋  | 5102/6672 [11:02<02:20, 11.20it/s]\u001b[A\n",
      " 76%|███████▋  | 5104/6672 [11:03<02:38,  9.91it/s]\u001b[A\n",
      " 77%|███████▋  | 5106/6672 [11:03<03:05,  8.44it/s]\u001b[A\n",
      " 77%|███████▋  | 5107/6672 [11:03<03:07,  8.34it/s]\u001b[A\n",
      " 77%|███████▋  | 5108/6672 [11:03<03:04,  8.46it/s]\u001b[A\n",
      " 77%|███████▋  | 5109/6672 [11:03<03:04,  8.49it/s]\u001b[A\n",
      " 77%|███████▋  | 5110/6672 [11:03<03:02,  8.57it/s]\u001b[A\n",
      " 77%|███████▋  | 5111/6672 [11:03<02:58,  8.73it/s]\u001b[A\n",
      " 77%|███████▋  | 5112/6672 [11:04<02:56,  8.84it/s]\u001b[A\n",
      " 77%|███████▋  | 5114/6672 [11:04<02:46,  9.35it/s]\u001b[A\n",
      " 77%|███████▋  | 5115/6672 [11:04<02:45,  9.41it/s]\u001b[A\n",
      " 77%|███████▋  | 5117/6672 [11:04<02:34, 10.04it/s]\u001b[A\n",
      " 77%|███████▋  | 5118/6672 [11:04<02:37,  9.84it/s]\u001b[A\n",
      " 77%|███████▋  | 5120/6672 [11:04<02:32, 10.20it/s]\u001b[A\n",
      " 77%|███████▋  | 5122/6672 [11:05<02:33, 10.11it/s]\u001b[A\n",
      " 77%|███████▋  | 5124/6672 [11:05<02:31, 10.25it/s]\u001b[A\n",
      " 77%|███████▋  | 5126/6672 [11:05<02:20, 10.98it/s]\u001b[A\n",
      " 77%|███████▋  | 5128/6672 [11:05<02:16, 11.34it/s]\u001b[A\n",
      " 77%|███████▋  | 5130/6672 [11:05<02:12, 11.67it/s]\u001b[A\n",
      " 77%|███████▋  | 5132/6672 [11:05<02:07, 12.06it/s]\u001b[A\n",
      " 77%|███████▋  | 5134/6672 [11:06<02:08, 11.93it/s]\u001b[A\n",
      " 77%|███████▋  | 5136/6672 [11:06<02:18, 11.12it/s]\u001b[A\n",
      " 77%|███████▋  | 5138/6672 [11:06<02:31, 10.12it/s]\u001b[A\n",
      " 77%|███████▋  | 5140/6672 [11:06<02:28, 10.34it/s]\u001b[A\n",
      " 77%|███████▋  | 5142/6672 [11:06<02:18, 11.01it/s]\u001b[A\n",
      " 77%|███████▋  | 5144/6672 [11:07<02:30, 10.13it/s]\u001b[A\n",
      " 77%|███████▋  | 5146/6672 [11:07<02:22, 10.70it/s]\u001b[A\n",
      " 77%|███████▋  | 5148/6672 [11:07<02:21, 10.77it/s]\u001b[A\n",
      " 77%|███████▋  | 5150/6672 [11:07<02:14, 11.30it/s]\u001b[A\n",
      " 77%|███████▋  | 5152/6672 [11:07<02:19, 10.92it/s]\u001b[A\n",
      " 77%|███████▋  | 5154/6672 [11:07<02:17, 11.02it/s]\u001b[A\n",
      " 77%|███████▋  | 5156/6672 [11:08<02:59,  8.43it/s]\u001b[A\n",
      " 77%|███████▋  | 5157/6672 [11:08<03:00,  8.38it/s]\u001b[A\n",
      " 77%|███████▋  | 5158/6672 [11:08<02:56,  8.57it/s]\u001b[A\n",
      " 77%|███████▋  | 5159/6672 [11:08<02:56,  8.59it/s]\u001b[A\n",
      " 77%|███████▋  | 5161/6672 [11:08<02:42,  9.31it/s]\u001b[A\n",
      " 77%|███████▋  | 5162/6672 [11:08<02:39,  9.44it/s]\u001b[A\n",
      " 77%|███████▋  | 5164/6672 [11:09<02:33,  9.84it/s]\u001b[A\n",
      " 77%|███████▋  | 5166/6672 [11:09<02:27, 10.20it/s]\u001b[A\n",
      " 77%|███████▋  | 5168/6672 [11:09<02:17, 10.97it/s]\u001b[A\n",
      " 77%|███████▋  | 5170/6672 [11:09<02:10, 11.54it/s]\u001b[A\n",
      " 78%|███████▊  | 5172/6672 [11:09<02:03, 12.19it/s]\u001b[A\n",
      " 78%|███████▊  | 5174/6672 [11:09<02:06, 11.86it/s]\u001b[A\n",
      " 78%|███████▊  | 5176/6672 [11:10<02:23, 10.41it/s]\u001b[A\n",
      " 78%|███████▊  | 5178/6672 [11:10<02:45,  9.04it/s]\u001b[A\n",
      " 78%|███████▊  | 5179/6672 [11:10<02:43,  9.12it/s]\u001b[A\n",
      " 78%|███████▊  | 5181/6672 [11:10<02:30,  9.94it/s]\u001b[A\n",
      " 78%|███████▊  | 5183/6672 [11:10<02:20, 10.59it/s]\u001b[A\n",
      " 78%|███████▊  | 5185/6672 [11:11<02:25, 10.25it/s]\u001b[A\n",
      " 78%|███████▊  | 5187/6672 [11:11<02:22, 10.42it/s]\u001b[A\n",
      " 78%|███████▊  | 5189/6672 [11:11<02:17, 10.81it/s]\u001b[A\n",
      " 78%|███████▊  | 5191/6672 [11:11<02:24, 10.23it/s]\u001b[A\n",
      " 78%|███████▊  | 5193/6672 [11:11<02:39,  9.26it/s]\u001b[A\n",
      " 78%|███████▊  | 5194/6672 [11:12<02:41,  9.14it/s]\u001b[A\n",
      " 78%|███████▊  | 5195/6672 [11:12<02:49,  8.74it/s]\u001b[A\n",
      " 78%|███████▊  | 5196/6672 [11:12<02:58,  8.29it/s]\u001b[A\n",
      " 78%|███████▊  | 5198/6672 [11:12<02:43,  9.00it/s]\u001b[A\n",
      " 78%|███████▊  | 5199/6672 [11:12<02:48,  8.73it/s]\u001b[A\n",
      " 78%|███████▊  | 5200/6672 [11:12<02:56,  8.32it/s]\u001b[A\n",
      " 78%|███████▊  | 5201/6672 [11:12<02:54,  8.42it/s]\u001b[A\n",
      " 78%|███████▊  | 5203/6672 [11:13<02:29,  9.82it/s]\u001b[A\n",
      " 78%|███████▊  | 5204/6672 [11:13<02:32,  9.61it/s]\u001b[A\n",
      " 78%|███████▊  | 5205/6672 [11:13<02:52,  8.51it/s]\u001b[A\n",
      " 78%|███████▊  | 5206/6672 [11:13<03:05,  7.91it/s]\u001b[A\n",
      " 78%|███████▊  | 5207/6672 [11:13<03:18,  7.38it/s]\u001b[A\n",
      " 78%|███████▊  | 5208/6672 [11:13<03:32,  6.90it/s]\u001b[A\n",
      " 78%|███████▊  | 5209/6672 [11:13<03:18,  7.37it/s]\u001b[A\n",
      " 78%|███████▊  | 5210/6672 [11:14<03:08,  7.74it/s]\u001b[A\n",
      " 78%|███████▊  | 5212/6672 [11:14<02:44,  8.87it/s]\u001b[A\n",
      " 78%|███████▊  | 5214/6672 [11:14<02:29,  9.76it/s]\u001b[A\n",
      " 78%|███████▊  | 5216/6672 [11:14<02:26,  9.96it/s]\u001b[A\n",
      " 78%|███████▊  | 5218/6672 [11:14<02:23, 10.16it/s]\u001b[A\n",
      " 78%|███████▊  | 5220/6672 [11:14<02:20, 10.32it/s]\u001b[A\n",
      " 78%|███████▊  | 5222/6672 [11:15<02:16, 10.60it/s]\u001b[A\n",
      " 78%|███████▊  | 5224/6672 [11:15<02:11, 11.03it/s]\u001b[A\n",
      " 78%|███████▊  | 5226/6672 [11:15<02:04, 11.60it/s]\u001b[A\n",
      " 78%|███████▊  | 5228/6672 [11:15<02:01, 11.87it/s]\u001b[A\n",
      " 78%|███████▊  | 5230/6672 [11:15<02:01, 11.86it/s]\u001b[A\n",
      " 78%|███████▊  | 5232/6672 [11:15<01:53, 12.73it/s]\u001b[A\n",
      " 78%|███████▊  | 5234/6672 [11:16<01:50, 12.99it/s]\u001b[A\n",
      " 78%|███████▊  | 5236/6672 [11:16<01:52, 12.76it/s]\u001b[A\n",
      " 79%|███████▊  | 5238/6672 [11:16<01:54, 12.55it/s]\u001b[A\n",
      " 79%|███████▊  | 5240/6672 [11:16<02:01, 11.75it/s]\u001b[A\n",
      " 79%|███████▊  | 5242/6672 [11:16<02:00, 11.83it/s]\u001b[A\n",
      " 79%|███████▊  | 5244/6672 [11:16<02:13, 10.74it/s]\u001b[A\n",
      " 79%|███████▊  | 5246/6672 [11:17<02:12, 10.73it/s]\u001b[A\n",
      " 79%|███████▊  | 5248/6672 [11:17<02:03, 11.55it/s]\u001b[A\n",
      " 79%|███████▊  | 5250/6672 [11:17<02:00, 11.82it/s]\u001b[A\n",
      " 79%|███████▊  | 5252/6672 [11:17<02:03, 11.46it/s]\u001b[A\n",
      " 79%|███████▊  | 5254/6672 [11:17<02:01, 11.67it/s]\u001b[A\n",
      " 79%|███████▉  | 5256/6672 [11:18<02:22,  9.91it/s]\u001b[A\n",
      " 79%|███████▉  | 5258/6672 [11:18<02:20, 10.08it/s]\u001b[A\n",
      " 79%|███████▉  | 5260/6672 [11:18<02:25,  9.72it/s]\u001b[A\n",
      " 79%|███████▉  | 5262/6672 [11:18<02:17, 10.23it/s]\u001b[A\n",
      " 79%|███████▉  | 5264/6672 [11:18<02:07, 11.09it/s]\u001b[A\n",
      " 79%|███████▉  | 5266/6672 [11:18<01:57, 11.98it/s]\u001b[A\n",
      " 79%|███████▉  | 5268/6672 [11:19<01:58, 11.82it/s]\u001b[A\n",
      " 79%|███████▉  | 5270/6672 [11:19<02:07, 10.97it/s]\u001b[A\n",
      " 79%|███████▉  | 5272/6672 [11:19<02:06, 11.03it/s]\u001b[A\n",
      " 79%|███████▉  | 5274/6672 [11:19<02:04, 11.22it/s]\u001b[A\n",
      " 79%|███████▉  | 5276/6672 [11:19<02:16, 10.25it/s]\u001b[A\n",
      " 79%|███████▉  | 5278/6672 [11:20<02:11, 10.59it/s]\u001b[A\n",
      " 79%|███████▉  | 5280/6672 [11:20<02:04, 11.18it/s]\u001b[A\n",
      " 79%|███████▉  | 5282/6672 [11:20<02:02, 11.37it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 79.33it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5282\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5282/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4676174819469452, 'eval_f1': 0.741523951352693, 'eval_recall': 0.694513587622186, 'eval_precision': 0.8337740172748105, 'eval_runtime': 4.3026, 'eval_samples_per_second': 295.168, 'eval_steps_per_second': 73.908, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5282/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5282/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5282/special_tokens_map.json\n",
      "\n",
      " 79%|███████▉  | 5284/6672 [11:28<28:41,  1.24s/it]\u001b[A\n",
      " 79%|███████▉  | 5285/6672 [11:28<24:05,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 5286/6672 [11:28<19:45,  1.17it/s]\u001b[A\n",
      " 79%|███████▉  | 5287/6672 [11:28<15:53,  1.45it/s]\u001b[A\n",
      " 79%|███████▉  | 5289/6672 [11:28<10:31,  2.19it/s]\u001b[A\n",
      " 79%|███████▉  | 5290/6672 [11:28<08:46,  2.63it/s]\u001b[A\n",
      " 79%|███████▉  | 5291/6672 [11:29<07:23,  3.11it/s]\u001b[A\n",
      " 79%|███████▉  | 5292/6672 [11:29<06:13,  3.69it/s]\u001b[A\n",
      " 79%|███████▉  | 5293/6672 [11:29<05:11,  4.43it/s]\u001b[A\n",
      " 79%|███████▉  | 5295/6672 [11:29<03:44,  6.13it/s]\u001b[A\n",
      " 79%|███████▉  | 5297/6672 [11:29<03:11,  7.19it/s]\u001b[A\n",
      " 79%|███████▉  | 5299/6672 [11:29<02:41,  8.50it/s]\u001b[A\n",
      " 79%|███████▉  | 5301/6672 [11:29<02:26,  9.33it/s]\u001b[A\n",
      " 79%|███████▉  | 5303/6672 [11:30<02:16, 10.02it/s]\u001b[A\n",
      " 80%|███████▉  | 5305/6672 [11:30<02:10, 10.47it/s]\u001b[A\n",
      " 80%|███████▉  | 5307/6672 [11:30<02:05, 10.89it/s]\u001b[A\n",
      " 80%|███████▉  | 5309/6672 [11:30<01:59, 11.42it/s]\u001b[A\n",
      " 80%|███████▉  | 5311/6672 [11:30<01:54, 11.87it/s]\u001b[A\n",
      " 80%|███████▉  | 5313/6672 [11:30<01:53, 11.97it/s]\u001b[A\n",
      " 80%|███████▉  | 5315/6672 [11:31<01:51, 12.12it/s]\u001b[A\n",
      " 80%|███████▉  | 5317/6672 [11:31<01:52, 12.07it/s]\u001b[A\n",
      " 80%|███████▉  | 5319/6672 [11:31<01:51, 12.11it/s]\u001b[A\n",
      " 80%|███████▉  | 5321/6672 [11:31<01:58, 11.41it/s]\u001b[A\n",
      " 80%|███████▉  | 5323/6672 [11:31<01:58, 11.36it/s]\u001b[A\n",
      " 80%|███████▉  | 5325/6672 [11:32<02:16,  9.88it/s]\u001b[A\n",
      " 80%|███████▉  | 5327/6672 [11:32<02:09, 10.35it/s]\u001b[A\n",
      " 80%|███████▉  | 5329/6672 [11:32<02:08, 10.45it/s]\u001b[A\n",
      " 80%|███████▉  | 5331/6672 [11:32<02:09, 10.38it/s]\u001b[A\n",
      " 80%|███████▉  | 5333/6672 [11:32<02:26,  9.15it/s]\u001b[A\n",
      " 80%|███████▉  | 5334/6672 [11:33<02:39,  8.40it/s]\u001b[A\n",
      " 80%|███████▉  | 5335/6672 [11:33<02:48,  7.95it/s]\u001b[A\n",
      " 80%|███████▉  | 5336/6672 [11:33<02:55,  7.62it/s]\u001b[A\n",
      " 80%|███████▉  | 5337/6672 [11:33<02:55,  7.62it/s]\u001b[A\n",
      " 80%|████████  | 5338/6672 [11:33<03:00,  7.40it/s]\u001b[A\n",
      " 80%|████████  | 5340/6672 [11:33<02:36,  8.52it/s]\u001b[A\n",
      " 80%|████████  | 5342/6672 [11:34<02:22,  9.36it/s]\u001b[A\n",
      " 80%|████████  | 5344/6672 [11:34<02:10, 10.14it/s]\u001b[A\n",
      " 80%|████████  | 5346/6672 [11:34<02:05, 10.58it/s]\u001b[A\n",
      " 80%|████████  | 5348/6672 [11:34<02:00, 11.02it/s]\u001b[A\n",
      " 80%|████████  | 5350/6672 [11:34<02:03, 10.71it/s]\u001b[A\n",
      " 80%|████████  | 5352/6672 [11:35<02:20,  9.41it/s]\u001b[A\n",
      " 80%|████████  | 5353/6672 [11:35<02:19,  9.46it/s]\u001b[A\n",
      " 80%|████████  | 5355/6672 [11:35<02:12,  9.93it/s]\u001b[A\n",
      " 80%|████████  | 5357/6672 [11:35<02:04, 10.59it/s]\u001b[A\n",
      " 80%|████████  | 5359/6672 [11:35<01:58, 11.09it/s]\u001b[A\n",
      " 80%|████████  | 5361/6672 [11:35<01:56, 11.29it/s]\u001b[A\n",
      " 80%|████████  | 5363/6672 [11:35<01:59, 10.96it/s]\u001b[A\n",
      " 80%|████████  | 5365/6672 [11:36<01:59, 10.94it/s]\u001b[A\n",
      " 80%|████████  | 5367/6672 [11:36<01:53, 11.51it/s]\u001b[A\n",
      " 80%|████████  | 5369/6672 [11:36<02:01, 10.77it/s]\u001b[A\n",
      " 81%|████████  | 5371/6672 [11:36<01:59, 10.93it/s]\u001b[A\n",
      " 81%|████████  | 5373/6672 [11:36<01:54, 11.31it/s]\u001b[A\n",
      " 81%|████████  | 5375/6672 [11:37<02:14,  9.66it/s]\u001b[A\n",
      " 81%|████████  | 5377/6672 [11:37<02:08, 10.08it/s]\u001b[A\n",
      " 81%|████████  | 5379/6672 [11:37<02:15,  9.57it/s]\u001b[A\n",
      " 81%|████████  | 5380/6672 [11:37<02:18,  9.33it/s]\u001b[A\n",
      " 81%|████████  | 5382/6672 [11:37<02:05, 10.30it/s]\u001b[A\n",
      " 81%|████████  | 5384/6672 [11:38<02:30,  8.54it/s]\u001b[A\n",
      " 81%|████████  | 5385/6672 [11:38<02:31,  8.49it/s]\u001b[A\n",
      " 81%|████████  | 5386/6672 [11:38<02:32,  8.44it/s]\u001b[A\n",
      " 81%|████████  | 5387/6672 [11:38<02:44,  7.80it/s]\u001b[A\n",
      " 81%|████████  | 5388/6672 [11:38<02:45,  7.74it/s]\u001b[A\n",
      " 81%|████████  | 5390/6672 [11:38<02:26,  8.76it/s]\u001b[A\n",
      " 81%|████████  | 5392/6672 [11:39<02:13,  9.58it/s]\u001b[A\n",
      " 81%|████████  | 5394/6672 [11:39<02:03, 10.37it/s]\u001b[A\n",
      " 81%|████████  | 5396/6672 [11:39<01:55, 11.04it/s]\u001b[A\n",
      " 81%|████████  | 5398/6672 [11:39<01:49, 11.61it/s]\u001b[A\n",
      " 81%|████████  | 5400/6672 [11:39<02:00, 10.53it/s]\u001b[A\n",
      " 81%|████████  | 5402/6672 [11:39<02:00, 10.55it/s]\u001b[A\n",
      " 81%|████████  | 5404/6672 [11:40<02:09,  9.79it/s]\u001b[A\n",
      " 81%|████████  | 5406/6672 [11:40<01:58, 10.68it/s]\u001b[A\n",
      " 81%|████████  | 5408/6672 [11:40<01:47, 11.75it/s]\u001b[A\n",
      " 81%|████████  | 5410/6672 [11:40<01:48, 11.65it/s]\u001b[A\n",
      " 81%|████████  | 5412/6672 [11:40<01:44, 12.06it/s]\u001b[A\n",
      " 81%|████████  | 5414/6672 [11:40<01:43, 12.21it/s]\u001b[A\n",
      " 81%|████████  | 5416/6672 [11:41<01:39, 12.62it/s]\u001b[A\n",
      " 81%|████████  | 5418/6672 [11:41<01:40, 12.49it/s]\u001b[A\n",
      " 81%|████████  | 5420/6672 [11:41<01:41, 12.39it/s]\u001b[A\n",
      " 81%|████████▏ | 5422/6672 [11:41<01:49, 11.45it/s]\u001b[A\n",
      " 81%|████████▏ | 5424/6672 [11:41<01:49, 11.43it/s]\u001b[A\n",
      " 81%|████████▏ | 5426/6672 [11:41<01:46, 11.66it/s]\u001b[A\n",
      " 81%|████████▏ | 5428/6672 [11:42<01:56, 10.67it/s]\u001b[A\n",
      " 81%|████████▏ | 5430/6672 [11:42<02:09,  9.62it/s]\u001b[A\n",
      " 81%|████████▏ | 5431/6672 [11:42<02:08,  9.65it/s]\u001b[A\n",
      " 81%|████████▏ | 5432/6672 [11:42<02:13,  9.26it/s]\u001b[A\n",
      " 81%|████████▏ | 5433/6672 [11:42<02:32,  8.11it/s]\u001b[A\n",
      " 81%|████████▏ | 5434/6672 [11:43<02:42,  7.62it/s]\u001b[A\n",
      " 81%|████████▏ | 5435/6672 [11:43<02:42,  7.60it/s]\u001b[A\n",
      " 81%|████████▏ | 5436/6672 [11:43<02:34,  8.00it/s]\u001b[A\n",
      " 81%|████████▏ | 5437/6672 [11:43<02:30,  8.22it/s]\u001b[A\n",
      " 82%|████████▏ | 5438/6672 [11:43<02:32,  8.09it/s]\u001b[A\n",
      " 82%|████████▏ | 5439/6672 [11:43<02:30,  8.21it/s]\u001b[A\n",
      " 82%|████████▏ | 5440/6672 [11:43<02:27,  8.38it/s]\u001b[A\n",
      " 82%|████████▏ | 5442/6672 [11:43<02:11,  9.38it/s]\u001b[A\n",
      " 82%|████████▏ | 5443/6672 [11:44<02:15,  9.04it/s]\u001b[A\n",
      " 82%|████████▏ | 5444/6672 [11:44<02:25,  8.42it/s]\u001b[A\n",
      " 82%|████████▏ | 5445/6672 [11:44<02:20,  8.72it/s]\u001b[A\n",
      " 82%|████████▏ | 5447/6672 [11:44<02:04,  9.83it/s]\u001b[A\n",
      " 82%|████████▏ | 5448/6672 [11:44<02:08,  9.54it/s]\u001b[A\n",
      " 82%|████████▏ | 5450/6672 [11:44<01:58, 10.33it/s]\u001b[A\n",
      " 82%|████████▏ | 5452/6672 [11:44<01:55, 10.53it/s]\u001b[A\n",
      " 82%|████████▏ | 5454/6672 [11:45<01:48, 11.27it/s]\u001b[A\n",
      " 82%|████████▏ | 5456/6672 [11:45<01:49, 11.09it/s]\u001b[A\n",
      " 82%|████████▏ | 5458/6672 [11:45<01:50, 10.97it/s]\u001b[A\n",
      " 82%|████████▏ | 5460/6672 [11:45<01:56, 10.41it/s]\u001b[A\n",
      " 82%|████████▏ | 5462/6672 [11:45<01:53, 10.67it/s]\u001b[A\n",
      " 82%|████████▏ | 5464/6672 [11:45<01:49, 11.08it/s]\u001b[A\n",
      " 82%|████████▏ | 5466/6672 [11:46<01:43, 11.62it/s]\u001b[A\n",
      " 82%|████████▏ | 5468/6672 [11:46<01:42, 11.74it/s]\u001b[A\n",
      " 82%|████████▏ | 5470/6672 [11:46<01:42, 11.77it/s]\u001b[A\n",
      " 82%|████████▏ | 5472/6672 [11:46<01:46, 11.32it/s]\u001b[A\n",
      " 82%|████████▏ | 5474/6672 [11:46<01:49, 10.97it/s]\u001b[A\n",
      " 82%|████████▏ | 5476/6672 [11:47<01:50, 10.81it/s]\u001b[A\n",
      " 82%|████████▏ | 5478/6672 [11:47<01:46, 11.23it/s]\u001b[A\n",
      " 82%|████████▏ | 5480/6672 [11:47<01:45, 11.30it/s]\u001b[A\n",
      " 82%|████████▏ | 5482/6672 [11:47<01:42, 11.66it/s]\u001b[A\n",
      " 82%|████████▏ | 5484/6672 [11:47<02:02,  9.68it/s]\u001b[A\n",
      " 82%|████████▏ | 5486/6672 [11:48<02:07,  9.34it/s]\u001b[A\n",
      " 82%|████████▏ | 5488/6672 [11:48<02:02,  9.68it/s]\u001b[A\n",
      " 82%|████████▏ | 5490/6672 [11:48<01:57, 10.02it/s]\u001b[A\n",
      " 82%|████████▏ | 5492/6672 [11:48<02:01,  9.72it/s]\u001b[A\n",
      " 82%|████████▏ | 5493/6672 [11:48<02:11,  8.96it/s]\u001b[A\n",
      " 82%|████████▏ | 5494/6672 [11:48<02:15,  8.69it/s]\u001b[A\n",
      " 82%|████████▏ | 5496/6672 [11:49<02:02,  9.58it/s]\u001b[A\n",
      " 82%|████████▏ | 5498/6672 [11:49<01:55, 10.20it/s]\u001b[A\n",
      " 82%|████████▏ | 5500/6672 [11:49<02:34,  7.59it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 82%|████████▏ | 5500/6672 [11:49<02:34,  7.59it/s]\u001b[A\n",
      " 82%|████████▏ | 5501/6672 [11:49<02:37,  7.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0146, 'learning_rate': 1.2278909206925509e-05, 'epoch': 19.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 5503/6672 [11:50<02:15,  8.63it/s]\u001b[A\n",
      " 83%|████████▎ | 5505/6672 [11:50<02:00,  9.71it/s]\u001b[A\n",
      " 83%|████████▎ | 5507/6672 [11:50<01:51, 10.47it/s]\u001b[A\n",
      " 83%|████████▎ | 5509/6672 [11:50<01:59,  9.75it/s]\u001b[A\n",
      " 83%|████████▎ | 5511/6672 [11:50<02:01,  9.57it/s]\u001b[A\n",
      " 83%|████████▎ | 5512/6672 [11:50<02:02,  9.50it/s]\u001b[A\n",
      " 83%|████████▎ | 5514/6672 [11:51<01:48, 10.67it/s]\u001b[A\n",
      " 83%|████████▎ | 5516/6672 [11:51<01:39, 11.63it/s]\u001b[A\n",
      " 83%|████████▎ | 5518/6672 [11:51<01:38, 11.66it/s]\u001b[A\n",
      " 83%|████████▎ | 5520/6672 [11:51<01:40, 11.49it/s]\u001b[A\n",
      " 83%|████████▎ | 5522/6672 [11:51<01:40, 11.48it/s]\u001b[A\n",
      " 83%|████████▎ | 5524/6672 [11:51<01:37, 11.73it/s]\u001b[A\n",
      " 83%|████████▎ | 5526/6672 [11:51<01:28, 12.92it/s]\u001b[A\n",
      " 83%|████████▎ | 5528/6672 [11:52<01:20, 14.20it/s]\u001b[A\n",
      " 83%|████████▎ | 5530/6672 [11:52<01:22, 13.78it/s]\u001b[A\n",
      " 83%|████████▎ | 5532/6672 [11:52<01:29, 12.73it/s]\u001b[A\n",
      " 83%|████████▎ | 5534/6672 [11:52<01:52, 10.10it/s]\u001b[A\n",
      " 83%|████████▎ | 5536/6672 [11:52<01:55,  9.87it/s]\u001b[A\n",
      " 83%|████████▎ | 5538/6672 [11:53<01:50, 10.23it/s]\u001b[A\n",
      " 83%|████████▎ | 5540/6672 [11:53<01:51, 10.13it/s]\u001b[A\n",
      " 83%|████████▎ | 5542/6672 [11:53<01:48, 10.43it/s]\u001b[A\n",
      " 83%|████████▎ | 5544/6672 [11:53<01:40, 11.21it/s]\u001b[A\n",
      " 83%|████████▎ | 5546/6672 [11:53<01:39, 11.32it/s]\u001b[A\n",
      " 83%|████████▎ | 5548/6672 [11:53<01:38, 11.43it/s]\u001b[A\n",
      " 83%|████████▎ | 5550/6672 [11:54<01:35, 11.80it/s]\u001b[A\n",
      " 83%|████████▎ | 5552/6672 [11:54<01:32, 12.16it/s]\u001b[A\n",
      " 83%|████████▎ | 5554/6672 [11:54<01:32, 12.13it/s]\u001b[A\n",
      " 83%|████████▎ | 5556/6672 [11:54<01:31, 12.23it/s]\u001b[A\n",
      " 83%|████████▎ | 5558/6672 [11:54<01:43, 10.75it/s]\u001b[A\n",
      " 83%|████████▎ | 5560/6672 [11:55<01:40, 11.01it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:03<00:00, 83.57it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5560\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5560/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42098379135131836, 'eval_f1': 0.7707358393623374, 'eval_recall': 0.7696109807268331, 'eval_precision': 0.771873207114171, 'eval_runtime': 4.1142, 'eval_samples_per_second': 308.684, 'eval_steps_per_second': 77.293, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5560/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5560/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5560/special_tokens_map.json\n",
      "\n",
      " 83%|████████▎ | 5562/6672 [12:03<23:22,  1.26s/it]\u001b[A\n",
      " 83%|████████▎ | 5563/6672 [12:03<19:40,  1.06s/it]\u001b[A\n",
      " 83%|████████▎ | 5564/6672 [12:03<16:13,  1.14it/s]\u001b[A\n",
      " 83%|████████▎ | 5565/6672 [12:03<13:01,  1.42it/s]\u001b[A\n",
      " 83%|████████▎ | 5566/6672 [12:03<10:35,  1.74it/s]\u001b[A\n",
      " 83%|████████▎ | 5567/6672 [12:03<08:32,  2.16it/s]\u001b[A\n",
      " 83%|████████▎ | 5568/6672 [12:03<06:44,  2.73it/s]\u001b[A\n",
      " 83%|████████▎ | 5570/6672 [12:04<04:41,  3.91it/s]\u001b[A\n",
      " 83%|████████▎ | 5571/6672 [12:04<04:02,  4.55it/s]\u001b[A\n",
      " 84%|████████▎ | 5573/6672 [12:04<03:01,  6.06it/s]\u001b[A\n",
      " 84%|████████▎ | 5575/6672 [12:04<02:26,  7.50it/s]\u001b[A\n",
      " 84%|████████▎ | 5577/6672 [12:04<02:10,  8.37it/s]\u001b[A\n",
      " 84%|████████▎ | 5579/6672 [12:04<01:57,  9.28it/s]\u001b[A\n",
      " 84%|████████▎ | 5581/6672 [12:04<01:47, 10.12it/s]\u001b[A\n",
      " 84%|████████▎ | 5583/6672 [12:05<01:38, 11.07it/s]\u001b[A\n",
      " 84%|████████▎ | 5585/6672 [12:05<01:35, 11.38it/s]\u001b[A\n",
      " 84%|████████▎ | 5587/6672 [12:05<01:29, 12.17it/s]\u001b[A\n",
      " 84%|████████▍ | 5589/6672 [12:05<01:28, 12.22it/s]\u001b[A\n",
      " 84%|████████▍ | 5591/6672 [12:05<01:27, 12.34it/s]\u001b[A\n",
      " 84%|████████▍ | 5593/6672 [12:05<01:27, 12.32it/s]\u001b[A\n",
      " 84%|████████▍ | 5595/6672 [12:06<01:40, 10.70it/s]\u001b[A\n",
      " 84%|████████▍ | 5597/6672 [12:06<01:38, 10.92it/s]\u001b[A\n",
      " 84%|████████▍ | 5599/6672 [12:06<01:41, 10.60it/s]\u001b[A\n",
      " 84%|████████▍ | 5601/6672 [12:06<01:35, 11.23it/s]\u001b[A\n",
      " 84%|████████▍ | 5603/6672 [12:06<01:30, 11.83it/s]\u001b[A\n",
      " 84%|████████▍ | 5605/6672 [12:06<01:26, 12.40it/s]\u001b[A\n",
      " 84%|████████▍ | 5607/6672 [12:07<01:26, 12.25it/s]\u001b[A\n",
      " 84%|████████▍ | 5609/6672 [12:07<01:31, 11.66it/s]\u001b[A\n",
      " 84%|████████▍ | 5611/6672 [12:07<02:01,  8.74it/s]\u001b[A\n",
      " 84%|████████▍ | 5612/6672 [12:07<02:06,  8.37it/s]\u001b[A\n",
      " 84%|████████▍ | 5613/6672 [12:07<02:06,  8.40it/s]\u001b[A\n",
      " 84%|████████▍ | 5614/6672 [12:08<02:06,  8.39it/s]\u001b[A\n",
      " 84%|████████▍ | 5615/6672 [12:08<02:06,  8.38it/s]\u001b[A\n",
      " 84%|████████▍ | 5616/6672 [12:08<02:13,  7.90it/s]\u001b[A\n",
      " 84%|████████▍ | 5617/6672 [12:08<02:07,  8.27it/s]\u001b[A\n",
      " 84%|████████▍ | 5618/6672 [12:08<02:16,  7.70it/s]\u001b[A\n",
      " 84%|████████▍ | 5619/6672 [12:08<02:14,  7.84it/s]\u001b[A\n",
      " 84%|████████▍ | 5621/6672 [12:08<01:56,  8.99it/s]\u001b[A\n",
      " 84%|████████▍ | 5623/6672 [12:09<01:48,  9.71it/s]\u001b[A\n",
      " 84%|████████▍ | 5625/6672 [12:09<01:39, 10.54it/s]\u001b[A\n",
      " 84%|████████▍ | 5627/6672 [12:09<01:37, 10.72it/s]\u001b[A\n",
      " 84%|████████▍ | 5629/6672 [12:09<01:34, 10.99it/s]\u001b[A\n",
      " 84%|████████▍ | 5631/6672 [12:09<01:40, 10.39it/s]\u001b[A\n",
      " 84%|████████▍ | 5633/6672 [12:09<01:36, 10.76it/s]\u001b[A\n",
      " 84%|████████▍ | 5635/6672 [12:10<01:29, 11.54it/s]\u001b[A\n",
      " 84%|████████▍ | 5637/6672 [12:10<01:29, 11.60it/s]\u001b[A\n",
      " 85%|████████▍ | 5639/6672 [12:10<01:25, 12.03it/s]\u001b[A\n",
      " 85%|████████▍ | 5641/6672 [12:10<01:28, 11.69it/s]\u001b[A\n",
      " 85%|████████▍ | 5643/6672 [12:10<01:31, 11.27it/s]\u001b[A\n",
      " 85%|████████▍ | 5645/6672 [12:10<01:27, 11.67it/s]\u001b[A\n",
      " 85%|████████▍ | 5647/6672 [12:11<01:27, 11.72it/s]\u001b[A\n",
      " 85%|████████▍ | 5649/6672 [12:11<01:21, 12.62it/s]\u001b[A\n",
      " 85%|████████▍ | 5651/6672 [12:11<01:21, 12.49it/s]\u001b[A\n",
      " 85%|████████▍ | 5653/6672 [12:11<01:24, 12.05it/s]\u001b[A\n",
      " 85%|████████▍ | 5655/6672 [12:11<01:25, 11.89it/s]\u001b[A\n",
      " 85%|████████▍ | 5657/6672 [12:11<01:23, 12.09it/s]\u001b[A\n",
      " 85%|████████▍ | 5659/6672 [12:12<01:23, 12.13it/s]\u001b[A\n",
      " 85%|████████▍ | 5661/6672 [12:12<01:37, 10.37it/s]\u001b[A\n",
      " 85%|████████▍ | 5663/6672 [12:12<01:47,  9.43it/s]\u001b[A\n",
      " 85%|████████▍ | 5664/6672 [12:12<01:58,  8.51it/s]\u001b[A\n",
      " 85%|████████▍ | 5665/6672 [12:12<01:57,  8.57it/s]\u001b[A\n",
      " 85%|████████▍ | 5667/6672 [12:13<01:49,  9.19it/s]\u001b[A\n",
      " 85%|████████▍ | 5669/6672 [12:13<01:42,  9.80it/s]\u001b[A\n",
      " 85%|████████▍ | 5670/6672 [12:13<01:46,  9.37it/s]\u001b[A\n",
      " 85%|████████▌ | 5672/6672 [12:13<01:40,  9.95it/s]\u001b[A\n",
      " 85%|████████▌ | 5674/6672 [12:13<01:36, 10.30it/s]\u001b[A\n",
      " 85%|████████▌ | 5676/6672 [12:14<01:49,  9.11it/s]\u001b[A\n",
      " 85%|████████▌ | 5678/6672 [12:14<01:42,  9.65it/s]\u001b[A\n",
      " 85%|████████▌ | 5680/6672 [12:14<01:36, 10.28it/s]\u001b[A\n",
      " 85%|████████▌ | 5682/6672 [12:14<01:38, 10.09it/s]\u001b[A\n",
      " 85%|████████▌ | 5684/6672 [12:14<01:39,  9.96it/s]\u001b[A\n",
      " 85%|████████▌ | 5686/6672 [12:14<01:38, 10.02it/s]\u001b[A\n",
      " 85%|████████▌ | 5688/6672 [12:15<01:36, 10.25it/s]\u001b[A\n",
      " 85%|████████▌ | 5690/6672 [12:15<01:30, 10.81it/s]\u001b[A\n",
      " 85%|████████▌ | 5692/6672 [12:15<01:27, 11.22it/s]\u001b[A\n",
      " 85%|████████▌ | 5694/6672 [12:15<01:26, 11.25it/s]\u001b[A\n",
      " 85%|████████▌ | 5696/6672 [12:15<01:37, 10.03it/s]\u001b[A\n",
      " 85%|████████▌ | 5698/6672 [12:16<01:40,  9.73it/s]\u001b[A\n",
      " 85%|████████▌ | 5699/6672 [12:16<01:46,  9.14it/s]\u001b[A\n",
      " 85%|████████▌ | 5700/6672 [12:16<01:44,  9.26it/s]\u001b[A\n",
      " 85%|████████▌ | 5702/6672 [12:16<01:33, 10.34it/s]\u001b[A\n",
      " 85%|████████▌ | 5704/6672 [12:16<01:27, 11.01it/s]\u001b[A\n",
      " 86%|████████▌ | 5706/6672 [12:16<01:37,  9.87it/s]\u001b[A\n",
      " 86%|████████▌ | 5708/6672 [12:17<01:36, 10.03it/s]\u001b[A\n",
      " 86%|████████▌ | 5710/6672 [12:17<01:29, 10.73it/s]\u001b[A\n",
      " 86%|████████▌ | 5712/6672 [12:17<01:44,  9.17it/s]\u001b[A\n",
      " 86%|████████▌ | 5713/6672 [12:17<01:45,  9.07it/s]\u001b[A\n",
      " 86%|████████▌ | 5714/6672 [12:17<01:45,  9.04it/s]\u001b[A\n",
      " 86%|████████▌ | 5716/6672 [12:18<01:40,  9.51it/s]\u001b[A\n",
      " 86%|████████▌ | 5717/6672 [12:18<01:45,  9.02it/s]\u001b[A\n",
      " 86%|████████▌ | 5718/6672 [12:18<01:47,  8.91it/s]\u001b[A\n",
      " 86%|████████▌ | 5720/6672 [12:18<01:36,  9.83it/s]\u001b[A\n",
      " 86%|████████▌ | 5722/6672 [12:18<01:32, 10.31it/s]\u001b[A\n",
      " 86%|████████▌ | 5724/6672 [12:18<01:37,  9.72it/s]\u001b[A\n",
      " 86%|████████▌ | 5726/6672 [12:18<01:29, 10.53it/s]\u001b[A\n",
      " 86%|████████▌ | 5728/6672 [12:19<01:31, 10.30it/s]\u001b[A\n",
      " 86%|████████▌ | 5730/6672 [12:19<01:25, 11.08it/s]\u001b[A\n",
      " 86%|████████▌ | 5732/6672 [12:19<01:31, 10.26it/s]\u001b[A\n",
      " 86%|████████▌ | 5734/6672 [12:19<01:25, 11.03it/s]\u001b[A\n",
      " 86%|████████▌ | 5736/6672 [12:19<01:22, 11.38it/s]\u001b[A\n",
      " 86%|████████▌ | 5738/6672 [12:20<01:20, 11.66it/s]\u001b[A\n",
      " 86%|████████▌ | 5740/6672 [12:20<01:29, 10.46it/s]\u001b[A\n",
      " 86%|████████▌ | 5742/6672 [12:20<01:23, 11.11it/s]\u001b[A\n",
      " 86%|████████▌ | 5744/6672 [12:20<01:26, 10.74it/s]\u001b[A\n",
      " 86%|████████▌ | 5746/6672 [12:20<01:29, 10.38it/s]\u001b[A\n",
      " 86%|████████▌ | 5748/6672 [12:21<01:24, 10.94it/s]\u001b[A\n",
      " 86%|████████▌ | 5750/6672 [12:21<01:33,  9.89it/s]\u001b[A\n",
      " 86%|████████▌ | 5752/6672 [12:21<01:26, 10.69it/s]\u001b[A\n",
      " 86%|████████▌ | 5754/6672 [12:21<01:26, 10.64it/s]\u001b[A\n",
      " 86%|████████▋ | 5756/6672 [12:21<01:27, 10.42it/s]\u001b[A\n",
      " 86%|████████▋ | 5758/6672 [12:21<01:23, 10.94it/s]\u001b[A\n",
      " 86%|████████▋ | 5760/6672 [12:22<01:19, 11.50it/s]\u001b[A\n",
      " 86%|████████▋ | 5762/6672 [12:22<01:40,  9.07it/s]\u001b[A\n",
      " 86%|████████▋ | 5764/6672 [12:22<01:42,  8.86it/s]\u001b[A\n",
      " 86%|████████▋ | 5765/6672 [12:22<01:44,  8.65it/s]\u001b[A\n",
      " 86%|████████▋ | 5767/6672 [12:23<01:38,  9.20it/s]\u001b[A\n",
      " 86%|████████▋ | 5769/6672 [12:23<01:32,  9.78it/s]\u001b[A\n",
      " 86%|████████▋ | 5771/6672 [12:23<01:27, 10.31it/s]\u001b[A\n",
      " 87%|████████▋ | 5773/6672 [12:23<01:27, 10.23it/s]\u001b[A\n",
      " 87%|████████▋ | 5775/6672 [12:23<01:25, 10.46it/s]\u001b[A\n",
      " 87%|████████▋ | 5777/6672 [12:23<01:26, 10.30it/s]\u001b[A\n",
      " 87%|████████▋ | 5779/6672 [12:24<01:26, 10.36it/s]\u001b[A\n",
      " 87%|████████▋ | 5781/6672 [12:24<01:24, 10.60it/s]\u001b[A\n",
      " 87%|████████▋ | 5783/6672 [12:24<01:22, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 5785/6672 [12:24<01:19, 11.15it/s]\u001b[A\n",
      " 87%|████████▋ | 5787/6672 [12:24<01:22, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 5789/6672 [12:25<01:23, 10.60it/s]\u001b[A\n",
      " 87%|████████▋ | 5791/6672 [12:25<01:19, 11.08it/s]\u001b[A\n",
      " 87%|████████▋ | 5793/6672 [12:25<01:18, 11.21it/s]\u001b[A\n",
      " 87%|████████▋ | 5795/6672 [12:25<01:15, 11.55it/s]\u001b[A\n",
      " 87%|████████▋ | 5797/6672 [12:25<01:21, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 5799/6672 [12:25<01:25, 10.21it/s]\u001b[A\n",
      " 87%|████████▋ | 5801/6672 [12:26<01:24, 10.36it/s]\u001b[A\n",
      " 87%|████████▋ | 5803/6672 [12:26<01:22, 10.57it/s]\u001b[A\n",
      " 87%|████████▋ | 5805/6672 [12:26<01:18, 11.11it/s]\u001b[A\n",
      " 87%|████████▋ | 5807/6672 [12:26<01:15, 11.47it/s]\u001b[A\n",
      " 87%|████████▋ | 5809/6672 [12:26<01:15, 11.47it/s]\u001b[A\n",
      " 87%|████████▋ | 5811/6672 [12:27<01:21, 10.51it/s]\u001b[A\n",
      " 87%|████████▋ | 5813/6672 [12:27<01:24, 10.13it/s]\u001b[A\n",
      " 87%|████████▋ | 5815/6672 [12:27<01:22, 10.39it/s]\u001b[A\n",
      " 87%|████████▋ | 5817/6672 [12:27<01:19, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 5819/6672 [12:27<01:17, 11.00it/s]\u001b[A\n",
      " 87%|████████▋ | 5821/6672 [12:27<01:15, 11.30it/s]\u001b[A\n",
      " 87%|████████▋ | 5823/6672 [12:28<01:21, 10.38it/s]\u001b[A\n",
      " 87%|████████▋ | 5825/6672 [12:28<01:26,  9.80it/s]\u001b[A\n",
      " 87%|████████▋ | 5827/6672 [12:28<01:21, 10.40it/s]\u001b[A\n",
      " 87%|████████▋ | 5829/6672 [12:28<01:18, 10.72it/s]\u001b[A\n",
      " 87%|████████▋ | 5831/6672 [12:28<01:16, 11.05it/s]\u001b[A\n",
      " 87%|████████▋ | 5833/6672 [12:29<01:13, 11.38it/s]\u001b[A\n",
      " 87%|████████▋ | 5835/6672 [12:29<01:10, 11.86it/s]\u001b[A\n",
      " 87%|████████▋ | 5837/6672 [12:29<01:09, 11.93it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 71.95it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5838\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5838/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5131015181541443, 'eval_f1': 0.7410511264650239, 'eval_recall': 0.6874925918023849, 'eval_precision': 0.8613395467836258, 'eval_runtime': 4.5888, 'eval_samples_per_second': 276.764, 'eval_steps_per_second': 69.3, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5838/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5838/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-5838/special_tokens_map.json\n",
      "\n",
      " 88%|████████▊ | 5839/6672 [12:37<17:27,  1.26s/it]\u001b[A\n",
      " 88%|████████▊ | 5840/6672 [12:37<14:42,  1.06s/it]\u001b[A\n",
      " 88%|████████▊ | 5841/6672 [12:37<12:08,  1.14it/s]\u001b[A\n",
      " 88%|████████▊ | 5842/6672 [12:37<09:53,  1.40it/s]\u001b[A\n",
      " 88%|████████▊ | 5843/6672 [12:37<07:51,  1.76it/s]\u001b[A\n",
      " 88%|████████▊ | 5844/6672 [12:38<06:18,  2.19it/s]\u001b[A\n",
      " 88%|████████▊ | 5845/6672 [12:38<05:09,  2.67it/s]\u001b[A\n",
      " 88%|████████▊ | 5847/6672 [12:38<03:27,  3.97it/s]\u001b[A\n",
      " 88%|████████▊ | 5848/6672 [12:38<03:04,  4.47it/s]\u001b[A\n",
      " 88%|████████▊ | 5849/6672 [12:38<02:39,  5.17it/s]\u001b[A\n",
      " 88%|████████▊ | 5850/6672 [12:38<02:20,  5.86it/s]\u001b[A\n",
      " 88%|████████▊ | 5852/6672 [12:38<01:47,  7.60it/s]\u001b[A\n",
      " 88%|████████▊ | 5854/6672 [12:39<01:32,  8.84it/s]\u001b[A\n",
      " 88%|████████▊ | 5856/6672 [12:39<01:24,  9.67it/s]\u001b[A\n",
      " 88%|████████▊ | 5858/6672 [12:39<01:28,  9.16it/s]\u001b[A\n",
      " 88%|████████▊ | 5860/6672 [12:39<01:24,  9.65it/s]\u001b[A\n",
      " 88%|████████▊ | 5862/6672 [12:39<01:18, 10.30it/s]\u001b[A\n",
      " 88%|████████▊ | 5864/6672 [12:40<01:20, 10.01it/s]\u001b[A\n",
      " 88%|████████▊ | 5866/6672 [12:40<01:17, 10.34it/s]\u001b[A\n",
      " 88%|████████▊ | 5868/6672 [12:40<01:18, 10.27it/s]\u001b[A\n",
      " 88%|████████▊ | 5870/6672 [12:40<01:26,  9.28it/s]\u001b[A\n",
      " 88%|████████▊ | 5871/6672 [12:40<01:26,  9.25it/s]\u001b[A\n",
      " 88%|████████▊ | 5873/6672 [12:40<01:19, 10.01it/s]\u001b[A\n",
      " 88%|████████▊ | 5875/6672 [12:41<01:17, 10.28it/s]\u001b[A\n",
      " 88%|████████▊ | 5877/6672 [12:41<01:14, 10.74it/s]\u001b[A\n",
      " 88%|████████▊ | 5879/6672 [12:41<01:12, 11.00it/s]\u001b[A\n",
      " 88%|████████▊ | 5881/6672 [12:41<01:10, 11.14it/s]\u001b[A\n",
      " 88%|████████▊ | 5883/6672 [12:41<01:13, 10.73it/s]\u001b[A\n",
      " 88%|████████▊ | 5885/6672 [12:42<01:14, 10.56it/s]\u001b[A\n",
      " 88%|████████▊ | 5887/6672 [12:42<01:22,  9.56it/s]\u001b[A\n",
      " 88%|████████▊ | 5889/6672 [12:42<01:26,  9.07it/s]\u001b[A\n",
      " 88%|████████▊ | 5890/6672 [12:42<01:29,  8.76it/s]\u001b[A\n",
      " 88%|████████▊ | 5891/6672 [12:42<01:32,  8.46it/s]\u001b[A\n",
      " 88%|████████▊ | 5892/6672 [12:42<01:33,  8.31it/s]\u001b[A\n",
      " 88%|████████▊ | 5893/6672 [12:43<01:37,  7.99it/s]\u001b[A\n",
      " 88%|████████▊ | 5894/6672 [12:43<01:35,  8.15it/s]\u001b[A\n",
      " 88%|████████▊ | 5895/6672 [12:43<01:33,  8.28it/s]\u001b[A\n",
      " 88%|████████▊ | 5896/6672 [12:43<01:30,  8.60it/s]\u001b[A\n",
      " 88%|████████▊ | 5898/6672 [12:43<01:21,  9.49it/s]\u001b[A\n",
      " 88%|████████▊ | 5900/6672 [12:43<01:20,  9.61it/s]\u001b[A\n",
      " 88%|████████▊ | 5901/6672 [12:43<01:21,  9.49it/s]\u001b[A\n",
      " 88%|████████▊ | 5903/6672 [12:44<01:13, 10.51it/s]\u001b[A\n",
      " 89%|████████▊ | 5905/6672 [12:44<01:15, 10.14it/s]\u001b[A\n",
      " 89%|████████▊ | 5907/6672 [12:44<01:16, 10.03it/s]\u001b[A\n",
      " 89%|████████▊ | 5909/6672 [12:44<01:24,  9.08it/s]\u001b[A\n",
      " 89%|████████▊ | 5910/6672 [12:44<01:27,  8.72it/s]\u001b[A\n",
      " 89%|████████▊ | 5911/6672 [12:45<01:26,  8.85it/s]\u001b[A\n",
      " 89%|████████▊ | 5912/6672 [12:45<01:27,  8.68it/s]\u001b[A\n",
      " 89%|████████▊ | 5913/6672 [12:45<01:31,  8.28it/s]\u001b[A\n",
      " 89%|████████▊ | 5914/6672 [12:45<01:36,  7.87it/s]\u001b[A\n",
      " 89%|████████▊ | 5915/6672 [12:45<01:31,  8.28it/s]\u001b[A\n",
      " 89%|████████▊ | 5917/6672 [12:45<01:25,  8.78it/s]\u001b[A\n",
      " 89%|████████▊ | 5918/6672 [12:45<01:29,  8.42it/s]\u001b[A\n",
      " 89%|████████▊ | 5919/6672 [12:46<01:33,  8.08it/s]\u001b[A\n",
      " 89%|████████▊ | 5921/6672 [12:46<01:20,  9.28it/s]\u001b[A\n",
      " 89%|████████▉ | 5923/6672 [12:46<01:14, 10.11it/s]\u001b[A\n",
      " 89%|████████▉ | 5924/6672 [12:46<01:15,  9.85it/s]\u001b[A\n",
      " 89%|████████▉ | 5926/6672 [12:46<01:13, 10.16it/s]\u001b[A\n",
      " 89%|████████▉ | 5928/6672 [12:46<01:10, 10.55it/s]\u001b[A\n",
      " 89%|████████▉ | 5930/6672 [12:47<01:13, 10.16it/s]\u001b[A\n",
      " 89%|████████▉ | 5932/6672 [12:47<01:18,  9.48it/s]\u001b[A\n",
      " 89%|████████▉ | 5934/6672 [12:47<01:13, 10.06it/s]\u001b[A\n",
      " 89%|████████▉ | 5936/6672 [12:47<01:13,  9.99it/s]\u001b[A\n",
      " 89%|████████▉ | 5938/6672 [12:47<01:11, 10.30it/s]\u001b[A\n",
      " 89%|████████▉ | 5940/6672 [12:48<01:35,  7.67it/s]\u001b[A\n",
      " 89%|████████▉ | 5941/6672 [12:48<01:34,  7.73it/s]\u001b[A\n",
      " 89%|████████▉ | 5942/6672 [12:48<01:31,  8.01it/s]\u001b[A\n",
      " 89%|████████▉ | 5944/6672 [12:48<01:22,  8.79it/s]\u001b[A\n",
      " 89%|████████▉ | 5946/6672 [12:48<01:16,  9.45it/s]\u001b[A\n",
      " 89%|████████▉ | 5947/6672 [12:48<01:20,  8.98it/s]\u001b[A\n",
      " 89%|████████▉ | 5948/6672 [12:49<01:21,  8.87it/s]\u001b[A\n",
      " 89%|████████▉ | 5949/6672 [12:49<01:21,  8.92it/s]\u001b[A\n",
      " 89%|████████▉ | 5950/6672 [12:49<01:25,  8.43it/s]\u001b[A\n",
      " 89%|████████▉ | 5952/6672 [12:49<01:16,  9.44it/s]\u001b[A\n",
      " 89%|████████▉ | 5954/6672 [12:49<01:10, 10.15it/s]\u001b[A\n",
      " 89%|████████▉ | 5956/6672 [12:49<01:18,  9.17it/s]\u001b[A\n",
      " 89%|████████▉ | 5958/6672 [12:50<01:11,  9.99it/s]\u001b[A\n",
      " 89%|████████▉ | 5960/6672 [12:50<01:08, 10.38it/s]\u001b[A\n",
      " 89%|████████▉ | 5962/6672 [12:50<01:06, 10.66it/s]\u001b[A\n",
      " 89%|████████▉ | 5964/6672 [12:50<01:02, 11.41it/s]\u001b[A\n",
      " 89%|████████▉ | 5966/6672 [12:50<00:59, 11.96it/s]\u001b[A\n",
      " 89%|████████▉ | 5968/6672 [12:50<00:59, 11.81it/s]\u001b[A\n",
      " 89%|████████▉ | 5970/6672 [12:51<01:06, 10.49it/s]\u001b[A\n",
      " 90%|████████▉ | 5972/6672 [12:51<01:02, 11.20it/s]\u001b[A\n",
      " 90%|████████▉ | 5974/6672 [12:51<00:59, 11.70it/s]\u001b[A\n",
      " 90%|████████▉ | 5976/6672 [12:51<00:57, 12.11it/s]\u001b[A\n",
      " 90%|████████▉ | 5978/6672 [12:51<00:58, 11.94it/s]\u001b[A\n",
      " 90%|████████▉ | 5980/6672 [12:51<00:56, 12.25it/s]\u001b[A\n",
      " 90%|████████▉ | 5982/6672 [12:52<01:06, 10.31it/s]\u001b[A\n",
      " 90%|████████▉ | 5984/6672 [12:52<01:02, 11.00it/s]\u001b[A\n",
      " 90%|████████▉ | 5986/6672 [12:52<01:01, 11.24it/s]\u001b[A\n",
      " 90%|████████▉ | 5988/6672 [12:52<00:59, 11.50it/s]\u001b[A\n",
      " 90%|████████▉ | 5990/6672 [12:53<01:10,  9.63it/s]\u001b[A\n",
      " 90%|████████▉ | 5992/6672 [12:53<01:12,  9.36it/s]\u001b[A\n",
      " 90%|████████▉ | 5993/6672 [12:53<01:16,  8.90it/s]\u001b[A\n",
      " 90%|████████▉ | 5994/6672 [12:53<01:20,  8.38it/s]\u001b[A\n",
      " 90%|████████▉ | 5995/6672 [12:53<01:22,  8.16it/s]\u001b[A\n",
      " 90%|████████▉ | 5997/6672 [12:53<01:14,  9.09it/s]\u001b[A\n",
      " 90%|████████▉ | 5999/6672 [12:54<01:09,  9.73it/s]\u001b[A\n",
      " 90%|████████▉ | 6000/6672 [12:54<01:26,  7.73it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 90%|████████▉ | 6000/6672 [12:54<01:26,  7.73it/s]\u001b[A\n",
      " 90%|████████▉ | 6001/6672 [12:54<01:30,  7.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0125, 'learning_rate': 7.040466712503364e-06, 'epoch': 21.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|████████▉ | 6002/6672 [12:54<01:27,  7.65it/s]\u001b[A\n",
      " 90%|████████▉ | 6004/6672 [12:54<01:14,  8.98it/s]\u001b[A\n",
      " 90%|█████████ | 6005/6672 [12:54<01:13,  9.09it/s]\u001b[A\n",
      " 90%|█████████ | 6007/6672 [12:54<01:05, 10.20it/s]\u001b[A\n",
      " 90%|█████████ | 6009/6672 [12:55<00:59, 11.11it/s]\u001b[A\n",
      " 90%|█████████ | 6011/6672 [12:55<00:56, 11.65it/s]\u001b[A\n",
      " 90%|█████████ | 6013/6672 [12:55<00:56, 11.58it/s]\u001b[A\n",
      " 90%|█████████ | 6015/6672 [12:55<01:06,  9.87it/s]\u001b[A\n",
      " 90%|█████████ | 6017/6672 [12:55<01:13,  8.91it/s]\u001b[A\n",
      " 90%|█████████ | 6018/6672 [12:56<01:12,  9.06it/s]\u001b[A\n",
      " 90%|█████████ | 6020/6672 [12:56<01:05,  9.98it/s]\u001b[A\n",
      " 90%|█████████ | 6022/6672 [12:56<01:01, 10.56it/s]\u001b[A\n",
      " 90%|█████████ | 6024/6672 [12:56<00:59, 10.93it/s]\u001b[A\n",
      " 90%|█████████ | 6026/6672 [12:56<00:57, 11.17it/s]\u001b[A\n",
      " 90%|█████████ | 6028/6672 [12:56<00:57, 11.13it/s]\u001b[A\n",
      " 90%|█████████ | 6030/6672 [12:57<00:57, 11.24it/s]\u001b[A\n",
      " 90%|█████████ | 6032/6672 [12:57<00:54, 11.78it/s]\u001b[A\n",
      " 90%|█████████ | 6034/6672 [12:57<00:50, 12.71it/s]\u001b[A\n",
      " 90%|█████████ | 6036/6672 [12:57<00:46, 13.69it/s]\u001b[A\n",
      " 90%|█████████ | 6038/6672 [12:57<00:45, 13.91it/s]\u001b[A\n",
      " 91%|█████████ | 6040/6672 [12:57<01:05,  9.67it/s]\u001b[A\n",
      " 91%|█████████ | 6042/6672 [12:58<01:15,  8.39it/s]\u001b[A\n",
      " 91%|█████████ | 6044/6672 [12:58<01:11,  8.76it/s]\u001b[A\n",
      " 91%|█████████ | 6046/6672 [12:58<01:10,  8.85it/s]\u001b[A\n",
      " 91%|█████████ | 6047/6672 [12:58<01:14,  8.42it/s]\u001b[A\n",
      " 91%|█████████ | 6048/6672 [12:58<01:13,  8.46it/s]\u001b[A\n",
      " 91%|█████████ | 6050/6672 [12:59<01:06,  9.40it/s]\u001b[A\n",
      " 91%|█████████ | 6052/6672 [12:59<01:01, 10.02it/s]\u001b[A\n",
      " 91%|█████████ | 6054/6672 [12:59<01:11,  8.63it/s]\u001b[A\n",
      " 91%|█████████ | 6055/6672 [12:59<01:14,  8.27it/s]\u001b[A\n",
      " 91%|█████████ | 6056/6672 [12:59<01:17,  7.99it/s]\u001b[A\n",
      " 91%|█████████ | 6057/6672 [13:00<01:14,  8.22it/s]\u001b[A\n",
      " 91%|█████████ | 6058/6672 [13:00<01:13,  8.37it/s]\u001b[A\n",
      " 91%|█████████ | 6060/6672 [13:00<01:04,  9.51it/s]\u001b[A\n",
      " 91%|█████████ | 6062/6672 [13:00<01:00, 10.14it/s]\u001b[A\n",
      " 91%|█████████ | 6064/6672 [13:00<01:00, 10.10it/s]\u001b[A\n",
      " 91%|█████████ | 6066/6672 [13:00<00:54, 11.07it/s]\u001b[A\n",
      " 91%|█████████ | 6068/6672 [13:00<00:51, 11.64it/s]\u001b[A\n",
      " 91%|█████████ | 6070/6672 [13:01<00:49, 12.10it/s]\u001b[A\n",
      " 91%|█████████ | 6072/6672 [13:01<00:47, 12.59it/s]\u001b[A\n",
      " 91%|█████████ | 6074/6672 [13:01<00:50, 11.95it/s]\u001b[A\n",
      " 91%|█████████ | 6076/6672 [13:01<00:50, 11.91it/s]\u001b[A\n",
      " 91%|█████████ | 6078/6672 [13:01<00:53, 11.19it/s]\u001b[A\n",
      " 91%|█████████ | 6080/6672 [13:02<00:59,  9.90it/s]\u001b[A\n",
      " 91%|█████████ | 6082/6672 [13:02<00:55, 10.58it/s]\u001b[A\n",
      " 91%|█████████ | 6084/6672 [13:02<00:54, 10.87it/s]\u001b[A\n",
      " 91%|█████████ | 6086/6672 [13:02<00:54, 10.68it/s]\u001b[A\n",
      " 91%|█████████ | 6088/6672 [13:02<00:56, 10.36it/s]\u001b[A\n",
      " 91%|█████████▏| 6090/6672 [13:03<01:07,  8.62it/s]\u001b[A\n",
      " 91%|█████████▏| 6091/6672 [13:03<01:08,  8.42it/s]\u001b[A\n",
      " 91%|█████████▏| 6092/6672 [13:03<01:08,  8.52it/s]\u001b[A\n",
      " 91%|█████████▏| 6093/6672 [13:03<01:10,  8.24it/s]\u001b[A\n",
      " 91%|█████████▏| 6094/6672 [13:03<01:13,  7.92it/s]\u001b[A\n",
      " 91%|█████████▏| 6095/6672 [13:03<01:11,  8.02it/s]\u001b[A\n",
      " 91%|█████████▏| 6096/6672 [13:03<01:11,  8.07it/s]\u001b[A\n",
      " 91%|█████████▏| 6098/6672 [13:04<01:02,  9.13it/s]\u001b[A\n",
      " 91%|█████████▏| 6099/6672 [13:04<01:01,  9.25it/s]\u001b[A\n",
      " 91%|█████████▏| 6101/6672 [13:04<00:53, 10.61it/s]\u001b[A\n",
      " 91%|█████████▏| 6103/6672 [13:04<00:49, 11.53it/s]\u001b[A\n",
      " 92%|█████████▏| 6105/6672 [13:04<00:57,  9.80it/s]\u001b[A\n",
      " 92%|█████████▏| 6107/6672 [13:04<00:55, 10.24it/s]\u001b[A\n",
      " 92%|█████████▏| 6109/6672 [13:05<00:51, 11.00it/s]\u001b[A\n",
      " 92%|█████████▏| 6111/6672 [13:05<00:53, 10.49it/s]\u001b[A\n",
      " 92%|█████████▏| 6113/6672 [13:05<00:52, 10.59it/s]\u001b[A\n",
      " 92%|█████████▏| 6115/6672 [13:05<00:52, 10.66it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 78.31it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6116\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6116/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4471867084503174, 'eval_f1': 0.7817286527474939, 'eval_recall': 0.7688997937557784, 'eval_precision': 0.7962753360729957, 'eval_runtime': 4.5783, 'eval_samples_per_second': 277.393, 'eval_steps_per_second': 69.457, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6116/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6116/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6116/special_tokens_map.json\n",
      "\n",
      " 92%|█████████▏| 6117/6672 [13:13<12:05,  1.31s/it]\u001b[A\n",
      " 92%|█████████▏| 6118/6672 [13:14<10:13,  1.11s/it]\u001b[A\n",
      " 92%|█████████▏| 6119/6672 [13:14<08:22,  1.10it/s]\u001b[A\n",
      " 92%|█████████▏| 6120/6672 [13:14<06:42,  1.37it/s]\u001b[A\n",
      " 92%|█████████▏| 6121/6672 [13:14<05:17,  1.74it/s]\u001b[A\n",
      " 92%|█████████▏| 6122/6672 [13:14<04:11,  2.18it/s]\u001b[A\n",
      " 92%|█████████▏| 6123/6672 [13:14<03:24,  2.68it/s]\u001b[A\n",
      " 92%|█████████▏| 6124/6672 [13:14<02:50,  3.21it/s]\u001b[A\n",
      " 92%|█████████▏| 6125/6672 [13:14<02:21,  3.87it/s]\u001b[A\n",
      " 92%|█████████▏| 6127/6672 [13:15<01:40,  5.45it/s]\u001b[A\n",
      " 92%|█████████▏| 6128/6672 [13:15<01:30,  5.99it/s]\u001b[A\n",
      " 92%|█████████▏| 6129/6672 [13:15<01:25,  6.34it/s]\u001b[A\n",
      " 92%|█████████▏| 6130/6672 [13:15<01:22,  6.54it/s]\u001b[A\n",
      " 92%|█████████▏| 6131/6672 [13:15<01:15,  7.19it/s]\u001b[A\n",
      " 92%|█████████▏| 6132/6672 [13:15<01:13,  7.38it/s]\u001b[A\n",
      " 92%|█████████▏| 6134/6672 [13:15<00:59,  9.01it/s]\u001b[A\n",
      " 92%|█████████▏| 6135/6672 [13:15<01:00,  8.89it/s]\u001b[A\n",
      " 92%|█████████▏| 6136/6672 [13:16<01:03,  8.40it/s]\u001b[A\n",
      " 92%|█████████▏| 6137/6672 [13:16<01:01,  8.69it/s]\u001b[A\n",
      " 92%|█████████▏| 6139/6672 [13:16<00:51, 10.28it/s]\u001b[A\n",
      " 92%|█████████▏| 6141/6672 [13:16<00:49, 10.63it/s]\u001b[A\n",
      " 92%|█████████▏| 6143/6672 [13:16<00:47, 11.03it/s]\u001b[A\n",
      " 92%|█████████▏| 6145/6672 [13:16<00:45, 11.47it/s]\u001b[A\n",
      " 92%|█████████▏| 6147/6672 [13:17<00:45, 11.66it/s]\u001b[A\n",
      " 92%|█████████▏| 6149/6672 [13:17<00:45, 11.56it/s]\u001b[A\n",
      " 92%|█████████▏| 6151/6672 [13:17<00:49, 10.48it/s]\u001b[A\n",
      " 92%|█████████▏| 6153/6672 [13:17<00:52,  9.91it/s]\u001b[A\n",
      " 92%|█████████▏| 6155/6672 [13:17<00:48, 10.68it/s]\u001b[A\n",
      " 92%|█████████▏| 6157/6672 [13:18<00:51, 10.07it/s]\u001b[A\n",
      " 92%|█████████▏| 6159/6672 [13:18<00:46, 10.97it/s]\u001b[A\n",
      " 92%|█████████▏| 6161/6672 [13:18<00:54,  9.31it/s]\u001b[A\n",
      " 92%|█████████▏| 6163/6672 [13:18<00:52,  9.75it/s]\u001b[A\n",
      " 92%|█████████▏| 6165/6672 [13:18<00:48, 10.41it/s]\u001b[A\n",
      " 92%|█████████▏| 6167/6672 [13:19<00:53,  9.39it/s]\u001b[A\n",
      " 92%|█████████▏| 6168/6672 [13:19<00:56,  8.87it/s]\u001b[A\n",
      " 92%|█████████▏| 6169/6672 [13:19<00:59,  8.50it/s]\u001b[A\n",
      " 92%|█████████▏| 6170/6672 [13:19<00:58,  8.60it/s]\u001b[A\n",
      " 92%|█████████▏| 6171/6672 [13:19<00:57,  8.70it/s]\u001b[A\n",
      " 93%|█████████▎| 6173/6672 [13:19<00:52,  9.46it/s]\u001b[A\n",
      " 93%|█████████▎| 6174/6672 [13:19<00:56,  8.76it/s]\u001b[A\n",
      " 93%|█████████▎| 6175/6672 [13:20<00:57,  8.61it/s]\u001b[A\n",
      " 93%|█████████▎| 6177/6672 [13:20<00:53,  9.32it/s]\u001b[A\n",
      " 93%|█████████▎| 6178/6672 [13:20<00:56,  8.77it/s]\u001b[A\n",
      " 93%|█████████▎| 6179/6672 [13:20<00:55,  8.89it/s]\u001b[A\n",
      " 93%|█████████▎| 6181/6672 [13:20<00:49,  9.84it/s]\u001b[A\n",
      " 93%|█████████▎| 6182/6672 [13:20<00:52,  9.26it/s]\u001b[A\n",
      " 93%|█████████▎| 6183/6672 [13:20<00:55,  8.78it/s]\u001b[A\n",
      " 93%|█████████▎| 6185/6672 [13:21<00:49,  9.85it/s]\u001b[A\n",
      " 93%|█████████▎| 6187/6672 [13:21<00:46, 10.42it/s]\u001b[A\n",
      " 93%|█████████▎| 6189/6672 [13:21<00:43, 11.19it/s]\u001b[A\n",
      " 93%|█████████▎| 6191/6672 [13:21<00:40, 11.92it/s]\u001b[A\n",
      " 93%|█████████▎| 6193/6672 [13:21<00:39, 12.19it/s]\u001b[A\n",
      " 93%|█████████▎| 6195/6672 [13:21<00:41, 11.62it/s]\u001b[A\n",
      " 93%|█████████▎| 6197/6672 [13:22<00:38, 12.26it/s]\u001b[A\n",
      " 93%|█████████▎| 6199/6672 [13:22<00:38, 12.31it/s]\u001b[A\n",
      " 93%|█████████▎| 6201/6672 [13:22<00:43, 10.92it/s]\u001b[A\n",
      " 93%|█████████▎| 6203/6672 [13:22<00:48,  9.77it/s]\u001b[A\n",
      " 93%|█████████▎| 6205/6672 [13:22<00:45, 10.29it/s]\u001b[A\n",
      " 93%|█████████▎| 6207/6672 [13:23<00:44, 10.40it/s]\u001b[A\n",
      " 93%|█████████▎| 6209/6672 [13:23<00:51,  9.06it/s]\u001b[A\n",
      " 93%|█████████▎| 6210/6672 [13:23<00:52,  8.81it/s]\u001b[A\n",
      " 93%|█████████▎| 6211/6672 [13:23<00:52,  8.81it/s]\u001b[A\n",
      " 93%|█████████▎| 6213/6672 [13:23<00:46,  9.93it/s]\u001b[A\n",
      " 93%|█████████▎| 6215/6672 [13:23<00:43, 10.52it/s]\u001b[A\n",
      " 93%|█████████▎| 6217/6672 [13:24<00:48,  9.46it/s]\u001b[A\n",
      " 93%|█████████▎| 6218/6672 [13:24<00:51,  8.88it/s]\u001b[A\n",
      " 93%|█████████▎| 6219/6672 [13:24<00:52,  8.57it/s]\u001b[A\n",
      " 93%|█████████▎| 6220/6672 [13:24<00:53,  8.39it/s]\u001b[A\n",
      " 93%|█████████▎| 6221/6672 [13:24<00:54,  8.31it/s]\u001b[A\n",
      " 93%|█████████▎| 6222/6672 [13:24<00:52,  8.64it/s]\u001b[A\n",
      " 93%|█████████▎| 6223/6672 [13:24<00:53,  8.46it/s]\u001b[A\n",
      " 93%|█████████▎| 6224/6672 [13:25<00:51,  8.74it/s]\u001b[A\n",
      " 93%|█████████▎| 6226/6672 [13:25<00:49,  9.00it/s]\u001b[A\n",
      " 93%|█████████▎| 6228/6672 [13:25<00:45,  9.70it/s]\u001b[A\n",
      " 93%|█████████▎| 6230/6672 [13:25<00:43, 10.22it/s]\u001b[A\n",
      " 93%|█████████▎| 6232/6672 [13:25<00:42, 10.48it/s]\u001b[A\n",
      " 93%|█████████▎| 6234/6672 [13:25<00:38, 11.31it/s]\u001b[A\n",
      " 93%|█████████▎| 6236/6672 [13:26<00:41, 10.45it/s]\u001b[A\n",
      " 93%|█████████▎| 6238/6672 [13:26<00:41, 10.36it/s]\u001b[A\n",
      " 94%|█████████▎| 6240/6672 [13:26<00:41, 10.53it/s]\u001b[A\n",
      " 94%|█████████▎| 6242/6672 [13:26<00:39, 10.77it/s]\u001b[A\n",
      " 94%|█████████▎| 6244/6672 [13:26<00:38, 11.05it/s]\u001b[A\n",
      " 94%|█████████▎| 6246/6672 [13:27<00:36, 11.52it/s]\u001b[A\n",
      " 94%|█████████▎| 6248/6672 [13:27<00:35, 11.87it/s]\u001b[A\n",
      " 94%|█████████▎| 6250/6672 [13:27<00:42,  9.90it/s]\u001b[A\n",
      " 94%|█████████▎| 6252/6672 [13:27<00:41, 10.08it/s]\u001b[A\n",
      " 94%|█████████▎| 6254/6672 [13:27<00:46,  9.07it/s]\u001b[A\n",
      " 94%|█████████▍| 6255/6672 [13:28<00:47,  8.81it/s]\u001b[A\n",
      " 94%|█████████▍| 6256/6672 [13:28<00:50,  8.23it/s]\u001b[A\n",
      " 94%|█████████▍| 6258/6672 [13:28<00:44,  9.37it/s]\u001b[A\n",
      " 94%|█████████▍| 6259/6672 [13:28<00:44,  9.33it/s]\u001b[A\n",
      " 94%|█████████▍| 6260/6672 [13:28<00:43,  9.43it/s]\u001b[A\n",
      " 94%|█████████▍| 6261/6672 [13:28<00:45,  8.94it/s]\u001b[A\n",
      " 94%|█████████▍| 6262/6672 [13:28<00:45,  8.97it/s]\u001b[A\n",
      " 94%|█████████▍| 6264/6672 [13:28<00:40, 10.10it/s]\u001b[A\n",
      " 94%|█████████▍| 6266/6672 [13:29<00:37, 10.90it/s]\u001b[A\n",
      " 94%|█████████▍| 6268/6672 [13:29<00:49,  8.16it/s]\u001b[A\n",
      " 94%|█████████▍| 6269/6672 [13:29<00:49,  8.12it/s]\u001b[A\n",
      " 94%|█████████▍| 6270/6672 [13:29<00:48,  8.31it/s]\u001b[A\n",
      " 94%|█████████▍| 6271/6672 [13:29<00:47,  8.43it/s]\u001b[A\n",
      " 94%|█████████▍| 6272/6672 [13:29<00:46,  8.66it/s]\u001b[A\n",
      " 94%|█████████▍| 6274/6672 [13:30<00:41,  9.54it/s]\u001b[A\n",
      " 94%|█████████▍| 6276/6672 [13:30<00:39,  9.90it/s]\u001b[A\n",
      " 94%|█████████▍| 6278/6672 [13:30<00:40,  9.66it/s]\u001b[A\n",
      " 94%|█████████▍| 6279/6672 [13:30<00:43,  9.05it/s]\u001b[A\n",
      " 94%|█████████▍| 6280/6672 [13:30<00:42,  9.19it/s]\u001b[A\n",
      " 94%|█████████▍| 6281/6672 [13:30<00:45,  8.56it/s]\u001b[A\n",
      " 94%|█████████▍| 6283/6672 [13:31<00:42,  9.09it/s]\u001b[A\n",
      " 94%|█████████▍| 6285/6672 [13:31<00:39,  9.90it/s]\u001b[A\n",
      " 94%|█████████▍| 6286/6672 [13:31<00:40,  9.43it/s]\u001b[A\n",
      " 94%|█████████▍| 6287/6672 [13:31<00:40,  9.47it/s]\u001b[A\n",
      " 94%|█████████▍| 6288/6672 [13:31<00:42,  9.04it/s]\u001b[A\n",
      " 94%|█████████▍| 6290/6672 [13:31<00:38,  9.91it/s]\u001b[A\n",
      " 94%|█████████▍| 6291/6672 [13:31<00:39,  9.66it/s]\u001b[A\n",
      " 94%|█████████▍| 6293/6672 [13:32<00:36, 10.40it/s]\u001b[A\n",
      " 94%|█████████▍| 6295/6672 [13:32<00:36, 10.43it/s]\u001b[A\n",
      " 94%|█████████▍| 6297/6672 [13:32<00:34, 10.76it/s]\u001b[A\n",
      " 94%|█████████▍| 6299/6672 [13:32<00:35, 10.49it/s]\u001b[A\n",
      " 94%|█████████▍| 6301/6672 [13:32<00:37,  9.99it/s]\u001b[A\n",
      " 94%|█████████▍| 6303/6672 [13:33<00:35, 10.47it/s]\u001b[A\n",
      " 94%|█████████▍| 6305/6672 [13:33<00:33, 10.88it/s]\u001b[A\n",
      " 95%|█████████▍| 6307/6672 [13:33<00:32, 11.21it/s]\u001b[A\n",
      " 95%|█████████▍| 6309/6672 [13:33<00:31, 11.43it/s]\u001b[A\n",
      " 95%|█████████▍| 6311/6672 [13:33<00:30, 11.67it/s]\u001b[A\n",
      " 95%|█████████▍| 6313/6672 [13:33<00:30, 11.95it/s]\u001b[A\n",
      " 95%|█████████▍| 6315/6672 [13:34<00:30, 11.64it/s]\u001b[A\n",
      " 95%|█████████▍| 6317/6672 [13:34<00:38,  9.27it/s]\u001b[A\n",
      " 95%|█████████▍| 6319/6672 [13:34<00:41,  8.61it/s]\u001b[A\n",
      " 95%|█████████▍| 6320/6672 [13:34<00:43,  8.18it/s]\u001b[A\n",
      " 95%|█████████▍| 6321/6672 [13:34<00:43,  8.12it/s]\u001b[A\n",
      " 95%|█████████▍| 6322/6672 [13:35<00:41,  8.43it/s]\u001b[A\n",
      " 95%|█████████▍| 6324/6672 [13:35<00:37,  9.26it/s]\u001b[A\n",
      " 95%|█████████▍| 6325/6672 [13:35<00:38,  9.02it/s]\u001b[A\n",
      " 95%|█████████▍| 6326/6672 [13:35<00:41,  8.38it/s]\u001b[A\n",
      " 95%|█████████▍| 6327/6672 [13:35<00:42,  8.07it/s]\u001b[A\n",
      " 95%|█████████▍| 6329/6672 [13:35<00:39,  8.62it/s]\u001b[A\n",
      " 95%|█████████▍| 6330/6672 [13:35<00:38,  8.88it/s]\u001b[A\n",
      " 95%|█████████▍| 6331/6672 [13:36<00:38,  8.77it/s]\u001b[A\n",
      " 95%|█████████▍| 6332/6672 [13:36<00:40,  8.47it/s]\u001b[A\n",
      " 95%|█████████▍| 6333/6672 [13:36<00:41,  8.23it/s]\u001b[A\n",
      " 95%|█████████▍| 6335/6672 [13:36<00:37,  8.94it/s]\u001b[A\n",
      " 95%|█████████▍| 6337/6672 [13:36<00:32, 10.28it/s]\u001b[A\n",
      " 95%|█████████▌| 6339/6672 [13:36<00:28, 11.57it/s]\u001b[A\n",
      " 95%|█████████▌| 6341/6672 [13:36<00:27, 12.24it/s]\u001b[A\n",
      " 95%|█████████▌| 6343/6672 [13:37<00:25, 12.71it/s]\u001b[A\n",
      " 95%|█████████▌| 6345/6672 [13:37<00:25, 12.60it/s]\u001b[A\n",
      " 95%|█████████▌| 6347/6672 [13:37<00:26, 12.22it/s]\u001b[A\n",
      " 95%|█████████▌| 6349/6672 [13:37<00:26, 12.36it/s]\u001b[A\n",
      " 95%|█████████▌| 6351/6672 [13:37<00:24, 13.07it/s]\u001b[A\n",
      " 95%|█████████▌| 6353/6672 [13:37<00:26, 11.85it/s]\u001b[A\n",
      " 95%|█████████▌| 6355/6672 [13:38<00:31, 10.00it/s]\u001b[A\n",
      " 95%|█████████▌| 6357/6672 [13:38<00:33,  9.52it/s]\u001b[A\n",
      " 95%|█████████▌| 6359/6672 [13:38<00:31,  9.79it/s]\u001b[A\n",
      " 95%|█████████▌| 6361/6672 [13:38<00:32,  9.47it/s]\u001b[A\n",
      " 95%|█████████▌| 6363/6672 [13:38<00:30, 10.11it/s]\u001b[A\n",
      " 95%|█████████▌| 6365/6672 [13:39<00:29, 10.26it/s]\u001b[A\n",
      " 95%|█████████▌| 6367/6672 [13:39<00:35,  8.59it/s]\u001b[A\n",
      " 95%|█████████▌| 6368/6672 [13:39<00:37,  8.04it/s]\u001b[A\n",
      " 95%|█████████▌| 6369/6672 [13:39<00:36,  8.23it/s]\u001b[A\n",
      " 95%|█████████▌| 6370/6672 [13:39<00:36,  8.27it/s]\u001b[A\n",
      " 96%|█████████▌| 6372/6672 [13:40<00:32,  9.31it/s]\u001b[A\n",
      " 96%|█████████▌| 6374/6672 [13:40<00:30,  9.92it/s]\u001b[A\n",
      " 96%|█████████▌| 6376/6672 [13:40<00:28, 10.49it/s]\u001b[A\n",
      " 96%|█████████▌| 6378/6672 [13:40<00:31,  9.41it/s]\u001b[A\n",
      " 96%|█████████▌| 6380/6672 [13:40<00:29,  9.92it/s]\u001b[A\n",
      " 96%|█████████▌| 6382/6672 [13:41<00:30,  9.53it/s]\u001b[A\n",
      " 96%|█████████▌| 6384/6672 [13:41<00:28, 10.02it/s]\u001b[A\n",
      " 96%|█████████▌| 6386/6672 [13:41<00:28, 10.05it/s]\u001b[A\n",
      " 96%|█████████▌| 6388/6672 [13:41<00:27, 10.21it/s]\u001b[A\n",
      " 96%|█████████▌| 6390/6672 [13:41<00:27, 10.11it/s]\u001b[A\n",
      " 96%|█████████▌| 6392/6672 [13:42<00:27, 10.10it/s]\u001b[A\n",
      " 96%|█████████▌| 6394/6672 [13:42<00:28,  9.77it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.74it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6394\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6394/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.456085741519928, 'eval_f1': 0.7788535209305565, 'eval_recall': 0.7535658124520936, 'eval_precision': 0.8117779656241195, 'eval_runtime': 4.5789, 'eval_samples_per_second': 277.36, 'eval_steps_per_second': 69.449, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6394/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6394/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6394/special_tokens_map.json\n",
      "\n",
      " 96%|█████████▌| 6395/6672 [13:50<06:54,  1.50s/it]\u001b[A\n",
      " 96%|█████████▌| 6396/6672 [13:50<05:37,  1.22s/it]\u001b[A\n",
      " 96%|█████████▌| 6397/6672 [13:50<04:28,  1.02it/s]\u001b[A\n",
      " 96%|█████████▌| 6398/6672 [13:50<03:31,  1.29it/s]\u001b[A\n",
      " 96%|█████████▌| 6399/6672 [13:50<02:47,  1.63it/s]\u001b[A\n",
      " 96%|█████████▌| 6400/6672 [13:50<02:11,  2.08it/s]\u001b[A\n",
      " 96%|█████████▌| 6402/6672 [13:51<01:24,  3.19it/s]\u001b[A\n",
      " 96%|█████████▌| 6403/6672 [13:51<01:14,  3.62it/s]\u001b[A\n",
      " 96%|█████████▌| 6404/6672 [13:51<01:03,  4.24it/s]\u001b[A\n",
      " 96%|█████████▌| 6405/6672 [13:51<00:55,  4.81it/s]\u001b[A\n",
      " 96%|█████████▌| 6406/6672 [13:51<00:47,  5.55it/s]\u001b[A\n",
      " 96%|█████████▌| 6408/6672 [13:51<00:36,  7.15it/s]\u001b[A\n",
      " 96%|█████████▌| 6410/6672 [13:51<00:31,  8.42it/s]\u001b[A\n",
      " 96%|█████████▌| 6412/6672 [13:52<00:27,  9.38it/s]\u001b[A\n",
      " 96%|█████████▌| 6414/6672 [13:52<00:29,  8.83it/s]\u001b[A\n",
      " 96%|█████████▌| 6415/6672 [13:52<00:28,  8.89it/s]\u001b[A\n",
      " 96%|█████████▌| 6416/6672 [13:52<00:29,  8.83it/s]\u001b[A\n",
      " 96%|█████████▌| 6417/6672 [13:52<00:30,  8.37it/s]\u001b[A\n",
      " 96%|█████████▌| 6418/6672 [13:52<00:30,  8.39it/s]\u001b[A\n",
      " 96%|█████████▌| 6420/6672 [13:53<00:26,  9.51it/s]\u001b[A\n",
      " 96%|█████████▋| 6422/6672 [13:53<00:25,  9.99it/s]\u001b[A\n",
      " 96%|█████████▋| 6424/6672 [13:53<00:23, 10.47it/s]\u001b[A\n",
      " 96%|█████████▋| 6426/6672 [13:53<00:22, 11.11it/s]\u001b[A\n",
      " 96%|█████████▋| 6428/6672 [13:53<00:23, 10.43it/s]\u001b[A\n",
      " 96%|█████████▋| 6430/6672 [13:54<00:25,  9.67it/s]\u001b[A\n",
      " 96%|█████████▋| 6432/6672 [13:54<00:24,  9.83it/s]\u001b[A\n",
      " 96%|█████████▋| 6433/6672 [13:54<00:25,  9.49it/s]\u001b[A\n",
      " 96%|█████████▋| 6435/6672 [13:54<00:25,  9.37it/s]\u001b[A\n",
      " 96%|█████████▋| 6436/6672 [13:54<00:25,  9.38it/s]\u001b[A\n",
      " 96%|█████████▋| 6438/6672 [13:54<00:23, 10.08it/s]\u001b[A\n",
      " 97%|█████████▋| 6440/6672 [13:54<00:21, 10.77it/s]\u001b[A\n",
      " 97%|█████████▋| 6442/6672 [13:55<00:23,  9.77it/s]\u001b[A\n",
      " 97%|█████████▋| 6444/6672 [13:55<00:23,  9.82it/s]\u001b[A\n",
      " 97%|█████████▋| 6445/6672 [13:55<00:27,  8.40it/s]\u001b[A\n",
      " 97%|█████████▋| 6446/6672 [13:55<00:27,  8.15it/s]\u001b[A\n",
      " 97%|█████████▋| 6447/6672 [13:55<00:27,  8.25it/s]\u001b[A\n",
      " 97%|█████████▋| 6448/6672 [13:55<00:26,  8.37it/s]\u001b[A\n",
      " 97%|█████████▋| 6449/6672 [13:56<00:25,  8.72it/s]\u001b[A\n",
      " 97%|█████████▋| 6450/6672 [13:56<00:25,  8.58it/s]\u001b[A\n",
      " 97%|█████████▋| 6451/6672 [13:56<00:24,  8.93it/s]\u001b[A\n",
      " 97%|█████████▋| 6453/6672 [13:56<00:22,  9.54it/s]\u001b[A\n",
      " 97%|█████████▋| 6454/6672 [13:56<00:23,  9.16it/s]\u001b[A\n",
      " 97%|█████████▋| 6455/6672 [13:56<00:23,  9.06it/s]\u001b[A\n",
      " 97%|█████████▋| 6456/6672 [13:56<00:23,  9.27it/s]\u001b[A\n",
      " 97%|█████████▋| 6457/6672 [13:56<00:23,  9.34it/s]\u001b[A\n",
      " 97%|█████████▋| 6458/6672 [13:57<00:24,  8.59it/s]\u001b[A\n",
      " 97%|█████████▋| 6459/6672 [13:57<00:27,  7.84it/s]\u001b[A\n",
      " 97%|█████████▋| 6460/6672 [13:57<00:28,  7.56it/s]\u001b[A\n",
      " 97%|█████████▋| 6461/6672 [13:57<00:25,  8.12it/s]\u001b[A\n",
      " 97%|█████████▋| 6462/6672 [13:57<00:25,  8.21it/s]\u001b[A\n",
      " 97%|█████████▋| 6464/6672 [13:57<00:21,  9.46it/s]\u001b[A\n",
      " 97%|█████████▋| 6465/6672 [13:57<00:23,  8.91it/s]\u001b[A\n",
      " 97%|█████████▋| 6466/6672 [13:58<00:24,  8.38it/s]\u001b[A\n",
      " 97%|█████████▋| 6467/6672 [13:58<00:24,  8.28it/s]\u001b[A\n",
      " 97%|█████████▋| 6469/6672 [13:58<00:21,  9.35it/s]\u001b[A\n",
      " 97%|█████████▋| 6470/6672 [13:58<00:21,  9.36it/s]\u001b[A\n",
      " 97%|█████████▋| 6472/6672 [13:58<00:19, 10.04it/s]\u001b[A\n",
      " 97%|█████████▋| 6473/6672 [13:58<00:20,  9.67it/s]\u001b[A\n",
      " 97%|█████████▋| 6475/6672 [13:58<00:18, 10.44it/s]\u001b[A\n",
      " 97%|█████████▋| 6477/6672 [13:59<00:17, 11.01it/s]\u001b[A\n",
      " 97%|█████████▋| 6479/6672 [13:59<00:16, 11.47it/s]\u001b[A\n",
      " 97%|█████████▋| 6481/6672 [13:59<00:18, 10.55it/s]\u001b[A\n",
      " 97%|█████████▋| 6483/6672 [13:59<00:16, 11.14it/s]\u001b[A\n",
      " 97%|█████████▋| 6485/6672 [13:59<00:16, 11.35it/s]\u001b[A\n",
      " 97%|█████████▋| 6487/6672 [13:59<00:15, 11.60it/s]\u001b[A\n",
      " 97%|█████████▋| 6489/6672 [14:00<00:16, 11.19it/s]\u001b[A\n",
      " 97%|█████████▋| 6491/6672 [14:00<00:15, 11.48it/s]\u001b[A\n",
      " 97%|█████████▋| 6493/6672 [14:00<00:15, 11.70it/s]\u001b[A\n",
      " 97%|█████████▋| 6495/6672 [14:00<00:18,  9.71it/s]\u001b[A\n",
      " 97%|█████████▋| 6497/6672 [14:01<00:20,  8.65it/s]\u001b[A\n",
      " 97%|█████████▋| 6498/6672 [14:01<00:20,  8.44it/s]\u001b[A\n",
      " 97%|█████████▋| 6499/6672 [14:01<00:21,  8.17it/s]\u001b[A\n",
      " 97%|█████████▋| 6500/6672 [14:01<00:27,  6.16it/s]\u001b[A\n",
      "\u001b[A                                                \n",
      " 97%|█████████▋| 6500/6672 [14:01<00:27,  6.16it/s]\u001b[A\n",
      " 97%|█████████▋| 6501/6672 [14:01<00:28,  6.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0065, 'learning_rate': 1.802024218081218e-06, 'epoch': 23.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 6502/6672 [14:01<00:25,  6.72it/s]\u001b[A\n",
      " 97%|█████████▋| 6503/6672 [14:02<00:25,  6.63it/s]\u001b[A\n",
      " 97%|█████████▋| 6504/6672 [14:02<00:23,  7.26it/s]\u001b[A\n",
      " 98%|█████████▊| 6506/6672 [14:02<00:19,  8.51it/s]\u001b[A\n",
      " 98%|█████████▊| 6507/6672 [14:02<00:18,  8.78it/s]\u001b[A\n",
      " 98%|█████████▊| 6509/6672 [14:02<00:17,  9.58it/s]\u001b[A\n",
      " 98%|█████████▊| 6511/6672 [14:02<00:15, 10.19it/s]\u001b[A\n",
      " 98%|█████████▊| 6513/6672 [14:02<00:15, 10.44it/s]\u001b[A\n",
      " 98%|█████████▊| 6515/6672 [14:03<00:14, 10.77it/s]\u001b[A\n",
      " 98%|█████████▊| 6517/6672 [14:03<00:13, 11.34it/s]\u001b[A\n",
      " 98%|█████████▊| 6519/6672 [14:03<00:13, 11.10it/s]\u001b[A\n",
      " 98%|█████████▊| 6521/6672 [14:03<00:13, 11.24it/s]\u001b[A\n",
      " 98%|█████████▊| 6523/6672 [14:03<00:14,  9.93it/s]\u001b[A\n",
      " 98%|█████████▊| 6525/6672 [14:04<00:14, 10.34it/s]\u001b[A\n",
      " 98%|█████████▊| 6527/6672 [14:04<00:13, 10.44it/s]\u001b[A\n",
      " 98%|█████████▊| 6529/6672 [14:04<00:13, 10.73it/s]\u001b[A\n",
      " 98%|█████████▊| 6531/6672 [14:04<00:14,  9.42it/s]\u001b[A\n",
      " 98%|█████████▊| 6532/6672 [14:04<00:14,  9.49it/s]\u001b[A\n",
      " 98%|█████████▊| 6534/6672 [14:05<00:13, 10.03it/s]\u001b[A\n",
      " 98%|█████████▊| 6536/6672 [14:05<00:14,  9.39it/s]\u001b[A\n",
      " 98%|█████████▊| 6537/6672 [14:05<00:14,  9.21it/s]\u001b[A\n",
      " 98%|█████████▊| 6538/6672 [14:05<00:14,  9.22it/s]\u001b[A\n",
      " 98%|█████████▊| 6540/6672 [14:05<00:13,  9.82it/s]\u001b[A\n",
      " 98%|█████████▊| 6541/6672 [14:05<00:14,  9.24it/s]\u001b[A\n",
      " 98%|█████████▊| 6542/6672 [14:05<00:14,  8.72it/s]\u001b[A\n",
      " 98%|█████████▊| 6543/6672 [14:06<00:15,  8.35it/s]\u001b[A\n",
      " 98%|█████████▊| 6544/6672 [14:06<00:14,  8.67it/s]\u001b[A\n",
      " 98%|█████████▊| 6545/6672 [14:06<00:16,  7.89it/s]\u001b[A\n",
      " 98%|█████████▊| 6546/6672 [14:06<00:16,  7.82it/s]\u001b[A\n",
      " 98%|█████████▊| 6547/6672 [14:06<00:16,  7.44it/s]\u001b[A\n",
      " 98%|█████████▊| 6548/6672 [14:06<00:17,  7.10it/s]\u001b[A\n",
      " 98%|█████████▊| 6549/6672 [14:06<00:16,  7.37it/s]\u001b[A\n",
      " 98%|█████████▊| 6551/6672 [14:07<00:14,  8.58it/s]\u001b[A\n",
      " 98%|█████████▊| 6552/6672 [14:07<00:13,  8.76it/s]\u001b[A\n",
      " 98%|█████████▊| 6553/6672 [14:07<00:13,  8.74it/s]\u001b[A\n",
      " 98%|█████████▊| 6554/6672 [14:07<00:13,  8.69it/s]\u001b[A\n",
      " 98%|█████████▊| 6555/6672 [14:07<00:13,  8.97it/s]\u001b[A\n",
      " 98%|█████████▊| 6557/6672 [14:07<00:11,  9.68it/s]\u001b[A\n",
      " 98%|█████████▊| 6558/6672 [14:07<00:11,  9.54it/s]\u001b[A\n",
      " 98%|█████████▊| 6560/6672 [14:08<00:11,  9.66it/s]\u001b[A\n",
      " 98%|█████████▊| 6562/6672 [14:08<00:10, 10.19it/s]\u001b[A\n",
      " 98%|█████████▊| 6564/6672 [14:08<00:11,  9.61it/s]\u001b[A\n",
      " 98%|█████████▊| 6565/6672 [14:08<00:11,  8.99it/s]\u001b[A\n",
      " 98%|█████████▊| 6566/6672 [14:08<00:12,  8.43it/s]\u001b[A\n",
      " 98%|█████████▊| 6567/6672 [14:08<00:13,  7.90it/s]\u001b[A\n",
      " 98%|█████████▊| 6568/6672 [14:09<00:13,  7.63it/s]\u001b[A\n",
      " 98%|█████████▊| 6569/6672 [14:09<00:13,  7.43it/s]\u001b[A\n",
      " 98%|█████████▊| 6570/6672 [14:09<00:13,  7.41it/s]\u001b[A\n",
      " 99%|█████████▊| 6572/6672 [14:09<00:11,  8.68it/s]\u001b[A\n",
      " 99%|█████████▊| 6574/6672 [14:09<00:10,  9.26it/s]\u001b[A\n",
      " 99%|█████████▊| 6575/6672 [14:09<00:10,  8.83it/s]\u001b[A\n",
      " 99%|█████████▊| 6576/6672 [14:09<00:10,  9.05it/s]\u001b[A\n",
      " 99%|█████████▊| 6578/6672 [14:10<00:09,  9.85it/s]\u001b[A\n",
      " 99%|█████████▊| 6580/6672 [14:10<00:09,  9.80it/s]\u001b[A\n",
      " 99%|█████████▊| 6581/6672 [14:10<00:09,  9.61it/s]\u001b[A\n",
      " 99%|█████████▊| 6583/6672 [14:10<00:08, 10.35it/s]\u001b[A\n",
      " 99%|█████████▊| 6585/6672 [14:10<00:07, 10.91it/s]\u001b[A\n",
      " 99%|█████████▊| 6587/6672 [14:10<00:08,  9.84it/s]\u001b[A\n",
      " 99%|█████████▉| 6589/6672 [14:11<00:07, 10.40it/s]\u001b[A\n",
      " 99%|█████████▉| 6591/6672 [14:11<00:07, 10.98it/s]\u001b[A\n",
      " 99%|█████████▉| 6593/6672 [14:11<00:07, 11.05it/s]\u001b[A\n",
      " 99%|█████████▉| 6595/6672 [14:11<00:07, 10.00it/s]\u001b[A\n",
      " 99%|█████████▉| 6597/6672 [14:12<00:08,  8.79it/s]\u001b[A\n",
      " 99%|█████████▉| 6598/6672 [14:12<00:08,  8.92it/s]\u001b[A\n",
      " 99%|█████████▉| 6599/6672 [14:12<00:08,  9.00it/s]\u001b[A\n",
      " 99%|█████████▉| 6601/6672 [14:12<00:07,  9.00it/s]\u001b[A\n",
      " 99%|█████████▉| 6602/6672 [14:12<00:08,  8.46it/s]\u001b[A\n",
      " 99%|█████████▉| 6603/6672 [14:12<00:08,  7.99it/s]\u001b[A\n",
      " 99%|█████████▉| 6604/6672 [14:12<00:08,  8.32it/s]\u001b[A\n",
      " 99%|█████████▉| 6605/6672 [14:12<00:08,  8.01it/s]\u001b[A\n",
      " 99%|█████████▉| 6606/6672 [14:13<00:08,  7.87it/s]\u001b[A\n",
      " 99%|█████████▉| 6607/6672 [14:13<00:07,  8.23it/s]\u001b[A\n",
      " 99%|█████████▉| 6608/6672 [14:13<00:07,  8.54it/s]\u001b[A\n",
      " 99%|█████████▉| 6609/6672 [14:13<00:07,  8.53it/s]\u001b[A\n",
      " 99%|█████████▉| 6610/6672 [14:13<00:07,  8.17it/s]\u001b[A\n",
      " 99%|█████████▉| 6611/6672 [14:13<00:07,  7.71it/s]\u001b[A\n",
      " 99%|█████████▉| 6612/6672 [14:13<00:07,  7.81it/s]\u001b[A\n",
      " 99%|█████████▉| 6613/6672 [14:13<00:07,  7.81it/s]\u001b[A\n",
      " 99%|█████████▉| 6614/6672 [14:14<00:07,  8.10it/s]\u001b[A\n",
      " 99%|█████████▉| 6616/6672 [14:14<00:06,  9.30it/s]\u001b[A\n",
      " 99%|█████████▉| 6617/6672 [14:14<00:05,  9.28it/s]\u001b[A\n",
      " 99%|█████████▉| 6618/6672 [14:14<00:05,  9.18it/s]\u001b[A\n",
      " 99%|█████████▉| 6619/6672 [14:14<00:06,  8.17it/s]\u001b[A\n",
      " 99%|█████████▉| 6620/6672 [14:14<00:06,  7.59it/s]\u001b[A\n",
      " 99%|█████████▉| 6621/6672 [14:14<00:06,  7.72it/s]\u001b[A\n",
      " 99%|█████████▉| 6622/6672 [14:15<00:06,  7.66it/s]\u001b[A\n",
      " 99%|█████████▉| 6623/6672 [14:15<00:06,  8.01it/s]\u001b[A\n",
      " 99%|█████████▉| 6625/6672 [14:15<00:04,  9.44it/s]\u001b[A\n",
      " 99%|█████████▉| 6626/6672 [14:15<00:05,  9.00it/s]\u001b[A\n",
      " 99%|█████████▉| 6627/6672 [14:15<00:04,  9.20it/s]\u001b[A\n",
      " 99%|█████████▉| 6628/6672 [14:15<00:05,  8.46it/s]\u001b[A\n",
      " 99%|█████████▉| 6629/6672 [14:15<00:05,  8.00it/s]\u001b[A\n",
      " 99%|█████████▉| 6630/6672 [14:15<00:05,  7.94it/s]\u001b[A\n",
      " 99%|█████████▉| 6631/6672 [14:16<00:05,  7.81it/s]\u001b[A\n",
      " 99%|█████████▉| 6632/6672 [14:16<00:05,  7.68it/s]\u001b[A\n",
      " 99%|█████████▉| 6633/6672 [14:16<00:05,  7.71it/s]\u001b[A\n",
      " 99%|█████████▉| 6634/6672 [14:16<00:04,  8.21it/s]\u001b[A\n",
      " 99%|█████████▉| 6636/6672 [14:16<00:03,  9.34it/s]\u001b[A\n",
      " 99%|█████████▉| 6638/6672 [14:16<00:03, 10.04it/s]\u001b[A\n",
      "100%|█████████▉| 6640/6672 [14:17<00:02, 10.75it/s]\u001b[A\n",
      "100%|█████████▉| 6642/6672 [14:17<00:02, 11.38it/s]\u001b[A\n",
      "100%|█████████▉| 6644/6672 [14:17<00:02, 12.77it/s]\u001b[A\n",
      "100%|█████████▉| 6646/6672 [14:17<00:02,  9.76it/s]\u001b[A\n",
      "100%|█████████▉| 6648/6672 [14:17<00:02,  9.79it/s]\u001b[A\n",
      "100%|█████████▉| 6650/6672 [14:17<00:02,  9.71it/s]\u001b[A\n",
      "100%|█████████▉| 6652/6672 [14:18<00:02,  9.00it/s]\u001b[A\n",
      "100%|█████████▉| 6653/6672 [14:18<00:02,  9.10it/s]\u001b[A\n",
      "100%|█████████▉| 6655/6672 [14:18<00:01, 10.07it/s]\u001b[A\n",
      "100%|█████████▉| 6657/6672 [14:18<00:01, 10.05it/s]\u001b[A\n",
      "100%|█████████▉| 6659/6672 [14:18<00:01, 11.00it/s]\u001b[A\n",
      "100%|█████████▉| 6661/6672 [14:19<00:00, 11.67it/s]\u001b[A\n",
      "100%|█████████▉| 6663/6672 [14:19<00:00, 11.94it/s]\u001b[A\n",
      "100%|█████████▉| 6665/6672 [14:19<00:00, 11.96it/s]\u001b[A\n",
      "100%|█████████▉| 6667/6672 [14:19<00:00, 11.50it/s]\u001b[A\n",
      "100%|█████████▉| 6669/6672 [14:19<00:00, 11.37it/s]\u001b[A\n",
      "100%|█████████▉| 6671/6672 [14:19<00:00, 10.21it/s]\u001b[AThe following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 77.10it/s]\n",
      "                                                   \n",
      "Saving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6672\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6672/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45793232321739197, 'eval_f1': 0.7834044641891498, 'eval_recall': 0.7693304569771393, 'eval_precision': 0.799553528269219, 'eval_runtime': 4.4484, 'eval_samples_per_second': 285.494, 'eval_steps_per_second': 71.486, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6672/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6672/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-6672/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Checkpoints/MarBertv2_taskB_hyperparams/run-10/checkpoint-2224 (score: 0.805722764855707).\n",
      "\n",
      "\u001b[A                                                \n",
      "100%|██████████| 6672/6672 [14:28<00:00,  7.68it/s]\u001b[A\n",
      "\u001b[32m[I 2022-03-29 18:34:12,973]\u001b[0m Trial 10 finished with value: 2.352288449435508 and parameters: {'learning_rate': 6.990177664556911e-05, 'weight_decay': 1.0100807769614473e-10, 'num_train_epochs': 24, 'seed': 50, 'per_device_train_batch_size': 32}. Best is trial 5 with value: 2.4375231510484783.\u001b[0m\n",
      "Trial:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 878.9819, 'train_samples_per_second': 242.653, 'train_steps_per_second': 7.591, 'train_loss': 0.051059936894644366, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/config.json from cache at /home/ashapiro/.cache/huggingface/transformers/ff060a5035cde771cddd0649d04ca5403ad27e4dd88e31cdb10ce3a3169c7eea.8480f475cb3f32e19cacdd9bac8fc808a24bd5d183a66fbcb4525caebf3a97a7\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"UBC-NLP/MARBERTv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/UBC-NLP/MARBERTv2/resolve/main/pytorch_model.bin from cache at /home/ashapiro/.cache/huggingface/transformers/2c47a44e0e26f215b8c363985acfda530be3524fceaba13725029808d858978e.c7ac1b4c527f48f02818c23f9101e0a07137aef2ac3e97f70fce56b829081034\n",
      "Some weights of the model checkpoint at UBC-NLP/MARBERTv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ashapiro/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8887\n",
      "  Num Epochs = 24\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25346<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_181940-1wetux90/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_181940-1wetux90/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>0.45793</td></tr><tr><td>eval/f1</td><td>0.7834</td></tr><tr><td>eval/recall</td><td>0.76933</td></tr><tr><td>eval/precision</td><td>0.79955</td></tr><tr><td>eval/runtime</td><td>4.4484</td></tr><tr><td>eval/samples_per_second</td><td>285.494</td></tr><tr><td>eval/steps_per_second</td><td>71.486</td></tr><tr><td>train/epoch</td><td>24.0</td></tr><tr><td>train/global_step</td><td>6672</td></tr><tr><td>_runtime</td><td>871</td></tr><tr><td>_timestamp</td><td>1648571652</td></tr><tr><td>_step</td><td>37</td></tr><tr><td>train/loss</td><td>0.0065</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/train_runtime</td><td>878.9819</td></tr><tr><td>train/train_samples_per_second</td><td>242.653</td></tr><tr><td>train/train_steps_per_second</td><td>7.591</td></tr><tr><td>train/total_flos</td><td>2188849133422740.0</td></tr><tr><td>train/train_loss</td><td>0.05106</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>eval/loss</td><td>█▁▂▄▅▃▃▄▄▄▆▇▇▇▆▅▇▅▇▆█▇▇▇</td></tr><tr><td>eval/f1</td><td>▅▁▇▇▆▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>eval/recall</td><td>█▁▇▅▄▆█▇▆▇▆▆▅▅▇▇▇▆▅▆▅▆▆▆</td></tr><tr><td>eval/precision</td><td>▄▁▅▆█▇▆▇▇▆▇▆▇▇▆▅▅▆▇▆█▇▇▇</td></tr><tr><td>eval/runtime</td><td>▆▆█▅▃▆▅▅▅▇▆▆▆▆▇▁▅▅▅▄▇▇▇▆</td></tr><tr><td>eval/samples_per_second</td><td>▃▃▁▃▅▃▃▃▄▂▃▃▂▃▂█▃▃▃▄▂▂▂▃</td></tr><tr><td>eval/steps_per_second</td><td>▃▃▁▃▅▃▃▃▄▂▃▃▂▃▂█▃▃▃▄▂▂▂▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▄▄▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▄▄▃▃▂▂▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">deep-oath-21</strong>: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/1wetux90\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/1wetux90</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">drawn-bush-22</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ahmadshapiro/huggingface/runs/2cz9s7t9\" target=\"_blank\">https://wandb.ai/ahmadshapiro/huggingface/runs/2cz9s7t9</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/mt/ashapiro/Hate_Speech/wandb/run-20220329_183424-2cz9s7t9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 278/6672 [00:33<11:00,  9.68it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 80.86it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 82.90it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 81.04it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:04, 66.88it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:04, 67.54it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 71.71it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 73.07it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 74.89it/s]\u001b[A\n",
      " 24%|██▍       | 77/318 [00:01<00:03, 76.68it/s]\u001b[A\n",
      " 27%|██▋       | 85/318 [00:01<00:03, 75.59it/s]\u001b[A\n",
      " 29%|██▉       | 93/318 [00:01<00:02, 76.67it/s]\u001b[A\n",
      " 32%|███▏      | 101/318 [00:01<00:02, 77.51it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:02, 78.00it/s]\u001b[A\n",
      " 37%|███▋      | 118/318 [00:01<00:02, 79.00it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 79.69it/s]\u001b[A\n",
      " 42%|████▏     | 135/318 [00:01<00:02, 70.65it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:01<00:02, 68.58it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 71.18it/s]\u001b[A\n",
      " 50%|█████     | 159/318 [00:02<00:02, 72.72it/s]\u001b[A\n",
      " 53%|█████▎    | 167/318 [00:02<00:02, 74.57it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 75.67it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 77.57it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 79.15it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 80.14it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 74.06it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:02<00:01, 69.21it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 70.97it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 73.95it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 75.98it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 77.03it/s]\u001b[A\n",
      " 82%|████████▏ | 262/318 [00:03<00:00, 78.20it/s]\u001b[A\n",
      " 85%|████████▌ | 271/318 [00:03<00:00, 79.18it/s]\u001b[A\n",
      " 88%|████████▊ | 279/318 [00:03<00:00, 79.21it/s]\u001b[A\n",
      " 91%|█████████ | 288/318 [00:03<00:00, 80.02it/s]\u001b[A\n",
      " 93%|█████████▎| 297/318 [00:03<00:00, 79.96it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 66.82it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 68.77it/s]\u001b[A\n",
      "                                                  \n",
      "  4%|▍         | 278/6672 [00:37<11:00,  9.68it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-278\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-278/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19642768800258636, 'eval_f1': 0.770843877214215, 'eval_recall': 0.8722115544176564, 'eval_precision': 0.7237629688747007, 'eval_runtime': 4.3608, 'eval_samples_per_second': 291.23, 'eval_steps_per_second': 72.922, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-278/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-278/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-278/special_tokens_map.json\n",
      "  8%|▊         | 501/6672 [01:09<19:30,  5.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2071, 'learning_rate': 5.5344912735804665e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 556/6672 [01:16<07:57, 12.80it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 75.75it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 74.21it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 76.29it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 73.71it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 74.88it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 73.98it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 75.06it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 75.20it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 75.41it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 75.68it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 72.79it/s]\u001b[A\n",
      " 30%|███       | 96/318 [00:01<00:03, 72.94it/s]\u001b[A\n",
      " 33%|███▎      | 104/318 [00:01<00:02, 74.22it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 74.71it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:02, 75.37it/s]\u001b[A\n",
      " 40%|████      | 128/318 [00:01<00:02, 76.49it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:01<00:02, 75.40it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:01<00:02, 77.51it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 72.92it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 72.77it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 74.23it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 76.40it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 76.94it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 77.24it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 76.97it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:02<00:01, 78.16it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:02<00:01, 76.85it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 77.16it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 77.75it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:00, 77.84it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 69.69it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 71.98it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 73.74it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 74.23it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 73.39it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 74.11it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 75.22it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 75.80it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 76.69it/s]\u001b[A\n",
      "                                                  \n",
      "  8%|▊         | 556/6672 [01:20<07:57, 12.80it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-556\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-556/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4721205234527588, 'eval_f1': 0.7134490438596918, 'eval_recall': 0.874175220665513, 'eval_precision': 0.6739706298382326, 'eval_runtime': 4.3124, 'eval_samples_per_second': 294.498, 'eval_steps_per_second': 73.74, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-556/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-556/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-556/special_tokens_map.json\n",
      " 12%|█▏        | 833/6672 [01:50<09:12, 10.57it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 83.74it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 79.87it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 62.74it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 67.03it/s]\u001b[A\n",
      " 14%|█▎        | 43/318 [00:00<00:03, 71.65it/s]\u001b[A\n",
      " 16%|█▌        | 51/318 [00:00<00:03, 73.71it/s]\u001b[A\n",
      " 19%|█▊        | 59/318 [00:00<00:03, 72.07it/s]\u001b[A\n",
      " 21%|██        | 67/318 [00:00<00:03, 73.53it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:01<00:03, 73.68it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:03, 74.84it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 75.17it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 71.06it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:03, 70.30it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 73.64it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 74.95it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:01<00:02, 74.08it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:01<00:02, 69.07it/s]\u001b[A\n",
      " 47%|████▋     | 149/318 [00:02<00:02, 72.39it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 69.14it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 69.20it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:02, 70.73it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 70.79it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 72.93it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 73.78it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 75.07it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 72.72it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 75.06it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 73.89it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 74.55it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 75.06it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 75.12it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 73.30it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 73.45it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 74.63it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 75.12it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:04<00:00, 70.76it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:04<00:00, 72.67it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 73.64it/s]\u001b[A\n",
      "100%|█████████▉| 317/318 [00:04<00:00, 69.39it/s]\u001b[A\n",
      "                                                  \n",
      " 12%|█▎        | 834/6672 [01:55<09:12, 10.57it/s][A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-834\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-834/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.283794105052948, 'eval_f1': 0.7735969777113538, 'eval_recall': 0.7233285130660851, 'eval_precision': 0.8661639718076285, 'eval_runtime': 4.4938, 'eval_samples_per_second': 282.61, 'eval_steps_per_second': 70.764, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-834/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-834/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-834/special_tokens_map.json\n",
      " 15%|█▌        | 1001/6672 [02:14<13:48,  6.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0792, 'learning_rate': 5.086136504171809e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1111/6672 [02:24<07:56, 11.67it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 10/318 [00:00<00:03, 91.83it/s]\u001b[A\n",
      "  6%|▋         | 20/318 [00:00<00:03, 77.22it/s]\u001b[A\n",
      "  9%|▉         | 29/318 [00:00<00:03, 78.94it/s]\u001b[A\n",
      " 12%|█▏        | 37/318 [00:00<00:03, 74.08it/s]\u001b[A\n",
      " 14%|█▍        | 45/318 [00:00<00:03, 71.98it/s]\u001b[A\n",
      " 17%|█▋        | 53/318 [00:00<00:03, 74.20it/s]\u001b[A\n",
      " 19%|█▉        | 61/318 [00:00<00:03, 75.09it/s]\u001b[A\n",
      " 22%|██▏       | 70/318 [00:00<00:03, 77.04it/s]\u001b[A\n",
      " 25%|██▍       | 78/318 [00:01<00:03, 77.90it/s]\u001b[A\n",
      " 27%|██▋       | 86/318 [00:01<00:03, 70.92it/s]\u001b[A\n",
      " 30%|██▉       | 94/318 [00:01<00:03, 72.40it/s]\u001b[A\n",
      " 32%|███▏      | 103/318 [00:01<00:02, 75.38it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:02, 77.17it/s]\u001b[A\n",
      " 38%|███▊      | 121/318 [00:01<00:02, 78.08it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 79.26it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 80.58it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:01<00:02, 82.17it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:01, 82.26it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:01, 81.83it/s]\u001b[A\n",
      " 55%|█████▌    | 175/318 [00:02<00:01, 81.35it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:01, 75.94it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 74.91it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 76.86it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 78.00it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 77.42it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:02<00:01, 77.59it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 72.25it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 73.69it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:00, 71.89it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 74.81it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 70.44it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 72.43it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 74.05it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:03<00:00, 74.90it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:03<00:00, 73.80it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 75.09it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 76.28it/s]\u001b[A\n",
      "                                                   \n",
      " 17%|█▋        | 1112/6672 [02:28<07:56, 11.67it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1112\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1112/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3496984839439392, 'eval_f1': 0.7802261190586064, 'eval_recall': 0.7320721617713297, 'eval_precision': 0.8643689284252056, 'eval_runtime': 4.2476, 'eval_samples_per_second': 298.996, 'eval_steps_per_second': 74.867, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1112/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1112/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1112/special_tokens_map.json\n",
      " 21%|██        | 1390/6672 [02:57<06:30, 13.52it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 79.96it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:03, 75.70it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:03, 77.04it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 77.87it/s]\u001b[A\n",
      " 13%|█▎        | 40/318 [00:00<00:03, 76.52it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 77.64it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:03, 75.65it/s]\u001b[A\n",
      " 20%|██        | 64/318 [00:00<00:03, 75.09it/s]\u001b[A\n",
      " 23%|██▎       | 72/318 [00:00<00:03, 74.46it/s]\u001b[A\n",
      " 25%|██▌       | 80/318 [00:01<00:03, 69.00it/s]\u001b[A\n",
      " 28%|██▊       | 88/318 [00:01<00:03, 71.91it/s]\u001b[A\n",
      " 31%|███       | 97/318 [00:01<00:02, 74.97it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:03, 69.59it/s]\u001b[A\n",
      " 36%|███▌      | 113/318 [00:01<00:03, 67.73it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:03, 65.19it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 65.92it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 66.98it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:01<00:02, 70.23it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 72.11it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 73.71it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 75.44it/s]\u001b[A\n",
      " 55%|█████▍    | 174/318 [00:02<00:01, 75.64it/s]\u001b[A\n",
      " 57%|█████▋    | 182/318 [00:02<00:01, 71.46it/s]\u001b[A\n",
      " 60%|█████▉    | 190/318 [00:02<00:01, 72.93it/s]\u001b[A\n",
      " 62%|██████▏   | 198/318 [00:02<00:01, 66.01it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:02<00:01, 66.81it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:02<00:01, 65.39it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 68.93it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 67.08it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 70.64it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:01, 72.88it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 74.17it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 72.31it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 73.84it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:03<00:00, 67.44it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:03<00:00, 69.13it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 67.45it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 70.09it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 72.60it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 71.74it/s]\u001b[A\n",
      "                                                   \n",
      " 21%|██        | 1390/6672 [03:02<06:30, 13.52it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1390\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1390/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30919522047042847, 'eval_f1': 0.772465183413199, 'eval_recall': 0.7158768540249232, 'eval_precision': 0.8886280869466257, 'eval_runtime': 4.578, 'eval_samples_per_second': 277.413, 'eval_steps_per_second': 69.463, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1390/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1390/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1390/special_tokens_map.json\n",
      " 23%|██▎       | 1502/6672 [03:16<10:38,  8.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'learning_rate': 4.637781734763152e-05, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1667/6672 [03:31<08:09, 10.22it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 82.09it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 76.74it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 76.30it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:03, 75.99it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 76.62it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 76.80it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 77.63it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 71.68it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:00<00:03, 71.36it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 70.45it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 70.78it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 72.43it/s]\u001b[A\n",
      " 34%|███▎      | 107/318 [00:01<00:02, 75.27it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:02, 76.38it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:03, 64.85it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 65.94it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 68.55it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 71.54it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 73.39it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 74.80it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 73.84it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 75.55it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 73.20it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 73.93it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 75.00it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 75.14it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:02<00:01, 78.02it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 79.99it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 78.90it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:00, 78.48it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 77.62it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 77.87it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 72.52it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 64.34it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:03<00:00, 68.75it/s]\u001b[A\n",
      " 93%|█████████▎| 295/318 [00:04<00:00, 72.54it/s]\u001b[A\n",
      " 95%|█████████▌| 303/318 [00:04<00:00, 73.75it/s]\u001b[A\n",
      " 98%|█████████▊| 311/318 [00:04<00:00, 74.30it/s]\u001b[A\n",
      "                                                   \n",
      " 25%|██▌       | 1668/6672 [03:36<08:09, 10.22it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1668\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1668/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41769760847091675, 'eval_f1': 0.7778388644542182, 'eval_recall': 0.8081612655967254, 'eval_precision': 0.754511339533366, 'eval_runtime': 4.4028, 'eval_samples_per_second': 288.45, 'eval_steps_per_second': 72.226, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1668/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1668/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1668/special_tokens_map.json\n",
      " 29%|██▉       | 1945/6672 [04:05<07:17, 10.81it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 65.47it/s]\u001b[A\n",
      "  5%|▍         | 15/318 [00:00<00:04, 69.66it/s]\u001b[A\n",
      "  7%|▋         | 23/318 [00:00<00:04, 72.91it/s]\u001b[A\n",
      " 10%|▉         | 31/318 [00:00<00:03, 74.80it/s]\u001b[A\n",
      " 12%|█▏        | 39/318 [00:00<00:03, 75.97it/s]\u001b[A\n",
      " 15%|█▌        | 48/318 [00:00<00:03, 78.37it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 79.85it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 80.39it/s]\u001b[A\n",
      " 24%|██▎       | 75/318 [00:00<00:03, 78.59it/s]\u001b[A\n",
      " 26%|██▌       | 83/318 [00:01<00:02, 78.57it/s]\u001b[A\n",
      " 29%|██▊       | 91/318 [00:01<00:03, 73.30it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:02, 76.43it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:03, 66.73it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:02, 69.33it/s]\u001b[A\n",
      " 39%|███▉      | 125/318 [00:01<00:02, 73.00it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:01<00:02, 75.59it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:01<00:02, 77.09it/s]\u001b[A\n",
      " 48%|████▊     | 152/318 [00:02<00:02, 78.12it/s]\u001b[A\n",
      " 50%|█████     | 160/318 [00:02<00:02, 77.45it/s]\u001b[A\n",
      " 53%|█████▎    | 168/318 [00:02<00:01, 77.99it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:01, 79.11it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 78.42it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 76.85it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 77.28it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 78.69it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:02<00:01, 79.66it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:02<00:01, 79.51it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 76.62it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:01, 74.15it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 75.96it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 70.17it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 72.75it/s]\u001b[A\n",
      " 87%|████████▋ | 277/318 [00:03<00:00, 75.06it/s]\u001b[A\n",
      " 90%|████████▉ | 285/318 [00:03<00:00, 76.16it/s]\u001b[A\n",
      " 92%|█████████▏| 293/318 [00:03<00:00, 77.15it/s]\u001b[A\n",
      " 95%|█████████▍| 301/318 [00:03<00:00, 77.06it/s]\u001b[A\n",
      " 97%|█████████▋| 309/318 [00:04<00:00, 77.59it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 79.22it/s]\u001b[A\n",
      "                                                   \n",
      " 29%|██▉       | 1946/6672 [04:10<07:17, 10.81it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1946\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1946/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.409309059381485, 'eval_f1': 0.7855092045262626, 'eval_recall': 0.8214920702652728, 'eval_precision': 0.7587924355475832, 'eval_runtime': 4.2923, 'eval_samples_per_second': 295.881, 'eval_steps_per_second': 74.087, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-1946/special_tokens_map.json\n",
      " 30%|██▉       | 2001/6672 [04:20<12:16,  6.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0141, 'learning_rate': 4.1894269653544945e-05, 'epoch': 7.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2223/6672 [04:42<06:37, 11.19it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 84.36it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 78.89it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:03, 73.49it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 69.05it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 72.43it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 71.83it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 67.59it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 70.00it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 72.41it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 74.04it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 72.75it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 73.84it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 73.00it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 71.87it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 67.50it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:02, 68.14it/s]\u001b[A\n",
      " 43%|████▎     | 137/318 [00:01<00:02, 70.70it/s]\u001b[A\n",
      " 46%|████▌     | 145/318 [00:02<00:02, 72.75it/s]\u001b[A\n",
      " 48%|████▊     | 153/318 [00:02<00:02, 73.02it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 70.11it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 71.29it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:02, 61.96it/s]\u001b[A\n",
      " 58%|█████▊    | 184/318 [00:02<00:02, 61.81it/s]\u001b[A\n",
      " 60%|██████    | 192/318 [00:02<00:01, 66.39it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 69.63it/s]\u001b[A\n",
      " 65%|██████▌   | 208/318 [00:03<00:01, 61.40it/s]\u001b[A\n",
      " 68%|██████▊   | 216/318 [00:03<00:01, 64.58it/s]\u001b[A\n",
      " 70%|███████   | 224/318 [00:03<00:01, 68.17it/s]\u001b[A\n",
      " 73%|███████▎  | 232/318 [00:03<00:01, 66.75it/s]\u001b[A\n",
      " 76%|███████▌  | 241/318 [00:03<00:01, 70.73it/s]\u001b[A\n",
      " 78%|███████▊  | 249/318 [00:03<00:00, 72.58it/s]\u001b[A\n",
      " 81%|████████  | 257/318 [00:03<00:00, 74.11it/s]\u001b[A\n",
      " 83%|████████▎ | 265/318 [00:03<00:00, 75.18it/s]\u001b[A\n",
      " 86%|████████▌ | 273/318 [00:03<00:00, 75.12it/s]\u001b[A\n",
      " 88%|████████▊ | 281/318 [00:03<00:00, 73.79it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:04<00:00, 75.60it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 74.23it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 75.04it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 74.98it/s]\u001b[A\n",
      "                                                   \n",
      " 33%|███▎      | 2224/6672 [04:47<06:37, 11.19it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2224\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2224/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4618496596813202, 'eval_f1': 0.797603110856123, 'eval_recall': 0.7951307398715122, 'eval_precision': 0.8001301821746851, 'eval_runtime': 4.5533, 'eval_samples_per_second': 278.921, 'eval_steps_per_second': 69.84, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2224/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2224/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2224/special_tokens_map.json\n",
      " 37%|███▋      | 2501/6672 [05:19<10:46,  6.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0067, 'learning_rate': 3.741072195945837e-05, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2502/6672 [05:19<10:44,  6.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 72.98it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 71.64it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 72.06it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:03, 74.10it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:03, 76.68it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 78.66it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 76.82it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 71.71it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 71.05it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 68.67it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 71.03it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:03, 55.26it/s]\u001b[A\n",
      " 33%|███▎      | 105/318 [00:01<00:03, 56.72it/s]\u001b[A\n",
      " 35%|███▌      | 112/318 [00:01<00:03, 59.70it/s]\u001b[A\n",
      " 38%|███▊      | 120/318 [00:01<00:03, 64.02it/s]\u001b[A\n",
      " 40%|███▉      | 127/318 [00:01<00:02, 64.31it/s]\u001b[A\n",
      " 42%|████▏     | 134/318 [00:02<00:03, 56.65it/s]\u001b[A\n",
      " 45%|████▍     | 142/318 [00:02<00:02, 61.94it/s]\u001b[A\n",
      " 47%|████▋     | 150/318 [00:02<00:02, 64.87it/s]\u001b[A\n",
      " 49%|████▉     | 157/318 [00:02<00:02, 63.55it/s]\u001b[A\n",
      " 52%|█████▏    | 165/318 [00:02<00:02, 67.23it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 70.42it/s]\u001b[A\n",
      " 57%|█████▋    | 181/318 [00:02<00:01, 69.08it/s]\u001b[A\n",
      " 59%|█████▉    | 189/318 [00:02<00:02, 61.08it/s]\u001b[A\n",
      " 62%|██████▏   | 197/318 [00:02<00:01, 65.36it/s]\u001b[A\n",
      " 64%|██████▍   | 205/318 [00:03<00:01, 67.86it/s]\u001b[A\n",
      " 67%|██████▋   | 213/318 [00:03<00:01, 71.07it/s]\u001b[A\n",
      " 69%|██████▉   | 221/318 [00:03<00:01, 71.85it/s]\u001b[A\n",
      " 72%|███████▏  | 229/318 [00:03<00:01, 64.72it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 67.39it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 69.60it/s]\u001b[A\n",
      " 80%|███████▉  | 253/318 [00:03<00:00, 71.61it/s]\u001b[A\n",
      " 82%|████████▏ | 261/318 [00:03<00:00, 72.43it/s]\u001b[A\n",
      " 85%|████████▍ | 270/318 [00:03<00:00, 74.57it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:04<00:00, 71.30it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 73.21it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 74.01it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 75.29it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 75.29it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 75.50it/s]\u001b[A\n",
      "                                                   \n",
      " 38%|███▊      | 2502/6672 [05:24<10:44,  6.47it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2502\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2502/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4412645697593689, 'eval_f1': 0.7719030270674635, 'eval_recall': 0.8283629266134067, 'eval_precision': 0.7365107913669064, 'eval_runtime': 4.7754, 'eval_samples_per_second': 265.946, 'eval_steps_per_second': 66.591, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2502/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2502/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2502/special_tokens_map.json\n",
      " 42%|████▏     | 2779/6672 [05:56<05:43, 11.32it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 7/318 [00:00<00:04, 66.55it/s]\u001b[A\n",
      "  4%|▍         | 14/318 [00:00<00:04, 68.48it/s]\u001b[A\n",
      "  7%|▋         | 21/318 [00:00<00:04, 68.97it/s]\u001b[A\n",
      "  9%|▉         | 28/318 [00:00<00:04, 68.66it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:03, 71.45it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:03, 72.74it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:04, 63.43it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 66.16it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 69.21it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 71.70it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 66.79it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 68.41it/s]\u001b[A\n",
      " 31%|███       | 99/318 [00:01<00:03, 65.84it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:03, 62.33it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:03, 65.31it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 67.67it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 69.72it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:02<00:02, 72.04it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:02<00:02, 72.44it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 71.20it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 67.86it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:02, 70.07it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:02, 67.52it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:01, 68.16it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 69.24it/s]\u001b[A\n",
      " 63%|██████▎   | 200/318 [00:02<00:01, 66.82it/s]\u001b[A\n",
      " 65%|██████▌   | 207/318 [00:03<00:01, 65.67it/s]\u001b[A\n",
      " 68%|██████▊   | 215/318 [00:03<00:01, 67.94it/s]\u001b[A\n",
      " 70%|███████   | 223/318 [00:03<00:01, 69.54it/s]\u001b[A\n",
      " 72%|███████▏  | 230/318 [00:03<00:01, 68.05it/s]\u001b[A\n",
      " 75%|███████▍  | 237/318 [00:03<00:01, 63.94it/s]\u001b[A\n",
      " 77%|███████▋  | 245/318 [00:03<00:01, 66.35it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 67.20it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 68.89it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 71.68it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:04<00:00, 72.92it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:04<00:00, 74.27it/s]\u001b[A\n",
      " 92%|█████████▏| 292/318 [00:04<00:00, 75.12it/s]\u001b[A\n",
      " 94%|█████████▍| 300/318 [00:04<00:00, 75.31it/s]\u001b[A\n",
      " 97%|█████████▋| 308/318 [00:04<00:00, 75.96it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 67.50it/s]\u001b[A\n",
      "                                                   \n",
      " 42%|████▏     | 2780/6672 [06:00<05:43, 11.32it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2780\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2780/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5078285336494446, 'eval_f1': 0.7112494000151575, 'eval_recall': 0.6533793234241282, 'eval_precision': 0.8945121951219512, 'eval_runtime': 4.6904, 'eval_samples_per_second': 270.765, 'eval_steps_per_second': 67.798, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2780/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2780/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-2780/special_tokens_map.json\n",
      " 45%|████▍     | 3002/6672 [06:26<07:24,  8.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0041, 'learning_rate': 3.29271742653718e-05, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 3058/6672 [06:31<05:06, 11.81it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 89.32it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 82.59it/s]\u001b[A\n",
      "  8%|▊         | 27/318 [00:00<00:03, 80.72it/s]\u001b[A\n",
      " 11%|█▏        | 36/318 [00:00<00:04, 64.61it/s]\u001b[A\n",
      " 14%|█▍        | 44/318 [00:00<00:04, 67.42it/s]\u001b[A\n",
      " 16%|█▋        | 52/318 [00:00<00:03, 69.69it/s]\u001b[A\n",
      " 19%|█▉        | 60/318 [00:00<00:03, 72.38it/s]\u001b[A\n",
      " 21%|██▏       | 68/318 [00:00<00:03, 73.56it/s]\u001b[A\n",
      " 24%|██▍       | 76/318 [00:01<00:03, 74.11it/s]\u001b[A\n",
      " 26%|██▋       | 84/318 [00:01<00:03, 74.69it/s]\u001b[A\n",
      " 29%|██▉       | 92/318 [00:01<00:03, 68.12it/s]\u001b[A\n",
      " 31%|███▏      | 100/318 [00:01<00:03, 70.12it/s]\u001b[A\n",
      " 34%|███▍      | 108/318 [00:01<00:03, 69.12it/s]\u001b[A\n",
      " 36%|███▌      | 115/318 [00:01<00:03, 63.88it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:03, 61.60it/s]\u001b[A\n",
      " 41%|████      | 129/318 [00:01<00:03, 62.08it/s]\u001b[A\n",
      " 43%|████▎     | 136/318 [00:02<00:03, 59.94it/s]\u001b[A\n",
      " 45%|████▍     | 143/318 [00:02<00:02, 61.81it/s]\u001b[A\n",
      " 47%|████▋     | 151/318 [00:02<00:02, 65.89it/s]\u001b[A\n",
      " 50%|████▉     | 158/318 [00:02<00:02, 66.47it/s]\u001b[A\n",
      " 52%|█████▏    | 166/318 [00:02<00:02, 67.98it/s]\u001b[A\n",
      " 54%|█████▍    | 173/318 [00:02<00:02, 68.35it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:02, 66.75it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:01, 69.54it/s]\u001b[A\n",
      " 62%|██████▏   | 196/318 [00:02<00:01, 71.64it/s]\u001b[A\n",
      " 64%|██████▍   | 204/318 [00:02<00:01, 73.04it/s]\u001b[A\n",
      " 67%|██████▋   | 212/318 [00:03<00:01, 71.05it/s]\u001b[A\n",
      " 69%|██████▉   | 220/318 [00:03<00:01, 72.60it/s]\u001b[A\n",
      " 72%|███████▏  | 228/318 [00:03<00:01, 73.44it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 75.02it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:01, 71.33it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 71.05it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 71.82it/s]\u001b[A\n",
      " 84%|████████▍ | 268/318 [00:03<00:00, 69.46it/s]\u001b[A\n",
      " 87%|████████▋ | 276/318 [00:03<00:00, 71.18it/s]\u001b[A\n",
      " 89%|████████▉ | 284/318 [00:04<00:00, 68.90it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 66.37it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 69.45it/s]\u001b[A\n",
      " 96%|█████████▌| 306/318 [00:04<00:00, 69.18it/s]\u001b[A\n",
      " 99%|█████████▊| 314/318 [00:04<00:00, 70.43it/s]\u001b[A\n",
      "                                                   \n",
      " 46%|████▌     | 3058/6672 [06:36<05:06, 11.81it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3058\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3058/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4681772291660309, 'eval_f1': 0.7974003433027254, 'eval_recall': 0.7765015922686074, 'eval_precision': 0.8228666863512217, 'eval_runtime': 4.6797, 'eval_samples_per_second': 271.388, 'eval_steps_per_second': 67.954, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3058/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3058/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3058/special_tokens_map.json\n",
      " 50%|████▉     | 3335/6672 [07:07<05:06, 10.89it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:03, 79.12it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 73.84it/s]\u001b[A\n",
      "  8%|▊         | 25/318 [00:00<00:03, 77.00it/s]\u001b[A\n",
      " 10%|█         | 33/318 [00:00<00:03, 73.21it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:03, 70.21it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:04, 63.63it/s]\u001b[A\n",
      " 18%|█▊        | 56/318 [00:00<00:04, 62.18it/s]\u001b[A\n",
      " 20%|█▉        | 63/318 [00:00<00:04, 62.36it/s]\u001b[A\n",
      " 22%|██▏       | 71/318 [00:01<00:03, 65.96it/s]\u001b[A\n",
      " 25%|██▍       | 79/318 [00:01<00:03, 67.63it/s]\u001b[A\n",
      " 27%|██▋       | 87/318 [00:01<00:03, 70.65it/s]\u001b[A\n",
      " 30%|██▉       | 95/318 [00:01<00:03, 69.01it/s]\u001b[A\n",
      " 32%|███▏      | 102/318 [00:01<00:03, 66.03it/s]\u001b[A\n",
      " 34%|███▍      | 109/318 [00:01<00:03, 66.96it/s]\u001b[A\n",
      " 36%|███▋      | 116/318 [00:01<00:03, 66.14it/s]\u001b[A\n",
      " 39%|███▉      | 124/318 [00:01<00:02, 69.81it/s]\u001b[A\n",
      " 42%|████▏     | 132/318 [00:02<00:03, 58.98it/s]\u001b[A\n",
      " 44%|████▍     | 140/318 [00:02<00:02, 63.75it/s]\u001b[A\n",
      " 47%|████▋     | 148/318 [00:02<00:02, 66.66it/s]\u001b[A\n",
      " 49%|████▉     | 156/318 [00:02<00:02, 69.89it/s]\u001b[A\n",
      " 52%|█████▏    | 164/318 [00:02<00:02, 68.28it/s]\u001b[A\n",
      " 54%|█████▍    | 172/318 [00:02<00:02, 70.80it/s]\u001b[A\n",
      " 57%|█████▋    | 180/318 [00:02<00:01, 73.00it/s]\u001b[A\n",
      " 59%|█████▉    | 188/318 [00:02<00:02, 62.83it/s]\u001b[A\n",
      " 61%|██████▏   | 195/318 [00:02<00:01, 64.45it/s]\u001b[A\n",
      " 64%|██████▍   | 203/318 [00:03<00:01, 67.68it/s]\u001b[A\n",
      " 66%|██████▋   | 211/318 [00:03<00:01, 69.41it/s]\u001b[A\n",
      " 69%|██████▉   | 219/318 [00:03<00:01, 66.89it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 69.75it/s]\u001b[A\n",
      " 74%|███████▍  | 235/318 [00:03<00:01, 72.19it/s]\u001b[A\n",
      " 76%|███████▋  | 243/318 [00:03<00:01, 73.56it/s]\u001b[A\n",
      " 79%|███████▉  | 251/318 [00:03<00:00, 73.84it/s]\u001b[A\n",
      " 81%|████████▏ | 259/318 [00:03<00:00, 75.13it/s]\u001b[A\n",
      " 84%|████████▍ | 267/318 [00:03<00:00, 69.67it/s]\u001b[A\n",
      " 86%|████████▋ | 275/318 [00:04<00:00, 71.85it/s]\u001b[A\n",
      " 89%|████████▉ | 283/318 [00:04<00:00, 74.02it/s]\u001b[A\n",
      " 92%|█████████▏| 291/318 [00:04<00:00, 74.90it/s]\u001b[A\n",
      " 94%|█████████▍| 299/318 [00:04<00:00, 76.16it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 77.27it/s]\u001b[A\n",
      " 99%|█████████▉| 315/318 [00:04<00:00, 77.98it/s]\u001b[A\n",
      "                                                   \n",
      " 50%|█████     | 3336/6672 [07:12<05:06, 10.89it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3336\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3336/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5234766006469727, 'eval_f1': 0.77097234290211, 'eval_recall': 0.7299188456645251, 'eval_precision': 0.8373214616954183, 'eval_runtime': 4.7281, 'eval_samples_per_second': 268.604, 'eval_steps_per_second': 67.257, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3336/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3336/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3336/special_tokens_map.json\n",
      " 52%|█████▏    | 3501/6672 [07:32<06:14,  8.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0019, 'learning_rate': 2.844362657128522e-05, 'epoch': 12.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 3613/6672 [07:43<03:51, 13.19it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 8/318 [00:00<00:04, 74.39it/s]\u001b[A\n",
      "  5%|▌         | 16/318 [00:00<00:04, 69.93it/s]\u001b[A\n",
      "  8%|▊         | 24/318 [00:00<00:04, 72.24it/s]\u001b[A\n",
      " 10%|█         | 32/318 [00:00<00:04, 67.68it/s]\u001b[A\n",
      " 13%|█▎        | 41/318 [00:00<00:03, 72.30it/s]\u001b[A\n",
      " 15%|█▌        | 49/318 [00:00<00:03, 74.14it/s]\u001b[A\n",
      " 18%|█▊        | 57/318 [00:00<00:03, 74.93it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 76.83it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 72.37it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 73.31it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 74.05it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 74.83it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 73.54it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 74.76it/s]\u001b[A\n",
      " 38%|███▊      | 122/318 [00:01<00:02, 75.59it/s]\u001b[A\n",
      " 41%|████      | 130/318 [00:01<00:02, 74.48it/s]\u001b[A\n",
      " 43%|████▎     | 138/318 [00:01<00:02, 75.82it/s]\u001b[A\n",
      " 46%|████▌     | 146/318 [00:01<00:02, 75.89it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 75.24it/s]\u001b[A\n",
      " 51%|█████     | 162/318 [00:02<00:02, 73.18it/s]\u001b[A\n",
      " 53%|█████▎    | 170/318 [00:02<00:01, 75.09it/s]\u001b[A\n",
      " 56%|█████▌    | 178/318 [00:02<00:01, 76.39it/s]\u001b[A\n",
      " 58%|█████▊    | 186/318 [00:02<00:01, 76.65it/s]\u001b[A\n",
      " 61%|██████    | 194/318 [00:02<00:01, 77.30it/s]\u001b[A\n",
      " 64%|██████▎   | 202/318 [00:02<00:01, 77.72it/s]\u001b[A\n",
      " 66%|██████▌   | 210/318 [00:02<00:01, 76.35it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:02<00:01, 71.81it/s]\u001b[A\n",
      " 71%|███████   | 226/318 [00:03<00:01, 68.67it/s]\u001b[A\n",
      " 74%|███████▎  | 234/318 [00:03<00:01, 70.25it/s]\u001b[A\n",
      " 76%|███████▌  | 242/318 [00:03<00:01, 71.65it/s]\u001b[A\n",
      " 79%|███████▊  | 250/318 [00:03<00:01, 66.32it/s]\u001b[A\n",
      " 81%|████████  | 258/318 [00:03<00:00, 69.68it/s]\u001b[A\n",
      " 84%|████████▎ | 266/318 [00:03<00:00, 71.78it/s]\u001b[A\n",
      " 86%|████████▌ | 274/318 [00:03<00:00, 70.97it/s]\u001b[A\n",
      " 89%|████████▊ | 282/318 [00:03<00:00, 72.92it/s]\u001b[A\n",
      " 91%|█████████ | 290/318 [00:03<00:00, 74.57it/s]\u001b[A\n",
      " 94%|█████████▎| 298/318 [00:04<00:00, 74.74it/s]\u001b[A\n",
      " 97%|█████████▋| 307/318 [00:04<00:00, 76.80it/s]\u001b[A\n",
      " 99%|█████████▉| 316/318 [00:04<00:00, 77.97it/s]\u001b[A\n",
      "                                                   \n",
      " 54%|█████▍    | 3614/6672 [07:48<03:51, 13.19it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3614\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3614/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5806882977485657, 'eval_f1': 0.7468274576006015, 'eval_recall': 0.6958055772862686, 'eval_precision': 0.8524951633094344, 'eval_runtime': 4.422, 'eval_samples_per_second': 287.203, 'eval_steps_per_second': 71.914, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3614/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3614/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3614/special_tokens_map.json\n",
      " 58%|█████▊    | 3892/6672 [08:17<03:32, 13.06it/s]  The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1270\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|          | 0/318 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 9/318 [00:00<00:03, 81.17it/s]\u001b[A\n",
      "  6%|▌         | 18/318 [00:00<00:03, 75.53it/s]\u001b[A\n",
      "  8%|▊         | 26/318 [00:00<00:04, 66.22it/s]\u001b[A\n",
      " 11%|█         | 34/318 [00:00<00:04, 69.91it/s]\u001b[A\n",
      " 13%|█▎        | 42/318 [00:00<00:03, 72.62it/s]\u001b[A\n",
      " 16%|█▌        | 50/318 [00:00<00:03, 72.38it/s]\u001b[A\n",
      " 18%|█▊        | 58/318 [00:00<00:03, 72.52it/s]\u001b[A\n",
      " 21%|██        | 66/318 [00:00<00:03, 73.47it/s]\u001b[A\n",
      " 23%|██▎       | 74/318 [00:01<00:03, 72.32it/s]\u001b[A\n",
      " 26%|██▌       | 82/318 [00:01<00:03, 73.91it/s]\u001b[A\n",
      " 28%|██▊       | 90/318 [00:01<00:03, 75.01it/s]\u001b[A\n",
      " 31%|███       | 98/318 [00:01<00:02, 75.44it/s]\u001b[A\n",
      " 33%|███▎      | 106/318 [00:01<00:02, 75.44it/s]\u001b[A\n",
      " 36%|███▌      | 114/318 [00:01<00:02, 76.12it/s]\u001b[A\n",
      " 39%|███▊      | 123/318 [00:01<00:02, 77.49it/s]\u001b[A\n",
      " 41%|████      | 131/318 [00:01<00:02, 74.43it/s]\u001b[A\n",
      " 44%|████▎     | 139/318 [00:01<00:02, 71.57it/s]\u001b[A\n",
      " 46%|████▌     | 147/318 [00:02<00:02, 60.95it/s]\u001b[A\n",
      " 48%|████▊     | 154/318 [00:02<00:02, 58.28it/s]\u001b[A\n",
      " 51%|█████     | 161/318 [00:02<00:02, 59.02it/s]\u001b[A\n",
      " 53%|█████▎    | 169/318 [00:02<00:02, 63.85it/s]\u001b[A\n",
      " 56%|█████▌    | 177/318 [00:02<00:02, 66.77it/s]\u001b[A\n",
      " 58%|█████▊    | 185/318 [00:02<00:02, 65.33it/s]\u001b[A\n",
      " 61%|██████    | 193/318 [00:02<00:01, 67.92it/s]\u001b[A\n",
      " 63%|██████▎   | 201/318 [00:02<00:01, 70.48it/s]\u001b[A\n",
      " 66%|██████▌   | 209/318 [00:02<00:01, 72.15it/s]\u001b[A\n",
      " 69%|██████▊   | 218/318 [00:03<00:01, 74.79it/s]\u001b[A\n",
      " 71%|███████▏  | 227/318 [00:03<00:01, 77.38it/s]\u001b[A\n",
      " 74%|███████▍  | 236/318 [00:03<00:01, 75.57it/s]\u001b[A\n",
      " 77%|███████▋  | 244/318 [00:03<00:00, 74.99it/s]\u001b[A\n",
      " 79%|███████▉  | 252/318 [00:03<00:00, 75.13it/s]\u001b[A\n",
      " 82%|████████▏ | 260/318 [00:03<00:00, 73.74it/s]\u001b[A\n",
      " 85%|████████▍ | 269/318 [00:03<00:00, 76.49it/s]\u001b[A\n",
      " 87%|████████▋ | 278/318 [00:03<00:00, 78.57it/s]\u001b[A\n",
      " 90%|████████▉ | 286/318 [00:04<00:00, 68.10it/s]\u001b[A\n",
      " 92%|█████████▏| 294/318 [00:04<00:00, 63.96it/s]\u001b[A\n",
      " 95%|█████████▍| 302/318 [00:04<00:00, 67.79it/s]\u001b[A\n",
      " 97%|█████████▋| 310/318 [00:04<00:00, 69.58it/s]\u001b[A\n",
      "100%|██████████| 318/318 [00:04<00:00, 71.82it/s]\u001b[A\n",
      "                                                   \n",
      " 58%|█████▊    | 3892/6672 [08:21<03:32, 13.06it/s]A\n",
      "                                                 \u001b[ASaving model checkpoint to ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3892\n",
      "Configuration saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3892/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5073124170303345, 'eval_f1': 0.7742039298823646, 'eval_recall': 0.741526997447629, 'eval_precision': 0.821060924369748, 'eval_runtime': 4.578, 'eval_samples_per_second': 277.416, 'eval_steps_per_second': 69.463, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3892/pytorch_model.bin\n",
      "tokenizer config file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3892/tokenizer_config.json\n",
      "Special tokens file saved in ./Checkpoints/MarBertv2_taskB_hyperparams/run-11/checkpoint-3892/special_tokens_map.json\n",
      " 59%|█████▉    | 3942/6672 [08:29<03:19, 13.66it/s]  "
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=30, direction=\"maximize\",  hp_space=my_hp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80088e-00be-4846-b713-789d84bc4bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT-Jupyter",
   "language": "python",
   "name": "mt-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
